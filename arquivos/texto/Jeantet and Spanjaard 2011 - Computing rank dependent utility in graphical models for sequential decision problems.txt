Artiﬁcial Intelligence 175 2011 13661389 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Computing rank dependent utility graphical models sequential decision problems Gildas Jeantet Olivier Spanjaard Laboratoire dInformatique Paris 6 LIP6CNRS Université Pierre et Marie Curie UPMC 4 Place Jussieu F75252 Paris Cedex 05 France r t c l e n f o b s t r c t Article history Received 2 March 2009 Received revised form 31 August 2010 Accepted 31 August 2010 Available online 2 December 2010 Keywords Algorithmic decision theory Rank dependent utility Decision trees Inﬂuence diagrams Planning uncertainty This paper devoted automated sequential decision AI More precisely focus Rank Dependent Utility RDU model This model able encompass rational decision behaviors Expected Utility model accommodate However nonlinearity RDU makes diﬃcult compute RDUoptimal strategy sequential decision problems This considerably slowed use RDU operational contexts In paper interested providing new algorithmic solutions compute RDUoptimal strategy graphical models Speciﬁcally present algorithms solving decision tree models inﬂuence diagram models sequential decision problems For decision tree models propose mixed integer programming formulation valid subclass RDU models corresponding risk seeking behaviors This formulation reduces linear program mixed strategies considered In general case particular assumption parameters RDU propose branch bound procedure compute RDUoptimal strategy pure ones After highlighting diﬃculties induced use RDU inﬂuence diagram models procedure extended optimize RDU inﬂuence diagram Finally provide empirical evaluations presented algorithms 2010 Elsevier BV All rights reserved 1 Introduction In AI problems agents act uncertainty robot control relief organization medical diagnosis games When consequences action depend events probabilities known decision theory risk provides useful tools automate decisions The purpose theory design decision criteria evaluate probability distributions outcomes called lotteries according preferences decision maker A popular criterion expected utility EU model proposed von Neumann Morgenstern 49 In model agent endowed utility function u assigns numerical value outcome The evaluation lottery L p1 x1 pn xn lottery yields outcome xi probability pi performed computation cid2 utility expectation EUL n i1 pi uxi However despite intuitive appeal EU model possible account rational decision behaviors An example impossibility socalled Allais paradox 2 Table 1 We present simple version paradox Kahneman Tversky 23 Table 2 Example 1 Kahneman Tverkys example Consider choice situation options presented decision cid3 maker He chooses lottery L1 lottery L 2 second cid3 1 ﬁrst problem lottery L2 lottery L This paper extends preliminary results authors 20 Corresponding author Email address olivierspanjaardlip6fr O Spanjaard 00043702 matter 2010 Elsevier BV All rights reserved doi101016jartint201011019 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 1367 Table 1 Original Allais paradox Columns represent probabilities 100M stands 100 millions Most people prefers si cid3 multaneously L1 L 2 L2 cid3 1 L Lottery 001 L1 cid3 L 1 L2 cid3 L 2 100M 0M 100M 0M 01 100M 500M 100M 500M 089 100M 100M 0M 0M Table 2 Kahneman Tverskys version Columns represent cid3 outcomes Most people prefers simultaneously L1 L 1 L cid3 2 L2 Lottery L1 cid3 L 1 L2 cid3 L 2 0 000 010 090 091 3000 4000 100 000 010 000 000 090 000 009 cid3 1 second problem prefers L cid3 problem Table 2 In ﬁrst problem prefers L1 L 1 certain earn 3000 L1 earn cid3 L 2 probability earning 3000 L2 The EU model simultaneously account preferences cid3 1 implies u3000 01u0 09u4000 This equivalent 01u3000 001u0 Indeed preference L1 L 009u4000 09u0 01u3000 091u0 009u4000 adding 09u0 sides Hence cid3 1 implies preference L2 L utility function preference L1 L cid3 2 L2 probability earning 4000 L cid3 2 EU model Actually Allais points preference reversal far paradoxical consequence reasonable behavior preference security neighborhood certainty 3 In words bird hand worth cid3 bush preference L1 L 1 It known certainty effect The preference reversal explained follows probability winning low sensitivity value earnings increases sensitivity probabilities decreases To encompass certainty effect decision criterion handling probabilities linear Given situation new models developed models grounded alternative representation uncertainty theory possibility 12 try sophisticate deﬁnition expected utility prospect theory 23 cumulative prospect theory 48 rank dependent utility RDU model introduced Quiggin 40 This model popular generalization EU In model nonlinear probability weighting function ϕ incorporated expectation calculus gives greater expressive power In particular RDU model compatible versions Allais paradox Furthermore probability weighting function ϕ useful model attitude agent risk Indeed unlike EU model RDU model makes possible distinguish weak risk aversion option yields guaranteed utility preferred risky option expected utility strong risk aversion lotteries expected utility agent prefers lottery minimum spread possible outcomes For reason RDU criterion search problems risk state space graphs aim ﬁnding optimal paths riskaverse agents 38 Note AI community rank dependent utility function best known Weighted Ordered Weighted Averaging operator 4546 In particular WOWA operator studied ﬁelds AI aggregation function required synthesis information 45 decision making risk 3436 metadata aggregation problems 10 interactive techniques multicriteria optimization 35 The algorithmic issues related use RDU sequential decision problems prevented adoption setting today In sequential decision problem risk simple decision follows strategy sequence decisions conditioned events resulting nondeterministic outcome This type problem particular encountered decisiontheoretic planning 67 This term refers planners involving decisiontheoretic tools Formally aim decisiontheoretic planner ﬁnd plan optimizing given decision criterion For purpose lottery induced plan evaluated according decision criterion usually EU Several representation formalisms sequential decision problems decision trees 41 inﬂuence diagrams 44 Markov decision processes 1122 A decision tree explicit representation sequential decision problem inﬂuence diagrams Markov decision processes compact representations possible deal decision problems greater size It important note formalisms set potential strategies combinatorial size increases exponentially size instance The computation optimal strategy given representation given decision criterion algorithmic issue Contrary computation strategy maximizing EU directly resort dynamic programming computing strategy maximizing RDU nonlinearity Evaluating decision tree inﬂuence diagram according RDU computing optimal strategy according RDU raises challenging algorithmic problem This precisely issue tackle paper The paper organized follows In Section 2 recall main features RDU In Section 3 place work stream research aiming incorporating risksensitivity probabilistic planning problems Then Section 4 detailing RDU criterion sequential decision problem propose approaches optimizing RDU decision tree provide numerical tests approaches In Section 5 investigate optimization RDU inﬂuence diagram After recalling inﬂuence diagram formalism highlight diﬃculty present decision tree formalism strategies considered inﬂuence diagram We propose approach overcome diﬃculty provide numerical tests 1368 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 2 Rank dependent utility Given ﬁnite set S x1 xn outcomes strategy sequential decision problem seen lottery characterized probability distribution P S In paper explicitely mentioned assume comes real numbers ordered follows x1 xn We denote L p1 x1 pn xn lottery yields outcome xi probability pi P xi The decumulative function G L given G Lα ixi cid2α pi denoted G Lx1 x1 G Lxn xn For sake clarity consider lottery L function S 0 1 Lxi pi As indicated decision problems lotteries compared according decision criterion instance EU cid2 cid3 1 cid3 x i0 cid3 p1 x 1 cid3 2 obtained lotteries L1 L i0 arbitrary index 1 n L1 preferred L cid3 1 89 percent chance win L2 L Rank Dependent Utility RDU introduced Quiggin 40 popular generalizations EU makes possible sophisticated rational decision behaviors From axiomatic viewpoint RDU model grounded weakening sure thing principle 43 It known sure thing principle holds EU criterion In framework decision risk principle stated follows let cid3 lotteries L1 p1 x1 pn xn L pn x n outcomes necessarily ranked cid3 increasing order xi0 1 implies L2 preferred cid3 cid3 L 1 merely replacing common outcome xi0 common 2 lotteries L2 L outcome yi0 In Allais paradox Table 1 sure thing principle clearly violated There 89 percent chance cid3 win 100 millions L1 L 2 ceteris paribus In order encompass examples validity axiom restricted cases common outcome ranked cid3 similarly lotteries replacement affect ranking lotteries L1 preferred L 1 implies L2 preferred L 0 common outcome xi0 cid3 common outcome yi0 ith 2 This weaker version axiom called comonotonic sure thing principle 9 It allows preference reversals cases extreme change level risk For instance Allais paradox extreme change level risk ﬁrst comparison probability earn 1 percent second comparison 90 percent Comonotonic sure thing principle continuity axiom axiom compatibility stochastic dominance characterize RDU model A lottery L cid3 cid3 k α R G Lα cid2 G Lcid3 α In p1 x1 pk xk said stochastically dominate lottery L k x words α R probability outcome α lottery L high probability soon L stochastically lottery L dominates L Compatibility stochastic dominance means lottery L preferred lottery L This property obviously desirable guarantee rational behavior cid3 2 obtained lotteries L1 L cid3 1 merely replacing ith cid3 2 lotteries L2 L 0 rank L2 L p cid3 p cid3 cid3 1 x 1 cid3 cid3 cid3 In order allow preference reversals cases extreme change level risk handling probabilities RDU model nonlinear In purpose ﬁrst proposal come mind consists distorting individual cid2 n probabilities nonlinear function ϕ yields decision criterion form i1 ϕpiuxi u denotes increasing utility function Actually choice criterion proposed Handa 16 compatible stochastic dominance For reason distortion RDU model performed probabilities reverse cumulative probabilities The formula rank dependent expected utility easily obtained rewriting uxi expected utility respect reverse cumulative probabilities EUL uxi1G Lxi utility lottery L ux1 probability 1 utility increase ux1 ux2 probability G Lx2 applies ux2 ux3 probability G Lx3 The rank dependent utility lottery L deﬁned follows i1 pi uxi ux1 cid2 n i2 cid2 n RDUL ux1 cid5 uxi uxi1 ϕ cid6 cid7 G Lxi ncid3 cid4 i2 Rank dependent utility involves increasing utility function consequences u S R EU trans cid3 formation function probabilities ϕ 0 1 0 1 It compatible stochastic dominance RDUL cid2 RDUL The transformation function ϕ nondecreasing function proper agent soon L stochastically dominates L ϕ0 0 ϕ1 1 When ϕp p p RDU obviously reduces EU cid3 Example 2 Coming Example 1 deﬁne utility function ux x set ϕ009 ϕ01 02 ϕ09 07 The preferences induced RDU compatible Kahneman Tverskys example Indeed RDUL1 u3000 3000 cid6 u0 ϕ09 RDU cid7 cid6 L cid3 1 cid7 u4000 u0 2800 Therefore L1 preferred L cid3 1 Similarly cid6 cid7 600 u3000 u0 RDUL2 u0 ϕ01 cid7 cid6 u0 ϕ009 800 u4000 u0 RDU cid7 cid6 L cid3 2 We conclude L cid3 2 preferred L2 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 1369 In order elicit function ϕ methods Several functional forms proposed func tion ϕ economic literature As indicated Quiggin 40 simplest functions form ϕp pγ γ 0 1 Actually trying exactly reproduce behavior human agents empirical evidence function ϕ general inverse Sshaped ﬁrst concave convex 488 This means probabilities best consequences overweighted potential effect probabilities worst consequences underweighted certainty effect The functional form proposed Karmarkar 24 purpose pγ pγ 1 pγ γ 0 1 After setting functional form ϕ estimates right value parameter γ standard nonlinear regression methods maximum likehood squares For detailed discussion different possible functional forms ϕ interested reader refer book Quiggin 40 Note exist parametricfree elicitation methods works assuming prespeciﬁed shape function ϕ 11347 3 Position paper By studying use RDU computational viewpoint place work stream research aiming incorporating risk sensitivity probabilistic planning problems The nonlinearity risksensitive criteria raises new algorithmic diﬃculties A pioneering work topic carried Howard Matheson framework Markov decision processes 17 They risk sensitivity treated evaluating plan expected utility instead expectation In case riskaverse agents practicality approach relies use exponential utility function u maximize deﬁned ux γ x outcome x R γ 0 1 The adoption utility function involves agreement decision maker cid5property attitude risk depend wealth level Koenig Simmons performed similar work slightly different representation probabilistic planning problems required design new algorithms 25 The representation use called probabilistic decision graph resembles decision trees study Then framework MDPs Liu Koenig proposed resort oneswitch utility function order account wealth level preferences For riskaverse agent riskneutral limit level wealth increases oneswitch utility function u form ux x Dγ x D 0 γ 0 1 After exhibiting conditions guaranteeing optimal expected utilities total planexecution reward exist ﬁnite fully observable MDP models risksensitive utility functions 26 authors proposed functional value iteration algorithm approximate optimal expected utilities oneswitch utility functions 27 Finally proposed policy iteration algorithm subsequent paper enables return optimal policy 28 cid2 n All results real advances account accurately risk sensitivity probabilistic planning problems especially highstakes situations However induced preferences reproduce biases EU theory To explain details need previously introduce notions weak riskaversion strong riskaversion An agent said weakly riskaverse lottery L considers sure lottery 1 EL good L i1 pi xi L p1 x1 pn xn 439 In EU theory riskaversion means agents utility function u EL cid3x 4 Strong outcomes increasing concave coeﬃcient riskaversion agent measured u riskaversion deﬁned notion mean preserving spread 42 Basically agent said strongly riskaverse lotteries expectation prefers spread Interestingly shown cid3 increasing concave utility lottery L mean preserving spread lottery L cid2 functions u EUL n i1 pi uxi 40 Consequently EU compare lotteries weakly riskaverse agent strongly riskaverse A nice virtue RDU model precisely enables distinction weak strong riskaversion contrary EU Within model concave utility function u agent weakly riskaverse iff ϕp cid3 p p 0 1 strongly riskaverse iff ϕ convex directly follows result Quiggin 40 As stated rank dependent utility powerful tool modeling risksensitive agents illustrated Allais paradox This motivates study EUL cid3 EUL cid3cid3xu cid3 4 Computing RDU decision tree 41 Decision tree formalism A decision tree arborescence types nodes decision nodes represented squares chance nodes represented circles terminal nodes leaves arborescence The branches starting cision node correspond different possible decisions ones starting chance node correspond different possible events probabilities known The values indicated leaves correspond utilities consequences Note omits orientation edges representing decision trees For sake illustration decision tree representation sequential decision problem strategies given Fig 1 More formally decision tree T N E set N nodes ND N A NU ND set decision nodes N A set chance nodes NU set terminal nodes The root node denoted Nr N NU The valuations deﬁned follows edge E A N E A N A weighted probability pE corresponding event terminal node NU NU labeled utility uNU Besides pastN past 1370 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 Fig 1 A decision tree representation Fig 2 A compound lotery N N set edges path Nr N T Finally denote SN set successors N T T N subtree T rooted N Following Jaffray Nielsen 19 deﬁnes strategy set edges cid5 N N cid3 N N cid5 D N cid3 N cid5 E N cid5 N set nodes including root Nr T successor decision node N N cid5 D successors chance node N N cid5 A N A N cid5 ND N cid5 Given decision node N restriction strategy T subtree T N deﬁnes strategy T N called substrategy In order evaluate strategy important note strategy associated compound lottery utilities For instance decision tree Fig 1 strategy D1 A1 D2 A3 corresponds compound lottery depicted Fig 2 Evaluating strategy amounts evaluating compound lottery From ease presentation manipulate lotteries directly deﬁned utilities outcomes A lottery function U 0 1 Lxi ui U u1 u1 u2 image set S respect u Coming example natural assume compound lottery Fig 2 equivalent lottery L 05 2 025 3 025 10 actually assumption known reduction compound lotteries axiom 29 axiomatizations EU RDU Given value function V maps lottery real number V EU V R DU evaluation strategy V L For example V EU evaluation strategy D1 A1 D2 A3 05 2 025 3 025 10 425 42 Computing RDU decision tree decision theory combinatorial optimization In decision tree T number potential strategies grow exponentially size decision tree For example binary decision tree n nodes strict alternation decisionchance nodes easily n For reason necessary develop optimization algorithm determine number strategies Θ2 optimal strategy decision tree It known rolling method makes possible compute linear time optimal strategy wrt EU Indeed strategy satisﬁes optimality principle substrategy optimal strategy optimal The optimality principle closely related condition monotonicity 32 value function In context given value function V V EU condition stated follows cid7 cid3 cid6 L cid6 V αL 1 αL cid7 cid3cid3 cid6 cid2 V αL cid3 1 αL cid3cid3 cid7 V L cid2 V cid3 L cid3cid3 cid3cid3x lotteries α scalar 0 1 αL 1 αL L L cid3cid3x In framework decision theory condition seen weak version independence αLx 1 αL axiom von Neumann Morgenstern 49 characterize EU criterion This axiom states mixture lotteries L L αL 1 αL The monotonicity condition holds V EU justiﬁes optimality principle holds EU reverse preferences induced V L strictly preferred L lottery deﬁned αL 1 αL strictly preferred αL cid3 1 αL cid3cid3 cid3cid3 cid3cid3 cid3 cid3 Hence starting leaves compute recursively node expected utility optimal substrategy optimal expected utility chance node equals expectation optimal utilities successors optimal expected utility decision node equals maximum expected utility successors Example 3 In Fig 1 optimal expected utility node D2 max65 6 65 Consequently optimal expected utility node A1 425 The expected utility node A2 03 1 045 2 025 11 395 The optimal expected utility G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 1371 root node D1 max425 395 425 correspond strategy D1 A1 D2 A3 Note strategy suboptimal RDU evaluate lotteries In decision theory behavior agent adopts recursively computed strategy called consequentialist More precisely consequentialism means preferences substrategies subtree depend rest decision tree Besides agent said dynamically consistent decision node willing carry plan action determined optimal exante It proved preferences agent consequentialist dynamically consistent follow EU model 1415 An agent preferences follow RDU model named RDUmaximizer renounce consequentialism dynamic consistency Assume ﬁrst agent adopts consequentialist behavior computes recursively strategy leaves selecting optimal substrategies RDU follows strategy As shown Example 4 strategy determined exante suboptimal monotonicity condition hold V RDU noticed Nielsen Jensen 33 By committing consequentialism agent renounces dynamic consistency follow strategy optimal exante cid3 05 1 05 11 corre cid3cid3 1 2 Assume decision maker preferences follow RDU model 0 Example 4 Consider lotteries L 05 3 05 10 corresponding chance node A3 Fig 1 L sponding chance node A4 Fig 1 L following ϕ function p 0 0 p cid3 025 025 p cid3 05 05 p cid3 07 07 p cid3 075 p 075 ϕp 075 045 06 08 1 The RDU values lotteries L L cid3 RDUL 3 10 3ϕ05 72 1 11 1ϕ05 7 RDU cid6 cid7 L cid3 Thus RDUL cid2 RDUL monotonicity condition α 05 RDU05L 05L cid3 substrategy D2 A3 preferred substrategy D2 A4 D2 Fig 1 By cid3cid3 However cid3cid3 cid2 RDU05L cid3 05L cid6 cid7 cid3cid3 cid6 RDU RDU 05L 05L cid3 05L 2 3 1ϕ05 10 3ϕ025 575 cid7 1 2 1ϕ075 11 2ϕ025 665 cid3cid3 RDU05L Therefore RDU05L 05L Fig 1 Consequently monotonicity property hold cid3 05L 05L cid3cid3 cid3cid3 strategy D1 A1 D2 A4 preferred strategy D1 A1 D2 A3 More seriously consequentialist RDUmaximizer follow stochastically dominated strategy shown following example Example 5 Consider decision tree Fig 1 In decision tree RDU values different strategies root RDU RDU cid6cid12 cid6cid12 cid6cid12 cid13cid7 D1 A2 58 cid13cid7 D1 A1 D2 A3 cid13cid7 RDU D1 A1 D2 A4 575 665 Thus optimal strategy root D1 A1 D2 A4 However recursion gets node D2 RDUD2 A3 72 RDUD2 A4 7 This substrategy D2 A3 obtained node D2 Example 4 At node D1 strategy D1 A2 58 vs 575 D1 A1 D2 A3 stochastically dominated D1 A1 D2 A4 ﬁnally obtained At ﬁrst sight example misinterpreted illustrating weakness RDU model sequential decision situations Actually primarily shows RDU model inappropriate consequentialist agents Conversely EU model unable reproduce nonconsequentialist behaviors This type behaviors routinely displayed rational agents An intuitive example nonconsequentialist behavior proposed Machina 30 1372 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 Assume Mom single treat daughter Abigail son Benjamin She indifferent Abigail getting treat Benjamin getting treat strictly prefers coin ﬂip sure outcomes Assume Abigail wins coin ﬂip We different state coin ﬂip Mom prefers Abigail getting treat new ﬂip History case matters far preferences Benjamin chance fact Benjamin won matters coin ﬂipped This justiﬁcation non consequentialism More generally nonconsequentialist agent gives importance events occurred contrary consequentialist agent risk account borne In paper consider dynamically consistent agent sets plan initially deviates later 31 nonconsequentialist behavior optimal strategy root include substrategies appear suboptimal subtrees In words study sequel compute RDUoptimal plan viewed initial situation comply By sure encounter stochastically dominated substrategy contrary method consist performing backward induction RDU Unfortunately determination RDUoptimal strategy decision tree NPhard problem size instance number involved decision nodes Proposition 1 Jeantet Spanjaard 2008 20 The determination RDUoptimal strategy problem RDUOPT decision tree NPhard problem Proof This proved polynomial reduction 3SAT Appendix A cid2 Note Jaffray Nielsen studied use RDU decision trees 19 Nevertheless approach differs focus RDU agents close consequentialist Consequently compute optimal strategy viewed initial situation 43 Two approaches computing RDU We propose approaches determining RDUoptimal strategy decision tree One approach uses mixed integer linear programming formulation proceeds implicit enumeration exhaustive enumeration backward induction conceivable RDUOPT NPhard 431 A Mixed Integer Linear Programming formulation We present Mixed Integer Linear Programming MIP formulation problem RDUOPT case function ϕ concave piecewise linear Consider decision tree T We ﬁrst set constraints deﬁning feasible strategies For purpose boolean variable yi j created MIP formulation decision branch D A j The ND constraints deﬁning set feasible strategies cid3 y1 j 1 j cid3 j yi j yprevD cid12 cid13 2 ND yi j 1 resp yi j 0 D A j selected resp selected prevD decision branch preceding D path root temporal order Example 6 For decision tree represented Fig 3 constraints deﬁning set feasible strategies y11 y12 1 y23 y24 y11 y35 y36 y11 y47 y48 y12 y59 y510 y12 We modeling objective function The set utilities leaves T denoted U u1 u2 u1 cid3 u2 cid3 cid3 probability obtain utility uh denoted ph Probability ph product probabilities path root utility uh The rank dependent utility written follows ncid3 uh uh1ϕ u1 h2 cid15 p j yprevu j cid14cid3 jcid2h G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 1373 Fig 3 A decision tree corresponding variables parameters MIP formulation yprevu j decision branch preceding u j path root By introducing n 1 variables ϕh rewritten follows ncid3 u1 uh uh1ϕh h2 ϕh ϕ cid2 jcid2h p j yprevu j h 2 n Example 7 For decision tree represented Fig 3 objective function written 1 4 1ϕ2 31 25ϕ13 31 31ϕ14 31 31ϕ15 40 31ϕ16 1 3ϕ2 2ϕ3 ϕ4 3ϕ5 5ϕ6 3ϕ7 2ϕ8 ϕ9 ϕ10 2ϕ11 2ϕ12 6ϕ13 9ϕ16 Note variables ϕ14 ϕ15 appear ﬁnal objective function eliminated program The expression deﬁning value ϕh course nonlinear presence function ϕ This diﬃculty overcome case ϕ concave piecewise linear Recall concave function ϕ reﬂects riskseeking behavior certain forms utility function convexBy concave piecewise linear function ϕ approximate concave regular function This family functions interesting study It known concave piecewise linear function written lower envelope set aﬃne functions Let f 1 f 2 fm denote set fkp ak p bk We ϕp min f 1p f 2p fmp The value ϕh obtained optimization ϕh max α α cid14cid3 α cid3 fk α cid2 0 jcid2h cid15 p j yprevu j k 1 m The problem linear program given strategy y Example 8 Assume ϕp 18p p cid3 05 ϕp 04p 06 p 05 We ϕp min f 1p f 2p f 1p 18p f 2p 04p 06 For given assignment boolean values variables yi j decision tree represented Fig 3 value ϕ13 written result following linear program α α ϕ13 max α cid3 18030 y23 028 y35 036 y59 009 y510 α cid3 04030 y23 028 y35 036 y59 009 y510 06 α cid2 0 1374 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 Fig 4 Onetoone correspondence assignments probabilities P D A j D pi j Since uh uh1 cid2 0 objective function maximize beneﬁt maximizing ϕh MIP formulation following concave piecewise case ncid3 h2 uh uh1ϕi cid15 u1 max ϕ cid14cid3 ϕh cid3 fk p j yprevu j jcid2h cid3 j cid3 j y1 j 1 yi j yprevD cid12 cid13 2 ND yi j 0 1 ϕh cid2 0 h 2 n k 1 m This program includes n 1 continuous variables ND binary variables n 1m ND constraints m straints created variable ϕh Its size linear size T ﬁxed number m pieces ϕ We recall complexity solution procedure course exponential number binary variables worst case ﬁxed number m pieces ϕ Let brieﬂy study relaxation problem considers pure strategies mixed strate gies In mixed strategy chooses randomly according predeﬁned probability distribution decision taken decision node When expected utility evaluate strategy worth considering mixed strategies exists pure strategy yielding expected utility best mixed strategy This longer case rank dependent utility evaluate strategy Consider decision tree single decision node leading different options sure outcome lottery 1 5 lottery 05 1 05 10 Assume probability transfor mation function deﬁned ϕ0 0 ϕp 045 p 0 07 ϕp 1 p 07 The RDU values pure strategies respectively 5 505 Comparatively mixed strategy chooses sure outcome lot tery probability 06 probability 04 results RDU value 725 We optimal mixed strategy polynomially computed previous cases concave piecewise linear ϕ piecewise constant ϕ slighting modifying MIP formulations boolean variables appear anymore number constraints remains It yields course linear programming formulation In mixed strategy proba bility obtaining utility uh equals product probabilities chance decision branches path root uh For reason real variable pi j created MIP formulation decision branch D A j instead boolean variable However obtain linear constraints variable represent probability P D A jD probability decision D A j conditionally reach node D product probabili ties decision branches root node A j There onetoone correspondence assignments probabilities P D A jD pi j P D A jD equals pi jpprevD This illustrated Fig 4 The proba bility obtaining utility uh ph pprevu h path uh ph product probabilities chance branches pprevu h product probabilities decision branches The objective function written G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 1375 ncid3 uh uh1ϕ u1 h2 cid15 p j pprevu j cid14cid3 jcid2h cid2 Let study constraints satisfy variables pi j By deﬁnition A jD Then j P D A jD pprevD Consequently constraints variables pi j similar previous constraints variables yi j j pprevD P D A jD pprevD cid2 cid2 cid2 j pi j cid2 j pprevD P D j pi j pprevD The cid3 p1 j 1 j cid3 j pi j pprevD cid12 cid13 2 ND pi j 0 1 All constraints identical ones pure strategies yi j replaced pi j This proves polynomial solvability determination RDUoptimal mixed strategy case function ϕ concave piecewise linear size linear program linear size decision tree 432 Implicit enumeration algorithm We present branch bound method determining RDUoptimal pure strategy Unlike previous approach method advantage remaining valid probability transformation function ϕ The branching cid3 decision principle partition set strategies subsets according choice given edge N N node N More formally nodes enumeration tree characterized partial strategy deﬁnes subset strategies Consider decision tree T set nodes N Γ including root Nr T successor decision node N N Γ D ND N Γ cid3 N N Γ cid3 N Γ E deﬁnes partial strategy T subgraph induced N Γ The set edges Γ N N tree A strategy cid5 said compatible partial strategy Γ Γ cid5 The subset strategies characterized partial strategy corresponds set compatible strategies At iteration search chooses edge ones starting given decision node The order decision nodes considered given priority function rk ND 1 2 ND decision nodes candidates enter N Γ lowest priority rank considered ﬁrst The ranking function rk deﬁned D N rkNr 1 cid16 cid16 cid16pastN cid16 cid16 cid16 cid16pastN cid16 cid6 cid6 cid16 cid16past cid16 cid16past N N cid7cid16 cid16 rkN rk cid7cid16 cid7 cid16 EU T N cid6 cid3 cid3 cid7 cid3 cid6 N EU cid7cid7 cid6 cid6 T cid3 N rkN rkN cid3 EUT N optimal value EU T N recall T N subtree rooted N Example 9 For decision tree Fig 3 unique ranking function rk deﬁned rkD1 1 rkD2 5 rkD3 3 rkD4 4 rkD5 2 EUT D5 EUT D3 EUT D4 EUT D2 Algorithm 1 describes formally implicit enumeration procedure propose Algorithm 1 BBΓ RDUopt N1 N1 ND N1 candidate Nmin arg minNN1 rkN Emin Nmin A E A SNmin N A Emin evΓ N A RDUopt RDUtemp BBΓ N A RDUopt If RDUtemp RDUopt RDUopt RDUtemp end end end return RDUopt It takes argument partial strategy Γ best RDU value far denoted RDUopt The search depth ﬁrst The decision nodes candidates enter N Γ denoted N1 Among node lowest 1376 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 priority rank denoted Nmin The set incident edges denoted Emin It deﬁnes set possible extensions Γ considered search words children node associated Γ enumeration tree For partial strategy Γ words node enumeration tree evaluation function ev gives upper bound RDU value strategy compatible Γ The optimality returned value RDUopt guaranteed suboptimal strategies pruned search soon ev upper bound We main features algorithm Initialization A branch bound procedure notoriously eﬃcient good solution known starting search In method lower bound RDUopt initially set RDU value EUoptimal strategy Computing lower bound At node search computes EUoptimal strategy strategies compatible Γ When RDU value greater best far update RDUopt This makes possible prune search quickly Computing upper bound The evaluation function denoted ev It returns upper bound RDU value strategy compatible Γ The principle evaluation determine lottery stochastically dominates lottery corresponding strategy compatible Γ evaluate ideal lottery according RDU This yields RDUL cid2 upper bound RDU compatible stochastic dominance L stochastically dominates L cid3 In order compute lottery proceeds dynamic programming decision tree Actually RDUL indifferently manipulate decumulative functions lotteries sets bijection recall lottery utilities considered function U 0 1 paper For sake clarity recursion referring decumulative functions The initialization performed follows terminal node T NU assigned decumulative function G L T 1 uT Next node N N computes decumulative function lottery stochastically dominates lotteries subtree T N More precisely chance node A computes decumulative function G L A induced decumulative functions children follows cid3 u G L A u cid3 cid6 cid7 A N p G L N u NS A G L N corresponds decumulative function assigned node N N Besides decision node D apply following recurrence relation decumulative functions cid17 u G L D u G L N u u G L D u maxNSD G L N u N SD D N Γ Finally value returned ev RDUL Nr L Nr corresponds lottery decumulative function G L Nr The complexity recursive procedure Γ O N U U number distinct utilities leaves node N examined support set lottery upper bounded U However branch bound procedure edge D N j inserted Γ necessary recompute G L N node N One use functions G L N computed evaluating evΓ suﬃcient update functions G L N nodes N belong path Nr D Since length path T upper bounded height h complexity computing evΓ Γ cid16 O hU To prove validity recursive procedure proceeds induction At chance node A consider tuple L N NS A lotteries L N stochastically dominates L N N NS A p A NG L N u u NS A p A NL N denotes compound lottery This proves L A stochastically dominates lottery correspond S A We G L A u Gcid2 cid2 NS A p A NG L N u cid2 NS A p ANL N u cid2 cid2 ing strategy T A At decision node D exists N SD D N Γ validity obvious In case sider tuple L N NSD lotteries L N stochastically dominates L N N SD By deﬁnition G L D u maxNSD G L N u u Thus G L D u cid2 G L N u cid2 G L N u u lottery L N tuple This proves L D stochastically dominates lottery corresponding strategy T D Consequently lottery L Nr stochastically dominates lotteries corresponding strategy compatible Γ Example 10 Let come decision tree Fig 1 Assume Γ D1 A1 The decumulative functions 2 11 They represented left Fig 5 assigned nodes A3 A4 G L A3 The decumulative function G L D2 computed dynamic programming upper envelope G L A3 G L A4 More formally decumulative function computed D2 deﬁned x G L D2 x maxG L A3 x G L A4 x This decumulative function represented bold right Fig 5 Then G L D2 2 11 Similarly computes 2 10 G L A4 1 3 1 1 3 1 1 1 1 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 1377 Fig 5 Computation stochastically dominating lottery Table 3 Execution times concave piecewise linear function ϕ seconds Approach Height nodes MIP Implicit enumeration 4 11 1 1 6 127 8 511 1 1 1 1 10 2047 21 23 28 01 25 50 12 8191 794 860 1073 03 56 202 G L A1 u2 G L D1 05G L D2 05G Lu2 1 2 1 2 3 1 4 11 G Lu2 decumulative function associated node utility G L A1 1 2 1 2 3 1 4 11 Γ D1 A1 Decumulative function G L D1 corresponds lottery 1 evΓ RDU 1 4 11 2 2 1 4 3 1 2 2 1 4 3 1 4 11 The upper bound Γ D1 A1 44 Numerical tests Algorithms implemented C computational experiments carried PC Pentium IV CPU 213 GHz processor 35 GB RAM Tests random instances We ﬁrst compared performances MIP approach ones implicit enumeration approach Our tests performed complete binary decision trees height The height decision trees varies 4 12 alternation decision nodes chance nodes The utilities leaves real numbers randomly drawn interval 1 1000 conditional probabilities chance nodes randomly drawn positive real numbers summing 1 Since MIP approach requires concave piecewise linear function ϕ function ϕ deﬁned ϕp min f 1p f 5p f 1p 4p f 4p 4 p 085 Table 3 shows average execution CPU times obtained approaches The mixed 2 p 07 1 integer linear programs solved ILOG CPLEX v1110 solver Note solution times indicated Table 3 MIP approach account preprocessing time When informative min max values indicated following format min average max Both approaches instantly optimal strategy trees height 8 However height exceeds 12 implicit enumeration approach eﬃcient MIP approach f 2p 2p 02 f 3p p 05 f 5p 1 Next gone study implicit enumeration algorithm For purpose measured performances implicit enumeration approach function ϕ deﬁned ϕp pγ pγ 1 pγ This function concave piecewise linear This usually proposed model sophisticated behaviors EU model unable 24 Parameter γ takes value interval 0 1 For γ 1 ϕp p RDU reduces EU We tested algorithm values parameter γ γ 02 γ 05 γ 08 Table 4 presents performances algorithm respect parameter γ height decision tree When informative min max values indicated For value γ height average performance computed 50 decision trees Unsurprisingly performances improve γ near 1 RDU close EU Note bigger instances height greater 14 hard instances begin appear solution time high 1378 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 Table 4 Execution time γ 02 γ 05 γ 08 Depth nodes 5 11 01 01 01 7 127 9 511 01 01 01 01 01 01 11 2047 01 04 11 01 01 05 01 01 05 13 8191 03 43 138 01 27 74 01 16 80 15 32767 30 621 5129 12 173 994 06 109 1014 Table 5 Quality upper lower bound Bound Height nodes γ 02 RDU RDULEU RDULSDRDU γ 05 RDU RDULEU RDULSDRDU γ 08 RDU RDULEU RDULSDRDU 4 11 951 1044 996 1055 998 1064 6 127 9246 1051 993 1096 995 1063 8 511 900 1069 990 1094 994 1088 10 2047 12 8191 912 1124 988 1091 989 1078 909 1175 982 1102 986 1072 RDULSDRDU order evaluate quality lower bound upper bound investigated ratios Finally respect parameter γ height decision tree LEU RDULEURDU lottery corresponding optimal strategy EU LSD lottery computed evaluating upper bound RDU value optimal strategy RDU The results presented Table 5 value average 50 instances One observes RDULEU provides good lower bound naturally deteriorates γ close 0 probabilities distorted The upper bound appears 10 optimal value instances However complete binary trees considered actually worst cases encountered In fact applications decision trees balanced number decision nodes RDUoptimal strategy computed faster illustrated TV game example Application Who wants millionaire Who wants millionaire popular game contestant answer sequence multiplechoice questions possible answers increasing diﬃculty numbered 1 15 This double game answer given question k wrong contestant quits money However question k contestant decide stop instead answering quits game monetary value question k 1 Following Perea Puerto 37 study Spanish version game 2003 monetary values questions 150 300 450 900 1800 2100 2700 3600 4500 9000 18 000 36 000 72 000 144 000 300 000 Euros respectively Note actually 5th 10th questions money banked lost contestant gives incorrect response subsequent question example contestant gives wrong answer question 7 quits game 1800 Euros Finally contestant lifelines game Phone friend friend ask answer 5050 incorrect answers removed Ask audience audience votes percentage votes answer received shown We applied algorithm compute RDUoptimal strategy game For purpose ﬁrst model proposed 37 build decision tree representing game In model strategy completely characterized giving question numbers different lifelines question number contestant quits game We carried experimentations probability transformation functions modeling different attitudes risk The identity resp square square root function corresponds expected reward maximizer resp risk averse risk seeker decision maker The results reported Table 6 For function ϕ expected reward column Exp optimal strategy maximum possible reward column Max probability win 2700 Euros column G L27K Note cases response time procedure second 14 400 decision nodes height 30 This good behavior algorithm linked shape decision tree strongly impacts number potential strategies A limitation model introduced Perea Puerto 37 choice use lifeline dependent contestant knows answer For reason introduced following reﬁnement model contestant knows answers question k directly gives correct answer decision A small decision tree new modeling represented Fig 6 dotted lines represent omitted parts G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 1379 Table 6 Optimal strategies ϕ functions ϕp p p2 p 5050 Phone 9 4 14 10 5 15 Ask 12 5 13 Quit 13 8 X Exp 2387 1536 1987 Max 36K 27K 300K G L 27K 010 035 006 Fig 6 Reﬁned decision tree TV game 1s resp Q tree Chance nodes Q 2s represent question 1 resp 2 possible events know answer Decision nodes D 1s represent decision use available lifeline answer quit facing question 1 fact opportunity realistic question 2 Finally answer represented chance node Ai 1s probabilities events correct wrong answer depend lifelines We data provided Perea Puerto 37 evaluate different probabilities chance nodes The decision tree 75 millions nodes The problem harder number potential strategies explodes Unlike previous numerical tests use 64 GB RAM able store instance Despite high size instance procedure able return optimal strategy 2992 sec ϕp p2 risk averse behavior 4026 sec ϕp p23 risk seeker behavior Note risk seeker behaviors solution time increases concavity probability transformation function 5 Computing RDU inﬂuence diagram The previous approaches face main inconvenience decision trees size grows quickly number decision stages increases For reason study optimization RDU inﬂuences diagrams provide compact representations sequential decision problems 51 Inﬂuence diagram formalism An inﬂuence diagram 18 graphical model sequential decision problem Unlike decision trees emphasis decomposability underlying probability structure By taking advantage independences involved random variables utility variables gets compact representation obtained expliciting possible scenarios decision tree An inﬂuence diagram including random variables A1 A p decision variables D1 Dn acyclic digraph G N E 1380 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 Fig 7 Inﬂuence diagram corresponding decision tree set N partitioned subsets set ND D1 Dn decision variables represented squares set N A A1 A p random variables represented circles set NU U 1 Um utility nodes repre sented diamonds set E directed edges partitioned subsets set functional edges decision variable random variable random variable utility node edges representing dependences set informational edges decision variable random variable decision variable edges representing observed variables making decision nodes representing random variables endowed conditional probability table indicating probability event conditionally parent nodes utility nodes endowed table indicating utility conditionally parent nodes The following structural condition graph hold exists path including functional informational edges connecting nodes representing decision variables An inﬂuence diagram represented left Fig 7 conditional probability tables utility tables deliberately omitted sake brevity The possible decisions D1 resp D2 denoted α β resp γ δ The modalities random variable A1 resp A2 η1 η2 resp θ1 θ2 The order decisions observations assumed D1 A1 A2 D2 A3 U We adopt convention temporal order decisions read left right By unfolding diagram obtains decision tree represented right Fig 7 note probabilities utilities indicated tree comply conditionings imposed diagram Since A3 U independent A1 conditionally D1 subtrees identical Fig 7 Note presence identical subtrees leads repeat times calculations determining strategy maximizing EU decision tree Inﬂuence diagrams possible avoid pitfall detailed following section 52 RDU inﬂuence diagram consequentialism The purpose work solve inﬂuence diagram preferences decision maker follow EU model RDU model The aim solving diagram determine best strategy according decision criterion EU RDU In order deﬁne strategy necessary know random variables observed making decision temporal order decisions A strategy consists setting value decision variable conditionally past In decision tree past decision variable simply deﬁned set random variables decision variables lying path root variable The decision G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 1381 2 D7 2 D6 δ D4 2 δ D3 2 γ D2 2 2 D8 δ tree right Fig 7 includes 32 feasible strategies strategy D1 α D1 2 2 reached D1 α In inﬂuence diagram temporal order note nodes D5 apparent For reason set N A partitioned disjoint sets I0 I1 In Set I0 includes random variables observed ﬁrst decision D1 corresponding parents D1 Ik random variables observed Dk Dk1 corresponding parents Dk1 ﬁnally In remaining random variables ones observed observed decision Dn variables parent decision variable This induces partial order ND N A I0 D1 I1 Dn In For instance diagram left Fig 7 partial order D1 A1 A2 D2 A3 The past decision variable Dk set variables X X Dk Formally strategy inﬂuence diagram set decision rules variables Dk decision rule Dk maps instantiation variables past Dk value domain Dk However practice consequentialist strategies decision depends variables inﬂuencing parameters future considered inﬂuence diagrams Therefore necessary know values variables past set value decision variable This property crucial description consequentialist strategy remains linear size diagram case nonconsequentialist strategies For instance diagram Fig 7 variables D1 A2 A1 inﬂuence future D2 Therefore consequentialist strategy decision D2 depends D1 A2 A1 A decision rule D2 instance D2 γ D1 α A2 θ1 D2 δD1 α A2 θ2 D2 δD1 β A2 θ1 D2 γ D1 β A2 θ2 It means decision γ D2 decision α D1 event θ1 occurred A2 decision δ D2 decision α D1 event θ2 occurred A2 As result set strategies diagram Fig 7 includes 16 strategies It important note set strategies considered inﬂuence diagram subset strategies considered corresponding decision tree instance abovementioned strategy decision tree subset When optimizing EU harm known exists EUoptimal strategy included subset exists EUoptimal strategy consequentialist A contrario strategy optimizing RDU necessarily included subset exist RDUoptimal strategy consequentialist illustrated following example 2 D3 Example 11 Consider decision tree right Fig 7 A strategy maximizing EU consists making decision α D1 decision γ D1 2 D4 2 This strategy consequentialist Now assume adopts following probability transformation function ϕ ϕp 0 0 cid3 p 0175 ϕp 009 0175 cid3 p 025 ϕp 01 025 cid3 p 035 ϕp 015 035 cid3 p 075 ϕp 05 075 cid3 p 0825 ϕp 09 0825 cid3 p 1 ϕ1 1 Then unique strategy maximizing RDU consists making decision α D1 decision γ D1 2 decision 2 D3 δ D2 2 2 This strategy consequentialist distinct decisions D1 2 decision δ D2 2 D4 2 D3 53 Algorithms Note determining EUoptimal strategy inﬂuence diagram proved NPhard Determining RDUoptimal strategy harder description nonconsequentialist strategy require memory space size exponential size diagram 531 Twophases method Since RDUoptimal strategy necessarily consequentialist ﬁrst method natural consists phases 1 unfolding inﬂuence diagram decision tree 2 determining optimal strategy according RDU directly decision tree For phase 2 use implicit enumeration approach proposed Section 432 However enables determination real RDUoptimal strategy method course costly memory space impracticable size decision tree prohibitive 532 cid5relaxation method For reason propose method takes advantage compact structure inﬂuence diagrams unfolding decision trees cost reduction set considered strategies For purpose ﬁrst idea explore space consequentialist strategies lose important descriptive power RDU model Consequently approach propose renounce consequentialism introduce relaxed form consequentialism order realize compromise descriptive power compactness representation By inserting additional functional edges diagram enlarges space considered strategies Note creating ﬁctitious dependences independent variables change problem representation In Example 12 illustrate changes induced insertion new functional edge Example 12 After inserting edge A1 U inﬂuence diagram Fig 7 obtains diagram represented Fig 8 From point view compactness representation noted variable A1 modalities double number lines table assigned variable U old table insertion edge represented utility U D1 D2 A3 new table insertion edge represents U D1 A1 D2 A3 However 1382 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 Fig 8 Modiﬁed inﬂuence diagram beneﬁt space considered strategies enlarged A1 inﬂuences parameters future D2 decision D2 conditioned value A1 Consequently decision rule D2 takes account variables D1 A1 A2 In words case insertion edge A1 U makes possible account nonconsequentialist strategies cid3 cid3 V D V In sequel cid5relaxation consequentialism fact adding cid5 dependences decision variable At worst adds ND cid5 supplementary edges Adding dependence decision variable D amounts inserting edge1 V V provided D depend V This condition graphically formalized follows V W E W ND W cid19 D The inserted edges course chosen arbitrarily We procedure select Our aim primarily representation compact possible In purpose heuristic select edges insert consists choosing greedily ones impact sizes cid3 increases size tables diagram Note ﬁrst given variables V V cid3 W table V V inﬂuence diagram cid3 cid3 Inserting edge V V cid3V 1 The aim insertion size sV heuristic greedy procedure insert edges minimize increment step To end time cid3 minimum cid3 iV V edge selected set candidate edges choose edge V V cid3 depends V Algorithm 2 summarizes procedure update table primitive makes table V duplicating entries inserting edge V V equal V cid3 cid3 set predecessors V cid3V insertion yielding increment iV V cid3 multiplies size table V number entries More precisely size table V cid3 number modalities variable V V In words table V PredV size sV cid3 sV W PredV cid3 cid18 cid3 cid3 cid3 cid3 cid3 Algorithm 2 AddEdges foreach D ND 0 cid5 V D V V V arg minW D W W W cid3 arg minW ND V cid3 E E V V cid3 update table V 1 W cid18 cid3 E V cid3 E W W cid3 ND V cid3 ND V cid3 W cid19 D cid3 cid19 D cid3 cid19 D W cid3PredW end end We procedure determining strategy maximizing RDU cid5relaxation diagram As decision trees propose branch bound procedure solve inﬂuence diagram The main differences way strategies enumerated branching rule dynamic programming procedure compute upper bound precisely lottery stochastically dominating possible lotteries We main features implicit enumeration scheme Initialization As decision trees determines strategy optimizing EU Several solving algorithms proposed literature accomplish task 4421 Schachters algorithm 44 consists eliminating incrementally nodes diagram respecting partial order For purpose edge reversals edges representing probabilistic dependences performed costly computation time Jensen et als algorithm 21 inspired inference algorithms Bayesian networks consists transforming inﬂuence diagram junction tree applying nonserial dynamic programming 5 junction tree We adopted approach implementation performances generally assumed better ones Schachters algorithm 1 Note insertion single edge V V cid3 cid3 V D cid3 V D cid3 V N A ND V cid3 N A NU likely create additional dependences variables G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 1383 Fig 9 Enumeration tree Branching rule The branching rule use set value decision variable conditionally variables ﬂuence For instance diagram Fig 8 separates set strategies characterized D 1 α D2 γ D1 α A1 η1 A2 θ1 D2 δD1 α A1 η2 A2 θ1 D2 δD1 α A1 η1 A2 θ2 subsets characterized respectively D1 α D2 γ D1 α A1 η1 A2 θ1 D2 δD1 α A1 η2 A2 θ1 D2 δD1 α A1 η1 D1 α D2 γ D1 α A1 η1 A2 θ1 D2 δD1 α A1 η2 A2 θ1 D2 δD1 α A1 η1 A2 θ2 D2 γ D1 α A1 η2 A2 θ 2 A2 θ2 D2 δD1 α A1 η2 A2 θ 2 The enumeration tree represented Fig 9 The instanciated nodes indicated bold The order variables considered enumeration tree compatible temporal order decision nodes remember exists path linking decision nodes diagram Computing lower bound This similar decision trees At node enumeration tree computes strategy optimizing EU subset considered strategies evaluates according RDU Computing upper bound As decision trees need compute lottery stochastically dominating lottery corresponding feasible strategy RDU value upper bound For purpose use dynamic pro gramming procedure We recursively compute lottery decision variable possible instantiation variables past compatible decisions set In following simplicity assume single utility variable U takes value u1 um u1 cid3 cid3 um We use backward induction procedure The initialization U performed following formula 1384 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 cid2 1 P U uiI0 In D1 Dn cid17 1 U I0 In D1 Dn ui 0 U I0 In D1 Dn gives value taken variable U according values taken variables I0 In D1 Dn Consider decision variable Dk For given realization random variables I0 Ik1 given choice decisions D1 Dk1 stochastically dominating lottery Dk computed following recurrence relation cid2 1 P U cid2 uiI0 Ik1 D1 Dk1 max Dk mcid3 cid3 ji Ik P IkI0 Ik1 D1 Dk P U u jI0 Ik1 Ik D1 Dk The stochastically dominating lottery easily determined following formula P U uiI0 Ik1 D1 Dk1 P U cid2 uiI0 Ik1 D1 Dk1 P U cid2 ui1I0 Ik1 D1 Dk1 The value ﬁnally returned computed applying RDU lottery obtained D1 Note conditionings fact performed smaller sets variables thanks independences displayed inﬂuence diagram In order optimize calculations junction tree like Jensens algorithm 21 54 Numerical tests The proposed algorithms twophases method operating directly inﬂuence diagram endowed ﬁctitious dependences implemented C computational experiments carried PC Pentium IV CPU 213 GHz processor 35 GB RAM decision trees We present results obtained randomly generated inﬂuence diagrams We ﬁrst mechanism random generator We analyze performances algorithms terms computation time solution quality We function ϕ decision trees ϕp pγ pγ 1 pγ γ 02 value γ probabilities distorted 55 Random generator In order control size generated inﬂuence diagrams nodes diagram taken account computing optimal strategy For purpose given ﬁxed number n decision nodes ﬁrst creates path length 2n 1 alternating decision variables random variables utility variable leaf node For instance decision variables gives Then avoid variables diagram play real role impact choice optimal strategy imposes random variable inﬂuences random variable long exists random variable future Coming previous example obtain To densify diagram edges randomly inserted nodes Concerning utilities conditional prob abilities randomly generated Finally greedy algorithm described Section 53 perform cid5relaxation consequentialism 56 Numerical results To evaluate computational gain directly working inﬂuence diagram compared execution times implicit enumeration algorithm twophases method execution times algorithm performing cid5relaxation consequentialism values cid5 Table 7 indicates execution times obtained average time seconds 40 randomly generated instances entry In column vary number decision variables vary value n row varied value cid5 The time taken twophases method indicated line table Symbol appears exist instances execution time important 30 min Not surprisingly n cid5 increase execution times increase The twophases method possible solve instances 7 decision nodes In comparison cid5relaxation method enables solve instances 10 decision nodes cost optimality In order evaluate quality solutions returned cid5relaxation method compared RDU values optimal ones corresponding decision trees obtained applying twophases method Given inﬂuence G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 1385 Table 7 Execution time sec cid5 0 1 2 3 4 5 n 4 0 0 0 0 0 0 2 ph 017 5 0 0 0 0 0 008 093 6 0 0 0 010 056 191 502 Table 8 Inﬂuence parameter cid5 strategy quality n 2 3 4 5 6 cid5 0 97 93 92 93 92 cid5 2 100 96 93 94 93 7 021 023 038 072 107 343 1738 cid5 3 98 95 95 93 8 085 062 110 233 446 1984 9 278 394 479 925 1861 8740 cid5 4 100 97 95 95 10 911 1215 2336 2997 9352 cid5 5 97 97 96 ID resp RDUcid5ID RDU value strategy optimizing RDU corresponding diagram ID denote RDU decision tree resp optimizing RDU ID performing cid5relaxation consequentialism In order evaluate ID different values inﬂuence parameter cid5 strategy quality wrt RDU computed ratio RDUcid5IDRDU cid5 n For value n 200 instances randomly generated Then instances performed cid5 relaxation consequentialism cid5 varying 0 5 Table 8 shows average ratio obtained percentage 200 instances The entries correspond cases dependences present value 100 When cid5 0 considers consequentialist strategies One instances considered values returned strategies signiﬁcantly closer optimum cid5 5 cid5 0 thanks consideration nonconsequentialist strategies 6 Conclusion In article proposed algorithms optimizing RDU sequential decision problems represented decision trees inﬂuence diagrams The problem NPhard representations For optimizing RDU decision trees provided MIP formulation adapted risk seeker decision makers branch bound procedure adapted attitude risk The upper bound branch bound procedure computed dynamic programming polynomial number decision nodes Note upper bound actually customizable decision criterion compatible stochastic dominance The tests performed dedicated branch bound algorithm performs better CPLEX applied MIP formulation Our method makes possible solve eﬃciently random instances number decision nodes near thousands realworld instances number decision nodes 75 millions thanks particular shape decision tree However number stages grows decision tree formalism possible compactly store problem instance Inﬂuence diagrams expresses concise way problem instance independences variables useful When optimizing RDU inﬂuence diagrams aim conciliating op timality compactness issues determining strategy RDU value close optimum storage require memory space We shown space strategies considered inﬂuence diagram smaller space strategies considered corresponding decision tree restricted sequentialist strategies For reason proposed approach inﬂuence diagram endowed new edges representing ﬁctitious dependences cid5relaxation consequentialism This enables enrich space strategies nonconsequentialist strategies Such strategies appreciated RDUmaximizers The numerical experiments carried cid5relaxation RDU value computed strategy signiﬁcantly improves value obtained consequentialist strategy In order enhance approach proposed promising research direction identify crucial edges edges insertion inﬂuence diagram signiﬁcantly increase RDU value returned strategy It limit growth size diagram improve quality returned strategy In different research direction worth investigating new compact graphical model able handle nonconsequentialist decision criteria inﬂuence diagram representation suitable 1386 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 Appendix A Proofs Fig 10 An example reduction Proposition 1 The determination RDUoptimal strategy problem RDUOPT decision tree NPhard problem Proof The proof relies polynomial reduction problem 3SAT stated follows INSTANCE set X boolean variables collection C clauses X c 3 clause c C QUESTION exist assignment truth values boolean variables X satisﬁes simultaneously clauses C Let X x1 xn C c1 cm We reduce problem 3SAT ﬁnding strategy value greater equal m polynomially generated decision tree The polynomial generation decision tree instance 3SAT performed follows One deﬁnes decision node variable X Given xi variable X corresponding decision node decision tree denoted xi children ﬁrst chance node denoted T corresponds statement xi truth value true second chance node denoted F corresponds statement xi truth value false The subset clauses includes positive resp negative C For clause cih 1 cid3 h cid3 j generates child literal xi denoted ci1 ci j cid3 k T denoted cih terminal node Besides generates additional child T denoted c0 corresponding 1 cid3 h cid3 k additional child ﬁctive consequence Similarly generates child F clause ci corresponding ﬁctive consequence c0 Node T j 1 children node F k 1 children In order single decision tree adds chance node C predecessor decision nodes xi 1 cid3 cid3 n Finally adds decision node root C unique child The obtained decision tree includes n 1 decision nodes 2n 1 chance nodes 2nm 1 terminal nodes Its size O nm guarantees polynomiality transformation For sake illustration Fig 10 represent decision tree obtained following instance 3SAT x1 x2 x3 x1 x3 x4 x2 x3 x4 C resp ci ci cid3 1 cid3 h Note establish bijection set strategies decision tree set assignments problem 3SAT For purpose suﬃcient set xi 1 problem 3SAT iff edge xi T included strategy xi 0 iff edge xi F included strategy An assignment entire expression true 3SAT corresponds strategy clause ci 1 cid3 cid3 m possible consequence clause appears times To complete reduction deﬁne hand probabilities assigned edges nodes C T F hand utilities consequences function ϕ The reduction consists deﬁning strategies maximizing RDU correspond assignments entire expression true 3SAT More precisely aim satisfying following properties RDU value strategy depends set multiset possible consequences words set clauses true corresponding assignment ii RDU value strategy corresponding assignment makes satisﬁable 3SAT expression equals m G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 1387 iii strategy yields set possible consequences strictly included set possible consequences strategy RDU value strictly greater For purpose assigning probability 1 n edges originating C deﬁnes probabilities utilities follows cid16 0 pi cid14 cid15 1 10 icid3 uci 10 j1 j1 pi probability assigned edges leading consequence ci For edges type T j c0 F j c0 sets uc0 0 assigns probability probabilities edges originating T j F j sum 1 Note probability positive sum pi s strictly smaller 1 construction Finally function ϕ deﬁned follows2 0 p pi p 1 p cid19 cid19 cid19 ϕp cid15 0 pm n pi1 n pi n cid15 p1 n 1 cid15 m For sake illustration function ϕ obtained instance 3SAT indicated ϕp cid19 0 p 0 cid15 1 4 1000 1 100 1 10 p p cid19 cid19 cid19 1 p 1 4 100 cid15 1 4 10 cid15 1 4 1000 1 4 100 1 4 10 1 cid15 In following consider strategy cid5 inducing lottery denoted L denote I 0 m set indices possible consequences cid5 Note consequence c0 present strategy cid5 We denote αi 1 2 3 number occurrences consequence ci cid5 By abuse notation use indifferently ci uci Proof The RDU value cid5 RDUL c0 ϕ1 j We I ϕ cid2 cid2 p j n ϕ jI jcid2i α j jI jcid2i cid21 p j n cid20 cid3 ϕ jI jcid2i cid3 ϕ cid20 cid3 jI jcid2i cid21 α j p j n cid3 ϕ cid21 3 p j n cid20 cid3 jI jcid2i cid2 iI ci cprevI iϕ cid2 jI jcid2i p j n By increasingness ϕ α j p j n prevI max j I Therefore cid20 ϕ cid21 cid15 j cid14 1 n 1 10 cid3 ϕ cid20 cid3 jI jcid2i cid21 α j p j n cid3 ϕ cid20 cid3 jI jcid2i cid21 cid15 j cid14 3 n 1 10 cid3 jI jcid2i 2 Note function ϕ strictly increasing reader easily convince slightly adapted strictly increasing 1388 Since G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 cid20 cid3 ϕ jI jcid2i cid21 cid15 j cid14 1 n 1 10 ϕ cid21 cid15 j cid14 3 n 1 10 cid20 cid3 jI jcid2i pi1 bounding cid21 cid20 cid3 ϕ jI jcid2i Hence α j p j n ϕ cid21 p j n cid20 cid3 jI jcid2i RDUL cid3 ci cprevI iϕ iI cid21 p j n cid20 cid3 jI jcid2i c0 ϕ1 0 Proof ii Consider strategy cid5 L consequences ci C possible By cid20 cid21 cid6 cid7 RDU L mcid3 ci ci1ϕ mcid3 i1 ji p j n cid2 corresponding assignment makes expression true induced lottery We note cid3 m ci ci1ϕ m ji p j n 10i1 pi1 10i1 1 10 i1 1 Consequently RDUL m Proof iii Let cid5 resp cid5cid3 let I 0 m resp denote strategy induced lottery L resp L J I k denote set indices possible consequences We assume k max I case k max I obvious By deﬁnition I cid16 k J cid16 k We state RDU value sum terms cid21 cid21 cid20 cid20 cid21 cid20 cid3 cid3 cid3 RDUL ci cprev J iϕ J icid3k1 jI jcid2i p j n ck cprev J kϕ cid3 p j n cid3 jI jcid2k ci cprev J iϕ J icid2k1 j J jcid2i cid3 p j n stated sum terms cid20 cid21 cid20 cid21 p j n ck cprev J kϕ p j n cid3 j J jcid2k ci cprev J iϕ cid3 J icid2k1 cid21 p j n cid20 cid3 j J jcid2i Similarly RDU value strategy cid5cid3 cid6 RDU L cid7 cid3 cid3 ci cprev J iϕ J icid3k1 By increasingness ϕ cid3 j J jcid2i cid21 I J cid3 k 1 ϕ cid20 cid3 jI jcid2i p j n cid3 ϕ cid21 p j n cid20 cid3 j J jcid2i cid2 Thus ﬁrst term RDUL smaller equal ﬁrst term RDUL p j n p j n pprev J k pk1 succI min j I j But psuccI k1 pk1 succI k 1 cid3 Finally term psuccI k1 ϕ k 1 Therefore second term RDUL strictly smaller second term RDUL RDUL course equal term RDUL cid3 Consequently RDUL RDUL cid3 One checks easily ϕ jI jcid2k j J jcid2k cid3 cid2 From ii iii conclude strategy corresponding assignment expression true RDU value strictly smaller m strategy corresponding assignment makes ex pression true RDU value exactly equal m Solving 3SAT reduces determining strategy value m RDUOPT cid2 G Jeantet O Spanjaard Artiﬁcial Intelligence 175 2011 13661389 1389 References 1 M Abdellaoui Parameterfree elicitation utilities probabilities weighting functions Management Science 46 11 2000 14971512 2 M Allais Le comportement lhomme rationnel devant le risque critique des postulats lécole américaine Econometrica 21 1953 503546 3 M Allais An outline main contributions economic science The American Economic Review 87 6 1997 312 4 KJ Arrow The Theory Risk Aversion Ynjo Jahnsonin Saatio Helsinki 1965 5 U Bertelé F Brioschi Nonserial Dynamic Programming Academic Press 1972 6 J Blythe Decisiontheoretic planning AI Magazine 20 1999 115 7 C Boutilier T Dean S Hanks Decisiontheoretic planning Structural assumptions computational leverage Journal AI Research 11 1999 194 8 C Camerer T Ho Nonlinear weighting probabilities violations betweenness axiom Journal Risk Uncertainty 8 1994 167196 9 A Chateauneuf Comonotonicity axioms rankdependent expected utility theory arbitrary consequences Journal Mathematical Economics 32 1999 2145 10 E Damiani S De Capitani di Vimercati P Samarati M Viviani A WOWAbased aggregation technique trust values connected metadata Electronic Notes Theoretical Computer Science 157 2006 131142 11 T Dean L Kaelbling J Kirman A Nicholson Planning deadlines stochastic domains Proc 11th AAAI 1993 pp 574579 12 D Dubois H Prade R Sabbadin Decisiontheoretic foundations qualitative possibility theory European Journal Operational Research 128 3 2001 459478 13 R Gonzales G Wu On shape probability weighting function Cognitive Psychology 38 1999 129166 14 P Hammond Consequentialism independence axiom Risk Decision Rationality D Reidel Publishing Co Dordrecht Holland 1988 pp 503515 15 P Hammond Consequentialist foundations expected utility Theory Decision 25 1 1988 2578 16 J Handa Risk probabilities new theory cardinal utility Journal Political Economics 85 1977 97122 17 R Howard J Matheson Risksensitive Markov decision processes Management Science 18 7 1972 356369 18 R Howard J Matheson Inﬂuence diagrams Readings Principles Applications Decision Analysis Strategic Decisions Group Menlo Park CA 1984 pp 721762 Reprinted Decision Analysis 2 3 2005 127143 19 JY Jaffray T Nielsen An operational approach rational decision making based rank dependent utility European Journal Operational Re search 169 1 2006 226246 20 G Jeantet O Spanjaard Rankdependent probability weighting sequential decision problems uncertainty Proc International Con ference Automated Planning Scheduling ICAPS 2008 pp 148155 21 F Jensen FV Jensen SL Dittmer From inﬂuence diagrams junction trees Proc Tenth Annual Conference Uncertainty Artiﬁcial Intelligence UAI 1994 pp 367373 22 L Kaebling M Littman A Cassandra Planning acting partially observable stochastic domains Artiﬁcial Intelligence 101 1999 99134 23 D Kahneman A Tversky Prospect theory An analysis decision risk Econometrica 47 1979 263291 24 U Karmarkar Subjectively weighted utility Allais paradox Organisational Behavior Human Performance 24 1 1979 6772 25 S Koenig RG Simmons Risksensitive planning probabilistic decision graphs Proc International Conference Principles Knowledge Representation Reasoning KR 1994 PP 363373 26 Y Liu S Koenig Existence ﬁniteness conditions risksensitive planning Results conjectures Proc Twentieth Annual Conference Uncertainty Artiﬁcial Intelligence UAI 2005 pp 354363 27 Y Liu S Koenig Risksensitive planning oneswitch utility functions Value iteration Proc Twentieth National Conference Artiﬁcial Intelligence AAAI 2005 pp 993999 28 Y Liu S Koenig An exact algorithm solving MDPs risksensitive planning objectives oneswitch utility functions Proc International Joint Conference Autonomous Agents Multiagent Systems AAMAS 2008 pp 453460 29 R Luce H Raiffa Games Decisions John Wiley New York 1957 30 MJ Machina Dynamic consistency nonexpected utility models choice uncertainty Journal Economic Literature 27 4 1989 1622 1668 31 E McClennen Rationality Dynamic Choice Foundational Explorations Cambridge University Press 1990 32 T Morin Monotonicity principle optimality Journal Mathematical Analysis Applications 86 1982 665674 33 TD Nielsen FV Jensen Learning decision makers utility function possibly inconsistent behavior Artiﬁcial Intelligence Journal 160 2004 5378 34 W Ogryczak T Sliwinski On decision support risk WOWA optimization ECSQARU 2007 pp 779790 35 W Ogryczak WOWA enhancement preference modeling reference point method Proc Fifth International Conference Modeling Decisions Artiﬁcial Intelligence Lecture Notes Artiﬁcial Intelligence vol 5285 Springer 2008 pp 3849 36 W Ogryczak T Sliwinski On eﬃcient WOWA optimization decision support risk International Journal Approximate Reasoning 50 2009 915928 37 F Perea J Puerto Dynamic programming analysis TV game Who wants millionaire European Journal Operational Research 183 2007 805811 38 P Perny O Spanjaard LX Storme State space search riskaverse agents 20th International Joint Conference Artiﬁcial Intelligence 2007 pp 23532358 39 J Pratt Risk aversion small large Econometrica 32 1 1964 122136 40 J Quiggin Generalized Expected Utility Theory The RankDependent Model Kluwer 1993 41 H Raiffa Decision Analysis Introductory Lectures Choices Uncertainty AddisonWesley 1968 42 M Rotshild J Stiglitz Increasing risk I A deﬁnition Journal Economic Theory 2 3 1970 225243 43 L Savage The Foundations Statistics Wiley 1954 44 R Shachter Evaluating inﬂuence diagrams Operations Research 34 1986 871882 45 V Torra Weighted OWA operators synthesis information Proc Fifth IEEE International Conference Fuzzy Systems IEEEFUZZ96 1996 pp 966971 46 V Torra The weighted OWA operator International Journal Intelligent Systems 12 1997 153166 47 V Torra The WOWA operator interpolation function W Chen Ottos interpolation method revisited Fuzzy Sets Systems 113 3 2000 389396 48 A Tversky D Kahneman Advances prospect theory Cumulative representation uncertainty Journal Risk Uncertainty 5 1992 297323 49 J von Neumann O Morgenstern Theory Games Economic Behaviour Princeton University Press 1947