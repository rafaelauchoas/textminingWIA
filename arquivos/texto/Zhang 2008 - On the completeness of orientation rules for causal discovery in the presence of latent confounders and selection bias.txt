Artiﬁcial Intelligence 172 2008 18731896 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint On completeness orientation rules causal discovery presence latent confounders selection bias Jiji Zhang ab Division Humanities Social Sciences California Institute Technology USA b Department Philosophy Lingnan University Hong Kong r t c l e n f o b s t r c t Article history Received 28 October 2007 Received revised form 30 June 2008 Accepted 6 August 2008 Available online 14 August 2008 Keywords Ancestral graphs Automated causal discovery Bayesian networks Causal models Markov equivalence Latent variables 1 Introduction Causal discovery especially challenging possibility latent confounding andor selection bias assumed away For task ancestral graph models particularly useful represent presence latent confounding selection effect explicitly invoking unobserved variables Based machinery ancestral graphs provably sound causal discovery algorithm known FCI algorithm allows possibility latent confounders selection bias However orientation rules algorithm complete In paper provide additional orientation rules augmented FCI algorithm shown complete sense standard assumptions discover aspects causal structure uniquely determined facts probabilistic dependence independence The result useful developing causal discovery reasoning based ancestral graph models 2008 Elsevier BV All rights reserved Directed acyclic graphs DAGs widely statistical models causal models This double terpretation DAGs better known causal Bayesian networks AI literature springboard research automated causal discovery reasoning 122025 Given set variables V causal structure V properly represented DAG try learn causal structure data exploiting statistical implications DAGs statistical models In general causal structure underdetermined multiple DAGs equally compatible correlational pattern suggested data But DAGs usually share common features constitute aspects causal structure underdetermined principle learnable observational data To develop algorithms inferring learnable causal features correlational patterns important goal project automated causal discovery Assuming confounding selection effect unobserved variables causal discovery algorithms provably sound complete plausible assumptions relating causal structure probability distribution 717 2532 However assumption latent confounding selection effect seldom appropriate desirable necessary situations relax Unfortunately problem diﬃcult drop assumption fact causal structure properly representable DAG latent variables explicitly invoked Not DAG models latent variables hard handle statistically 511 inﬁnite search space seriously constrain number latent variables topology unknown causal network Email address jijihsscaltechedu 00043702 matter 2008 Elsevier BV All rights reserved doi101016jartint200808001 1874 J Zhang Artiﬁcial Intelligence 172 2008 18731896 Fig 1 A causal mechanism latent selection variables One way represent models explicitly introducing latent variables especially interested latent variables se A class graphical models developed purpose known ancestral graph models 23 As major virtue ancestral graphs DAG latent confounding selection variables unique maximal ancestral graph MAG observed variables represents conditional independence relations causal relations entailed original DAG Instead directly targeting causal DAG know involve number latent variables tractable goal causal discovery learn features causal MAG possible There provably sound procedure purpose known FCI algorithm 261 Whether completethat principle discover causal information underdeterminedhas open problem 18252 In fact explain later algorithm complete stands In paper provide additional orientation rules rules inferring edge marks augmented FCI algorithm complete The result amounts constructive characterization common features shared equivalence class MAGs useful causal discovery reasoning based ancestral graph models In regard result generalizes Meeks characterization commonalities shared Markov equivalent DAGs 17 builds directly earlier results established 2 Causal discovery aside paper interested ancestral graph models drawn attention statisticians scientists 12910233037 We suspect results paper especially lemmas Appendix A useful providing characterization equivalence classes MAGs style Andersson et als characterization equivalence classes DAGs 4 The rest paper organized follows Section 2 introduces relevant background ancestral graphs In Section 3 FCI algorithm report important step 2 completeness result We present additional orientation rules Section 4 augmented FCI algorithm complete We conclude Section 5 Most proofs postponed appendices 2 Ancestral graphs interpretations The following example attributed Chris Meek 22 illustrates nicely primary motivation ancestral graphs The graph Fig 1 represents randomized trial ineffective drug unpleasant sideeffects Patients randomly assigned treatment control group A Those treatment group suffer unpleasant sideeffects Ef severity inﬂuenced patients general level health H sicker patients suffering worse sideeffects Those patients suffer suﬃciently severe sideeffects likely drop study The selection variable Sel records patient remains study remaining study Sel StayIn Since unhealthy patients taking drug likely drop patients treatment group remain study tend healthier control group Finally health status H inﬂuences rapidly patient recovers R 22 p 234 This simple case shows presence latent confounders selection variables matters The variables primary A R observed correlated supposed causal mechanism entails independence This correlation sample variation corresponds genuine probabilistic association induced designonly subjects eventually stay study considered The observed correlation effect correlation conditional selection variable Sel canonical example selection effect On hand H familiar latent confounder contributes spurious correlation 1 FCI stands fast causal inference probably overly optimistic 2 These authors raised problem regard older version algorithm designed based representation called inducing path graphs There close relationship inducing path graphs MAGs explained appendix 34 It suﬃces note completeness problem addressed paper harder problem completeness problem formulated terms inducing path graphs Also FCI algorithm claimed complete 28 weaker sense consider paper J Zhang Artiﬁcial Intelligence 172 2008 18731896 1875 A main attraction ancestral graphs explicitly including latent variables represent conditional independence relations causal relations observed variables underlying data generating process involves latent confounders andor selection variables This course requires richer syntax DAGs 21 Ancestral graphs A mixed graph vertexedge graph contain kinds edges directed bidirected undi rected edge vertices The ends edge marks orientations The marks bidirected edge arrowheads marks undirected edge tails directed edge We edge vertex edge mark vertex arrowhead tail Two vertices said adjacent mixed graph edge kind Given mixed graph G adjacent vertices A B A parent B B child A A B G A called spouse B B spouse A A B G A called neighbor B B neighbor A AB G A path G sequence distinct vertices cid4V 0 V ncid5 0 cid2 cid2 n 1 V V i1 adjacent G A directed path V 0 V n G sequence distinct vertices cid4V 0 V ncid5 0 cid2 cid2 n 1 V parent V i1 G A called ancestor B B descendant A A B directed path A B Let AnG B denote set ancestors B G A directed cycle occurs G B A G A AnG B An directed cycle occurs B A G A AnG B Deﬁnition 1 A mixed graph ancestral following conditions hold a1 directed cycle a2 directed cycle a3 undirected edge V 1V 2 V 1 V 2 parents spouses Obviously DAGs special cases ancestral graphs The ﬁrst condition Deﬁnition 1 familiar DAGs Together second condition deﬁne nice connotation arrowheads ancestral graphs arrowhead implies nonancestorship The condition requires edge vertex undirected component ancestral graph This property simpliﬁes parameterization ﬁtting ancestral graphs 923 allows selection effect properly represented 22 Probabilistic interpretation ancestral graphs As statistical model vertices ancestral graph represent random variables graph interpreted encoding set conditional independence3 relations graphical criterion called mseparation generalizes known dseparation criterion DAGs 19 Given path p mixed graph nonendpoint vertex V p called collider edges incident V p V V called noncollider p In Fig 2a example B collider path cid4 A B Dcid5 noncollider path cid4C B Dcid5 Deﬁnition 2 mseparation In mixed graph path p vertices X Y active mconnecting relative possibly set vertices Z X Y Z noncollider p member Z ii collider p descendant Z X Y said mseparated Z active path vertex X vertex Y relative Z The probabilistic interpretation ancestral graphs given global Markov property X Y mseparated Z X Y probabilistically independent conditional Z This interpretation obviously consistent DAGs mseparation reduces dseparation case DAGs The following property true DAGs vertices adjacent subset vertices mseparates dseparates This true ancestral graphs For example graph Fig 2 ancestral graph fails condition C D adjacent subset A B mseparates This motivates following deﬁnition 3 We refer standard notion conditional independence probability theory 1876 J Zhang Artiﬁcial Intelligence 172 2008 18731896 Fig 2 An ancestral graph maximal b maximal ancestral graph Deﬁnition 3 maximality An ancestral graph said maximal nonadjacent vertices set vertices mseparates DAGs maximal In fact maximality corresponds socalled pairwise Markov property missing edge corresponds conditional independence relation basis inferring adjacency skeleton unknown causal graph causal discovery procedures including FCI algorithm discuss later Maximality closely related notion inducing path The deﬁnition convoluted basic motivation following question Partition set vertices V O L S consider mseparation relations form X Y mseparated Z S X Y O Z O X Y 4 When true X Y mseparated Z S Z O X Y The answer given notion inducing path Deﬁnition 4 inducing path In ancestral graph let X Y vertices L S disjoint sets vertices containing X Y A path p X Y called inducing path relative cid4L Scid5 nonendpoint vertex p L collider collider p ancestor X Y member S When L S Ø p called primitive inducing path X Y An important fact established Richardson Spirtes 23 Theorem 42 X Y mseparated Z S Z VL S X Y inducing path X Y relative cid4L Scid5 For example Fig 1 path cid4 A E f H Rcid5 inducing path relative cid4H Selcid5 A mseparated R Ef Sel Sel This fact plays important role constructing MAG represents given DAG As special case fact presence primitive inducing path suﬃcient necessary vertices mseparated set variables ancestral graph obviously connected maximality Proposition 1 An ancestral graph maximal primitive inducing path nonadjacent vertices graph For example Fig 2a path cid4C A B Dcid5 primitive inducing path C D graph maximal It shown 23 Theorem 51 nonmaximal ancestral graph unique supergraph ancestral maximal nonmaximal ancestral graph transformed maximal supergraph series additions bidirected edges For example Fig 2 b unique maximal supergraph extra bidirected edge C D From focus maximal ancestral graphs MAGs 23 Causal interpretation maximal ancestral graphs The simple motivating example Fig 1 suggests correlational structure set observed variables misleading causal structure reasons First unobserved common causes confounders contribute observed association Second samples representative subpopulation population The subpopulation particular characterized set unobserved selection conditioning variables units subpopulation share values selection variables Hence observed association independence facto conditional selection variables One formally represent situation causal DAG union disjoint sets variables V O L S O denotes set observed variables L denotes set latent unobserved variables S denotes set unobserved selection variables conditioned The DAG entails set conditional independence constraints V Among constraints principle observable testable ones form ABC S5 A B C O disjoint sets observed variables 4 These mseparation relations particularly interesting L intended set latent variables marginalized observable distribution S intended set selection variables observable distribution conditions 5 symbol denotes probabilistic independence introduced Dawid 8 The vertical bar denotes conditioning Strictly speaking conditioning speciﬁc value vector values S accurate write ABC S s J Zhang Artiﬁcial Intelligence 172 2008 18731896 1877 A distinctive virtue MAGs represent inprincipletestable constraints explicitly introduc ing L S Given DAG G V O L S exists MAG O disjoint sets variables A B C O A B entailed independent conditional C S G A B entailed independent conditional C MAG When case MAG probabilistically represents DAG The following construction gives MAG Input DAG G V O L S Output MAG MG O 1 pair variables A B O A B adjacent MG inducing path relative cid4L Scid5 G 2 pair adjacent vertices A B MG orient edge follows orient A B MG A AnG B S B AnG A S b orient A B MG B AnG A S A AnG B S c orient A B MG A AnG B S B AnG A S d orient AB MG A AnG B S B AnG A S It shown MG MAG probabilistically represents Git follows Theorem 418 23 More easy MG causally represents G retains ancestral relationships G So G represents causal structure V fair MG causal MAG O edges encode causal information presence absence causal pathway underlying structure Speciﬁcally A B means A cause B selection variable B cause A selection variable6 A B means A cause B selection variable B cause A selection variable7 AB means A cause B selection variable B cause A selection variable8 Put simply edge marks causal MAG represent qualitative causal information arrowheads represent nega tive causal information noncause tails represent positive causal information cause The positive causal information admittedly informative wish possibility selection bias allowed This ﬂects fact presence selection bias seriously limits possibility inferring useful causal information observations If worry confounding selection bias A B read unambiguously A cause B Of course disjunctive information combined information deduce useful facts9 Detailed exploration use causal information carried ancestral graphs causal reasoning scope paper10 Our present concern extent information discovered correlational pattern It limited Markov equivalence 24 Markov equivalence Two different MAGs carry different causal information share exact mseparation structure entail set conditional independence constraints Such MAGs distinguishable correlational pattern Deﬁnition 5 Markov equivalence Two MAGs G1 G2 set vertices Markov equivalent disjoint sets vertices X Y Z X Y mseparated Z G1 X Y mseparated Z G2 Several characterizations Markov equivalence MAGs available 1273537 We rely char acterization 27 paper Deﬁnition 6 unshielded path In MAG path consisting triple vertices cid4 X Y Z cid5 said unshielded X Z adjacent The triple called unshielded collider edge X Y edge Y Z Y 6 By saying A cause B mean directed path A B underlying causal structure 7 This adjacency A B MAG implies latent common cause A B 8 Due assumed acyclicity causal structure equivalent saying A cause selection variable B cause selection variable 9 For example A B MAG edge A deduced A cause selection variable cause B 10 Some relevant results 24 34 1878 J Zhang Artiﬁcial Intelligence 172 2008 18731896 Fig 3 A discriminating path X Y V It known DAGs Markov equivalent adjacencies unshielded colliders 32 These conditions necessary Markov equivalence MAGs suﬃcient For MAGs Markov equivalent shielded colliders present graphs The deﬁnition related Deﬁnition 7 discriminating path In MAG path X Y p cid4 X W V Y cid5 discriminating path V p includes edges ii V nonendpoint vertex p adjacent Y p iii X adjacent Y vertex X V collider p parent Y A canonical depiction discriminating path given Fig 3 Note write discriminating path form p cid4 X W V Y cid5 specify endpoints vertices adjacent V vertex discriminated The ellipsis designates number possibly zero vertices The following proposition proved Spirtes Richardson 27 Proposition 2 Two MAGs set vertices Markov equivalent e1 They adjacencies e2 They unshielded colliders e3 If path p discriminating path vertex V graphs V collider path graph collider path Given MAG G denote Markov equivalence class set MAGs Markov equivalent G G According Proposition 2 members G adjacencies But adjacent vertices edge marks edge different different members G We mark G invariant mark members G It adjacencies invariant marks unknown causal MAG hope discover correlational pattern 3 The FCI algorithm arrowhead completeness The MAG representation gives relatively tractable problem causal discovery presence latent confounders selection variables infer features causal MAG data In case learning causal DAGs assuming latent confounders selection variables assumptions commonly adopted known Causal Markov Condition Causal Faithfulness Condition These conditions assuming conditional independence relations hold population distribution precisely conditional independence relations entailed causal DAG dseparation11 If assume conditions underlying causal DAG latent variables follows exact correspondence observable conditional independence relations observed variables mseparation relations causal MAG causal MAG probabilistically represents causal DAG Under assumptions learn mseparation relations causal MAG correlational patternfacts conditional independence dependence The correlational pattern turn built based statistical tests conditional independence The constraintbased approach causal discovery seeks employ conditional independence mseparation constraints recover features causal MAG In paper sidestep statistical problem inferring genuine conditional independence data focus problem inferring causal information facts conditional independence As idealization suppose perfect oracle conditional independence available course approximated practice12 11 For detailed exposition discussion conditions 20 25 The causal Markov condition generalizes familiar principle common cause subject philosophical debate 361315 Recent reﬂections causal Faithfulness condition include 29 36 In paper assume conditions explore consequence 12 There course important practical issues require investigations developing powerful robust statistical tests conditional independence quantifying uncertainty handling inconsistency arising imperfect oracle J Zhang Artiﬁcial Intelligence 172 2008 18731896 1879 For query conditional independence given observed variables oracle supplies correct answer conditional independence question holds Moreover given causal Markov Faithful ness assumptions mentioned unknown true causal MAG perfectly consistent oracle sense true conditional independence relations judged oracle precisely conditional independence relations entailed MAG Such oracle supply information mseparation relations true causal MAG denote GT In general mseparation relations uniquely determine MAG Markov equivalence class MAGs denote GT So causal information principle identiﬁable given oracle corresponds invariant features true causal MAG features shared MAGs GT The question recover features oracle A provably sound algorithm task known FCI algorithm latest version presented 2613 The algorithm consists mainly stages In ﬁrst stage algorithm determines adjacencies causal MAG The inference adjacencies based fact variables adjacent MAG mseparated set variables MAG So basic idea search pair variables set variables renders conditionally independent They adjacent set The FCI algorithm uses tricks search eﬃcient details shall concern Suﬃce know proved 26 given reliable oracle conditional independence FCI algorithm ﬁnds correct adjacencies14 Our concern second stage stage inferring edge marks In stage algorithm executes set orientation rules mark inference rules introduce arrowheads tails circles representing undetermined edge marks The output algorithm referred partial ancestral graph PAG short15 It intended representation Markov equivalence class determined oracle conditional independence Deﬁnition 8 partial ancestral graph Let G Markov equivalence class MAG G A partial ancestral graph PAG G graph P possibly kinds marks kinds edges 1 P adjacencies G member G 2 noncircle mark P invariant mark G If furthermore true 3 circle P corresponds variant mark G P called maximally informative PAG G It known FCI algorithm sound means given perfect oracle conditional independence algorithm outputs PAG GT Markov equivalence class true causal MAG Whether complete matter output maximally informative PAG GT We equivalent version FCI algorithm 26 omitting details adjacency stage In stating orientation rules metasymbol asterisk wildcard denotes marks16 More speciﬁcally appears antecedent rule means matter mark place arrowhead tail circle If appears consequent rule means mark place remains ﬁring rule Greek letters denote generic variablesvertices FCI algorithm F1 Form complete graph U set variables edge pair variables F2 For pair variables α β search clever way set variables render indepen dent If set S remove edge α β U record S Sepsetα β F3 Let P graph resulting step F2 Execute orientation rule R0 For unshielded triple cid4α γ βcid5 P orient collider α γ β γ Sepsetα β F4 Execute following mark inference rules applies R1 If α β γ α γ adjacent orient triple α β γ R2 If α β γ α β γ α γ orient α γ α γ R3 If α β γ α θ γ α γ adjacent θ β orient θ β θ β 13 The algorithm initially designed based called inducing path graphs 25 reinterpreted terms partial ancestral graphs Not ancestral graph models amenable statistical analysis inducing path graphs causal discovery based principle reveal causal information causal discovery based reasons elaborated 33 Appendix 14 There ambiguity original formulation algorithm 25 interpreted right way suggests ﬂaw algorithm 16 But interpreted intended algorithm provably correct 15 PAGs ﬁrst invented Richardson 21 context learning causal models feedback They reinterpreted represent output FCI procedure represent Markov equivalence class MAGs 16 By mean rule question applies matter marks actually appears position It imply marks appear position 1880 J Zhang Artiﬁcial Intelligence 172 2008 18731896 R4 If u cid4θ α β γ cid5 discriminating path θ γ β β γ β Sepsetθ γ orient β γ β γ orient triple cid4α β γ cid5 α β γ 17 R0R3 essentially slight generalization inference rules context learning causal DAGs shown sound complete purpose 17 R4 peculiar MAGs bidirected edges It motivated condition e3 Markov equivalence Proposition 2 Section 24 justiﬁed fact discriminating paths behave similarly unshielded triples following way path X Y discriminating V V collider path set mseparates X Y contain V V noncollider path set mseparates X Y contains V For proof fact soundness R0R4 FCI algorithm 26 To establish completeness need PAG returned FCI maximally informative circle PAG corresponds variant mark GT In words need circle PAG MAG perfectly consistent oracle conditional independence Markov equivalent GT circle oriented tail MAG circle oriented arrowhead This turns highly nontrivial problem An important step Ali et al 2 Their result amounted showing R0R4 complete respect invariant arrowheads18 In words circle PAG output FCI MAG Markov equivalent GT circle marked tail The present paper aims establish completeness result The FCI algorithm stands complete There invariant tails fail picked R0R4 illustrate simple example shortly In section provide extra tail inference rules able pick remaining invariant tails The demonstration unfortunately diﬃcult arrowheadcompleteness 4 Extra orientation rules tail completeness To introduce extra tail inference rules need note couple special paths In deﬁnitions graph contain kinds edge marksarrowhead tail circlea partial mixed graph PMG Deﬁnition 9 uncovered path In PMG path p cid4V 0 V ncid5 said uncovered 1 cid2 cid2 n 1 V i1 V i1 adjacent consecutive triple path unshielded A distinctive property uncovered path course R0 executed consecutive triple path deﬁnite status collider noncollider Deﬁnition 10 potentially directed path In PMG path p cid4V 0 V ncid5 said potentially directed abbreviated pd V 0 V n 0 cid2 cid2 n 1 edge V V i1 V V i1 Intuitively pd path oriented directed path changing circles path appropriate tails arrowheads As shall uncovered pd paths play important role locating invariant tails A special case pd path edge path form path circle path Here ﬁrst block additional rules R5 For remaining αβ uncovered circle path p cid4α γ θ βcid5 α β st α θ adjacent β γ adjacent orient αβ edge p undirected edges R6 If αβ γ α γ adjacent orient β γ β γ R7 If α β γ α γ adjacent orient β γ β γ A pictorial illustration R5R7 given Fig 4 These rules obviously related undirected edges R5 lead undirected edges R6 depend undirected edges So known true casual MAG contain undirected edgesfor example cases selection bias known absentthese needed In case R7 triggered R0R4 introduced earlier R8R10 introduced shortly lead edges antecedent R7 17 See 2 alternative eﬃcient formulation rule takes special kind discriminating paths 18 Ali et al 2 employed slightly different graphical object called Joined Graphs represent Markov equivalence classes MAGs The difference Joined Graphs PAGs represent invariant arrowheads distinguish tails circles This makes Joined Graphs syntactically simpler price losing information invariant tails Our result paper seen attempt distinguish real tails pseudo tails joined graphs J Zhang Artiﬁcial Intelligence 172 2008 18731896 1881 Fig 4 Graphical illustrations R5R7 That introduce rules block If issue selection bias consider MAGs directed bidirected edges case R5R7 ignored principle19 The block rules contrast applicable R8 If α β γ αβ γ αγ orient αγ α γ R9 If αγ p cid4α β θ γ cid5 uncovered pd path α γ γ β adjacent orient α γ α γ R10 Suppose αγ β γ θ p1 uncovered pd path α β p2 uncovered pd path α θ Let μ vertex adjacent α p1 μ β ω vertex adjacent α p2 ω θ If μ ω distinct adjacent orient αγ α γ These rules visualized Fig 5 All turning partially directed edges directed ones valuable represent different causal information Call FCI algorithm supplemented rules Augmented FCI AFCI algorithm20 We ﬁrst rules sound Theorem 1 Let PFCI output FCI algorithm PAFCI graph resulting applying R5R10 PFCI applies The extra tails introduced PAFCI invariant Proof For rule need mixed graph violates rule belong GT MAG Markov equivalent GT The theorem follows simple induction R5 The antecedent rule implies cid4α γ θ β αcid5 forms uncovered cycle consists edges Suppose mixed graph contrary rule requires arrowhead cycle In light R1 cycle oriented directed cycle avoid unshielded colliders GT But graph ancestral R6 graph contrary rule requires contains αβγ graph ancestral R7 Suppose mixed graph contrary rule requires arrowhead β edge β γ Then αβγ present case graph ancestral α βγ present case graph contains unshielded collider GT R8 This rule analogous R2 Obviously mixed graph contrary rule requires contains α γ directed cycle present arrowhead undirected edge graph ancestral 19 We add principle caution true prefect conditional independence oracle In practice occasions R5 R7 applicable theory invoked 20 We worry implementation Note antecedent rule involves checking presence certain kind paths like R4 checked O mn generic algorithm checking reachability m number edges n number vertices graph So big O notation time complexity AFCI algorithm FCI algorithm 26 1882 J Zhang Artiﬁcial Intelligence 172 2008 18731896 Fig 5 Graphical illustrations R8R10 Fig 6 An example R9 needed unknown causal MAG b gives FCI output R9 applied twice yield c R9 The essentially argument soundness R5 applies R10 The antecedent rule implies triple cid4μ α ωcid5 collider GT means edges involved triple α MAG GT Suppose graph GT contrary rule requires contains α γ Then edges α directed edge graph ancestral It follows p1 p2 directed path graph avoid unshielded colliders GT In case α ancestor γ graph ancestral contradiction cid2 Here simple example R9 needed Suppose true causal MAG Fig 6a Given oracle consistent MAG FCI algorithm R0R4 gives graph 6b apply R9 tails shown 6c B D C D Given soundness R9 know additional tails invariant So FCI algorithm R0R4 complete In fact hard construct cases orientation rules given possibly R8 independent We know R8 independentwe construct case R8 applicable derive R8 rulesbut current proof completeness uses R8 The main result established R5R10 suﬃcient picking remaining invariant tails Let PAFCI denote output AFCI algorithm We need demonstrate circle PAFCI MAG GT corresponding mark arrowhead As shall main diﬃculty proving fact lies circles edges For circles kinds edges argument analogous argument arrowhead completeness given 2 33 We deal ﬁrst Section 41 diﬃcult task Section 42 circle edges PAFCI hides invariant tail 41 Circles edges Since PAFCI sound MAG GT orientation PAFCI unambiguous edge marks arrow heads tails PAFCI retained MAG circles PAFCI turned appropriate arrowheads J Zhang Artiﬁcial Intelligence 172 2008 18731896 1883 tails MAG Let subgraph PAFCI consisting edges PAFCI circle component PAFCI denote P C AFCI The ﬁrst thing note P C AFCI following property AFCI P C Lemma 41 For edge AB P C oriented DAG unshielded colliders A B appears AFCI oriented DAG unshielded colliders A B appears The proof given Appendix A makes use Lemma 5 Meek 1995 This fact relevant following theorem Theorem 2 Let H graph resulting following procedure applied PAFCI 1 orient circles edges PAFCI tails orient circles edges PAFCI arrowheads turn edges edges directed edges AFCI DAG unshielded colliders 2 orient P C Then H member GT The proof theorem given Appendix A The theorem couple important implications First suggests way turn PAFCI representation Markov equivalence class MAGs representative MAG What special construction extra undirected edges bidirected edges introduced So outcome representative member Markov equivalence class fewest undirected edges bidirected edges Such representative conceivably easier ﬁt score members class light fact UGs general harder ﬁt DAGs results presented 10 suggesting better fewer bidirected edges ﬁtting MAG model If particularly useful developing scorebased causal discovery algorithm based MAGs More importantly present purpose Theorem 2 Lemma 41 entail circle edge edge PAFCI member GT corresponding mark arrowhead In words circle edges PAFCI corresponds invariant tail Therefore left order establish completeness circles edges PAFCI hide invariant tails 42 Circles edges Let This task turns diﬃcult fulﬁll Unlike circles edges PAFCI simultaneously turned arrowheads saw Theorem 2 circles edges general turned arrowheads simultaneously order MAG GT The simplest example XY Z unshielded path appear PAFCI If turn circles arrowheads new unshielded collider created resulting graph belong GT By contrast unshielded triple XY Z appear PAFCI light R7 So handle edges wholesale manner J K denote arbitrary edge PAFCI We need MAG GT edge appears J K Our argument consists major steps In ﬁrst step orient P C AFCIthe circle component PAFCIinto DAG unshielded colliders satisﬁes certain conditions relative J K This DAG orientation P C AFCI operation 1 Theorem 2 yield MAG GT This MAG want J K oriented J K J K operation 1 Theo rem 2 In second step argument use result equivalencepreserving mark changes given 30 35 prove MAG constructed ﬁrst step transformed MAG containing J K sequence equivalencepreserving changes It follows resulting MAG J K Markov equivalent GT need The following deﬁnitions specify conditions want DAG orientation P C AFCI satisfy Deﬁnition 11 Relevance Let J K arbitrary edge PAFCI For AB PAFCI said relevant J K A J pd path J A PAFCI vertex path including endpoints parent K ii B K B parent K B K PAFCI If AB relevant J K A circlerelevant J K B arrowheadrelevant J K Intuitively relevant edges turned bidirected edges order J K J B oriented oriented pain creating directed cycles This obvious Fig 7a J B J K oriented J K lest directed cycle created 1884 J Zhang Artiﬁcial Intelligence 172 2008 18731896 Fig 7 Conﬁgurations relevance J B relevant J K B parent K b AK relevant J K pd path J A parent K path c AB relevant J K pd path J A parent K path B parent K Let REL J K denote set edges relevant J K PAFCI Notice J K belongs set eventually edges REL J K J K particular turned bidirected edges simultaneously For easy reference let denote set circlerelevant vertices CR J K set arrowrelevant vertices AR J K Deﬁnition 12 Agreeable orientation A DAG orientation P C J K following conditions hold AFCIthe circle component PAFCIis said agreeable C1 For ABC PAFCI AB REL J K C AR J K BC oriented B C C2 For C AB PAFCI AB REL J K C parent B C B PAFCI C A C3 For C AB PAFCI AB REL J K C adjacent B PAFCI C A oriented DAG oriented C A DAG C A DAG Roughly speaking C1C3 motivated necessary conditions orienting edge relevant J K bi directed edge This especially clear C2 C3 Regarding relevant edge AB C2 violated AB turned bidirected edge pain creating directed cycle similarly C3 violated pain creating new unshielded collider The rationale C1 obvious basically line revealed proof Theorem 3 The ﬁrst question orient P C As proof Lemma 41 goes Appendix A reason P C colliders P C colliders Meek 17 AFCI DAG unshielded colliders agreeable J K AFCI oriented DAG unshielded AFCI chordal aka triangulated One way orient chordal graph DAG free unshielded Meeks Algorithm Input chordal unoriented graph U Output DAG orientation U unshielded colliders Repeat 1 choose unoriented edge AB U 2 orient edge A B A B close orientations following rules21 UR1 If A BC A C adjacent orient B C UR2 If A B C AC orient A C UR3 If A B C ADC BD A C adjacent orient DC D C Until edge oriented H So idea simple In round choose arbitrary unoriented edge orient direction propagate orientation rules Then repeat edge oriented We adapt algorithm ﬁt purpose Given edge J K PAFCI let Ei 1 2 3 set edges PAFCI orientations required condition Ci Deﬁnition 12 Note Ei s necessarily disjoint 21 There rule 17 However antecedent rule involves unshielded collider triggered orienting chordal graph DAG unshielded colliders So need include J Zhang Artiﬁcial Intelligence 172 2008 18731896 1885 Orientation algorithm circle component PAFCI Input P C AFCI PAFCI edge J K Output DAG orientation P C AFCI unshielded colliders Let D P C Repeat AFCI If edge E1 oriented D choose edge AB E1 orient condition C1 requires b close orientations UR1 UR2 UR3 Else If edge E2 oriented D choose edge AB E2 orient condition C2 requires b close orientations UR1 UR2 UR3 Else If edge E3 oriented D choose edge AB E3 orient condition C3 requires b close orientations UR1 UR2 UR3 Else choose unoriented edge AB D b orient edge A B close orientations UR1 UR2 UR3 Until edge oriented D Return D This restricted version Meeks algorithm Therefore given correctness Meeks algorithm AFCI unshielded colliders Moreover Orientation Algorithm obviously returns DAG orientation P C agreeable J K Lemma 42 Let D JK DAG output Orientation Algorithm D JK DAG orientation P C colliders agreeable J K AFCI free unshielded This lemma diﬃcult establish argument proof given Appendix B The reason trouble Lemma 42 enables prove following fact Theorem 3 Let J K edge PAFCI Construct H PAFCI following procedure 1 orient edges REL J K orient edges 2 orient edges PAFCI 3 orient P C AFCI D JK Orientation Algorithm Then H member GT See Appendix B proof As hinted basic idea proof start MAG constructed procedure Theorem 2 MAG transformed graph constructed sequence equivalencepreserving changes The main theorem paper readily follows Theorem 4 Completeness The Augmented FCI algorithm additional tail inference rules R5R10 complete sense given perfect conditional independence oracle algorithm returns maximally informative PAG true causal MAG Proof Theorem 2 implies circle edges AFCI output MAG Markov equivalent true causal MAG circle marked arrowhead Theorem 3 implies case circle edges Hence circle AFCI output invariant tail Together arrowheadcompleteness result shown AFCI algorithm complete cid2 5 Conclusion Causal discovery data especially challenging possibility latent confounding selection bias ruled Maximal ancestral graphs provide neat representation causal systems explicitly troducing unobserved variables facilitates automated search classes causal structures based correlational 1886 J Zhang Artiﬁcial Intelligence 172 2008 18731896 information We established completeness result framework concerning extent causal infor mation extracted facts probabilistic independence dependence standard causal Markov Faithfulness assumptions Although presented result context FCI algorithm signiﬁcance goes particular algo rithm effect shown orientation rules R0R10 provide complete characterization invariant marks Markov equivalence class MAGs In particular given arbitrary MAG orientation rules identify invariant marks This useful causal discovery algorithm causal reasoning based MAGs The orientation rules fall naturally independent blocks R0R4 arrowhead complete R5R7 relevant selection bias present In fact common literature consider latent confounding selection bias case R5R7 ignored serve check assumption selection bias Moreover selection bias directed edge causal MAG carries especially clear qualitative causal information R8R10 particularly valuable pick directed edges missed R0R4 Besides constraintbased approach causal discovery FCI algorithm representative scorebased Bayesian approach causal discovery literature 714 It ongoing project develop score based causal discovery procedure based MAGs Not orientation rules relevant problem Theorem 2 Section 41 probably useful purpose scoring equivalence class MAGs gives procedure constructing representative MAG fewest undirected edges bidirected edges We close noting related open problems First implicitly assumed substantial background causal knowledge available causal MAG determined Markov equivalence When prior causal knowledge limited experimental control available possible discriminate Markov equivalent MAGs edge marks invariant ones true causal MAG identiﬁable How adapt AFCI algorithm handle background knowledge adapted algorithm complete worth investigating Second emphasized completeness result regard causal information inferred probabilistic independence dependence facts But kind probabilistic facts infor mative causation In fact known causal DAGs latent variables entail testable constraints marginal probability observed variables form conditional independence 31 illu minating discussion Such constraints retained MAG representation underlying causal structure This limitation MAG framework effectively employ nonindependence constraints automated causal discovery remains intriguing open question Acknowledgements I thank Peter Spirtes Thomas Richardson suggestions especially time checking proofs I grateful referees useful comments Appendix A Proof Lemma 41 Theorem 2 We need utility lemmas PAFCI Lemma A1 In PAFCI following property holds P1 vertices A B C A B C edge A C arrowhead C A C Furthermore edge A B A B edge A C A C AC A C This key lemma proving arrowhead completeness concerns R0R4 extra inference rules supply arrowheads See proof Lemma 41 2 formulated different equivalent way We omit details space Lemma A2 In PAFCI following property holds P2 For vertices A B AB edge A B Proof By P1 AB PAFCI edge C B edge C A So suﬃces prove edge A Let E XY PAFCIZ st Z X PAFCI We need E Suppose Let X0Y 0 E ﬁrst member E gets orientedie tail marks edges E oriented X0Y 0 oriented X0Y 0 Choose Z0 Z0 X0 PAFCI Since X0Y 0 oriented X0Y 0 R6 R7 consider cases Case 1 It oriented R6 That means vertex W W X0 PAFCI But Z0 X0W violates a3 deﬁnition ancestral graphs contradicts soundness PAFCI J Zhang Artiﬁcial Intelligence 172 2008 18731896 1887 Case 2 It oriented R7 That means time orientation vertex W W Y 0 adjacent edge W X0 This implies W X0 W X0 appears PAFCI arrowhead added R5R10 The case ruled a3 deﬁnition ancestral graphs In case Z0 X0 PAFCI P1 Z0 W PAFCI But W X0 E gets oriented X0Y 0 contradicts choice X0Y 0 Hence supposition E false CP2 holds PAFCI cid2 Call cid4V 0 V ncid5 tailcircle path V 0 V n 0 cid2 cid2 n 1 edge V V i1 V iV i1 Lemma A3 In PAFCI following hold For AB uncovered tailcircle path endpoint undirected edge B ends edge AB ii If p uncovered tailcircle path nonconsecutive vertices p adjacent Proof Let TC set edges PAFCI Order members TC order occurrence orientation process We induction Base case Let XY ﬁrst edge TCthat gets oriented member TC Of mark inference rules R6 R7 yield edges If XY oriented R6 obviously X endpoint undirected edge Suppose XY oriented R7 means vertex Z Z Y adjacent Z XY conﬁguration point orienting XY If Z X remains PAFCI belongs TC occurs earlier XY contradicts choice XY So PAFCI Z X inference rule orient Hence X endpoint undirected edge Then XY uncovered tailcircle path endpoint undirected edge Y Inductive step Suppose ﬁrst n edges TC satisfy consider n 1st edge U W TC Again oriented R6 R7 If oriented R6 U endpoint undirected edge U W constitutes uncovered tailcircle path U W Suppose oriented R7 vertex V V W adjacent V U W conﬁguration point orienting XY If V U remains PAFCI ﬁrst n edges TC By inductive hypothesis uncovered tailcircle path p endpoint undirected edge U includes edge V U Since V W adjacent p appended U W constitutes uncovered tailcircle path endpoint undirected edge W If hand V U PAFCI V U makes U endpoint undirected edge U W desired path Therefore edge TC property stated holds Next prove ii If p edge proposition trivially holds pair nonconsecutive vertices p edges proposition trivially holds p uncovered pair nonconsecutive vertices p deﬁnition nonadjacent Now suppose proposition holds uncovered circletail paths fewer n edges Consider covered circletail path n edges V 0V 1 V n1V n By inductive hypothesis pair nonconsecutive vertices adjacent V 0 V n By P2 Lemma A2 edge V 0 V n V 0 V n It undirected edge circle V n V n1V n oriented R6 However cid4V 0 V 1 V n1 V n V 0cid5 forms uncovered cycle edges cycle ori ented R5 anyedge appears contradicts fact noedge cycle So V 0 V n adjacent cid2 The main use Lemma A3 establish properties PAFCI Lemma A4 In PAFCI following property holds P3 For vertices A B C ABC A C adjacent Furthermore ABC AC ABC A C AC Proof The ﬁrst claim obvious If ABC A C adjacent circle B BC oriented R7 Suppose speciﬁcally ABC Consider edge A C P1 Lemma A1 implies C P2 Lemma A2 implies A It undirected circle C BC oriented R6 Hence 1 AC 2 AC 3 AC We 1 2 impossible Suppose contradiction 1 2 case By Lemma A3 uncovered tailcircle path p E endpoint undirected edge B includes edge AB We claim vertex V p V C V C present The argument goes induction Obviously B A satisfy claim Suppose starting 1888 J Zhang Artiﬁcial Intelligence 172 2008 18731896 B nth vertex p V n satisﬁes claim Consider n 1st vertex p V n1 Since p tailcircle path V n1V n By inductive hypothesis V nC V nC So established V n1 C adjacent Again P1 implies edge C P2 implies edge V n1 The edge undirected circle C BC oriented R6 Furthermore ii Lemma A3 V n1 B adjacent So edge V n1 C V n1C circle C CB oriented R7 It follows V n1C V n1C Therefore vertex p particular endpoint E satisﬁes claim So EC EC occurs But E endpoint undirected edge circle E EC EC oriented Contradiction Hence 1 2 case means AC occurs PAFCI On hand ABC occurs PAFCI P2 implies edge A C A presence AB It follows edge mark C tail PAFCI sound arrowhead incident undirected edge P2 violated arrowhead incident edge Note edge mark C circle P1 violated Hence edge mark C arrowhead edge A C AC cid2 Lemma A5 In PAFCI following property holds P4 For AB tailcircle path B A That cycle ABC A Proof We ﬁrst argue cycle PAFCI cycle edges ABC A To note cycle c cid4V 0 V 1 V 2 V n V 0cid5 edges c uncovered edge c oriented R5 That means consecutive triple c shielded Without loss generality suppose cid4V 0 V 1 V 2cid5 shielded V 0 V 2 adjacent The edge V 0 V 2 contain arrowhead Lemma A2 shows undirected circle c oriented R6 implied Lemma A4 V 0V 1V 2 present So V 0V 2 V 2V 0 In case shorter cycle c consists edges Hence established cycle edges shorter It follows cycle edges So prove P4 suﬃces ABC A impossible Suppose contradiction ABC A appears PAFCI By Lemma A3 uncovered tailcircle path p E endpoint undirected edge B includes edge AB We claim vertex V p A E including A E CV present PAFCI The argument induction The vertex A supposition satisﬁes claim Suppose starting A nth vertex p V n satisﬁes claim Consider n 1st vertex p V n1 Since p tailcircle path V n1V n By inductive hypothesis CV n So Lemma A4 V n1 C adjacent Lemma A2 implies edge vertex The edge undirected circle C BC oriented R6 Furthermore ii Lemma A3 V n1 B adjacent Since BC edge V n1 C oriented CV n1 Therefore vertex A E particular endpoint E satisﬁes claim But E endpoint undirected edge circle E CE oriented This contradiction cid2 With P1P4 ready prove Lemma 41 Theorem 2 Lemma 41 For edge AB P C oriented DAG unshielded colliders A B appears AFCI oriented DAG unshielded colliders A B appears AFCI P C Proof Given Lemma 5 17which showed chordal undirected graphs desired propertyit suﬃces P C AFCI chordal Suppose sake contradiction chordless cycle edges P C AFCI Let cid4V 0 V 1 V 2 V 3 V 0cid5 shortest cycle implies nonconsecutive vertices cycle adjacent P C AFCI For pair nonconsecutive vertices V V j adjacent PAFCI The reason V V j connected circle path PAFCI given easy derive P1 P3 V V j adjacent PAFCI edge adjacent P C AFCI Therefore cycle remains shortest chordless cycle consisting edges PAFCI oriented R5 A contradiction cid2 Theorem 2 Let H graph resulting following procedure applied PAFCI 1 orient circles edges PAFCI tails orient circles edges PAFCI arrowheads turn edges edges directed edges AFCI DAG unshielded colliders 2 orient P C Then H member GT J Zhang Artiﬁcial Intelligence 172 2008 18731896 1889 Proof For space details easy construct given sketch Most details extremely similar proof Theorem 42 2 P2 P4 ensure turning circles edges arrowheads create directed cycle directed cycle P1 P3 ensure turning circles edges tails create directed cycle directed cycle So operation 1 directed cycle directed cycle created For operation 2 P1 P3 guarantee matter orient edge yield directed cycle AFCI oriented DAG directed cycle AFCI So P C directed cycle involves edge outside P C directed cycle created H Furthermore new undirected edges bidirected edges created constructing H undirected edge bidirected edge H PAFCI It easy given soundness PAFCI H edge vertex incident undirected edge inducing path nonadjacent vertices Therefore H ancestral maximal To Markov equivalence H GT need check conditions Proposition 2 satisﬁed They adjacencies given correctness adjacency inference step FCI algorithm P2 P3 ensure turning circles edges PAFCI arrowheads create new unshielded collider P1 implies matter orient edge create new unshielded collider involves edge outside P C AFCI So P C AFCI oriented DAG unshielded colliders unshielded colliders PAFCI constructed H So H GT unshielded colliders Finally new bidirected edges created constructing H hard verify condition e3 Proposition 2 concerning discriminating paths It follows H member GT cid2 Appendix B Proof Lemma 42 Theorem 3 The proof Lemma 42 diﬃcult argument requires utility lemmas Again space note skip easy similar steps We begin noting facts uncovered pd paths Deﬁnition 10 PAFCI Lemma B1 If p cid4 A Bcid5 pd path A B PAFCI subsequence p forms uncovered pd path A B PAFCI Proof The proof induction length p If edge p trivially degenerate uncovered pd path A B If edges p p cid4 A C Bcid5 uncovered covered A B adjacent In case edge A B A B constitutes desired path A B We ﬁrst argue A Suppose contradiction mark A edge A B arrowhead Then edge A C circle mark A P1 Lemma A1 edge C B arrowhead C contradicts fact p potentially directed It follows edge A C tail A PAFCI Since edge A B A follows P2 Lemma A2 edge A C A C Then mark C edge C B arrowhead implied R2 contradiction So edge A B A Next B Suppose contradiction mark B edge A B tail Then AB AB The implies edge C B tail B R6 contradicts fact p potentially directed So AB Then P2 implies arrowhead B Since p potentially directed edge C B B Hence mark B edge C B circle It easy check possible conﬁgurations consistent P1 P2 fact p potentially directed ACB ACB ACB ACB The ﬁrst cases contradict P3 Lemma A4 case contradicts P4 Lemma A5 The inductive step easy Suppose proposition holds length p n 1 n cid3 3 Consider case p n edges Either p uncovered triple cid4 X Y Z cid5 path shielded In case foregoing argument edge X Z X Z So replace cid4 X Y Z cid5 edge X Z p subsequence p pd path A B length n 1 By inductive hypothesis subsequence new path subsequence p forms uncovered pd path A B cid2 Lemma B2 If p uncovered pd path A B PAFCI edge p edge p edge edge p edge ii p include edge edge iii edge p Proof To true notice p uncovered potentially directed edge edge edge p oriented R1 So appear edge p appear edge 1890 J Zhang Artiﬁcial Intelligence 172 2008 18731896 p The true edge Since p uncovered edge p oriented R7 R1 ii iii evident given argument For iii note edge edge p oriented edge For ii suppose contradiction p contains edge edge Then edge appear edge p edge p oriented R1 On hand appear edge p edge p This contradiction cid2 Lemma B3 In PAFCI circle patha path consisting edgesbetween A B vertex C C A C B Proof This easily follows P1 cid2 Lemma B4 In PAFCI pd path A B edge A B A Proof By Lemma B1 uncovered pd path p A B Suppose contradiction edge A B A AB There edge p following reason ﬁrst edge incident A connected A circle path according Lemma B2 In case Lemma B3 edge tail endpoint edge contradicts P2 Lemma A2 So Lemma B2 p form A XY B A X edge andor X Y edge andor Y B directed edge If Y B easy P1 violated supposed presence AB If Y cid14 B P1 supposed presence AB entail edge B Y Y But Y ancestor B This contradicts soundness PAFCI Hence initial supposition AB false cid2 Lemma B5 In PAFCI pd path A B B uncovered pd path A B B Proof Suppose contradiction uncovered pd path A B B Then edge path It light P2 pd path B It follows Lemma B2 path circle path Let C vertex adjacent B pd path B C B It follows Lemma B3 C A But pd path A C contradicts Lemma B4 cid2 Corollary B6 In PAFCI A B adjacent pd path A B B edge A B AB A B Proof This easily follows Lemmas B4 B5 A2 cid2 Lemma B7 If circle path adjacent vertices PAFCI edge vertices Proof This easy given P1 Lemma B3 P3 cid2 Lemma B8 Let u uncovered circle path PAFCI If A B nonconsecutive vertices u A B adjacent PAFCI Proof It follows Lemma B7 fact P C AFCI chordal cid2 The lemmas useful facts edges REL J K Deﬁnition 11 Lemma B9 For AB REL J K uncovered pd path u J B PAFCI vertex V u B edge V K Proof The lemma holds trivially A J B K Suppose A cid14 J B cid14 K By Deﬁnition 11 pd path J A PAFCI vertex path including endpoints parent K Note B pd path pd path B A presence AB contradict Lemma B4 So concatenate pd path AB form pd path J B B In light Lemma B1 follows uncovered pd path u J B vertex u B parent K We prove induction vertex V u B edge V K PAFCI The base case J K obvious Suppose holds nth vertex u V n Consider V n1 cid14 B Since B cid14 K Deﬁnition 11 B parent K This implies pd path V n1 K By Corollary B6 V n1 K J Zhang Artiﬁcial Intelligence 172 2008 18731896 1891 adjacent edge V n1 K V n1K But vertex u B parent K suﬃces V n1 adjacent K Suppose It easy circle V n V nK oriented R9 contradiction Therefore V n1 K adjacent edge V n1K PAFCI cid2 Lemma B10 If AB REL J K AK appears PAFCI Proof The lemma trivially holds A J B K Suppose A cid14 J B cid14 K Since AB REL J K uncovered pd path u J B satisfying condition Lemma B9 By Lemma B5 know u B Let X B edge u By Lemma B9 XK PAFCI Also B cid14 K B K PAFCI edge X B X B XK oriented R8 It follows edge XB PAFCI Note A K adjacent path cid4 A B X K cid5 discriminating path X Deﬁnition 7 Hence circle XK oriented R4 contradiction So A adjacent K By Corollary B6 edge A K A K AK But Deﬁnition 11 A parent K AK PAFCI cid2 Our goal course Orientation Algorithm violation C1C3 Deﬁnition 12 occur The block lemmas important steps goal They showing choose edge orient away violation C1C3 Orientation Algorithm orientation trigger violation C1C3 applications UR1 Lemma B11 For vertices B C AR J K uncovered circle path B C consisting edge PAFCI Proof Given Lemma B8 suﬃces B C adjacent This obviously true B C K Suppose B cid14 K C cid14 K parents K Deﬁnition 11 Let A vertex AB REL J K It follows Lemma B3 AC A C PAFCI But A C AK shown present Lemma B10 oriented R8 So AC Then B C adjacent AK oriented R10 cid2 Lemma B12 Suppose AB REL J K If AC appears PAFCI C parent B PAFCI edge AC required condition C2 oriented A C C parent K PAFCI Proof If B K trivial Suppose B cid14 K B parent K By Lemma B10 AK present PAFCI It follows C adjacent K cid4C B A K cid5 constitute discriminating path A PAFCI orient AK R4 Furthermore edge C K C K required R2 R8 Hence C parent K cid2 Lemma B13 Suppose AB REL J K AC C parent B PAFCI edge AC required condition C2 oriented A C Then 1 D AR J K CD PAFCI C AR J K edge CD subject C1 2 If u cid4C A cid5 uncovered circle path vertex u possibly C AR J K Proof To 1 note D AR J K vertex X XD REL J K By P1 Lemma A1 XC X C PAFCI By Lemma B12 C parent K So X C PAFCI XK shown present Lemma B10 oriented X K R8 So XC PAFCI Since XD REL J K C parent K XC satisﬁes Deﬁnition 11 means C AR J K To prove 2 suppose contradiction vertex E cid14 C u AR J K Obviously E cid14 K AE present PAFCI Lemma B10 contradicts Lemma B3 So E parent K Now consider edge AK shown exist Lemma B10 AC uncovered pd path A C parent K Lemma B12 u A E uncovered pd path A E parent K Since u uncovered AK oriented A K R10 contradiction cid2 Lemma B14 For uncovered circle path u cid4 A Ecid5 PAFCI edge incident A required C2 oriented A edge incident E required C2 oriented E Proof Suppose contradiction contrary true By Lemma B12 A E parents K Let B vertex adjacent A u By supposition Deﬁnition 12 vertex C BC REL J K A parent C Consider BK cf Lemma B10 B A constitutes uncovered pd path B A parent K uB E constitutes uncovered pd path B E parent K A E adjacent Lemma B8 Thus BK oriented B K R10 contradiction cid2 1892 J Zhang Artiﬁcial Intelligence 172 2008 18731896 Lemma B15 If AB REL J K u cid4 A C cid5 uncovered circle path C adjacent B PAFCI edge A C required C3 oriented A C vertex u parent K PAFCI Proof Since AB REL J K Lemma B10 AK present PAFCI Suppose contradiction vertex D C u parent K We consider possible cases Case 1 B K K C adjacent means D C case So u A D D K pd path A K vertex adjacent A path C adjacent K Let E ﬁrst vertex C path adjacent K D adjacent K The edge E K Corollary B6 EK E K It follows cid4 A C E K cid5 forms uncovered pd path A K C K adjacent Hence AK oriented A K R9 contradiction Case 2 B K PAFCI Then u A D uncovered pd path A D parent K AB uncovered pd path A B parent K Since C B adjacent edge AK oriented A K R10 contradiction cid2 Lemma B16 Suppose AB CD REL J K A cid14 C u cid4 A Ccid5 uncovered circle path PAFCI Either vertex A u adjacent B C3 require orienting edge A vertex C u adjacent D C3 require orienting edge C Proof Suppose contradiction contrary true We consider cases separately derive contradiction Case 1 B D In case D adjacent vertex C u u CB uncovered pd path A B vertex adjacent A path adjacent B Hence AB oriented R9 A B contradiction Case 2 B cid14 D K Without loss generality suppose B K Since CD REL J K D cid14 K Deﬁnition 11 D parent K B Then u CD constitutes uncovered pd path A D vertex adjacent A path adjacent B This situation Case 1 proof Lemma B15 leads contradiction Case 3 B cid14 D K So B D parents K Consider edge AK shown present Lemma B10 Since AB uncovered pd path A B parent K u CD uncovered pd path A D parent K vertex A u adjacent B edge AK oriented A K R10 contradiction cid2 Now time key lemma Lemma 42 Let D JK DAG output Orientation Algorithm D JK DAG orientation P C colliders agreeable J K AFCI free unshielded Proof As noted main text correctness Meeks algorithm 17 guarantees D JK DAG free shielded colliders We need agreeable Deﬁnition 12 In words need violation C1C3 occurs D JK Below details argument C1 The argument C2 C3 extremely parallel omit details Note violation occur occur end stage Orientation Algorithm edges E1 E2 E3 oriented So suﬃces stage violation C1 occurs In fact prove stronger We vertex W AR J K edge gets oriented W end stage Suppose sake contradiction orientation occurs Let ﬁrst occurrence AB oriented A B B AR J K We consider possible ways orientation occur derive contradiction We assume loss generality UR1 priority UR2 UR3 Case 1 AB oriented A B satisfy C1C3 Since B AR J K C1 dictate orientation Neither C2 entailed 2 Lemma B13 So C3 means vertex E AE REL J K E B adjacent Then Lemma B15 implies B parent K Furthermore Lemma B10 AK present PAFCI implies B cid14 K AB It follows B AR J K contradiction Case 2 AB oriented A B application UR222 That vertex C ACB P C AFCI oriented A C B AB oriented Then CB oriented C B earlier occurrence orientation B This contradicts choice AB Case 3 AB oriented A B application UR3 Again easy contradicts assumption A B ﬁrst orientation B 22 The case UR1 complicated considered J Zhang Artiﬁcial Intelligence 172 2008 18731896 1893 Case 4 AB oriented A B application UR1 Generically possibly step chain applications UR1 uncovered circle path initiated directed edge oriented UR1 Regarding ﬁrst initiating edge subcases consider Case 41 ﬁrst edge oriented satisfy C1C3 It C1 AFCI edge vertices AR J K contradicts Lemma B11 uncovered circle path P C The rest goes exactly like argument Case 1 Case 42 ﬁrst edge oriented UR2 That vertices X Y Z Z A XY Z P C AFCI oriented X Y Z turn orients edge XZ X Z And X Z initiates chain UR1 applications uncovered circle path u cid4 X Z Bcid5 eventually leads orientation A B We claim vertex V u Z B including B edge Y V oriented Y V X Z oriented The argument induction For base case let V 1 ﬁrst vertex Z u V 1 B Z A Y V 1 adjacent P C AFCI Z V 1 oriented Z V 1 UR1 X Z oriented UR2 according convention priority UR1 Since X V 1 adjacent u uncovered Y V 1 oriented Y V 1 UR1 X Z oriented The inductive step extremely similar Therefore claim holds vertex V u Z B including B In particular Y B present X Z gets oriented AB gets oriented This contradicts choice AB Case 43 ﬁrst edge oriented UR3 That vertices X Y Z W Z A W Y Z W XZ XY P C AFCI W Z adjacent Furthermore W Y Z ori ented W Y Z turn orients edge XZ X Z This initiates chain UR1 applications uncovered circle path u cid4 X Z Bcid5 eventually leads orientation A B Notice W Z adjacent cid4W X Z Bcid5 uncovered circle path P C AFCI implies W adjacent vertex u Z B Then run exact argument Case 42 derive contradiction choice AB Therefore occurrence orienting edge W W AR J K end stage Orientation Algorithm It follows violation C1 occurs D JK The arguments C2 C3 extremely similar different utility lemmas cited23 We omit details save space tediousness cid2 To prove Theorem 3 need relatively simple facts PAFCI Lemma B17 For AB PAFCI pd path u AB A B vertex u adjacent A B Proof The argument easy induction length u upshot vertex AB oriented R9 cid2 Lemma B18 Suppose C AB PAFCI If C B adjacent AB REL J K AC REL J K Proof Suppose contradiction AB REL J K AC REL J K By Lemma B10 AK PAFCI It follows B cid14 K C cid14 K B C adjacent Then Deﬁnition 11 B C parents K implies AK oriented R10 C B adjacent contradiction cid2 Finally prove Theorem 3 Theorem 3 Let J K edge PAFCI Construct H PAFCI following procedure 1 orient edges REL J K orient edges 2 orient edges PAFCI 3 orient P C AFCI D JK Orientation Algorithm Then H member GT Proof By Theorem 2 construct member GT turning edges edges directed edges orienting P C AFCI D JK Denote member H JK It suﬃces H MAG Markov equivalent H JK 23 The argument C2 identical The C3 slightly complicated exact structure 1894 J Zhang Artiﬁcial Intelligence 172 2008 18731896 Notice difference regard edges REL J K correspond directed edges H JK bidirected edges H In follows REL J K transformed H series changes directed edges bidirected edges edge time change preserve MAGness Markov equivalence Our theorem follows To suﬃces establish following Let M MAG identical H JK possibly edges REL J K oriented instead M Note H JK MAG Let DIFF cid2 cid3 A B M AB PAFCI AB REL J K We DIFF edge changed preserving MAGness Markov equivalence M In words long M H different identify directed edge M corresponds edge REL J K safely change bidirected edge decrease number differences M H If true obviously desired transformation H JK H We prove true Suppose DIFF Let W B A st A B DIFF W nonempty Let Y member W proper ancestor Y M belongs W Let X vertex X Y DIFF proper descendant X M property Let M graph resulting changing X Y M X Y We M MAG Markov equivalent M Obviously directed cycle created change It create directed cycle directed path X Y M edge X Y Suppose sake contradiction directed path X Y M contain X Y The corresponding path PAFCI potentially directed It follows Lemma B17 vertex Z path adjacent X Y Since M MAG X Z Y M corresponding path cid4 X Z Y cid5 PAFCI potentially directed Notice edge Z Y Z Y PAFCI according P2 Lemma A2 XY present So deﬁnition pd path edge X Z XZ X Z XZ XZ edge Z Y Z Y Z Y Z Y But 12 combinations possible It tedious So illustrate kind argument considering possible XZ Y appear PAFCI Suppose possible Then Z AR J K XZ REL J K Z proper ancestor Y M contradicts choice Y However Z Y oriented Z Y means D JK agreeable J K C1 violated This contradicts Lemma 42 The 11 cases similarly easily handled derive contradiction So initial supposition directed path X Y X Y M false directed cycle M Moreover conﬁguration M violates a3 Deﬁnition 1 Suppose contrary true Then But obvious Z X PAFCI means conﬁguration Z X Y Z M XY PAFCI oriented R6 contradiction So M ancestral maximal Markov equivalent M For purpose established What left M Zhang Spirtes 35 Lemma 1 30 suﬃces following hold M T2 For Z X M edge Z Y M Z X M edge Z Y Z Y M T3 In M discriminating path X Y endpoint adjacent X We ﬁrst establish T2 For Z X M corresponds Z X Z X Z X Z X PAFCI We claim Z Y adjacent case In cases P1 Z Y adjacent XY PAFCI In case Z X oriented Z X M Z adjacent Y D JK agreeable J K contradicts Lemma 42 In case Z X P3 Z Y adjacent Moreover edge Z Y Z Y M Z X Y M M MAG For Z X M corresponds Z X Z X Z X PAFCI In cases Z Y adjacent P1 In case Z X REL J K assumption bidirected edges M It follows Lemma B18 Z Y adjacent So case Z Y adjacent M Moreover M MAG edge Z Y Z Y Z Y M T2 true For T3 suppose sake contradiction M path p V 0 V 1 V n X Y discriminating X Without loss generality suppose p shortest path Below derive contradiction eventually showing p discriminating path PAFCI circle X XY oriented R4 Note ﬁrst subpath pV 0 X X M directed path X Y edge X Y follows deﬁnition discriminating path It follows edge subpath pV 1 X bidirected M Next claim PAFCI edge V 0 V 1 V 0 V 1 V 1 Suppose contradiction contrary true Then mark V 1 circle Hence edge V 0V 1 V 0V 1 V 0V 1 PAFCI In cases derive contradiction And facts useful showing V 1 V 2 V 2 X appears M noted ii In PAFCI isnt edge V 0 V 2 V 2 J Zhang Artiﬁcial Intelligence 172 2008 18731896 1895 For cid4V 0 V 2 V n X Y cid5 constitutes shorter discriminating path M V 2 cid14 X XY PAFCI oriented X Y R1 V 2 X contradiction Again wont cases use complicated case illustrate argument Consider V 0V 1 Suppose true PAFCI Then V 1 V 2 PAFCI Lemma B3 edge V 0 V 2 PAFCI contradicts fact ii By assumption bidirected edges M V 1V 2 V 1V 2 appears PAFCI belongs REL J K In case V 1V 2 V 0 adjacent V 2 orientation V 0V 1 V 0 V 1 agreeable J K C3 violated By Corollary B6 edge V 0 V 2 V 0 V 2 V 0V 2 PAFCI contradicts fact 2 In case V 1V 2 Lemma B3 V 0 V 2 V 0V 2 PAFCI Now V 0 parent K means V 0 AR J K V 0 cid14 K Y belongs AR J K adjacent V 0 deﬁnition discriminating path orientation V 0V 1 V 0 V 1 agreeable C1 violated So V 0 parent K implies Y cid14 K But edge V 2K implied present PAFCI Lemma B10could oriented V 2 K R10 V 0 Y adjacent deﬁnition discriminating path edge V 2 V 0 PAFCI constitutes uncovered pd path V 2 V 0 edge V 2 Y constitutes uncovered pd path PAFCI V 2 Y contradiction The cases handled easily It follows edge V 0 V 1 PAFCI V 0 V 1 Finally supposed p discriminating path X PAFCI We prove induction 1 cid2 cid2 n 1 V collider p PAFCI parent Y PAFCI Consider V 1 base case Since shown V 0 V 1 appears PAFCI V 0 adjacent Y edge V 1 Y V 1 Y PAFCI virtue R1 So V 1 parent Y PAFCI Suppose contradiction V 1 collider p PAFCI Since V 0 V 1 PAFCI V 1 V 2 M edge V 1 V 2 V 1V 2 PAFCI And assumption bidirected edges M V 1V 2 REL J K Then Lemma B10 implies edge V 1K PAFCI But Y K Y parent K PAFCI implies V 1 parent K oriented parent K R8 PAFCI contradiction So V 1 collider p PAFCI parent Y PAFCI The inductive step similar invoke R4 base case invoked R1 Therefore T3 true This concludes proof cid2 References 1 RA Ali T Richardson P Spirtes Markov equivalence ancestral graphs Technical Report 466 Department Statistics University Washington 2004 2 RA Ali T Richardson P Spirtes Proceedings 21th Conference Uncertainty Artiﬁcial ables httpwwwstatwashingtoneduwwwresearchreports2005tr476pdf J Zhang Towards characterizing Markov equivalence classes directed acyclic graphs latent vari Intelligence AUAI Press 2005 pp 1017 Full version available 3 F Artzenius The common cause principle D Hull K Okruhlik Eds Philosophy Science Proceeding vol 2 East Lansing MI 1992 pp 227237 4 SA Andersson D Madigan MD Perlman A characterization Markov equivalence classes acyclic digraphs The Annals Statistics 25 2 1997 505541 5 KA Bollen Structural Equations Latent Variables Wiley New York 1989 6 N Cartwright The Dappled World Cambridge University Press Cambridge 1999 7 DM Chickering Optimal structure identiﬁcation greedy search Journal Machine Learning Research 3 2002 507554 8 P Dawid Conditional independence statistical theory Journal Royal Statistical Society Series B 41 1979 131 9 M Drton T Richardson Iterative conditional ﬁtting Gaussian ancestral graph models Proceedings 20th Conference Uncertainty Artiﬁcial Intelligence Morgan Kaufmann 2003 pp 130137 10 M Drton T Richardson Graphical answers questions likelihood inference Gaussian covariance models Technical Report 467 Department Statistics University Washington 2004 11 D Geiger D Heckerman H King C Meek Stratiﬁed exponential families graphical models model selection The Annals Statistics 29 2001 505529 12 C Glymour G Cooper Eds Computation Causation Discovery MIT Press Cambridge MA 1999 13 DM Hausman J Woodward Independence invariance causal Markov condition British Journal Philosophy Science 50 1999 521 583 14 D Heckerman C Meek GF Cooper A Bayesian approach causal discovery C Glymour G Cooper Eds Computation Causation Discovery MIT Press Cambridge MA 1999 pp 141165 15 KD Hoover Causality Macroeconomics Cambridge University Press Cambridge 2001 16 MA Klopotek On deﬁciency FCI algorithm learning Bayesian networks data Demonstratio Mathematica XXXIII 1 2000 181194 17 C Meek Causal inference causal explanation background knowledge Proceedings Eleventh Conference Uncertainty Artiﬁcial Intelligence Morgan Kaufmann 1995 pp 403411 18 RE Neapolitan Learning Bayesian Networks Prentice Hall Upper Saddle River NJ 2004 19 J Pearl Probabilistic Reasoning Intelligent Systems Morgan Kaufmann San Mateo California 1988 20 J Pearl Causality Models Reasoning Inference Cambridge University Press Cambridge UK 2000 21 T Richardson Models Feedback Interpretation Discovery PhD Thesis Department Philosophy Carnegie Mellon University 1996 22 T Richardson Chain graphs symmetric associations M Jordan Ed Learning Graphical Models Kluwer Dordrecht 1998 pp 231259 23 T Richardson P Spirtes Ancestral graph Markov models The Annals Statistics 30 4 2002 9621030 24 T Richardson P Spirtes Causal inference ancestral graph models P Green N Hjort S Richardson Eds Highly Structured Stochastic Systems Oxford University Press 2003 pp 83105 25 P Spirtes C Glymour R Scheines Causation Prediction Search SpringerVerlag New York 1993 second ed MIT Press Cambridge MA 2000 26 P Spirtes C Meek T Richardson An algorithm causal inference presence latent variables selection bias C Glymour G Cooper Eds Computation Causation Discovery MIT Press Cambridge MA 1999 pp 211252 1896 J Zhang Artiﬁcial Intelligence 172 2008 18731896 27 P Spirtes T Richardson A polynomial time algorithm determining DAG equivalence presence latent variables selection bias Proceedings 6th International Workshop Artiﬁcial Intelligence Statistics 1996 httpciteseeristpsueduspirtes97polynomialhtml 28 P Spirtes T Verma Equivalence causal models latent variables Technical Report Phil36 Department Philosophy Carnegie Mellon University 1992 29 D Steel Homogeneity selection faithfulness condition Minds Machines 16 2006 303317 30 J Tian Generating Markov equivalent maximal ancestral graphs single edge replacement Proceedings 21th Conference Uncertainty Artiﬁcial Intelligence AUAI Press 2005 pp 591598 31 J Tian J Pearl On testable implications causal models hidden variables Proceedings 18th Conference Uncertainty Artiﬁcial Intelligence Morgan Kaufmann 2002 pp 519552 32 T Verma J Pearl Equivalence Synthesis Causal Models Proceedings 6th Conference Uncertainty Artiﬁcial Intelligence 1990 pp 220227 33 J Zhang Causal inference reasoning causally insuﬃcient systems PhD Thesis Department Philosophy Carnegie Mellon University 2006 available wwwhsscaltechedujijidissertationpdf 34 J Zhang Causal reasoning ancestral graphs Journal Machine Learning Research 9 2008 14371474 35 J Zhang P Spirtes A transformational characterization Markov equivalence directed acyclic graphs latent variables Proceedings 21th Conference Uncertainty Artiﬁcial Intelligence AUAI Press 2005 pp 667674 36 J Zhang P Spirtes Detection unfaithfulness robust causal inference Minds Machines 18 2008 239271 37 H Zhao Z Zheng B Liu On Markov equivalence maximal ancestral graphs Science China Mathematics 48 4 2005 548562