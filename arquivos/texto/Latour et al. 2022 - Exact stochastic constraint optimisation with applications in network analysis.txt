Artiﬁcial Intelligence 304 2022 103650 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Exact stochastic constraint optimisation applications network analysis Anna LD Latour Holger H Hoos ac Siegfried Nijssen d LIACS Leiden University PO Box 9512 2300 RA Leiden Netherlands b Polytechnique Montréal Montréal Québec H3T 1J4 Canada c University British Columbia Vancouver British Columbia V6T 1Z4 Canada d ICTEAM UCLouvain Place SainteBarbe 2 bte L50201 B1348 LouvainlaNeuve Belgium Behrouz Babaki b Daniël Fokkinga Marie Anastacio r t c l e n f o b s t r c t Article history Received 15 August 2020 Received revised form 8 October 2021 Accepted 4 December 2021 Available online 10 December 2021 Keywords Constraint programming Probabilistic inference Stochastic constraints Ordered binary decision diagrams Monotonic probability distributions Global constraints Automated algorithm conﬁguration Probabilistic networks We present extensive study methods exactly solving stochastic constraint optimisation problems SCPs network analysis These problems prevalent science governance industry The ﬁrst method study generic decomposes stochastic constraints multitude smaller local constraints solved constraint programming CP mixedinteger programming MIP solver However SCPs formulated probability distributions monotonic property meaning adding positive decision partial solution problem cause decrease solution quality The second method speciﬁcally designed solving global stochastic constraints monotonic probability distributions SCMDs CP Both methods use knowledge compilation obtain decision diagram encoding relevant probability distributions focus ordered binary decision diagrams OBDDs We discuss theoretical advantages disadvantages methods evaluate experimentally We observed global approaches solving SCMDs outperform decomposition approaches CP perform complementarily MIP based decomposition approaches scaling favourably instance size Both methods alternative design choices knowledge compilation constraint solvers single pipeline To identify conﬁgurations work best apply programming optimisation Speciﬁcally automated algorithm conﬁgurator ﬁnd optimised conﬁgurations pipeline After conﬁguration global SCMD solving pipeline outperforms closest competitor MIP based decomposition pipeline test sets considered orders magnitude terms PAR10 scores 2021 The Authors Published Elsevier BV This open access article CC BY license httpcreativecommonsorglicensesby40 1 Introduction In business governance science daily lives solve problems involve optimal decision making constraints uncertainty Examples problems arise planning scheduling Corresponding authors miaanastacioliacsleidenunivnl M Anastacio hhliacsnl HH Hoos siegfriednijssenuclouvainbe S Nijssen Email addresses aldlatourliacsleidenunivnl ALD Latour behrouzbabakipolymtlca B Babaki dbfokkingaumailleidenunivnl D Fokkinga httpsdoiorg101016jartint2021103650 00043702 2021 The Authors Published Elsevier BV This open access article CC BY license httpcreativecommonsorglicensesby40 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 occur naturally ﬁelds data mining bioinformatics Given abundance relational data areas problems involve probabilistic network data Consider example following spread inﬂuence problem studied data mining literature 2641 We given social network people vertices stochastic inﬂuence relationships edges To promote new product want rely wordofmouth advertisement turn acquaintances people buy product new customers We start process infecting set people network giving free sample The budget marketing campaign limited constraint distribute k samples Each person customer inﬂuence friends customer certain probability Given social network k people free samples order maximise expected number eventual customers objective We note adding person set people receive free product sample decrease expected number people eventually infected viral campaign Another example optimisation variant power transmission grid reliability problem 29 We given power transmission network power lines power producers power consumers transmission stations Natural disasters earthquakes hurricanes cause power lines break breaks occur households lose power We reinforce power lines likely break natural disaster given budget b upgrades constraint Which power lines reinforce maximise expected number households power natural disaster objective exceeding budget Note adding power line set lines reinforced decrease expected number households power disaster A example enumeration problem aimed ﬁnding sets members social network ex pectation highly inﬂuential certain communities distribution fake news Using probabilistic spreadof inﬂuence framework similar described combine framework frequent itemset mining FIM 1 approach associated constraint Here repeatedly solve constraint satisfaction problem ﬁnd solutions problem instead solving optimisation problem These problems instances general class problems known stochastic constraint optimisation problems SCPs SCPs following characteristics They involve decision variables stochastic random variables They involve reasoning typically complex probability distributions They involve possibly complex constraints limit decisions The problems described feature fourth characteristic The probabilities expectations higher nodes edges selected makes probability dis tributions monotonic We special cases SCPs stochastic constraint optimisation problems monotonic distributions SCPMDs While fourth characteristic limiting problems property plentiful network analysis examples include applications mentioned signallingregulatory pathway inference problem described bioinformat ics literature 2452 variant landscape connectivity 74 We discuss relation SCPs SCPMDs problems Section 10 Both SCPs SCPMDs diﬃcult solve exactly way produces provably optimal solutions Wellknown instances SCPMDs spread inﬂuence problems NPhard 41 Calculation probability probabilistic networks requires solving counting problem known Pcomplete 62 Exact solving requires ﬁnding optimal solution search space grows exponentially problem size In work present main approaches solving SCPs exactly The ﬁrst based decomposing hard constraints probability distributions multitude local constraints applicable SCPs general The second designed solving SCPMDs applied exploiting structures result monotonicity obtain global constraint propagation algorithm solving stochastic constraints We discuss SCPs SCPMDs solve Section 2 The main algorithmic contributions work follows1 1 We present new versions constraint decomposition method solving SCPs 43 based ordered binary decision diagram OBDD 14 representations probability distributions Section 4 1 We presented earlier version work conference paper 44 This article extends earlier publication elaborate description propagation algorithm 44 new proofs additional contributions 46 Preliminary versions contributions 4 5 presented workshop paper 31 Here extended work including earlier approaches Latour et al 43 conﬁguration experiments signiﬁcantly extending design space methods 2 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 2 We decomposition approach generalised arc consistent GAC causing prune search space insuﬃciently straightforward arc consistent modiﬁcation approach signiﬁcantly im prove performance Section 42 3 To address ineﬃciency search introduce global constraint OBDD representations monotonic distributions stochastic constraint monotonic distributions SCMD introduce GACbydesign propagation algorithm constraint Section 5 In summary beneﬁts decomposition methods They applicable generic SCPs Section 4 Different types decision diagrams represent probability distributions Section 3 The implementation straightforward compatible different offtheshelf constraint programming CP solvers mixedinteger programming MIP solvers Section 7 Conversely beneﬁts global constraint speciﬁcally SCPMDs It guarantees GAC design contrary decomposition methods guarantee GAC traverses search space eﬃciently Section 52 Its space complexity better decomposition methods guarantee GAC Sections 42 54 Its worstcase time complexity O m n OBDD size m number decision variables n Section 54 It outperforms CPbased decomposition methods complements MIPbased methods scaling better OBDD size MIPbased methods Sections 7 9 Different design choices development solving method big impact overall eﬃciency approach different types problem instances especially hard problems SCPs SCPMDs We propose address problem applying programming optimisation PbO paradigm 36 decomposition global constraint optimisation methods obtain following additional contributions 4 We develop design alternatives different parts decompositionbased global constraint optimisation pipelines expose conﬁgurable parameters Section 84 5 We apply automated algorithm conﬁguration AAC 35 conﬁgurable algorithms demonstrate effective ness benchmarks application domains Section 93 6 We demonstrate optimised conﬁgurations methods generalise harder problems different problem settings Section 94 Note work compare methods speciﬁcally designed solving SCPs methods use offthe shelf solvers default settings However performance offtheshelf solvers depends signiﬁcantly conﬁguration Therefore use AAC help fairer comparison To best knowledge work represents ﬁrst time AAC applied exact solving methods probabilistic inference problems The remainder article organised follows We start describing SCPs SCPMDs Section 2 Then Section 3 discuss knowledge compilation help represent probability distributions way allows tractable online probabilistic inference We use representations turn constraints probability distributions CP MIP models decompositionbased approach Section 4 Section 5 describes global constraint solving SCPMDs performance compare performance CPbased decomposition methods Section 7 problem instances described Section 6 We brieﬂy discuss PbO AAC parameter space decomposition global stochastic constraint solving methods Section 8 In Section 9 use expanded conﬁguration spaces automated conﬁguration experiments Finally discuss related work Section 10 provide summary work outlook future work Section 11 2 Stochastic constraint optimisation problems We study stochastic constraint optimisation problems SCPs deﬁned Boolean decision variables We inter ested ﬁnding assignments truth values decision variables given constraints satisﬁed provided optimisation criterion optimised We refer assignments strategies The speciﬁc feature stochastic constraint satisfaction problems constraints optimisation criterion stochastic In section hard constraints probability distributions generic distributions distributions monotonicity property Then illustrate mathematically model SCPs described introduction Finally discuss solving kinds problems requires form counting 3 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 04 b 08 01 c 03 e A social network vertices b c e representing people undirected edges mutually independent probabilities representing stochastic inﬂuence relationships f e b c b A power transmission grid ﬁve vertices power pro ducer power consumers c e f transition station b Edge probabilities depend strategy fore omitted ﬁgure 21 Stochastic constraints probability distributions Fig 1 Two examples probabilistic networks The ﬁrst stochastic constraint study work form cid2 ρφ P φ σ θ 1 φcid3 The sum represents expected utility cid3 set stochastic events P φ σ represents probability event φ happening given strategy σ ρφ R reward event Speciﬁcally focus stochastic constraints φ represented propositional formula Boolean decision variables X σ X cid4 cid6 Boolean stochastic variables T variable t T takes value cid6 probability P t cid6 value probability P t 1 P t cid6 A special case constraint Equation 1 require probability distribution P φ σ monotonic deﬁne follows Deﬁnition 21 Let φ X T propositional formula Boolean decision variables X Boolean stochastic variables T deﬁned We probability distribution P φ σ monotonic distribution strategies σ d X following holds P φ σd P φ σdcid6 2 strategies σd σdcid6 differ truth values assign d cid6 respectively We deﬁne stricter notion local monotonicity Deﬁnition 31 use formally deﬁne stochastic constraint monotonic distributions SCMD Deﬁnition 51 We refer SCPs relevant probability distributions exhibit local monotonicity stochastic constraint optimisation problems monotonic distributions SCPMDs 22 Modelling SCPs Many problems probabilistic networks seen SCPs We illustrate running examples spread inﬂuence problem 2641 power grid reliability problem 29 Example 21 Spread inﬂuence SCP Consider network Fig 1a Edges represent probabilistic mutual inﬂuence lationships meaning person u inﬂuences person v probability puv labels edge u v The probability u inﬂuence v 1 puv We distribute free samples subset individuals probabilistically inﬂuence customers The objective maximise expected number people customer given limited number k free samples distribute people network We model follows With vertex network associate Boolean decision variable di cid6 representing person receives free sample We interested events cid3 φa φb φc φe φi denotes event person customer Our objective ﬁnd strategy σ maximises expected utility ﬁx ci 1 Constraint iabce ci di k threshold k N iabce ρi P φi σ ﬁx ρi 1 cid3 cid3 Example 22 Power grid reliability SCP Consider network Fig 1b Here edge represents power line u v probability puv remaining intact natural disaster This probability depend length terrain exists If lines damaged consumers lose power By spending money reinforce power line increase probability surviving disaster Our goal use budget b maintaining power 4 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 lines wisely expected number consumers power natural disaster maximised We simplifying assumption consumer power connected power source model problem follows We distinguish types stations power consumers V cons c e f power producers V prod transmission stations V trans b V cons V prod V trans V cons V prod V trans V set vertices network With power line u v L associate decision variable duv cid6 indicates power line reinforced We interested events cid3 φi V cons φi represents consumer connected power producer natural disaster Our objective ﬁnd strategy σ maximises expected utility Constraint iL ci di b threshold b N ci 1 cid3 cid3 iV cons ρi P φi σ ﬁx ρi 1 Note examples ﬁx ci ρi 1 reasons simplicity straightforward use alternative values Observe examples involves stochastic objective function stochastic constraint We straightforwardly employ constraints probability distributions solve maximisation problems expected utilities constraints In examples want maximise expected utility exceeding budget We solve problem ﬁrst writing constraint satisfaction problem repeatedly solving problem Thus start constraints cid2 0icid3 ρi P φi σ θ cid2 0i X ci di b setting θ 0 When ﬁnd solution σsol X cid4 cid6 constraint utility ρsol 0icid3 ρi P φi σsol update θ stochastic constraint longer satisﬁed setting θ ρsol We continue searching ﬁnd new solution exists guaranteed higher utility previously solution We repeat process ﬁnd new solution point θ represents maximum possible expected utility cid3 In order complete models problems described Examples 21 22 deﬁne probability events φi given strategy While formalisms deﬁning conditional probabilities use weighted model counting WMC approach work weighted propositional formulae deﬁne distributions approach generalises wellknown approaches use common practice domains probabilistic reasoning planning learning 517222527293064 In order WMC approach modelling probability distributions express event φ propositional formula φ X T Boolean decision variables X Boolean stochastic variables T A model assignment truth values variables X T φ X T evaluates true We assign weight wt variable t T reﬂecting probability true sample possible world wt pt cid6 wt pt 1 wt 65 We use φσ T denote residual formula obtained replacing decision variables d X propositional formula φ X T truth values speciﬁed strategy σ This allows evaluate probability φ true given strategy σ Under WMC approach following holds P φ σ cid2 cid4 μM tμ wt 3 μ set truth assignments stochastic variables T μ model φσ T M set models φσ T t T stochastic variable wt wt t cid6 μ wt wt t μ We illustrate weighted model counting formalise probability distributions running examples Example 23 Spread inﬂuence WMC We model problem following simplifying assumptions Inﬂuence relationships symmetric Once gets free product sample customer If u inﬂuences v u customer v customer The possible worlds event φe takes place Fig 1a modelled propositional formula φe dc tce db tbc tce da tac tce db tba tac tce da tab tbc dce This formula represents different situations e customer We use types variables di decision variables SCP ti j associated edge j network represent inﬂuence One possibility event φe happen person c gets free sample inﬂuences person e 5 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 cid5 To deﬁne distribution network associate probability p ti j Boolean variable ti j variable true We ti j stochastic variable The probability P φe σ deﬁned sum probabilities logical models formula given strategy Given strategy σ da cid6 db dc example model tac tce cid6 tab tbc probability 08 03 1 04 1 01 01296 cid6 Example 24 Power grid reliability WMC For sake simplicity following assumptions All power lines survival probability puv reinforced survival probability p With power line u v L associate survival probability πuv takes following values forced p cid13 uv puv cid7 πuv puv cid13 p uv duv duv cid6 cid13 uv rein 4 takes place Fig 1b deﬁned propositional formula φe The possible worlds event φe tae sae dae tab sab dab tbc sbc dbc tce sce dce This formula speciﬁes situations consumer e connected producer natural disaster Again use types variables duv decision variables SCP tuv suv stochastic variables associated edge u v network represent stochastic survival power line In model associate following probabilities variables tuv suv P tuv cid6 puv P suv cid6 cid5 cid6 1 puv Note probabilities deﬁned model πuv Consequently puv 04 p 0875 values literature 29 strategy σ dae dbc cid6 dab dbf dce example model φeσ T sae tab sab tce sbf cid6 tae tbc sbc sce tbf probability 0791673 0208332 042 063 744235 10 4 cid13 uv puv cid13 uv p 23 Complexity SCP solving Solving SCPs SCPMDs exactly NPhard general case There components solving SCPs brieﬂy address computational complexity To evaluate quality strategy σ compute P φ σ Pcomplete general 62 We compute P φ σ potentially exponential number times number possible strategies n decision variables 2n Thus naïvely solving SCP enumerating possible strategies evaluating score typically impractical In following section use existing knowledge compilation techniques problem probabilistic inference tractable search process means preprocessing In sections present methods use techniques combination CP MIP technology eﬃcient traversal search space 3 Probabilistic inference There methods obtaining propositional formulae model events φ However equally suitable For formulae conjunctive normal form CNF weighted model counting known Pcomplete 62 There fore computing weighted model count φσ involve solving exponentialtime search problem We address problem limiting attention representations propositional formulae probability calculated polynomial time Hence separate problem ﬁnding suitable representation distribution problem ﬁnding solution SCP We use knowledge compilation obtain representations 31 Knowledge compilation Historically knowledge compilation popular method making online WMC computation tractable ﬁeld probabilistic inference planning 1722253037 Knowledge compilation allows compactly represent truth table propositional formula decision diagram DD In work study use compiling proposi tional formulae ordered binary decision diagrams OBDDs 14 facilitate tractable WMC context solving SCPs Once formula φ X T compiled decision diagram time complexity computing P φ σ linear size diagram Note constraint programming literature OBDDs types decision diagrams employed compact representations satisfying assignments constraint 3233 Here use diagrams differently For performance algorithms use DDs size DD matters Note particular OBDD representations probability distributions resulting probabilistic networks exponential size networks particularly relevant SCPs considered work The size shape OBDD determined variable order Unfortunately ﬁnding variable order produces minimalsize OBDD NPhard 10 However key 6 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 P φe dc tce 03 tac 02 08 m o d e l s tbc 07 01 y t l b b o r p 09 0 tbc 01 09 04 04 da tab 06 db tab 06 da 1 Fig 2 An OBDD representation φe Circular nodes represent stochastic variables square nodes represent decision variables This OBDD variable order tce dc tac tbc tab da db advantage knowledge compilation SCP solving pipeline resulting approach modular model counting problem solved preprocessing phase knowledge compiler enables tractable online inference There decision diagrams produce compact representations probability distributions sentential decision diagrams SDDs 1256 weighted positive binary decision diagrams WPBDDs 19 However OBDDs properties exploit propagation algorithm stochastic constraints monotonic distributions Section 5 Therefore focus OBDDs To construct OBDDs networks use approach implemented ProbLog 2530 This provides convenient way modelling paths probabilistic networks uses knowledge compilers create OBDD representa tions propositional formulae 32 Performing WMC OBDDs Fig 2 demonstrates compute P φ σ time linear size OBDD representation probability 2022 The outgoing arcs OBDD nodes represent truth values variables labelling nodes Speciﬁcally hi solid arc represents true lo dashed arc represents false A path root OBDD leaf labelled 1 corresponds subset set variable truth value pairs form model formula encoded OBDD Here value variable determined outgoing arc node labelled variable taken path This subset satisﬁes formula weight equals sum weights models supersets Each model formula deﬁned exactly pathsubset We map OBDD arithmetic circuit AC compute probability φe Example 23 evaluates true strategy σ follows The weights outgoing arcs nodes represent stochastic variables labelled ti j correspond probability variable true hi arcs false lo arcs We add strategy σ OBDD adding weights 0 1 appropriate outgoing arcs nodes labelled decision variables We compute P φe σ follows In bottomup traversal OBDD node r assigned score vr wr v cid6 cid5 r 1 wr v cid6 cid5 r 5 0 wr 1 represents weight variable labels r r hi lo child r child connected solid dashed outgoing arc r In base cases vr 0 negative leaf vr 1 positive leaf Observe vroot P φ σ Note takes bottomup traversal AC compute score root r In brevity remainder work abuse terminology refer OBDD actually mean AC OBDD mapped 7 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Example 31 WMC OBDD Consider OBDD Fig 2 Suppose want compute P φe dc da db cid6 We label dashed outgoing arcs nodes labelled dc solid outgoing arcs nodes labelled da db value 1 Similarly label solid outgoing arcs nodes labelled dc dashed outgoing arcs nodes labelled da db value 0 Then perform bottomup sweep diagram compute score node computing weighted sum children Equation 5 This yields score 1 nodes labelled da db tab right node labelled tbc The left tbc node score 01 The tac dc nodes score 082 nodes labelled tce score 0246 Because node labelled root node diagram conclude P φe dc da db cid6 0246 33 OBDDs monotonicity In work consider types probability distributions monotonic Sec tion 21 Intuitively taking spread inﬂuence problem example monotonicity means adding person set people receive free product sample decrease expected number eventual customers likewise adding power line set lines receive maintenance decrease expected number households power natural disaster Recall deﬁnition monotonic probability distribution Deﬁnition 21 For OBDDs deﬁne concept local monotonicity Deﬁnition 31 Let φ X T σ P φ σ deﬁned Section 21 We OBDD representation probability distribution score root equals P φ σ locally monotonic iff following property holds projected σ Section 32 cid5 r v cid5 r 6 v cid6 cid6 d d cid5 OBDD node rd labelled decision variable d X Equation 5 compute v r cid6 d cid5 v r cid6 d Theorem 31 If probability distribution P φ σ represented locally monotonic OBDD deﬁned Deﬁnition 31 monotonic distribution deﬁned Deﬁnition 21 Proof In proof use v r σd denote score OBDD node r computed Equation 5 OBDD strategy σ decision variable d analogously d cid6 Since root OBDD OBDD node score represents P φ σ task prove node r locally monotonic OBDD holds v r σd v r σdcid6 Here σd σdcid6 differ truth assignment d We prove induction The inequality holds trivially r leaf fact equality case We assume inequality holds descendants node r distinguish following cases 1 Node r labelled decision variable d 2 Node r labelled decision variable d 3 Node r labelled stochastic variable For ﬁrst case inequality holds Deﬁnition 31 For second case vr determined child σ assigns truth value decision variable ﬁxes wr 0 1 Equation 5 Since inequality holds child holds r For case inequality holds children Since vr weighted sum children inequality holds r cid2 It unknown reverse Theorem 31 holds Ensuring distributions monotonic relatively easy WMC approach program written ProbLog 2530 negation resulting OBDD distribution locally monotonic renders probability distribution monotonic Note represent strong limitation problems discussed earlier written form An illustration distributions encoded negation yield locally monotonic OBDDs provided Appendix A We use notion local monotonicity deﬁne global propagation algorithm SCMDs Section 5 4 Solving SCPs decomposition In Section 23 discussed elements need eﬃcient SCP solving tractable WMC eﬃcient way traversing search space As described propose use knowledge compilation ﬁrst element We address second element section We propose leveraging constraint programming CP mixedinteger programming MIP technology eﬃciently traverse search space We assume familiarity paradigms refer readers like learn literature 1361 8 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 P φ 01 y1 04 0 09 x y2 03 1 07 06 P φ σ 04 09 zx 04 01 z y1 x z y2 zx 1 x z y1 06 y z y1 06 y 03 1 y z y2 x y 0 1 0 P φ σ 06 0 zx 06 06 0 z y1 06 03 z y2 Fig 3 A small OBDD left stochastic variables circles decision variables x y squares The nodes corresponding decision variable y indexed clarity The decomposition right constructed Equation 5 In following recall method combining knowledge compilation CP MIP technology SCP solv ing ﬁrst proposed 2017 This method decomposes global constraint DD representation probability distribution multitude local constraints 43 We method guarantee generalised arc consistency GAC propose straightforward way turn decomposition method guarantee GAC Recall Section 31 represent probability distributions OBDDs We explain OBDDs converted linear program LP encodes constraint probability distribution Equation 1 identify problem approach Note earlier work showed SDDs obtain linear programs stochastic straints Equation 1 formulated SDDrepresentations probability distributions 43 However discussion method outside scope work 41 Decomposing constraint OBDD Recall represent speciﬁc strategy labelling outgoing arcs OBDD nodes labelled decision variables values 0 1 Our aim solve Equation 1 interpret constraint values use label arcs We interpret Equation 1 constraint AC induced OBDD encoding probability distribution SCP Fig 3 shows example OBDD representation formula φ We impose constraint P φ σ 04 Fig 3 shows decomposition constraint OBDD multitude smaller constraints adding auxiliary variables z y1 z y2 zx domains include real numbers The step solving P φ σ 04 simply feed set smaller local constraints CP MIP solver 43 The decomposition Fig 3 contains quadratic constraints involving realvalued variables auxiliary variables z decomposition Fig 3 hard solve MIP solvers CP solvers We linearise decomposition bigM approach 49 M 1 easier solving For example quadratic constraint zx 1 x z y1 x z y2 linearised follows zx zxcid6 zx 0 zxcid6 1 0 zx 1 zxcid6 x zxcid6 z y2 zxcid6 z y2 1 x 1 x zx 1 x zx z y1 zx z y1 x x We linearise program repeating method quadratic constraints 42 GAC guarantees decomposition 7 We brieﬂy recall wellknown concept generalised arc consistency GAC 61 We note CP solver works ﬁxing unbound variables values branching updating domains remaining unbound variables builds partial solution branching propagation Let x variable domx domain A variable value pair x domx considered GAC respect constraint c iff exists assignment current domains variables scope c satisﬁes c x Propagation establishes GAC constraint c remaining values variables scope c GAC When CP solver solve decomposed constraint probability distribution represented OBDD encounter following problem 9 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Theorem 41 Propagation decomposed representation SCP described 43 guarantee GAC Proof We prove contradiction Assume propagation decomposition method 43 GAC Then following counterexample leads contradiction Consider OBDD Fig 3 associated constraint P φ σ 04 Observe possible strategies yield conditional probabilities P φ x y 0 0 P φ x y 1 06 P φ x 1 y 0 03 P φ x 0 y 1 06 From conclude strategies y 1 holds possibly satisfy constraint A propagator ensures GAC Boolean variables detect start search ﬁx y 1 Suppose constraint propagator called decomposed model Fig 3 search starts This propagator start trying infer minimum value z y1 needs zx takes maximum possible value To propagator assumes zx 06 holds Now infer order constraint satisﬁed z y1 04 09 0601 14 hold Unfortunately knew dom y 0 1 include 14 Based remove 0 dom y Repeating similar procedure determine bound zx z y1 z y2 yield conclusive evidence deduce y ﬁxed 1 cid2 As result search tree CP unnecessarily large One solution create decomposed representation GAC We achieve means modiﬁcations decomposition method First replace encoding score OBDD node rd vrd v v cid7 cid6 cid6 cid5 r cid5 r d d d cid6 d vrd max cid5 d v cid5 r cid6 d 1 d v cid6cid6 cid5 r d improves propagation cases d unassigned Additionally add redundant constraint vd0root θ d 1 decomposition decision variable d Here vd0root represents expression root diagram obtained Equation 5 conditioned d Each constraints encodes explicitly required maintain GAC setting decision variable d 0 causes score root OBDD low satisfy Equation 1 decision variable ﬁxed 1 instead The downside approach need add large number linear constraints model resulting space complexity O X O B D D τ approach X set decision variables O B D D size OBDD τ depth search tree We demonstrate practical inferiority approach Section 7 5 Solving SCPMDs global propagation For special case constraints monotonic distributions intend improve OBDD decomposition approach described Section 41 developing global constraint OBDD representation distributions We ﬁrst deﬁne constraint introduce corresponding propagator guarantees GAC We refer propagator global SCMD propagator Our propagator relies Theorem 51 eﬃcient constraint propagation It relies local monotonicity OBDD representation probability distribution Deﬁnition 31 able guarantee GAC In following refer OBDD nodes labelled decision variable decision nodes OBDD nodes labelled stochastic variable stochastic nodes 51 Stochastic constraint monotonic distributions Recall deﬁnition locally monotonic OBDDs Deﬁnition 31 We deﬁne corresponding stochastic constraint monotonic distributions SCMD follows Deﬁnition 51 For set propositional formulae cid3 threshold θ R utilities ρφ R cid2 ρφ P φ σ θ 8 φcid3 stochastic constraint monotonic distributions P φ σ represented locally monotonic OBDDs Given partial strategy σ GACguaranteeing propagator SCMD unbound decision variable d X remove value domd φ σ cid13 ρφ P θ cid2 cid6 cid5 φcid3 10 9 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 holds possible extension partial strategy σ strategy σ cid13 includes d In general case different propositional formulae encoded OBDD multiple roots formula avoiding redundancy share subformulae For simplicity discussion notation consider straints propositional formula φ section singlerooted OBDDs approach easily extended general situation implementation This makes corresponding utility ρ irrelevant discussion limits domain threshold θ 0 1 compare probability expectation 52 Naïve SCMD propagation For maintaining GAC key observation scoring function expected utility Equation 8 monotonic largest possible score obtained assigning value true unbound decision variables Given OBDD representation φ X T mapped AC following process unbound decision variable d X GAC 1 Fix variable d value 2 Fix remaining unbound variables value cid6 3 Calculate root node score resulting assignment Equation 5 4 If score lower equal θ remove value domd Fixing unbound variables cid6 step 2 ensures compute upper bound score given current partial assignment d step 3 local monotonicity OBDD deﬁned Deﬁnition 31 Consequently upper bound lower θ know extending current partial assignment decision variables d results partial assignment extended assignments unbound variables solution score exceeds θ Thus update ds domain step 4 guarantee GAC This algorithm require constraints variable order OBDD obtain strict bound step 3 contrast previous work SDDs dDNNFs 57 Let n number unbound decision variables let m size OBDD Then complexity naïve SCMD propagator O n m unbound variable perform bottomup traversal OBDD Since propagation algorithm called node search tree size OBDD exponential size input problem complexity prohibitively large Therefore improve complexity propagator O n m 53 A fullsweep SCMD propagator The key idea improving naïve propagator calculate partial derivative f d σ cid13 d d cid6 cid5 σ cid13 f cid5 d σ cid13 d cid6 f 10 unbound decision variable d Here function f represents scoring function deﬁned Equation 5 root OBDD Strategy σ cid13 represents assignment decision variables obtained taking partial assignment σ extending assigning true unbound decision variable X We use derivative remove value false domains variables meet following condition f σ cid13 f d σ cid13 d d θ 11 The main question calculate partial derivative unbound variables eﬃciently Here build ideas introduced Darwiche 2021 build linear algorithm furthermore maintain derivatives incrementally We ﬁrst need deﬁne concept path weight Deﬁnition 52 Let rm node labelled variable vm OBDD variable order x1 xn We deﬁne path weight rm cid2 cid4 π rm ui cid10Lrm ri cid10 12 cid10 path root OBDD rm Lrm set paths valid A path valid include hi respectively lo arc node labelled decision variable false respectively true unbound We deﬁne ui follows For outgoing arcs decision nodes valid path use ui 1 outgoing arcs valid path use ui 0 For outgoing arcs stochastic nodes labelled stochastic variable xi weight wi use 11 ALD Latour B Babaki D Fokkinga et al cid7 ui wi 1 wi hi arc ri lo arc ri Artiﬁcial Intelligence 304 2022 103650 13 The path weight π rm expressed terms variables xi xm In general case path weights initialised roots diagram root query corresponding utility ρ Because simplicity assume diagram single root section ρ irrelevant path weight root initialised 1 Our global SCMD propagation algorithm based following Theorem 51 The partial derivative OBDD respect unbound decision variable d calculated follows 14 15 f d σ cid13 d d cid2 rdOBDDd π rd cid5 vr d vr cid6 d OBDDd set OBDD nodes labelled decision variable d Proof Observe Equation 10 read f d σ cid13 d d cid5 vσ cid13ddcid6r vσ cid13ddr cid6 cid6 urr vσ cid13ddcid6r urr vσ cid13ddr r denotes root OBDD vσ cid13ddr score root r calculated Equation 5 conditioned partial strategy σ extended ﬁxing d unbound decision variables cid6 urr vσ cid13ddcid6r urr vσ cid13ddr 16 cid5 The expression Equation 15 states partial derivative f equals difference score Equation 5 taken root OBDD conditioned σ cid13 d cid6 d In Equation 16 expanded expressions sign according Equation 5 Here r represent hi lo children OBDD root r respectively urr urr corresponding weights outgoing arcs according deﬁnition r We continue expansion recursively ﬁnd vσ cid13ddcid6rd vσ cid13ddrd terms computing Equation 5 node rd labelled unbound decision variable d computing deriva tive The result expression contains following types terms 1 Constant terms expanded 0 1 leaf OBDD replace corresponding term accordingly d expanding vσ cid13ddcid6r Equation 15 d expanding vσ cid13ddr Equation 15 2 Terms vr 3 Terms vr The terms type 1 correspond paths OBDD root leaf contain OBDD node labelled d Therefore terms right sign Equation 16 cancel left Given particular node rd OBDD terms node remaining expression urr d These terms correspond node rd path cid10 urdr root r rd Hence rewrite terms follows d urr urdr vr vr d d urr urdr d vr d urr urdr urr urdr d d vr cid5 d d vr vr cid6 d 17 1 outgoing arcs unbound decision nodes Note valid paths use urdr root nodes labelled d ﬁnd term expanded expression f d σ cid13 dd Hence particular node rd group terms obtaining π rd Summing particular nodes rd yields Equation 14 cid2 d vr urdr cid6 d vr d d cid5 We use observation create O n m algorithm calculating derivatives stages 1 A topdown pass complete OBDD calculating path weights 2 A bottomup pass calculating values nodes complete OBDD calculating derivatives variable process 12 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 The topdown pass operates follows We initialise path weight π r node 0 We update path weight children r follows r labelled decision variable d cid6 cid6 cid5 r cid5 r π π π π r cid6 cid5 r cid5 r cid6 π r d unbound true π r d false cid6 cid5 r w π r π cid6 cid5 r cid6 cid5 r π 1 w π r 18 If r labelled stochastic variable weight w assign π π cid5 r cid6 We compute node values bottomup pass Equation 5 wr 0 r corresponds decision variable false wr 1 During bottomup pass recompute derivatives decision variables unbound Equation 14 evaluate Equation 11 remove false domain Clearly overall calculation completed time O n m 54 A partialsweep SCMD propagator We explore reduce empirical running time algorithm avoiding unnec essary traversal parts OBDD The following observations allow potentially eﬃcient propagation O1 As noted expression path weight OBDD node labelled variable xm Equation 12 contains variables xi xm We conclude ﬁxing decision variable d affect path weights nodes nodes labelled variable d O2 Path weights unbound decision nodes changed ﬁx unbound decision node true Therefore propagator needs update path weights ﬁx decision variable false O3 Similarly ﬁxing variable affect scores nodes labelled variable OBDD Again ﬁxing variable false requires propagator update scores O4 We need maintain scores nodes OBDD decision nodes closest root need calculate derivative variable diagram O5 Similarly need maintain path weights descendants variable closest leaves It shown maintaining OBDD borders unbound decision variables active OBDD calculate derivatives exactly calculate score solution O6 Some parts OBDD longer connected root consequence partial assignments We need update parts OBDD O7 We exploit partial derivatives O4 O5 branching heuristics guide search For example branch variable largest derivative likely ﬁnd failing partial strategies quickly Alternatively branching highest lowest decision variable applying O4 O5 respectively reduce size active OBDD We improve fullsweep OBDD propagation algorithm addressing observations Here short overview refer reader Appendix B pseudocode resulting partialsweep algorithm O1O3 addressed priority queues initialise update start traversing OBDD downwards upwards places path weights scores change decision variable assignments In implementation partialsweep algorithm maintain OBDD node r counters addressing ob servations O4O6 Maintaining counters requires extra passes OBDD time propagator called However allow traverse everdecreasing OBDD pass We ﬁrst counter FreeInr It indicates number parents r r valid If FreeInr0 need update scores nodes r cid13 cid13 r cid13 path unbound decision node r score r changes O4 The second indicates number children r unbound decision counter FreeOutr If value 0 changes rs path weight need propagated valid path r cid13 cid13 cid13 node r r O5 Because O6 use counter Reachabler It indicates number parents r If rs path weight 0 changes score need cid13 valid path OBDD root r propagated cid13 Example 51 Partialsweep propagation Fig 4 shows example execution partialsweep algorithm OBDD representation φe Example 21 When unbound decision nodes ﬁxed remove outgoing arcs indicate truth value This cause nodes longer reachable root Nodes inactive path unbound decision node coloured grey Next node indicate current score s current path weight π We indicate scores path weights 13 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 P φe 02 tbc s 1 π 1 01 09 s 1 π 01 dc dc s 1 π 09 P φe 02 tbc dc dc s 1 π 1 tce tce s 1 π 0 π 01 tce π 0 tce tce π 09 tce s 1 π 0 03 s 1 π 0 da 07 07 07 03 da s 1 π 0 db s 1 π 0 tac s 1 π 0 02 02 s 1 π 07 08 03 08 s 1 π 0 db db s 1 π 0 s 1 π 0 tac s 1 π 0 tac 02 s 1 π 0 08 s 04 π 0 tab π 003 da da π 027 π 003 db db db tac π 027 tac π 0754 tac tab 06 0 04 1 0 1 Iteration 0 initialisation b Iteration 1 branched dc P φe 02 tbc P φe 02 tbc dc dc dc dc tce tce tce tce tce tce da db db da db s 088 da da s 08 s 088 db db s 0 db s 0 π 003 tac tac tac s 088 tac tac s 08 tac π 0006 tab s 0 s 04 tab 0 1 0 1 c Iteration 2 branched db d Iteration 3 branched Fig 4 Illustration partialsweep propagator OBDD φe Example 21 change iteration The Reachable FreeIn FreeOut counters shown ﬁgure Suppose ﬁnd strategy σ P φe σ 02 holds Fig 4a shows state OBDD right initialisation current partial strategy σ cid13 The partial derivatives fda 0 fdb 0 fdc 0 fde 07 Since Equation 10 holds derivatives ﬁx decision variables true The upper bound score diagram sroot 1 Suppose branch dc Fig 4b Because active nodes nodes labelled dc scores change iteration However active nodes nodes labelled dc causing path weights change Note middle node labelled tce unreachable While Reachable counter 2 Fig 4a equals 0 Similarly FreeIn counters nodes labelled tce dc 0 14 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 We update upper bound score diagram P φe dc P φe fdc 1 0 1 compute new partial derivatives fda 0 fdb 0 fde 0754 Again infer speciﬁc decision variable ﬁxed true In Fig 4c branch db Note nodes labelled db remain active paths unbound decision nodes unbound decision nodes FreeIn FreeOut counters remain larger 0 Since scores nodes labelled db happen change case need update scores active nodes OBDD However need update path weight nodes We update upper bound score diagram P φe db dc P φe dc fdb 1 0 1 We compute new partial derivatives fda 0 fde 07576 Again reason ﬁx remaining decision variables true Next branch Fig 4d There active nodes nodes labelled FreeOut counters equal 0 path weights updated iteration However scores change The upper bound score root diagram changes P φe db dc P φe db dc fde 1 07576 02424 The remaining partial derivative fda 02424 Now know decision variable ﬁxed true P φe db dc fda 02424 02424 02 We ﬁx da cid6 conclude σ da cid6 db dc solution constraint P φe σ 02 value P φe σ 02424 Note example ﬁx decision variable iteration Our implementation allows multiple decision variables ﬁxed time example constraint linear constraint cardinality solution case Examples 21 22 Finally address observation O7 implementing different variable branching heuristics Top branches unbound variable highest OBDD counterpart Bottom Each combined value branching heuristics branch ﬁrst value 0 value 1 These heuristics static search depend variable order underlying OBDD We implement regretbased 15 branching heuristics use calculated derivatives Derivative1 Derivative0 The selects unbound decision variable largest small est absolute derivative ﬁrst branches 1 0 These heuristics dynamically computed search present overhead need compute derivatives Note space complexity approach O O B D D τ τ depth search tree This GACguaranteeing decomposition method Section 42 6 Problem settings data sets In section introduce problem types consider experiments Sections 7 9 Then data formulate problems We distinction data experiments Section 7 aim provide insight number different algorithms compare experiments Section 9 focus automated algorithm conﬁguration 61 Problem types We problem settings evaluated solving methods described Sections 4 5 All following problem settings involve probability distributions monotonic Theory compression graph sparsiﬁcation We setting literature 24 The problem following given probabilistic network set pairs vertices maximum number edges k extract subset given network induced k edges models strength interaction vertex pairs original network possible The goal obtain sparser network preserves pairwise interactions interested Here associate decision variable stochastic variable edge network For details refer earlier work 43 Spread inﬂuence This problem setting described Example 21 known data mining literature 26 41 For experiments relax simplifying assumptions Example 21 In particular set probability person turns customer receive free product sample 02 Similarly existing customer inﬂuences person person probability 02 turn customer We apply setting spreading ideas research interests research styles scientiﬁc community means citation In problem setting associate decision variables vertices network stochastic variables vertices edges For details refer reader earlier work 43 Power grid reliability This problem described Example 22 note somewhat similar theory compression sparsiﬁcation problem described Again associate stochastic variables decision variables edges network However problem given set paired vertices sets vertices power sources power consumers These vertices paired We wish maximise expected number consumers 15 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Table 1 Some characteristics test instances use Section 7 In particular entities decision variables associated OBDD size minimisation OBDDnm dynamic minimisation OBDDdm 63 compilation difference compilation times cid11t compilation methods size set cid3 number T X stochastic decision variables instance spine16 spine27a spine27b hepth47 hepth5 facebook12 facebook25 croatia illinois russia problem type sparsiﬁcation sparsiﬁcation sparsiﬁcation spread inﬂuence spread inﬂuence spread inﬂuence spread inﬂuence power grid reliability power grid reliability power grid reliability cid3 23 13 13 20 33 12 25 6 20 16 T 33 60 55 51 90 61 72 66 96 94 X 33 60 55 20 33 23 25 21 32 34 OBDDnm OBDDdm 80 1 898 9 350 10 815 14 555 7 836 6 981 4 873 68 019 1 616 80 266 476 3 658 8 865 794 2 198 429 3 040 947 cid11t s 001 003 113 059 1325 007 022 013 060 055 reached producers Moreover sparsiﬁcation problem setting variable represents edge false interpreted removing edge graph power grid reliability problem connection probability modelled edge lower zero corresponding variable set false Finally graphs power grid reliability problem undirected directed Top fake news distributors To investigate interaction stochastic constraint constraints cardinality constraints consider frequent itemset mining FIM problem based spread inﬂuence problem described A challenging problem times spread fake news Oftentimes fake news released speciﬁc bubbles spread It interesting identify necessarily fake news distributors inﬂuential fake news distributors inﬂuential set people We model FIM problem follows Given social network aim enumerate sets users U V following holds First selected iV P φi σU θ φi represents users U inﬂuential directly indirectly determined spread inﬂuence event user believes adopts piece fake news σU represents strategy users U considered initial distributors news In words require collective inﬂuence users U θ Second selected users directly inﬂuence large group users set users U associate set W V users size κ edge u w network user u U user w W meaning u directly tries inﬂuence w cid3 This second constraint corresponds minimum support constraint transaction database FIM 1 We create transaction database putting transaction τ user V Here τ represents set users inﬂuence v directly We aim identify sets users U itemsets U τ κ individual transactions τ making frequent Hence combine stochastic constraint Equation 1 minimum support constraint known FIM literature 67 62 Individual problem instances The problem instances initial experiments Section 7 shown Table 1 These experiments focused showing performance methods large range different problems We selected ﬁve problem instances literature In particular spine16 spine27a spine27b theory compression sparsiﬁcation problems formulated directed DNAprotein interaction networks 522 Similarly communities high energy physics collaboration undirected network 50 hepth47 hepth5 formulate spread inﬂuence problem 2641 We refer reader literature 43 detailed description ﬁve problem instances To expand range test cases graphs different sizes complexities created additional instances spread inﬂuence power grid reliability problems A number instances initial comparison included Table 1 The facebook instances created extracting communities different sizes Louvain algorithm 8 Facebook data 71 We converted communities probabilistic networks independent cascade model spread inﬂuence 2641 In particular user u posts nuv messages wall user v collapse corresponding nuv parallel edges edge weight 1 1 pnuv p 01 This weight represents probability user u inﬂuences user v As described Section 61 associate stochastic variables weight 02 vertex network Note networks directed In facebook25 people network set In facebook12 selected 50 people network uniformly random set 2 The dataset spine27a work corresponds spine27 43 spine27b problem network formulated different set 16 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Table 2 Characteristics set 52 test instances including range size set cid3 number stochastic vari ables T number decision variables X number test instances type spine hepth facebook highvoltage problem type sparsiﬁcation spread inﬂuence spread inﬂuence power grid reliability cid3 1323 2033 1018 220 T 3360 5190 4098 32154 X 3360 2033 2030 1545 instances 3 2 11 36 Table 3 Summary characteristics benchmark sets use Section 94 We provide range sizes set cid3 numbers stochastic variables T numbers decision variables X OBDD sizes OBDD sizes training test sets facebook highvoltage problem type spread inﬂuence power grid reliability cid3 1530 639 T 16107 30300 X 1530 15150 train 412 51 test 411 50 The power grid reliability instances based network models European NorthAmerican highvoltage power grids 73 extracted GridKit3 We taken connected components networks speciﬁc geographical areas countries Europe states North America contain power producer power consumer test networks Probabilities edges presented Example 22 These networks undirected Here set consists power consumers network wish maximise expected number power consumers continue receive power To complete problem instance need associate upper bound cardinality solution k In experiments Section 7 run example values k based number decision variables problem instance For spread inﬂuence problem k represents upper bound number people free sample product For sparsiﬁcation problem k represents upper bound size network extract Finally power grid reliability problem simplifying assumption cost reinforcing power lines uniform replace budget b upper bound number power lines reinforce k We total 52 instances evaluate method Section 7 summarised Table 2 For experiments FIM problem setting aim detect fake news distributors commu nities facebook dataset We generated 25 OBDDs combined different minimum expectation thresholds E different minimum support thresholds κ create FIM problem instances The problems sets size 5065 numbers decision variables The numbers stochastic variables range 151225 databases contain 3352 transactions Finally OBDD sizes range roughly 20 000 25 million nodes 63 Algorithm conﬁguration data sets For automated algorithm conﬁguration require larger set instances This need disjoint training testing suﬃcient size conﬁgurator learn different instances training validate performance suﬃciently varied set instances testing We created instances process described previous section summarise Table 3 Here facebook refers set spread inﬂuence problem instances generated Facebook 71 data extracting commu nities adding weights described Section 62 We select vertices problem set We choose upper bound cardinality solution constant examples Speciﬁcally use k 10 expected yield challenging problems seen results Section 7 Additionally ﬁxing threshold value problems different sizes realistic choice reallife applications setting After companies likely marketing budget depend directly size social network data access Similarly generated set power grid reliability problem instances European NorthAmerican high voltage transmission grids 73 described For examples use k X2 reinforce half total number power lines given problem instance We believe realistic reallife applications assuming maintenance budgets power grids roughly proportional sizes 7 Experimental evaluation OBDDbased SCMD solving methods We experimentally evaluated performance CPbased MIPbased OBDD decomposition methods described Section 4 fullsweep partialsweep global SCMD propagators OBDDs described Sections 53 3 Available httpsgithub com bdw GridKit 17 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 54 In experiments problem instances described Section 62 The remainder section organised follows First formulate research questions We provide details experimental setup hardware software use Section 72 overview different pipelines evaluated Finally report analyse results obtained experiments answering questions Section 73 71 Research questions The experiments section aim answer following questions Q1 How solving times depend CP encoding constraint decomposed versus new global constraint Q2 How branching heuristics Section 54 affect solving times global constraint Q3 How solving times global SCMD constraint compare decomposed constraint solved MIP solver Q4 How performances decomposed global approaches depend OBDD size Q5 How effective partialsweep propagation algorithm compared fullsweep algorithm practice Q6 How propagator perform combination constraints 72 Experimental setup The implementations propagation algorithms available httpsgithub com latower SCMD solving 721 Hardware software For modelling probability distributions SCProbLog 43 version based ProbLog 21 28 running Python 3694 We Cython binding dd 054 library CUDD 300 68 OBDD compilation implementation Sifting algorithm 63 dynamic minimisation5 We implemented MIPbased decomposition method modelling solving Gurobi 900 freely available academics provides convenient modelling interface gurobipy6 The CPbased decomposition implemented Gecode 601 wellknown wellperforming open source solver industry7 We implemented global OBDD propagators proposed Sections 53 54 Scala 212 library OscaR 400 51 This library contains stateoftheart implementation CoverSize constraint 67 needed answer question Q68 Since OscaR support ﬂoating point variables implement decomposition methods OscaR Our experiments Section 73 run different machines reasons availability The ﬁrst refer Pascaline equipped 24GB RAM Intel Xeon E5540 CPUs cores 8192 kB cache running 253 GHz CentOS Linux 741708 The second Grace cluster 32 nodes equipped 94GB RAM Intel Xeon E52683 CPUs 16 cores cache size 40 MB running 210 GHz CentOS Linux 771908 Unless indicated experiments Section 73 run Pascaline Note running times need compared directly obtained experiments ran machine Running times measured wall clock time solvers reports running times exclude time reading constructing models measure solving time 722 Overview pipelines We brieﬂy outline different pipelines evaluated section They start modelling problem SC ProbLog 2543 grounding resulting logical program propositional formulae φi Boolean decision variables Boolean stochastic variables examples Section 22 impose stochastic constraint Equation 1 In experiments section evaluated solving pipelines later Section 9 account knowledge compilation step CPbased decomposition In Section 4 described constraints probability distributions modelled OBDDs SDDs decomposed linear programs Using decomposition proposed method uses Gecode solve CP encoding stochastic constraint multirooted OBDD guarantee GAC Section 42 43 We refer pipeline GAC CP decomposition In Section 42 brieﬂy discussed turn CP encoding guarantee GAC We solve resulting CP programs encoding Gecode refer pipeline GAC CP decomposition MIPbased decomposition Since MIP solvers shown effective solving linear programs eval uated OBDD variant MIPbased pipeline described previous work 43 The OBDDtoMIP pipeline converts 4 Available httpsgithub com MLKULeuven problog tree sc problog 5 Available httpspypi org project dd 6 Available httpswwwgurobi com 7 Available httpswwwgecode org 8 Available httpssites uclouvain cp4dm ﬁm 18 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Fig 5 Solving times CPdecomposition methods global SCMD methods Cutoff time 3 600 s 1 hour Vertical axes log scale For interpretation colours ﬁgures reader referred web version article Table 4 PAR10 values seconds branching heuristics fullsweep propagation algorithm 52 test instances Cutoff time 3 600s Top0 1 502 Top1 1 575 Bottom0 Bottom1 Derivative0 Derivative1 1 526 1 385 2 412 27 propositional formulae φi multirooted OBDD converts OBDD stochastic constraint imposed linear program solved Gurobi Global SCMD propagation Finally evaluated variants new global SCMD propagator probability distribu tions represented OBDDs implemented OscaR fullsweep Section 53 partialsweep Section 54 723 Parameter settings Unless indicated default settings software experiments presented Section 73 In experiments answer Q1 constrained CP solvers branch variables lexicographical order branching ﬁrst false true In ﬁxed branching order attempt inﬂuence branching heuristics equation compare speed effect propagation For experiments global SCMD propagators branching heuristic Derivative1 Section 54 outperform branching heuristics shown Table 4 73 Results We study decomposition methods Section 4 compare global SCMD propagators Sections 53 54 terms solving time measured wallclock time reported different solvers time actually spent solving IO Comparison CP solvers We address Q1 comparing solver search times implementations fullsweep Section 53 partialsweep Section 54 versions propagator decomposed approaches Gecode GAC CP composition method GAC CP decomposition method Section 722 We kept branching order search process ﬁxed lexicographical branching ﬁrst false true This allows directly compare propagation strength speed CP methods ones guarantee GAC search trees The constraint threshold k indicates maximum allowed cardinality solution small strict large loose We ran propagators OBDDs obtained dynamic minimisation Fig 5 shows global SCMD propagators outperform decomposition methods set test instances While fullsweep version SCMD propagator outperforms partialsweep version difference pronounced 19 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Fig 6 Solving times MIPbased OBDD decomposition method compared fullsweep partialsweep methods Cutoff time 3 600 s 1 hour Vertical axes log scale Branching heuristics To answer Q2 evaluated performance branching heuristics described Section 54 We ran fullsweep propagation algorithm set 52 instances described Table 2 upper bound k cid17 X2cid18 cardinality solution X denotes number decision variables given instance We repeated branching heuristics Section 54 cutoff time 3 600 s computed PAR10 penalised average run time penalty factor 10 We present results Table 4 Clearly Derivative1 eﬃcient branching heuristic fullsweep propagator set test instances Comparison global CP decomposed MIP encoding Fig 6 compares performance partialsweep SCMD propagators observed OBDD decomposition method Gurobi solving problem OBDDtoMIP For global propagators branching heuristic Derivative1 We observe global propagators perform compara bly complementarily OBDDtoMIP method answering Q3 Scaling We address Q4 Fig 7 partialsweep SCMD propagators scale OBDDs different size obtained running OBDD compiler minimisation set problems Note SCMD propagators search tree regardless shape size OBDD operate We observe global SCMD propagators scale favourably OBDD size OBDDtoMIP decomposition method For example facebook12 minimised OBDD order magnitude smaller non minimised OBDD Both fullsweep partialsweep propagators scale linearly difference size However solving times OBDDtoMIP decomposition method increase orders magnitude OBDD size increases order magnitude Fullsweep versus partialsweep Recall fullsweep algorithm traverses entire OBDD twice iteration propagator partialsweep algorithm designed traverse OBDD iteration This renders partialsweep algorithm potentially eﬃcient fullsweep version especially branching strategies aim reduce size active OBDD While comes price overhead expect beneﬁts traversing smaller OBDD outweigh costs OBDD size increases To answer Q5 ran propagators dynamically minimised nonminimised OBDDs 52 test instances Table 2 We ran solver OBDD constraint thresholds k We performed experiment different branching heuristics Derivative1 Top0 Fig 8 Table 5 summarise results Looking left plot Fig 8 observe fullsweep propagator tends solve instances faster partial sweep Derivative1 branching heuristic This reﬂected results Table 5 PAR10 value partialsweep propagator 16 times fullsweep propagator However look 5 largest OBDDs PAR10 values similar This effect stronger use Top0 branching heuristic Recall heuristic attempts reduce size active OBDD search branching free decision variable highest OBDD The right plot Fig 8 shows Top0 branching heuristic partialsweep propagator outperforms fullsweep algorithm instances This reﬂected PAR10 values Table 5 set OBDDs 20 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Fig 7 Solving times OBDDtoMIP global SCMD propagators OBDDs different sizes obtained minimisation dynamic minimisation compilation Cutoff time 3 600 s 1 hour Vertical axes log scale R indicates size ratio OBDDnm OBDDdm Fig 8 Solving times partialsweep SCMD propagators dynamically minimised nonminimised OBDDs 52 instances Table 2 We compare branching heuristics Derivative1 Top0 Cutoff time 3 600 s 1 hour PAR10 value partialsweep 12 times higher fullsweep Again partialsweep smaller PAR10 value fullsweep largest 5 OBDDs These results conﬁrm branching heuristics aim minimise size active OBDD partialsweep edge fullsweep large OBDDs Derivative1 hand leads smaller search trees As active OBDDs case smaller partialsweep algorithm entails overhead compared fullsweep approach partialsweep offer substantial beneﬁts Nevertheless branching heuristic aims minimise size search tree Derivative1 indication partialsweep competitive fullsweep OBDD size increases Interaction constraints We conclude evaluation global constraint propagation algorithm experi ments FIM instances performed Grace In earlier experiments combined stochastic constraint cardinality constraint To answer Q6 experiment evaluated interaction global propaga 21 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Table 5 PAR10 values cutoff time 3 600 s fullsweep partialsweep SCMD propagators dynamically minimised OBDDs OBDDs minimised 52 instances Table 2 5 largest OBDDs set We ran values threshold k OBDD compare branching heuristics Derivative1 Top0 We indicate parentheses times total number instances solver timed fullsweep partialsweep All OBDDs Derivative1 847 s 21936 1 373 s 33936 Top0 2 366 s 59936 2 470 s 61936 Top 5 largest OBDDs Derivative1 13 817 s 1745 16 389 s 2045 Top0 21 028 s 2645 19 585 s 2445 partialsweepfullsweep 16 10 12 09 Solving times function minimum support threshold κ minimum expected inﬂuence threshold E typical example following characteristics cid3 65 X 65 T 225 O B D D 493 241 52 transactions database b Solving times 25 fake news distribution problem instances different instance κ E combinations partialsweep propagators Colour indicates minimum support threshold κ Fig 9 Experimental results fake news distributors problem setting Section 6 For interpretation colours ﬁgures reader referred web version article tor CoverSize constraint We note contrast experiments reported section constraint solving constraint optimisation setting Note enumerate solutions constraint solving problem We looked solving time fake news distributors problem instances different minimum support thresholds κ minimum expected inﬂuence thresholds E We present results typical example problem instance Fig 9a shows running time fullsweep propagator branching heuristic Derivative1 different combinations E κ Lower values E κ correspond looser constraints As expected solving times decrease constraints stricter In Fig 9b compare solving times fullsweep partialsweep propagators branching heuristic Derivative1 set 25 FIM problem instances combined different κ E combinations The colour indicates minimum support threshold κ We observe fullsweep propagator outperforms partialsweep version instances For large values κ partialsweep propagator competitive cases faster fullsweep propagator We explain observing large values κ itemsets support meet threshold likely small In CoverSize algorithm means decision variables ﬁxed early search Since partialsweep algorithm size active OBDD tends decrease decision variables ﬁxed active likely shrinks dramatically early search The beneﬁts reduction size start outweigh larger overhead 8 Solving SCMDs eﬃciently programming optimisation As results Section 7 different variants solving methods behave differently different problem instances Based decide optimal conﬁguration pipeline accurately predict alternative conﬁgurations behave new problem types Additionally largely relied default parameter settings minimal exploration alternatives Since generic solvers like Gurobi parameters defaults unlikely optimal speciﬁc type problem While indication decomposition method works box assess true potential need tune parameters Finally learning parameter settings yield shorter solving times speciﬁc problems learn problems solve eﬃciently potentially sparking interesting ideas future research 22 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 To address observations leverage programming optimisation PbO paradigm 36 We provide brief introduction concept Section 81 brieﬂy discuss automated algorithm conﬁguration AAC 35 critically enables PbO Finally applied PbO paradigm different elements pipelines described Section 722 81 Programming optimisation During algorithm software development typically multiple ways achieving subtasks For example solving SCPMDs use fullsweep Section 53 partialsweep Section 54 global SCMD propagation algorithm However design choices implemented ﬁnal version algorithm software The choice based limited experimentation speciﬁc application mind These design choices effect correctness affect performance especially computationally challenging problems SCPs The paradigm PbO introduces different approach design choices When taking PbObased approach software algorithm design developers implement multiple alternatives elements components software They provide end user choice options exposing conﬁgurable parameters Consequently developers focus exploring alternatives design choices instead determining best instantiations speciﬁc applications Moreover expanding design space given software exposing choices conﬁgurable param eters provides basis automated algorithm conﬁguration techniques performance optimisation Hence existence effective AAC procedures critically enables PbObased algorithm design 82 Automated algorithm conﬁguration PbObased algorithm design results algorithms come set parameters The parameter settings algorithm conﬁguration substantial impact performance optimal choice vary different sets problem instances This applies stateoftheart algorithms naturally come parameters Using suitable parameter settings critical reaching stateoftheart performance NPhard problems ones studied work We use AAC automatically ﬁnd optimised conﬁguration problem set After applying AAC target algorithm expected perform A parameters q1 qn set problem instances I obtain conﬁguration c according given performance metric m new instances similar I 35 83 Automated algorithm conﬁgurators There stateoftheart conﬁgurators available 2440 In particular SMAC 40 GGA 2 model based They build model captures dependency performance target algorithm conﬁguration This model predict performance conﬁgurations multiple instances select promising candidate conﬁgurations It supports different types parameters including conditional parameters activation depends values assigned parameters 84 Design space SCP pipelines In Section 722 described SCP solving pipelines CPbased decomposition method MIPbased decomposition method global SCMD propagation method Each consists compilation phase compile propositional formula φ X T OBDD followed solving phase encode constraint compiled diagram solve CP MIP solver We brieﬂy discuss design spaces phases We refer reader Appendix C details Note differ earlier approaches separating special values parameters regular domains Parameters domain N turned tuned automatically value 0 Contrary earlier approaches split parameters switch parameter normal parameter turns conﬁgured switch 841 Compilation phase In Section 7 limited study CP MIP methods use OBDDs encode probability distri butions However mentioned Section 3 use SDDs 23 encode probability distributions decompose constraints SDDs 43 Since SDDs succinct OBDDs 12 yield smaller linear programs consider SDD encodings conﬁguration experiments For OBDD compilation exposed number parameters related minimisation CUDD compiler In particular open possibility exploit different minimisation algorithms These applied dynamic minimi sation OBDD compilation compiling OBDD This results Boolean parameters categorical parameters integervalued parameters realvalued parameter 23 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 We use SDD minimisation algorithm proposed earlier work 43 option SDD compilation sure resulting decomposed constraints linearised Gurobi able ﬁnd solution cases We exposed available parameters conﬁguration resulting categorical parameters Boolean parameters ﬁve integer realvalued parameters tuned SDD compilation Finally added Boolean parameter conﬁgurator choose SDD encoding OBDD encoding We note parameter conﬁgured decomposition approach 842 Solving phase Gecode Gurobi For pipelines use Gecode Gurobi solve linear program obtained decomposing stochastic constraint probability distribution enabled conﬁguration parameters relevant speed solving problem exactly We based choices domains default values earlier work automated conﬁguration Gurobi 39 Gecode 42 Considering fact Gecode Gurobi offer wide range branching heuristics refrained exploring additional heuristics solvers For CPbased decomposition method introduced Boolean parameter GuaranteeGAC indicates use GACguaranteeing decomposition method described Section 42 CPdecomposition guarantee GAC 43 Since goals work develop eﬃcient SCMD propagation algorithm guarantees GAC uses OBDD probability distribution encoding consider developing GACguaranteeing CP encoding stochastic constraints probability distributions represented SDDs outside scope work Therefore GuaranteeGAC parameter unavailable SDDtoMIP pipeline encoding guarantee GAC The resulting conﬁguration space solving linear program encodings SCPs Gecode consists 2 Boolean param eters 3 categorical parameters 3 integer 1 realvalued parameter The conﬁguration space solving linear program encodings SCPs Gurobi consists 11 Boolean parameters 10 categorical parameters 37 integervalued parameters 5 realvalued parameters 49 switch parameters 843 Solving phase global SCMD propagator Our experiments Section 7 showed branching order important impact search eﬃciency Because study variety problems different properties Section 61 decided add range problemspeciﬁc branching heuristics explore result For global SCMD solving algorithm exposed parameter choose partialsweep algorithm Since good branching strategy dramatically limit size search space parameters introduced directly related choosing variable branch value assign variable ﬁrst For variable selection heuristic exposed Top Bottom Derivative variable branching heuristics Section 54 These heuristics derived topology OBDD Top Bottom dynamically determined search Derivative We propose seven new heuristics different approach derived directly probabilistic network SCPMD deﬁned Two reﬂect topological features network degree vertices degrees endpoints edge betweenness centrality vertices edges Another inspired work social inﬂuence 11 We introduced heuristics inspired work graph sparsiﬁcation 4566 An eighth new heuristic branches variables selected uniformly random Some branching heuristics incur preprocessing time The computational costs preprocessing steps quality resulting heuristic depend additional parameters exposed Finally parameter chooses branch true ﬁrst branch false ﬁrst The resulting parameter space global SCMD propagator consists Boolean parameters categorical param eter integervalued parameters realvalued parameters We provide table details parameters values Appendix C 9 Automated conﬁguration SCMD solving pipelines In section report experiments AAC determine pipeline outperforms sets problem instances described Section 63 gauge pipeline beneﬁts automatically conﬁgured speciﬁc sets problem instances Again ﬁrst discuss speciﬁc research questions trying answer Next provide details experimental setup Section 92 Finally analyse results experiments Section 93 answer questions 91 Research questions The experiments section aim answer following questions Q7 How improve performance decomposition methods global SCMD method different realworld problems automatically conﬁguring methods speciﬁc instance sets 24 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Table 6 PAR10 values CPU seconds default optimised conﬁgurations solving methods training set test set We indicate brackets number examples hit cutoff time 600 CPU s We highlight smallest PAR10 values test sets bold CPdecomposition train test MIPdecomposition train test global SCMD train facebook 412 training instances 411 test instances default optimised 4 338 295 2 518 168 4 270 289 2 615 174 1 888 124 594 39 1 664 108 627 41 797 52 751 49 test 782 51 682 44 highvoltage 51 training instances 50 test instances 4 386 37 default 4 379 37 optimised 4 351 36 4 452 37 3 686 31 3 188 27 3 989 33 3 031 25 2 379 20 2 260 19 2 782 23 2 669 22 Q8 Which automatically conﬁgured method solves problems best Q9 What learn solvers conﬁguration results Q10 How optimised conﬁgurations generalise harder instances problem type instances different problem type 92 Experimental setup For conﬁguration experiments software described Section 721 We NetworkX 22 NetworKit 501 Python toolkits computing scores variable branching heuristics described Section 8439 SDDs compiled version package 18 adapted generate SDDs decom posed linear programs 4310 Because nature parameters described Section 84 expect modelbased search process opti mal conﬁgurations yield best results For conﬁguration experiments chose generalpurpose conﬁgurator SMAC v3 40 bestperforming conﬁgurators modelbased freely available In experiments chose default values compilation CUDD Gecode Gurobi based literature 394243 default settings The default settings OscaR chosen based experiments Section 73 All experiments section performed Grace Section 72 93 Conﬁguration results To address Q79 performed ﬁfteen independent 48hour runs SMAC solving pipeline Section 722 training sets Table 3 minimising PAR10 penalised average running time penalty factor 10 cutoff time 600 CPU seconds Then method dataset evaluated ﬁnal incumbent conﬁguration smallest PAR10 value appropriate test set The results Table 6 MIPdecomposition method shows largest relative improvement conﬁgura tion answers Q7 We explain noting Gurobi relatively large conﬁguration space gives options improvement compared Gecode OscaR noting default settings Gurobi default conﬁguration chose default conﬁguration OscaR based results Section 7 We observe conﬁguration CPdecomposition method competitive MIP decomposition method global SCMD method similar Fig 5 Once appears CP encodings SCMDs global encoding favourable decomposed However performances MIPdecomposition method global SCMD method comparable complementary conﬁguration sim ilar Fig 6 Facebook instances MIP works better highvoltage datasets global constraint works better answers Q8 We provide optimised conﬁgurations obtained experiments online httpsgithub com latower SCPMD solving To answer Q9 ﬁrst note CPdecomposition MIPdecomposition pipelines SMAC chooses encode probability distributions OBDDs SDDs Furthermore global SCMD propagation pipeline SMAC tends favour group sifting algorithm OBDD minimisation CUDDs default minimisation algorithm Remarkably optimised conﬁgurations facebook highvoltage sets agree parameter choices OscaR SMAC chooses use fullsweep version propagator combined Derivative1 branching heuristic We believe detailed analysis similar results conﬁguration experiments provide useful directions improvements SCMD solving pipelines promising direction future work Finally note improvement running time highvoltage benchmark set impressive negative case CPdecomposition facebook benchmark set We explain noting high 9 Available httpsnetworkx github io httpsnetworkit github io 10 Available httpreasoning cs ucla edu sdd httpsgithub com MLKULeuven problog tree sc problog 25 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Table 7 PAR10 values CPU seconds default optimised conﬁgurations test sets We indicate brack ets total number problem k combinations ﬁrst column In columns indicate brackets combinations reached cutoff time 3 600 CPU seconds For problem set highlight lowest PAR10 value optimised conﬁgurations bold Results problems benchmark sets Table 3 solved solvers conﬁguration experiment Section 93 CPdecomposition MIPdecomposition global SCMD facebook 558 highvoltage 351 default optimised default optimised 35 398 548 32 607 504 34 325 334 32 597 317 b Results set 52 examples Table 2 28 780 441 18 528 278 33 523 326 31 302 304 11 330 168 10 716 158 29 300 285 29 186 284 CPdecomposition MIPdecomposition global SCMD spine 27 hepth 18 facebook 99 highvoltage 324 default optimised default optimised default optimised default optimised 12 308 9 16 220 12 30 177 15 26 254 13 19 100 52 15 482 42 8 808 77 8 538 75 569 0 35 0 6 493 3 568 0 4 428 11 791 2 8 410 74 4 447 39 17 0 17 0 65 0 68 0 58 0 51 0 55 0 52 0 voltage example set smaller facebook set fewer examples learn problems tend larger Table 3 causing relatively examples hit cutoff time 94 Generalisation automated conﬁguration results We addressed Q10 running default optimised conﬁgurations obtained Section 93 examples Table 3 solved solver experiment Section 93 represent hardest instances training test sets In new experiment cutoff time 3 600 CPU seconds instead 600 Rather threshold k problem instance ran conﬁguration different thresholds example like experiments Section 7 Similarly ran optimised conﬁguration obtained facebook dataset hepth facebook examples described Table 2 spread inﬂuence problems Finally ran optimised conﬁgurations obtained highvoltage dataset spine highvoltage examples similarity Note practical reasons small overlap 5 instances training Section 93 facebook highvoltage test sets experiment We present results Table 7 observe patterns similar Table 6 From Table 7a results harder examples larger cutoff time similar ones shown Table 6 conclude conﬁguration results translate predictably harder instances problem type answering Q10 Table 7b shows similar results facebook highvoltage problem instances This unsurprising taken datasets represent problem types ones conﬁguration experiments For spine hepth examples dramatic improvement performance MIPdecomposition pipeline global SCMD pipeline negative results hepth Still global SCMD pipeline outperforms MIP decomposition pipeline examples default optimised conﬁgurations We conclude results obtained Section 93 translate reasonably problem instances different types small advantage global SCMD approach answering remainder Q10 10 Related work Solving stochastic constraint like Equation 1 maximising stochastic optimisation criterion seen instances stochastic satisﬁability problem SSAT deﬁned Handbook Satisﬁability 6 An SSAT instance deﬁned given propositional formula φ preﬁx variable existentially randomly quantiﬁed meaning variable t takes value true given probability pt independently variables order If existential variables come ﬁrst preﬁx x1 x XRt1 RtT φ X T think variables X decision variables assigned value strategy σ variables T stochastic variables In setting proving σ Equation 1 satisﬁed instance SSAT problem For case X pt 12 variables T majority SAT MAJSAT problem 653 asks probability Rt1 RtT φ X T evaluates true exceeds 12 The slightly general version problem exists 26 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 MAJSAT EMAJSAT 46 takes input preﬁx formula form x1 x XRt1 RtT φ X T xi X t j T pt 12 variables t T aims ﬁnd strategy σ assigns truth values variables x X maximises probability φσ evaluates true 6 Finally functional EMAJSAT 57 generalises allowing pt arbitrary rational probability stochastic variable t T Clearly setting corresponds maximising stochastic optimisation criterion In context stochastic constraint optimisation problems studied work related maximum posteriori MAP inference problem In context propositional logic MAP problem stated follows Given propositional formula φ X T decision variables X stochastic variables T assignment truth values s variables T assignment truth values variables X maximises probability φ X T evaluates true This task known probabilistic inference literature probable explanation MPE task 3854 maximum probability assignment MPA task 9 It shown MAP problem seen constraint optimisation task 60 SCPs related chance constraint optimisation 16 probabilistic CP 69 In particular problems consider work framed singlestage stochastic constraint satisfaction problems SCSPs 72 Our work differs earlier generic approaches solving problems explicitly use structure DD representation probability distributions speed solving process While SCPs certainly related constraint optimisation soft constraints 7 impose hard constraints prob ability distributions refrain discussion soft constraints Mixed networks essentially combine probabilistic graphical models constraint networks 48 Since use probabilistic propositional framework repre sent models consider probabilistic graphical models conceptually somewhat related outside scope discussion In work pay special attention particular subclass SCPs SCPMDs The main difference SCPMDs SCPs SCPMDs deﬁned monotonic distributions We exploit property optimise constraint propagation process SCMDs distinguishes method general approaches 72 While global propagator applied monotonic distributions allow obtain strict bounds constraint propagation These strict bounds achieved alternative methods 57 constraining underlying variable order decision diagrams The variable order diagram determines size eﬃciency constraint propagators depends size diagrams operating Therefore having extra constraints variable order limit possibilities obtaining suﬃciently small diagram disadvantageous Note SDD decomposition method use experiments Section 9 underlying variable order SDDs constrained obtain linear program 43 However methods use OBDDs repre sent probability distributions require constraints variable order OBDD automated conﬁguration experiments indicate OBDDs preferable SDDs context We limited work singlestage optimisation problems In multistage SCPs ﬁrst set decisions value stochastic variables revealed This prompts set decisions value set stochastic variables revealed The goal optimal ﬁrst decision respect given objective function values stochastic variables ﬁrst stage revealed develop policy allows users choose decisions following stages based unfolds values stochastic variables revealed Multistage SCPs typically model planning scheduling problems 347 modelled special cases SSAT problem 6 blocks existentially quantiﬁed randomly quantiﬁed variables alternate preﬁx propositional formula The authors Stochastic MiniZinc 59 implemented generic framework encode generic multistage SCPs solver agnostic manner Since multistage problems typically yield SCPs monotonic distributions study work instead focused leveraging structure singlestage SCPMDs aiming solve faster Our approach keeping constraints linear constraint cardinality separated avoids complexity encoding combination constraints diagram approach taken Pipatsrisawat Darwiche 57 Consequently avoid blowup diagram exploit structure constraints leveraging power dedicated constraint propagators Finally modelling constraints separately allows users add constraints trivially encoded CNF allowing larger expressiveness method Pipatsrisawat Darwiche 57 The main feature distinguishes work similar works stochastic constraint satisfaction optimisation exploit structure probability distribution global SCMD propagator The majority existing methods sample scenarios distribution ignore structures 34 In CP literature OBDDs similar multivalued decision diagrams MDDs encode solutions constraint eﬃcient propagation algorithms data structures developed 323370 By associating MDD arcs encodings probabilities sample solutions constraint 55 Note data structure similar OBDDs solve fundamentally different problem address work Automated optimisation techniques tools SMAC 40 solve optimisation problems approximate probabilistic inference 58 However best knowledge applied optimisation conﬁguration exact probabilistic inference methods 27 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 11 Conclusion outlook We introduced main approaches exactly solving stochastic constraint optimisation problems monotonic dis tributions SCPMDs The ﬁrst general decompositionbased approach applicable stochastic constraint optimisation problems SCPs generic probability distributions leverages existing constraint programming CP mixedinteger programming MIP technology 43 The second speciﬁcally suited solving global stochastic constraints monotonic distributions SCMDs It operates ordered binary decision diagram OBDD encodings prob ability distributions implemented CP solver OscaR 51 In work demonstrated beneﬁts drawbacks methods In summary decomposition method applicable wider range problems eﬃcient traversal search space global SCMD constraint guarantee generalised arc consistency GAC We showed straightforward modiﬁcation method guarantee GAC signiﬁcantly improve solving speed We gave extensive description implementations global SCMD constraint propagator showed incremental way propagating results linear time complexity The beneﬁt partialsweep implementation need traverse complete OBDD cases additional data structures required possible fullsweep propagator considers OBDD incurs smaller overhead pass OBDD In initial set experiments set 52 problem instances different domains demonstrated global SCMD propagation method superior CPdecomposition method However comparing global SCMD approach variations MIP approach approaches complementary approaches consistently outperforming Small trends observed The global SCMD propagators scale better size OBDD MIPdecomposition method For smaller OBDDs fullsweep implementation global SCMD propagator outperforms partialsweep version pronounced larger OBDDs The branching heuristics CP important branching order focuses reducing size active OBDD leads eﬃcient propagation partialsweep implementation larger search trees Overall choice parameter settings important obtain good performance global SCMD propagation MIP methods For fairer comparison applied programming optimisation PbO 36 solving pipelines CP decomposition pipeline MIPdecomposition pipeline global SCMD pipeline We implemented different design choices compilation phase pipelines solving phases We opened parameters possible automated conﬁguration SMAC 40 optimise pipelines benchmarks different domains This approach ensured compare methods conﬁgurations optimised speciﬁc problem settings tested These experiments demonstrated default optimised conﬁgurations generalise larger different types problems Both default optimised conﬁgurations global SCMD approach outperforms CP decomposition method MIPdecomposition method complex problem sets terms solving time We showed SCMD propagator effectively combined constraints linear constraints CoverSize constraint We presented number ideas useful contexts The idea solving SCPs means modular approach decouples knowledge compilation search The creation global constraints search eﬃciently distributions guaranteeing GAC The idea applying algorithm conﬁguration simultaneously conﬁgure different stages pipeline complex tools A number questions remain While theoretical asymptotic worstcase time complexity partialsweep propagator fullsweep propagator practice ﬁnd overhead propagator large Based experiments cost overhead outweigh beneﬁts traversing smaller diagram suﬃciently large instances branching orders reduce size active diagrams Even alternative approach developed smaller overhead remains open question A ﬁrst step approach development propagation algorithm implements priority queues address observations O1O3 Section 54 These require little overhead beneﬁt shrinking active OBDD needs sweeped propagation In work limited attention applications network analysis problems complex interesting monotonicity properties applications require maximisation expected value It interesting study approaches work types problems For example believe constraint propagation algorithm easily modiﬁable applied problems require lower bound expected value minimise cardinality solution We expect methods ﬁnd possible applications domains scheduling vehicle routing problems Here exploit fact easy combine constraint constraints CP 28 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 We applied automated algorithm conﬁguration current study focus running time minimisation Other criteria For example memory use knowledge compilers prohibitively large optimising solving methods use memory increase applicability methods Furthermore best knowledge work represents ﬁrst use automated algorithm conﬁguration exact probabilistic inference The conﬁguration results presented work encourage expect automated solver conﬁguration beneﬁcial optimisation solvers exact probabilistic inference tasks ones discussed work Declaration competing The authors declare known competing ﬁnancial interests personal relationships appeared inﬂuence work reported paper Acknowledgements We thank Hélène Verhaeghe input suggestions We thank Roger Paredes Leonardo DueñasOsorio advice formulation power grid reliability problem interpretation highvoltage data Funding This work supported Netherlands Organisation Scientiﬁc Research NWO TAILOR project funded EU Horizon 2020 research innovation programme GA No 952215 Behrouz Babaki sup ported postdoctoral scholarship IVADO Canada First Research Excellence Fund CFREF grant Appendix A Monotonic distributions locally monotonic OBDDs Some monotonic distributions encoded OBDDs exhibit local nonmonotonic behaviour Here exam ple distribution Example A1 An OBDD locally monotonic Recall power grid reliability example Example 24 let focus encoding survival probability single power line The decision reinforce power line denoted Boolean decision variable d Following notation Example 24 denote survival probability cid13 1 The associated stochastic reinforced p survival probability reinforced p respectively value cid6 line survives value We variables t t encode event φ1 survival power line following formula 0 p p cid13 cid13 cid5 cid6 cid13 φ1 d t d t A1 cid13 cid6 cid13 cid13 p assumption ﬂipping ds truth value cid6 decrease survival probability power When ﬁx d cid6 formula models t cid6 t probability p p Since p line distribution monotonic according Deﬁnition 21 yielding total success probability P φ1 d cid6 p Similarly P φ1 d p cid13 probability p 1 p cid13 t t cid13 An example OBDD encoding formula shown Fig A10a Consider decision node right If set d score node p However set d cid6 score node 0 Consequently ﬂipping value d cid6 locally monotonic Deﬁnition 31 behaviour root OBDD remains monotonic This local nonmonotonic behaviour directly fact falsify φ1 ﬁxing d cid6 second clause This relevant partialsweep version global propagation algorithm Here happen left decision node Fig A10a inactive compute partial derivative right decision node The local nonmonotonic behaviour cause compute negative partial derivative Equation 14 causes longer able guarantee GAC possibly compute incorrect score optimal solution The following example shows construct monotonic probability distribution yield locally monotonic OBDD Example A2 A locally monotonic OBDD Taking example computing survival probability single power line consider alternative encoding φ2 d s t A2 decision variable d stochastic variable t corresponding survival power line rein forced corresponding probability p We associate probability ps p cid13 p1 p stochastic variable s Note Equation A2 contain negations If ﬁx d cid6 corresponding models residual formula s cid6 t probability ps 1 p s t cid6 probability p ps s t cid6 probability cid13 p1 p p 1 ps p bringing total survival probability P φ2 d cid6 p cid13 p1 p 1 p p p cid13 p1 p 1 p 29 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 P φ1 cid13 t cid13 p 1 p cid13 locally monotonic t p p t 1 p 1 p cid5 d t cid6 cid13 d 1 ps d P φ2 s 1 ps t p 1 p 1 0 d 0 An OBDD representation φ1 able order t cid13 d t Probabilities 0 p p d t vari cid13 1 b An OBDD representation φ2 d s t variable order s d t Here ps p cid13 p1 p 0 p ps p cid13 1 Fig A10 Two different OBDD representations probability distribution cid13 p p p cid13 p1 p p p cid13 p assumption distribution monotonic according Deﬁnition 21 p cid13 p1 p 1 p cid13 p p p cid13 Similarly P φ2 d p Again An example OBDD encoding formula shown Fig A10b Note decision node OBDD displays locally monotonic behaviour OBDD locally monotonic according Deﬁnition 31 Appendix B Pseudocode partialsweep propagation algorithm Because pseudo code partialsweep SCMD propagation algorithm lengthy include main paper provide appendix Note OscaR 51 uses reversible data structures provide convenient support backtracking We include undo operations backtracking algorithm mechanisms provided reversible data structures implemented OscaR B1 Notation terminology We use r refer node OBDD r lo hi child respectively We use varr indicate variable labels node r use wr indicate weight case varr stochastic variable The path weight r denoted π r score according Equation 5 sr r We assume nodes OBDD indexed topological way path root leaf corresponds series increasing indices In topdown bottomup sweep algorithms use queues limit number nodes visit sweep In pseudo code queue corresponding downward sweep represented Q elements queue sorted increasing order OBDD node index queue upward sweep denoted U elements queue sorted decreasing order OBDD node index Note treat queues sets contain unique elements We iterate OBDD nodes labelled particular decision variable d We denote set particular decision nodes OBDDd For compactness refer node labelled stochastic variable stochastic node We use similar shorthands free unbound decision nodes bound decision nodes true decision nodes false decision nodes In case decision nodes deﬁne active child node follows A child decision node active hi child free true decision node lo child false decision node Algorithm B9 We think propagation act removing outgoing arcs decision nodes ﬁx corresponding decision variable recall Fig 4 Section 54 Speciﬁcally remove OBDD arc p c parent p child c ﬁx varp true c ps lo child ﬁx varp false c ps hi child Algorithm B9 Through process removing arcs effectively remove valid paths recall deﬁnition valid path Section 53 OBDD Valid paths OBDD roots internal OBDD nodes active decision nodes determine consider OBDD nodes relevant given current partial strategy corresponding removed arcs There ways node r relevant In ﬁrst case free decision node reachable valid path OBDD root In second case free decision node 30 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 valid path free decision node r diagram r valid path r free decision node Algorithm B9 In order determine node relevant track OBDD active Section 54 associate counters node r Reachabler Indicates number valid paths artiﬁcial root OBDD r The counter artiﬁcial root actual OBDD roots 1 FreeInr Indicates number incoming arcs valid path free decision nodes r OBDD This counter values 0parentsr FreeOutr Indicates number arcs outgoing r valid path r free decision nodes r For node OBDD counter values 02 For leaves counter equal 0 In general case OBDD multiple roots corresponding query original SCPMD In order deﬁne Reachable counter implementation added artiﬁcial root OBDD outgoing arc original roots The intuition Reachable counter following search propagation assignments deci sion variables disconnect OBDD root remove arcs accordingly observation O6 Section 54 This happens example Fig 4b The FreeIn counter node r value domain Reachable counter represents different concept As addressed observation O4 Section 54 score changes nodes descendants free decision nodes inﬂuence scores decision nodes Therefore bottomup traversal OBDD update scores Algorithm B4 need propagate way roots Once encounter node r score changed recent value assignment decision variables valid path artiﬁcial OBDD root passes free decision node need enqueue parents r score updates We track counting incoming arcs node r path The logic FreeOut counter similar FreeIn counter However instead stopping ward sweep serves stop downward sweep path weight computation address observation O5 Section 54 The value FreeOut counter node r 0 1 2 represent number children FreeOut counter valid paths free decision nodes Observe node r ﬁxed decision node value FreeOut counter exceed 1 outgoing arcs r removed ﬁxing corresponding decision variable B2 An SCPMD solving algorithm Algorithm B1 shows basic steps needed solving SCPMD maximise expectation setting problems described Examples 21 22 belong Recall problems seek maximise expected score We use SCMD solving problems solving constraint cid2 ρr P r σ θ B1 rroots soon solution score s ﬁnd new solution larger score B3 Initialisation update θ value continue search Before search solution stochastic constraint Equation 1 begins initialise data structures needed enforcing SCMD function InitialiseSCMDOBDD X given Algorithm B2 B4 Partialsweep propagation algorithm During search decision variables ﬁxed repeatedly PropagateSCMD function Algorithm B3 recompute scores path weights partial derivatives score partial strategy track relevant OBDD We ﬁrst update arrays record current scores path weights nodes OBDD functions Algorithms B4 B5 Then detect currently free decision variables ﬁxed true order obtain score larger current value θ EnforceDomainConsistency function Algorithm B6 This function ﬁxes variables accordingly Finally maintain relevant OBDD updating counters presented Appendix B1 functions Algorithms B7 B8 To increase readability pseudocode use helper functions speciﬁed Algorithm B9 31 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Algorithm B1 Solving SCPMD maximise expectation setting Input OBDD set decision variables X maximum cardinality k These considered global variables Output optimal strategy σ corresponding score sσ d 1 procedure Branchσ cid13 Xfree Xfree d 2 F d 3 σ cid13 σ cid13 d 4 conﬂict σ cid13 F PropagateSCMDσ cid13 5 conﬂict return Backtrack end 6 conﬂict σ cid13 F PropagateCardinalityConstraintσ cid13 7 conﬂict return Backtrack end 8 Solveσ cid13 9 F cid21 The set decision variables ﬁxed Branch function cid21 Update partial strategy cid21 See Algorithm B3 F cid21 Assumed given outside scope work cid21 Score computed incrementally Algorithm B3 Xfree sσ cid13 s σ σ cid13 sσ s UpdateSCMDthresholds return Backtrack 10 procedure Solveσ cid13 11 12 13 14 15 16 17 18 19 d Xfree SelectValuedomd Branchσ cid13 d Branchσ cid13 d 20 InitialiseSCMD 21 InitialiseCardinalityConstraint X k 22 Xfree X 23 σ d d X s 24 σ cid13 EnforceDomainConsistency X f ree 25 Solveσ cid13 26 return σ 0 sσ cid21 There different selection strategies determining d branch cid21 And different strategies determining value branch cid21 See Algorithm B2 cid21 Assumed given outside scope work cid21 Set free decision variables global variable cid21 Optimal strategy corresponding score global variables cid21 Fix variables true obtain partial strategy Algorithm B6 32 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Algorithm B2 Initialisation data structures Note OBDD X considered global variables r OBDD FreeInr 0 end r sortedOBDD 1 procedure InitialiseFreeIn 2 3 4 5 6 FreeInr FreeInr varr decision OR FreeInr 0 FreeInr FreeInr 1 1 r OBDD FreeOutr 0 end r reversedsortedOBDD 7 procedure InitialiseFreeOut 8 9 10 11 varr decision OR FreeOutr 0 p parentsr FreeOutp FreeOutp 1 end r OBDD Reachabler 0 end Reachableroot 1 r sortedOBDD 12 procedure InitialiseReachable 13 14 15 16 17 FreeInr FreeInr Reachabler Reachabler 1 1 1 wr sr r reversedsortedOBDD r OBDD π r 0 end r sortedOBDD sr sr sr wr sr varr decision 18 procedure InitialiseScores 19 20 21 22 23 24 procedure InitialisePathWeights 25 26 27 28 29 30 31 32 33 34 p parentsr π r π r ρr varp decision 35 π r π r π p w r original root OBDD r hi child p w 1 w 0 r hi child p w wp w 1 wp cid21 Downward sweep cid21 Upward sweep cid21 Downward sweep cid21 Upward sweep cid21 Downward sweep 36 procedure InitialiseSCMD InitialiseFreeIn 37 InitialiseFreeOut 38 InitialiseReachable 39 InitialiseScores 40 InitialisePathWeights 41 θ 0 42 cid21 The current best score beat Algorithm B3 SCMD propagation algorithm propagating consequences given partial strategy σ cid13 set currently free decision variables X f ree global variable sold F Note 1 procedure PropagateSCMDσ cid13 2 3 4 5 6 7 8 9 10 s sold δ UpdateScoresF s s δ s θ return true σ cid13 F end UpdatePathWeightsF σ cid13 F EnforceDomainConsistencyσ cid13 UpdateReachableFreeInF UpdateFreeOutF return f alse σ cid13 F cid21 Score previous partial strategy cid21 δ sum derivatives decision variables recently ﬁxed false Algorithm B4 cid21 score current partial strategy σ cid13 cid21 If satisfy constraint return backtrack cid21 See Algorithm B5 cid21 See Algorithm B6 cid21 See Algorithm B7 cid21 See Algorithm B8 F s 33 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Algorithm B4 Given set F decision variables recently ﬁxed branching propagation update node scores Equation 5 changed new truth assignments See Algorithm B9 helper functions U r varr F varr Reachabler 0 δ 0 sold 0 U cid22 1 procedure UpdateScoresF 2 3 4 5 6 7 8 9 10 11 r U dequeue sold sr varr X sr s activeChildr varr F varr false cid5 sr δ δ π r sr cid6 1 wr sr sne w wr sr sne w cid22 sold sr sne w p parentsr removedp r enqueueRelevantU p end return δ cid21 Upward sweep cid21 Max heap treat set cid21 The combined derivative variables ﬁxed false round cid21 Old score OBDD node cid21 r decision node cid21 r stochastic node cid21 We need continue propagation score r changed Algorithm B5 Given set F decision variables ﬁxed branching propagation update path weights changed See Algorithm B9 helper functions r r varr F Reachabler 0 1 procedure UpdatePathWeightsF 2 Q 3 4 5 6 varr false Qenqueuer Qenqueuer cid21 Downward sweep cid21 Min heap treat set Q cid22 r Qdequeue πold π r r original root OBDD πne w ρr πne w 0 cid21 Roots path weight ρr utility corresponding query p parentsr varp decision variable activeChildp r w 1 w 0 r hi child p w wp w 1 wp πne w πne w π p w πne w cid22 πold π r πne w varr stochastic variable enqueueRelevantQ r enqueueRelevantQ r enqueueRelevantQ activeChildr cid21 r decision node cid21 r stochastic node cid21 We need continue propagation path weight changed cid21 r stochastic node cid21 r decision node 12 13 14 15 16 17 18 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 Algorithm B6 Enforce domain consistency ﬁxing free variables true ﬁnd ﬁxing false lead solution stochastic constraint 1 procedure EnforceDomainConsistencyσ cid13 2 3 4 5 d X f ree cid11 0 r r OBDDd Reachabler cid5 sr cid21 Partial derivative free decision variable d sr F s cid6 cid21 Update partial derivative d cid21 The current partial strategy extended valid solution ﬁx d false cid21 Infer d true cid11 cid11 π r s cid11 θ σ cid13 σ cid13 d true X f ree X f ree d F F d F return σ cid13 6 7 8 9 10 34 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Algorithm B7 Update Reachable FreeIn counters ﬁxing decision variables F See Algorithm B9 helper functions 1 procedure UpdateReachableFreeInF 2 Q 3 4 5 Qenqueuer procedure EnqueueIfNeedToPropagater FreeOutr 0 FreeInr 0 OR Reachable 0 cid21 Downward sweep cid21 Min heap treat set S r varr F Reachabler 0 FreeOutr 0 r S activeChildr inactiveChildr leaf FreeInr 0 FreeIna FreeIna 1 S EnqueueIfNeedToPropagatea end leaf FreeIni FreeIni 1 Reachablei Reachablei 1 S EnqueueIfNeedToPropagatei end Q cid22 r Qdequeue Reachabler 0 c childrenr c leaf removedr c FreeInc FreeInc 1 Reachablec Reachablec 1 EnqueueIfNeedToPropagatec FreeInr 0 varr decision varr bound c childrenr c leaf removedr c FreeInc FreeInc 1 EnqueueIfNeedToPropagatec 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 7 8 9 10 11 Algorithm B8 Update FreeOut counter ﬁxing decision variables V See Algorithm B9 helper functions cid21 Upward sweep cid21 Max heap treat set U r varr V Reachabler 0 FreeInr 0 U cid22 1 procedure UpdateFreeOutV 2 3 4 5 6 r U dequeue varr V FreeOutactiveChildr 0 FreeOutr 1 FreeOutr 0 FreeOutr 0 varr stochastic variable OR varr bound p parentsr removedp r relevantp FreeOutp FreeOutp 1 U enqueuep Appendix C Expansion parameter space In appendix provide details design space compilation phase global SCMD propagator solving phase addition brief summary Section 84 C1 Compilation phase parameter space We summarise parameters compilation phase pipelines Table C8 Note ﬁrst parame ters choose OBDD SDD compilation choose minimise DD Because focus OBDDs work explicitly listed OBDD compilation parameters Table C8 As table shows tune categorical OBDDspeciﬁc parameters parameters integer domains real domain Since SDDs succinct OBDDs yield smaller potentially easiertosolve LPs consider SDD encodings conﬁguration experiments For SDD compilation tune convergence threshold parameter parameters related limiting size Cartesian product created SDD minimisation operations parameters related limiting relative increase size SDD minimisation operations parameters related limiting time taken minimisation operations The SDDspeciﬁc parameters tune include categorical parameters ﬁve parameters integer domains parameters real domains 35 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Algorithm B9 Helper functions update algorithms Upon ﬁnding solution score s update threshold θ score beat 1 procedure UpdateSCMDthresholds 2 θ s For free true variables hi child active For false variables lo child active This function returns active child node r case varr free 3 procedure activeChildr switch varr 4 5 6 7 8 9 10 case varr true case varr false return r return r return r Fixing variables values corresponds removing outgoing arc corresponding opposite value diagram This function checks arc removed varp free activeChildp cid22 r 11 procedure removedp r 12 13 14 return false return true A node relevant corresponds free decision variable connection root node corresponds stochastic variable path free decision node varr free Reachabler 0 FreeInr 0 FreeOutr 0 return true 15 procedure relevantr 16 17 18 19 20 21 return false return true 22 procedure enqueueRelevantQ r 23 relevantr Qenqueuer end Table C8 The conﬁguration space compilation phase pipelines Note parameters conditional value parameters parameter Diagram Minimise DynMinimise domain OBDD SDD true false true false description Compile φ X T OBDD SDD Minimise DD compilation Use dynamic minimisation compilation Parameters conditional Diagram OBDD VarOrder Sif SymSif GSif WP SA GA Rand true false Converging MaxSwap MaxSift MaxGrowth WSizes N N R 2 3 4 Variable reordering algorithm OBDD minimisation Minimise true Repeat variable reordering algorithm improvement OBDD size VarOrder Sif SymSif GSif WP Upper bound number times variables swapped variable order VarOrder Sif SymSif GSif Upper bound number variables sifted moved variable order VarOrder Sif SymSif GSif Upper bound relative OBDD size increase minimisation VarOrder Sif SymSif GSif Evaluate permutations WSizes consecutive variables variable order time VarOrder WP C2 SCMD propagator parameter space Since branching heuristics big inﬂuence size search tree implemented number alternative branching heuristics global SCMD propagation method We brieﬂy discussed Section 84 summarise Table C9 In problems decision variables associated nodes network Example 21 Degree heuristic branches based unweighted undirected degree nodes Similarly Inﬂuence estimates inﬂuence nodes order quickly ﬁnd highquality solution inspired work social inﬂuence 11 We translate inﬂuence heuristic problems decision variables associated edges underlying network Example 22 taking edge sum inﬂuence scores endpoints We compute degreebased score edges local degree measure 45 36 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 Table C9 The branching heuristics global SCMD propagator Some parameters conditional value parameters parameter VarSelHeur ValSelHeur TimeSteps NumSamples FireProb EdgesBurnt domain Top Bottom Derivative Degree Inﬂuence Triangle Similarity Simmelian ForestFire Betweenness Ran dom 0 1 N N 0 1 0 1 description Heuristics select variable branch Heuristics select value branch ﬁrst If VarSelHeur Inﬂuence If VarSelHeur Betweenness If VarSelHeur ForestFire If VarSelHeur ForestFire We observe problems theory compression problem spine problem instances power grid reliability problem Example 22 similar graph sparsiﬁcation problems We derived Triangle Similarity Simmelian ForestFire heuristics recent work problem 4566 For Triangle heuristic simply number triangles node edge taking account weights directionality create versions heuristic suitable problems decision variables nodes edges respectively We translated Similarity Simmelian ForestFire heuristics problems decision variables associated nodes underlying network Example 21 summing scores incident edges node taking account weights directionality Finally use estimate node edge betweenness centrality proxy importance decision variable Betweenness heuristic References 1 CC Aggarwal J Han Eds Frequent Pattern Mining Springer 2014 2 C Ansótegui Y Malitsky H Samulowitz M Sellmann K Tierney Modelbased genetic algorithms algorithm conﬁguration IJCAI AAAI Press 3 B Babaki T Guns L De Raedt Stochastic constraint programming ANDOR branchandbound IJCAI ijcaiorg 2017 pp 539545 4 P Balaprakash M Birattari T Stützle Improvement strategies FRace algorithm sampling design iterative reﬁnement Proceedings 2015 pp 733739 HM Springer 2007 pp 108122 5 A Bart F Koriche J Lagniez P Marquis An improved CNF encoding scheme probabilistic inference ECAI IOS Press 2016 pp 613621 6 A Biere M Heule H van Maaren T Walsh Eds Handbook Satisﬁability Frontiers Artiﬁcial Intelligence Applications vol 185 IOS Press 2009 7 S Bistarelli F Rossi Semiringbased soft constraints Concurrency Graphs Models Springer 2008 pp 155173 8 VD Blondel J Guillaume R Lambiotte E Lefebvre Fast unfolding community hierarchies large networks arXiv0803 0476 abs 2008 9 HL Bodlaender F van den Eijkhof LC van der Gaag On complexity MPA problem probabilistic networks ECAI IOS Press 2002 pp 675679 10 B Bollig I Wegener Improving variable ordering OBDDs NPcomplete IEEE Trans Comput 45 1996 9931002 11 C Borgs M Brautbar JT Chayes B Lucier Maximizing social inﬂuence nearly optimal time SODA SIAM 2014 pp 946957 12 S Bova SDDs exponentially succinct OBDDs AAAI AAAI Press 2016 pp 929935 13 SP Bradley AC Hax TL Magnanti Applied Mathematical Programming AddisonWesley 1977 14 RE Bryant Graphbased algorithms Boolean function manipulation IEEE Trans Comput 35 1986 677691 15 Y Caseau F Laburthe Solving weighted matching problems constraints Constraints 5 2000 141160 16 A Charnes WW Cooper Chanceconstrained programming Manag Sci 6 1959 7379 17 M Chavira A Darwiche On probabilistic inference weighted model counting Artif Intell 172 2008 772799 18 A Choi A Darwiche Dynamic minimization sentential decision diagrams AAAI AAAI Press 2013 pp 187194 19 GH Dal PJF Lucas Weighted positive binary decision diagrams exact probabilistic inference Int J Approx Reason 90 2017 411432 20 A Darwiche On tractable counting theory models application truth maintenance belief revision J Appl NonClass Log 11 2001 1134 21 A Darwiche A differential approach inference Bayesian networks J ACM 50 2003 280305 22 A Darwiche Modeling Reasoning Bayesian Networks Cambridge University Press 2009 23 A Darwiche SDD new canonical representation propositional knowledge bases IJCAI IJCAIAAAI 2011 pp 819826 24 L De Raedt K Kersting A Kimmig K Revoredo H Toivonen Compressing probabilistic Prolog programs Mach Learn 70 2008 151168 25 L De Raedt A Kimmig H Toivonen ProbLog probabilistic Prolog application link discovery IJCAI 2007 pp 24622467 26 PM Domingos M Richardson Mining network value customers KDD ACM 2001 pp 5766 27 C Domshlak J Hoffmann Probabilistic planning heuristic forward search weighted model counting J Artif Intell Res 30 2007 565620 28 DTAI Research Group KU Leuven ProbLog Python library httpsgithub com MLKULeuven problog 20152019 29 L DueñasOsorio KS Meel R Paredes MY Vardi Countingbased reliability estimation powertransmission grids AAAI 2017 pp 44884494 30 D Fierens G Van den Broeck J Renkens D Shterionov B Gutmann I Thon G Janssens L De Raedt Inference learning probabilistic logic programs weighted Boolean formulas Theory Pract Log Program 15 2015 358401 31 D Fokkinga ALD Latour M Anastacio S Nijssen H Hoos Programming stochastic constraint optimisation algorithm optimisation Data Science Meets Optimisation Workshop Conjunction IJCAI 2019 32 G Gange PJ Stuckey V Lagoon Fast set bounds propagation BDDSAT hybrid J Artif Intell Res 38 2010 307338 33 P Hawkins PJ Stuckey A hybrid BDD SAT ﬁnite domain constraint solver PADL Springer 2006 pp 103117 34 D Hemmi G Tack M Wallace A recursive scenario decomposition algorithm combinatorial multistage stochastic optimisation problems AAAI 2018 pp 13221329 35 HH Hoos Automated algorithm conﬁguration parameter tuning Autonomous Search Springer 2012 pp 3771 36 HH Hoos Programming optimization Commun ACM 55 2012 7080 37 J Huang Combining knowledge compilation search conformant probabilistic planning ICAPS AAAI 2006 pp 253262 38 J Huang M Chavira A Darwiche Solving MAP exactly searching compiled arithmetic circuits AAAI AAAI Press 2006 pp 11431148 37 ALD Latour B Babaki D Fokkinga et al Artiﬁcial Intelligence 304 2022 103650 2011 pp 507523 39 F Hutter HH Hoos K LeytonBrown Automated conﬁguration mixed integer programming solvers CPAIOR Springer 2010 pp 186202 40 F Hutter HH Hoos K LeytonBrown Sequential modelbased optimization general algorithm conﬁguration Proceedings LION Springer 41 D Kempe JM Kleinberg Éva Tardos Maximizing spread inﬂuence social network KDD ACM 2003 pp 137146 42 L Kotthoff Constraint solvers empirical evaluation design decisions CoRR arXiv1002 0134 abs 2010 43 ALD Latour B Babaki A Dries A Kimmig G Van den Broeck S Nijssen Combining stochastic constraint optimization probabilistic programming knowledge compilation constraint solving CP Springer 2017 pp 495511 44 ALD Latour B Babaki S Nijssen Stochastic constraint propagation mining probabilistic networks IJCAI ijcaiorg 2019 pp 11371145 45 G Lindner CL Staudt M Hamann H Meyerhenke D Wagner Structurepreserving sparsiﬁcation social networks ASONAM ACM 2015 pp 448454 46 ML Littman J Goldsmith M Mundhenk The computational complexity probabilistic planning J Artif Intell Res 9 1998 136 47 M Lombardi M Milano Allocation scheduling conditional task graphs Artif Intell 174 2010 500529 48 R Mateescu R Dechter Mixed deterministic probabilistic networks Ann Math Artif Intell 54 2008 351 49 KIM McKinnon HP Williams Constructing integer programming models predicate calculus Ann Oper Res 21 1989 227245 50 ME Newman The structure scientiﬁc collaboration networks Proc Natl Acad Sci 98 2001 404409 51 OscaR Team OscaR scala OR Available httpsbitbucket org oscarlib oscar 2012 52 O Ourfali T Shlomi T Ideker E Ruppin R Sharan SPINE framework signalingregulatory pathway inference causeeffect experiments ISMBECCB Supplement Bioinformatics 2007 pp 359366 53 CH Papadimitriou Games nature J Comput Syst Sci 31 1985 288301 54 JD Park A Darwiche Solving MAP exactly systematic search UAI Morgan Kaufmann 2003 pp 459468 55 G Perez J Régin MDDs sampling probability constraints CP Springer 2017 pp 226242 56 K Pipatsrisawat A Darwiche New compilation languages based structured decomposability AAAI AAAI Press 2008 pp 517522 57 K Pipatsrisawat A Darwiche A new dDNNFbased bound computation algorithm functional EMAJSAT IJCAI 2009 pp 590595 58 T Rainforth TA Le J van Meent MA Osborne FD Wood Bayesian optimization probabilistic programs NIPS 2016 pp 280288 59 A Rendl G Tack PJ Stuckey Stochastic MiniZinc CP Springer 2014 pp 636645 60 S Riedel Improving accuracy eﬃciency map inference markov logic Proceedings TwentyFourth Conference Uncertainty Artiﬁcial Intelligence 2008 pp 468475 61 F Rossi P van Beek T Walsh Eds Handbook Constraint Programming Foundations Artiﬁcial Intelligence vol 2 Elsevier 2006 62 D Roth On hardness approximate reasoning Artif Intell 82 1996 273302 63 R Rudell Dynamic variable ordering ordered binary decision diagrams Proceedings IEEEACM ICCAD IEEE 1993 pp 4247 64 T Sang P Beame HA Kautz Performing Bayesian inference weighted model counting AAAI AAAI Press The MIT Press 2005 pp 475482 65 T Sato A statistical learning method logic programs distribution semantics ICLP MIT Press 1995 pp 715729 66 V Satuluri S Parthasarathy Y Ruan Local graph sparsiﬁcation scalable clustering SIGMOD Conference ACM 2011 pp 721732 67 P Schaus JOR Aoga T Guns Coversize global constraint frequencybased itemset mining CP Springer 2017 pp 529546 68 F Somenzi CUDD CU Decision Diagram packagerelease 240 University Colorado Boulder 2004 69 SA Tarim B Hnich SD Prestwich R Rossi Finding reliable solutions eventdriven probabilistic constraint programming Ann Oper Res 171 2009 7799 70 H Verhaeghe C Lecoutre P Schaus CompactMDD eﬃciently ﬁltering sMDD constraints reversible sparse bitsets IJCAI 2018 pp 13831389 71 B Viswanath A Mislove M Cha K Gummadi On evolution user interaction Facebook Proceedings ACM SIGCOMM WOSN 2009 pp 3742 72 T Walsh Stochastic constraint programming ECAI IOS Press 2002 pp 111115 73 B Wiegmans Gridkit European NorthAmerican extracts httpsdoi org 10 5281 zenodo 47317 2016 74 Y Xue X Wu D Morin B Dilkina A Fuller JA Royle CP Gomes Dynamic optimization landscape connectivity embedding spatialcapture recapture information AAAI AAAI Press 2017 pp 45524558 38