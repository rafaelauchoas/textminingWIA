Artiﬁcial Intelligence 300 2021 103555 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Hard choices artiﬁcial intelligence Thomas Krendl Gilbert b Roel Dobbe Faculty Technology Policy Management Delft University Technology The Netherlands b Center HumanCompatible AI UC Berkeley United States America c University WisconsinMadison United States America Yonatan Mintz c1 r t c l e n f o b s t r c t Article history Received 22 June 2020 Received revised form 31 May 2021 Accepted 5 July 2021 Available online 14 July 2021 Keywords AI ethics AI safety AI governance AI regulation Philosophy artiﬁcial intelligence Sociotechnical systems 1 Introduction As AI systems integrated high stakes social domains researchers examine design operate safe ethical manner However criteria identifying diagnosing safety risks complex social contexts remain unclear contested In paper examine vagueness debates safety ethical behavior AI systems We vagueness resolved mathematical formalism instead requiring deliberation politics development context deployment Drawing new sociotechnical lexicon redeﬁne vagueness terms distinct design challenges key stages AI development The resulting framework Hard Choices Artiﬁcial Intelligence HCAI empowers developers 1 identifying points overlap design decisions major sociotechnical challenges 2 motivating creation stakeholder feedback channels safety issues exhaustively addressed As HCAI contributes timely debate status AI development democratic societies arguing deliberation goal AI Safety procedure ensured 2021 The Authors Published Elsevier BV This open access article CC BY license httpcreativecommonsorglicensesby40 The rapid adoption AI systems reshaping public professional personal domains providing opportunities innovation generating new forms harm These harms diverse ranging physical dangers related new robotic systems autonomous vehicles 1 economic losses related welfare systems 2 forms racism discrimination systems engage biometrical data public spaces 34 personal data social media platforms 56 These cases reveal emerging gaps promised beneﬁcial outcomes AI applications actual consequences deployed systems Ongoing risks harms product sociotechnical gap great divide know support socially support technically 7 In response broad spectrum civil society initiatives emerged safeguard human domains effects AI systems Debates sociotechnical gap taken forms One proposal normative principles determine gap ﬁlled This led plethora reports statements 8 AI governed respect fundamental rights 910 alongside growing need operationalize principles 11 For example OECD Principles Artiﬁcial Intelligence promote artiﬁcial intelligence AI inno Corresponding author TU Delft Faculty Technology Policy Management Building 31 Jaffalaan 5 2628BX Delft The Netherlands Corresponding author UC Berkeley Graduate Division 424 Sproul Hall Delft CA 947205900 United States Email addresses rijdobbetudelftnl R Dobbe tg340berkeleyedu T Krendl Gilbert 1 All authors contributed equally work httpsdoiorg101016jartint2021103555 00043702 2021 The Authors Published Elsevier BV This open access article CC BY license httpcreativecommonsorglicensesby40 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 vative trustworthy respects human rights democratic values signed governments 12 The European Commission recently proposed regulatory framework translate higherlevel principles concrete technical legal solutions harmonized standards 13 However unclear standards reconcile diverse needs users context particular systems domains Second proposal technical tools better ﬁll gap While efforts generated technical approaches related mathematical criteria safety fairness systematic organization prioritization remains unclear contested 1417 Missing debates sustained interrogation means identify diagnose ultimately ﬁll sociotechnical gaps generated AI systems This entails asking deeper questions given restructure human values social practices technical governance criteria reconciled design choices gaps emerge systems development lifecycle Put differently lack presentation AI development form machine politics interrogating evaluating choices structure systems design implementation turn reorganize human domains In terms machine politics AI development deliberative practice comprising human constituencies basic organizational choices status political community Concretely AI requires consensus deﬁnition mean safe But present proposals technical safety governance AI systems tend focus safety criterion technical design operational conditions experience end users This means safety criteria marred underlying vagueness absence unifying categories establish systems capabilities safe This paper makes key claims First AI development reconceived terms multiple points encounter capabilities sociotechnical gaps This requires new vocabulary framework sense salient gaps context technical design decisions constituting reciprocal relationship development governance Second developers new roles sensitive feedback manage gaps This requires communicative channels stakeholders empowered help shape criteria design decisions Our contributions ﬂow claims In Section 2 supply lexicon terms problems stake sociotechnical gaps In Section 3 analyze present landscape proposed technical normative solutions particular gaps terms piecemeal responses vagueness In Section 4 present Hard Choices Artiﬁcial Intelligence HCAI systematic framework maps possible gaps particular feedback channels designers stakeholders use In Section 5 present frameworks implications designers advocates evaluating technical performance governance standards actual systems Section 6 concludes We emphasize concerns responding recent iterations AI systems new The research agenda situated design 18 Agres critical technical practice 19 comprise classic phe nomenological critiques good oldfashioned symbolic expert systems particular need critical certain formal assumptions intelligence reassess problematic metaphors perception action 20 Yet technical research today moved critiques Reinforcement learning RL example reﬂects Dreyfus exposition intelligence learned situated dynamic activity developed coping ones surrounding environment embodying different strategies action The question longer computers structure computation ways support human values concerns To support aim propose AI prac titioners need new cybernetic practices guide feedback solicited existing emerging political orders We apply insight AI development scholars Science Technology Studies STS appreciated decades technological political requiring collective agency corresponding forms deliberation ensure safety affected 21 2 Towards sociotechnical lexicon AI At present AI research lacks robust sociotechnical lexicon This include emerging problem space AI Safety newlyrelevant questions cybernetics context present future AI governance topics In section present preliminary lexicon reveal areas overlap divergence domains enabling comparison contemporary assumptions AI development possible alternative paradigms As stated original Dartmouth summer project proposal research artiﬁcial intelligence meant pursue conjecture aspect learning feature intelligence principle precisely described machine simulate 22 Beneath speciﬁc efforts simulate language brain models intellectual creativity AI theorists interested precision adequately specifying mechanisms underpinning intelligence possible replicate computation symbolic reasoning This quest exactness tinued underpin technical conceptual interventions model intelligent behavior agents environment including problem speciﬁcation reinforcement learning 2324 agencythe capacity agent human artiﬁcial act order achieve particular outcome result intelligent agent IAan autonomous entity acts directing activity achieving goals environmenta domain IA perceive sensors act actuators pursuit goal AI modela mathematical representation environment constructed simple rules model combination thereof parameters learned updated observed data 2 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 objective functiona mathematical representation capturing goals IA speciﬁcationthe deﬁnitions environment IAs sensors actuators internal model objective function necessary operate learn perform particular task artiﬁcial intelligencethe study design IAs simulate approximate surpass precise capabilities human intelligence In recent years rapid advent AI functionality societal domains motivated formulation principles deﬁnitions consider artifacts setting Here include deﬁnitions adopted OECD 2019 12 AI systema machinebased given set humandeﬁned objectives predictions recommen dations decisions inﬂuencing real virtual environments AI systems designed operate varying levels autonomy AI lifecycleinvolves design data models contextdependent sequence encompassing plan ning design data collection processing model building ii veriﬁcation validation iii deploy ment iv operation monitoring These phases place iterative manner necessarily sequential The decision retire AI operation occur point operation moni toring phase AI knowledgethe skills resources data code algorithms models research knowhow training pro grammes governance processes best practices required understand participate AI lifecycle AI actorsthose play active role AI lifecycle including organizations individuals deploy operate AI stakeholdersall organizations individuals involved affected AI systems directly indirectly AI actors subset stakeholders stakeholdera person entity vested AI systems performance operation Today lens AI largely inspired ﬁeld AI Safety associated technical project value alignment aims build provably beneﬁcial systems learn precise preference structures humans 25 Value alignment assumes deterministic description exists discoverable artiﬁcial agents create precise mechanisms learning modeled mathematical conditions uncertainty AI Safetythe interdisciplinary study build systems aligned structure human values particular stakeholders meant serve value alignmentthe creation systems speciﬁcation suﬃcient learn structure human values In practice AI research redeﬁning philosophical concepts context AI solving particular engineering science challenges But fundamental gap idea value alignment managing actual consequences deployed systems Decades research systems engineering safetycritical systems shown values safety fairness emergent property arise interactions components 26 Here boundary components entail technical elements intelligent agents human agents processes supporting infrastructure The emergent properties controlled imposing constraints behavior interactions compo nents Safety control problem goal control enforce safety constraints Accidents result inadequate control enforcement safetyrelated constraints development design operation 26 The emergent dynamic nature values inability discover formalize technical logics corroborated long tradition research computersupported cooperative work 27 humancomputer interaction 28 participatory design 29 As Halloran et al conclude values emerge look 29 This problem resonates classic problem space cybernetics continuously interrogating elaborating relationship actions goals forms feedback deterministic problem formulation static representation value 3031 In cybernetics performance thresholds determined concrete outcomes actions taken preciselydeﬁned capacities agent reﬂect stylized view intelligence This entails looking level systems composed integrated components values safety instantiated maintained conditions stability feedbackinformation results agents systems actions taken inputs future actions serving basis improvement stability cyberneticsthe interdisciplinary study systems behave response feedback 3 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 As pragmatist philosophers sociotechnical scholars long emphasized bridging gap design principles realworld performance requires specifying normativity problem domain terms acceptable haviors outcomes 3233 On interpretation cybernetic feedback needed bridge gap problem formulation deﬁning systems interface reality The question norms passively learned agent enacted new forms feedback The implies uncertainty norms principle modeled learning reward function represents human preferences The suggests indeterminacy resolved broader lens instantiate design governance norms Recent work AI Governance suggests As argued Wallach Marchant pressing regula tory questions require new institutional entities tasked articulating metrics standards new forms domain expertise determine acceptable performance thresholds particular AI systems 34 This include governance ordination committees 35 International Artiﬁcial Intelligence Organization 36 Facebook Oversight Board 37 judicial oversight spirit EU General Data Protection Regulation 38 issues studied National Institute Standards Technology 39 arms race scenario modeling 40 This emerging literature seeks resolve situations indeterminate performance levels normative abstraction ranging individual privacy global security concerns sociotechnicsthe relationship realworld conditions speciﬁcation requires active engage ment concerns stakeholders normativitythe reciprocal expectations agents conform particular agreedupon standards behavior given domain normative uncertaintythe unknown features environment agent learn order behave optimally normative indeterminacythe lack prior standards forms consensus sociotechnical context given rendering speciﬁcation problematic incomplete Contemporary sociotechnical concerns development AI systems share common theme data accumulation increasing computational capacity new algorithmic learning procedures reconstituting normative systems humans live 4143 In sense problem space AI Safety rediscovering cybernetics new ground There emerging need sociotechnical speciﬁcations able diagnose resolve undesirable performance semantic equivocations political conﬂicts This requires principled elaboration AI systems technical speciﬁcations model objective function sensors actuators interpreted light salient normative considera tions realworld performance thresholds stem social situated context operates Without clarifying landscape possible evaluate particular governance mechanisms different institutional scales appropriate addressing indeterminacies stake featurizationthe systems capacity represent features environment order achieve speciﬁed goal optimizationthe designers capacity articulate eﬃciently cost minimization appropriately com plete task integrationthe capacity users managers regulators stakeholders oversee incorporate systems real world performance sociotechnical speciﬁcationthe proposed normativity AI terms featurization optimization integration deﬁning meant serve purpose evaluated held accountable As Erdelyi Goldsmith note choice harder softer types legalization AI systems involves contextdependent tradeoff actors carefully consider casebycase basis 36 To weigh tradeoffs ﬁrst possible index values norms terms technical decisions speciﬁcation This means normative concerns comparable signiﬁcance scope rendered commensurable order responsible tradeoff struck translated systems speciﬁcation Ruth Chang highlighted related philosophical notion parity 4445 holds humans able articulate evaluative differences comparisons incommensurable values options 46 This permits practical deliberation ones overarching goals Parity constitutive Chang calls hard choices different alternatives par matter choose alternative isnt better alternatives neighborhood value terms care time different kind value Note Chang developed notion parity hard choices individual agent authority weighing different options values reinterpret concepts setting comprising different stakeholders This renders weighing options values notions parity hard choices inherently political different stakeholders different interests varying political power potentially diverging ideas evaluating different problem formulations solution directions associated values principles 47 We acknowledge recent empirical insights Van der Voort et al debunk rational view typically assumed decisionmaking They algorithms big data analytics encounter political managerial institutions practice leading spectrum possible outcomes theses technology speciﬁed 48 4 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 comparabilitythe evaluation AI systems technical capacities learnable features similar magnitude relevance problem stakes incommensurabilitythe evaluation AI systems normative capacities relationship users designers able measured standard parityA relation values comparable signiﬁcance unable directly measured better worse equal hard choicesSituations value parity AI development require normative deliberation order options technically commensurable machine politicsa mode deliberation associated stakes involved hard choices particular parties power resolution The possibility hard choices designing AI systems suggests need principled diagnostic approach folded development practices This approach specify commitments match appropriate modalities algorithmic governance potential harms faced stakeholders The goal developers choices stake holders behalf developers adopt diagnostic practices choices proactively anticipated resolved feedback As argued Elizabeth Anderson 49 form feedback particular modern democracies dissent indicating current speciﬁcation law problematic amended rejected Accommodating dissent path enacting appropriate features proportional mechanisms democratic governance denoting possible alternative form design practice commitmenta pledge developers stakeholders sociotechnical speciﬁcation AI terms intended operate dissentpurposive feedback lies outside distribution previous inputs serving challenge grounds consensus speciﬁcation cybernetic practiceactive attention types feedback needed address normative indeterminacies reﬁne sociotechnical speciﬁcation particular AI Revealingly ﬁeld cybernetics applied feedback cybernetic practices culminated called secondorder cybernetics 50 We embrace spirit tradition later work proposing reﬂective inquiry technical practices AI 51 From lexicon conclude recent work AI governance AI Safety reveals need 1 sociotechnical reframing classic problem domains AI agency models representation learning terms human behaviors institutions indeterminately reshaped designed systems 2 shared language diagnose different kinds normative indeterminacy intended vs actual behavior communities stakeholders 3 speciﬁcation requisite feedback modalities order achieve appropriate stability face operational indeterminacies 3 The problem vagueness As AI systems applied sensitive contexts safetycritical infrastructure normative indeterminacies visible Identifying missing feedback given speciﬁcation requires interrogating functions AI principled manner This includes examining task AI trying complete meant work support human contexts normative standards appropriate fulﬁll needs Here compare prominent technical policy standards proposed revealing partial response underlying problem vagueness The vagueness speciﬁcation ultimate source normative indeterminacies stake Vagueness central topic metaphysics philosophy logic language important application engineering artiﬁcial intelligence 51 It fundamental lack clarity relationship world terms ways able perceive language use world It addressed drawing boundariesforms classiﬁcation demonstration analogy rhetorical strategies sort phenomena particular qualities quantities draw distinctions form content 52 A classic example Sorites paradox grain sand removed heap turns heap nonheap Such situations yield existential uncertainty resolvable agreed standards lead arbitrary tradeoffs compromise restrictions We propose vagueness general descriptor situations developers attempts model domain technical uncertainty fall short way speciﬁc forms indeterminacy For approach indeterminacy present current AI policy governance literature ﬁrst organize present corresponding classical interpretation vagueness epistemicism ontic incomparabilism seman tic indeterminacy 53 We isolate respective standards unreﬂectively derived schools 5 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 Table 1 Relationship types vagueness standard normativity assumes types feedback prioritize Type vagueness Normative standard Mode feedback Epistemicism Ontic Incomparabilism Semantic Indeterminism metanormativism value pluralism fuzziness preference learning refusal equitable outcomes thought metanormativism value pluralism fuzziness Finally identify stylized form feedback school thought prioritizes enact standards preference learning refusal equitable outcomes We concisely summarize relationships Table 1 This exercise motivates need sustained engagement actual context development 31 Epistemicism resolving vagueness model uncertainty Epistemicism claims bivalence basic condition objects existence 54 This given property object principle sharp boundary object property Illustrated Sorites paradox epistemicists believe objective fact matter precise number sand grains necessary constitute heap vs nonheap ignorant cutoff point The position holds object property attribute terminate boundary matter inappre ciable boundary present This implies acquiring information help reveal boundary actually drawn Pure epistemicism counterintuitive philosophically controversial comparison claim boundaries semantic constructions 55 But essence position simply distinct commu nities person claim property applies object different ways ignorant propertys actual boundary describing distinct objects Epistemicism powerful aﬃnity metanormativism notion criteria rational decisionmaking fully known conﬁdently expressed suﬃcient information environment agents oneself absent Because epistemicists believe comparable options fundamentally apples oranges degree preferable metanormativism asserts existence clear positive value relation available ethical actions unambiguously better worse equal given choice demonstrably rational For example William MacAskill sought articulate secondorder norms guide act multiple appealing moral doctrines available 56 MacAskill work cited support technical work AI value alignment value learning 5758 proposed choice worthiness function generate reward functions appropriate manner appropriateness deﬁned degree decisionmaker ought choose option sense ought relevant decisionmaking normative uncertainty 59 As metanormativism natural ally expected utility theory particular ﬁrst axiom Von NeumannMorgenstern utility theorem specifying completeness agents welldeﬁned preferences 60 Distinct approaches AI Safety emerged deﬁne uncertain scale AI systems cause social harm At end continuum existential risk referred xrisk effort mathematically formalize control strategies help avoid creation systems deployment result irreparable harm human civilization The xrisk literature focused value alignment problem order ensure learned reward functions correspond values relevant stakeholders designers users affected agents actions 58 Here reward function serves representation stakeholder preferences AI agents objective function assumption common inverse reinforcement learning 64 This position practically adopted software engineers tech enthusiasts uncertain speciﬁcation human preferences comprise investment opportunity new AI systems The following quote Mark Zuckerberg illustrative Im curious fundamental mathematical law underlying human social relationships governs balance care I bet 61 The promise function continues provide guidance designers AI researchers decision procedures acceptable unacceptable follow speciﬁcally goal state risk scale diﬃcult deﬁne 6263 This research agenda prioritizes preference learning systematic observation user behavior choices learn underlying reward function salient form design feedback ﬁlling gaps speciﬁcation 64 As stated Stuart Russell 65 The machines objective maximize realization human preferences The machine initially uncertain preferences The ultimate source information human preferences human behavior However vision inadequate design situations human behavior diﬃcult observe Reasons empirical sparse behavioral signals normative concerns surveillance behavioral manipulation 6 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 32 Ontic incomparabilism respecting value pluralism Meanwhile ontic incomparabilism holds fundamental limits predicates semantics world objective basis prefer deﬁnition concept 66 More concretely knew universe way argue pile sand considered heap exactly n1 grains opposed n grains Ontic incomparabilism claims fully model world discovering additional criteria accumulating suﬃcient information dynamics fundamentally unsuited model speciﬁcation Note position distinct views world impossible human minds comprehend completely argued speciﬁc physical phenomena quantum mechanics world impossible accurately Instead claim ﬁnite number descriptions representations exhaust worlds richness basic features readily discernible principle different ways representing world agents capable realizing agency world This means modeling world robustly require securing worlds total cooperation boundaries drawn Ontic incomparabilism expression terms value pluralism ultimate scheme delineating human values humans exist world way exhaustively represented This transcends sociological fact people hold different beliefs values value beliefs differently axiological antimonist claim values indeterminately varied incommensurable ethical scheme account range values concerns held humans time 67 Value pluralism widely adopted queer theorists highlight formal value speciﬁcations typically exclude certain subpopulations favor 68 For example Kate Crawford endorsed Mouffes 1999 concept agonistic pluralism 69 design ideal engineers 70 Hoffmann argues abstract metrics fairness fail address hierarchical logic produces advantaged disadvantaged subjects disproportionately safety harms vulnerable populations 71 Mireille Hildebrandt taken perspectives logical extreme advocates agonistic machine learning suggesting human self treated fundamentally incomputible 61 These conclusions support ﬁeld Computer Supported Cooperative Work CSCW Presenting central challenge Ackerman described inevitability socialtechnical gap systems inherent divide know support socially support technically 7 This frames central danger terms software engineers neglect certain value hierarchies failing interrogate context historical data external cost biases design choices moralize existing structural inequalities 72 The value pluralism opposed pragmatism form external mechanisms regulate diverse commitments reconciled 73 Rather designers compromise public incomplete spec iﬁcations create external costs society merely reframed central problems modern political theory 74 inherited hallmarks structural inequality The history social technology modern census invention writing saturated ways forms human identity problematically obfuscated delimited protected left undetermined 75 This phenomenon underpins foundational concepts twentieth century social theory 76 deconstructionist critiques Western philosophy metaphysics presence 77 On view design requires fundamental political choices values relevant stakeholders cluding indirectly affected result value hierarchy undesirable consequences beneﬁts harms distributed society Correspondingly type feedback readily endorsed ontic incomparabilists refusal explicit rejection speciﬁcation unsuitable This expressed recently comparisons facial recognition systems plutonium 78 algorithmic classiﬁ cation new form Jim Code 79 refusal notion feminist data practice 80 However major open question refusal lead articulation equitable society absence alternative forms feedback 33 Semantic indeterminism declaring things fuzzy nature Finally semantic indeterminism asserts extent determine deﬁnition concept extent members given community agree deﬁnition Commonly associated Wittgenstein 81 position emphasizes rules languagegames deﬁning refer world speciﬁc boundaries given communitys concerns social tastes modes valuation To illustrate Sorites paradox Persians Romans distinct Greek citystates use alternative deﬁnitions heap conﬁdently draw different cutoff points ontological disagreement Semantic indeterminism argue radical version social constructivism according claim reality arbitrary ﬁctional notion claims objective world impossible Rather claims simply interpreted outside rules particular language communities adopted reﬁned time Semantic indeterminism illustrated formal assumptions fuzziness hold ways talking world admit nonbinary variations variable age including values somewhat young nearly middleaged centenarian newborn regulated modiﬁed distinct language communities modes expertise Fuzziness deals contingencies stake conventional approaches set membership 7 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 truthvalue As mode reasoning addresses uncertainty vagueness refer membership event vaguely deﬁned set purview fuzzy logic 83 indeterminate features world linguistic terms limited meaningful reference In words fuzziness captures imprecision language given communitys epistemic limitations result form uncertainty partial knowledge intractable forms logic semantics necessarily limited picture inherently complex continuous nature reality For purposes fuzziness makes semantic indeterminism institutionally tractable amenable elaboration stake holders For example Lessigs famous modalities regulation laws vs norms vs markets vs architecture fuzziness distinctively enacted revisited human forms infrastructure decisionmaking 82 In text AI Safety exemplary discourse formed 400 Fairness Accountability Transparency Computing Systems FAccT literature FAccT research harvested multitude deﬁnitions tools aiming address safety risks diagnosing reducing biases subgroups deﬁned lines race gender social class 84 While scholars pointed critical mathematical shortcomings abstract deﬁnitions bias mitigation instrumented practice means resolve fuzziness particular application domains For example indus try efforts embraced bias tools generate feedback equitable outcomes means engender trust given global efforts aim codify algorithmic bias considerations certiﬁable standards address eliminate issues negative bias creation algorithms 85 Still tension eliminating bias winning social trust reveals inconsistent determinations safety means entire lifecycle including norms guide design use decisions As argue important acknowledge semantic differences fairness inside outside ML communities ways differences abstract oversimplify social historical contexts 86 Scholars emphasized important semantic differences connections individual social fairness help clarify procedurally reshape way formal fairness criteria reconciled policy objectives 8788 How incorporating semantic differences mean accommodating additional types feedback preference learning represent people actually want refusal serve check systems tendency occlude suppress neglected values Thus semantic indeterminism resolve normative indeterminacies raised epistemicism ontic incomparabilism Instead fuzziness interprets limits language conditioned complexity world epistemic limitations Consequently ambiguities language deferred designers stakeholders deal decided advance inquiry This clearly exempliﬁed EUs recent pro posal regulating AI systems highstakes domains need harmonised standards advocated stating precise technical solutions achieve compliance requirements provided standards technical speciﬁcations developed accordance general engineering scientiﬁc knowledge discretion provider AI 13 Instead propose fuzziness sociotechnical commitment AI development unavoidably iterative interactive deliberative process inquiry This means systems core interface consists relations nonhuman human 89 dimensions users citizens operators regulators construction hindered limited knowledge subject error key technical innovations bear human contexts Even carefullydesigned formalisms sensitive implicit concerns human agents guaranteed learn right preference structures right way new forms surveillance control assigned roles humans systems 9091 Such setups limited ways 1 formalize require subsequent developers organize 2 attempt resolve fuse content procedure getgo treat sociotechnical development AI systems dynamic problem 3 limited addressing wider spectra values distinct peoples cultures 4 A framework commitments AI development As outlined Section 3 matching safety principles technical development procedures fraught hard choices There inherent sources vagueness safety means formalized enacted AI sys tem As result indeterminacies encountered possible design interventions technically comparable normatively incommensurable If left unaddressed underconsidered lead harms reinforcement structural inequalities unresolved conﬂict different stakeholders Section 3 analyzed broad spectrum technical gov ernance critical scholarship efforts address safety AI systems fall canonical approaches vagueness For lens determined affordances limitations associated cybernetic feedback modal ities interventions safeguard AI improve practices design govern In section integrate lessons arguing designers address hard choices incorporating appro priate types stakeholder feedback development governance We build lessons explicating role democratic dissent critical additional form cybernetic feedback AI development governance motivated Section 2 Together facilitation cybernetic feedback channels constitutes substantive commitments governance domain operate We delineate set commitments 8 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 Fig 1 The cyclical practices AI development Orange circles denote occurrence hard choices moments normative indeterminacy arises require revisiting sociotechnical speciﬁcation For interpretation colors ﬁgures reader referred web version article frame technical development deliberative systems normativity This recasts traditionally linear AI development pipeline process dynamic reﬂexive comprising cybernetic design principles AI governance The resulting Hard Choices AI HCAI Framework presented Fig 1 contains cybernetic practices sociotechnical speciﬁcation featurization optimization integration These activities corresponding commitments intro duced discussed following subsections We stress framework conceptual depiction deliberate critically constructively normative indeterminacy The framework help identify crete design approaches commitments action In instances regulatory measures form existing source constraints requirements development process informed We advocate particular law policy interpretations contextual design approaches translation work natural extension paper Our framework naturally connects concretizes AI lifecycle introduced OECD AI Principles 12 41 Sociotechnical commitments Developers diagnose situations normative indeterminacy remaining attentive fundamental limita tions technical logics resolve This necessitates alertness factors responsible situation including social affective corporeal political components 92 AI systems merely situated preexisting sociotechnical environment Rather development creates novel situations intervene social life reﬂected distinction preexisting technical emergent bias 93 These require formal treatment 94 Furthermore major stages AI development require feedback channels stakeholders assign appropriate meaning possible speciﬁcations In particular emphasize need dissent mechanisms help surface parity different design options related value hierarchies As Anderson emphasizes contexts policy set majority powerful player dissent needed simply majority check ensure decision making deliberativeundertaken experimental spiritrather simply imposed 49 These channels AI development opportunity communities reimagine moral boundaries Developers acquire practical reasoning navigate sociotechnical approaches problem deter speciﬁcations accordingly A speciﬁcation sense context sense terms feature detection facial vs handwriting integration scale municipal oversight vs nationwide surveillance Developers recognize differences internalize standards guide indeter minate application abstract principles concrete needs demands situation manner responsive stakeholder feedback These comprise distinct forms judgment formulating problem evaluating criteria articulating performance thresholds meet order safe We agree Philip Agre engagement requires reﬂexive inquiry places concepts methods risk threat rationality promise better way things 51 At distinct moments formal speciﬁcation ask 1 development stages associated cybernetic practice indeterminacies manifest forms parity 2 concrete ways feedback mechanismsin terventions needed address issues 3 form associated canonical dilemma 4 forms judgment needed interpret stakeholder feedback effectively manage indeterminacies dilemmas generates These points presented Table 2 42 Sociotechnical speciﬁcation engaging stakes forms agency The HCAI Framework identify clear start AI development require initial determination problem formulated tackled mechanisms improving determination feedback 9 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 Table 2 Relationship cybernetic practices normative interventions hard choice moments requiring feedback forms sociotechnical judgment needed interpret feedback Cybernetic practice Intervention Dilemma Sociotechnical judgment Sociotechnical speciﬁcation Featurization Optimization Integration integral epistemic semantic ontic inclusion vs resolution underfeaturized vs misfeaturized veriﬁcation vs validation exit vs voice solidarity context discernment stewardship public accountability dissent stakeholders implicated involved problem formulation Moreover mative dimensions foreseen upfront hard choices surface subsequent development considerations Aware historical critical empirical complexities center need sociotechnical speciﬁcation process facilitating different interests relevant understanding situation beneﬁt technological intervention Developers clarify actually forwhose agency intended serve administer mechanisms necessary ensure operational integrity The sociotechnical speciﬁcation facilitates integral inter ventions determine resolve safety means semantic formalized epistemic enacted ontic This facilitation fall exclusively plate designers developers To appropriately surface parity sociotechnical speciﬁcation following challenges taken 1 negotiate program requirements conditions process outcomes 2 determine roles responsibilities stakeholders 3 agree ethics modes inquiry deliberation decisionmaking In sociotechnical speciﬁ cation needs understand context integration This includes positions different stakeholders reasoning relate It requires understanding anticipation impacts social behav ior broader societal implications different solutions sit existing legal frameworks This yields following dilemma Inclusion What stakeholders directly involved indirectly affected issues solution directions considered How power agency assigned process development integration How boundaries AI implications determined Resolution What deliverables outcomes expected envisioned project What variables criteria needed measure outcomes What ethical principles decisionmaking process needed achieve resolution different stakeholders What conditions allow supportive dissenting groups express concerns contribute meaningfully development integration resulting The key hard choice successful AI include suﬃcient perspectives distribute decisionmaking power broadly development cultivate trust reach legitimate consensus resolving situation set requirements process roles responsibilities feasible While propose diagnostic pro cedural questions AI applications broadly prospectively computationally intensive systems future focus attention contexts safetycritical nature play important public infrastructural role This includes systems integrate global scale interacting wide spectrum local cultural contexts Solidarity necessary resolve hard choice specifying warranted interventions systems subsequent development The criterion interventions warranted twofold First indeterminacies necessar ily prevent systems successful operation resolved advance Second indeterminacies threaten successful operation deferred stakeholders evaluate interpret according involvement concerns In way interventions align abstract development commitments speciﬁc possible design decisions given particularities situation urgent needs relevant stakeholders Indeed subspecies hard choices described comprise linear abstract checklist forms situational alertness possibility parity iterative development process Ideally initial problematization stage identiﬁes strategies modes inquiry necessary track resolve indeterminacies This includes appropriate assignment roles responsibilities stakeholders Solidarity understood conﬂating interests designers stakeholders Rather motivates create channels stakeholders actively determine passively accept speciﬁcation 95 Here endorse Irani et als vision postcolonial computing acknowledges stakeholders active participants partners passive repositories lore mined 96 43 Featurization epistemic uncertainty AI systems generally represent predictive causal rulebased model combination thereof optimized integrated decision making capabilities human agent automated control As answer question information needs know adequate decisions predictions subjects notions safety As model represents abstraction phenomenon makes predictions chosen model parameterization data determine parameter values delimit possible features value hierarchies encoded If anticipated accounted deny stakeholders opportunity evaluate design 10 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 alternatives force potentially harmful unsafe hard choices In way featurization epistemic intervention indeterminacies present latent context precedes follows operation To surface parity stake featurization following challenges taken 1 explicit negotiate modeled inferred crystallized underfeaturizedmisfeaturized hard choice 2 engage stakeholders challenge inspire modeling assumptions ensure application aligns contextual expectations 3 validate design stakeholders anticipate possible value conﬂicts arise gap model world plurality values deployment preparing revisit modeling tools methodology Featurization speciﬁes computational powers limits model determine assumptions people broader environment kinds objects classes recognizable At minimum stakeholders resolve following dilemma Underfeaturized What possible input variables model parameterizations choose include What features model able learn fact open normative deliberation Misfeaturized What environmental features actions choose parameterize complexity What forms dissent foreclosed elements computation matter The danger lies failing adopt model parameters computationally tractable normatively defensi ble Given ﬁnite time material resources vested interests speciﬁc stakeholders err misspeciﬁcation ways developers perfectly anticipate The spirit hard choice crystal lized differently distinct algorithmic learning procedures For example division modelbased modelfree reinforcement learning essentially bears kind control designed respectively speciﬁcation establishes permissible space given problem formulated represented causally merely deﬁnes permissible predictive signals rewards elements qualities environment At corresponding domain features computationally tractable suited optimization despite experienced stakehold ers incommensurable Or features technically obfuscated despite mutual comparability integrity lived experience An returning example dilemma need interpret explain decisionlogic AI model While deep learning models offer higher performance need lead opting lower complexity model potential forms accountability The model capacious represent nature environment way safeguards stakeholders interests But training constrained tractable guarantee performance 97 preserve privacy boundaries Imposing modeling constraints necessarily creates technical bias away space stakeholders express protect speciﬁc values terms phenomena permitted excluded models boundaries 94 There technical work acknowledging formal dilemma optimal solution context reinforcement learning 9899 But deeper sociotechnical point criterion constraints entail choice moment model remain technically ignorant intentionally suboptimal speciﬁed terms commitment selfdetermination stakeholders Featurization requires context discernment disqualiﬁcation speciﬁc features modeling choices tech nically proﬁcient judged sociotechnically inappropriate problem space hand Here draw 100 The task craftsman generate meaning cultivate skill discerning meanings Featurization anticipating model interact context deployment misused bias issues arise training protect vulnerable affected groups learned objective functions generate externalities In event consensus reached dissent persists option designing preserved 101 44 Optimization semantic indeterminacy The parameters systems internal model determined performing form optimization This determines inputoutput behavior model interact human agents systems Optimization extends design stage training algorithm implementation ﬁnetuning parameters answers question criteria speciﬁcations considered measure determine safe integrate Depending chosen representation optimization performed mathematically manually use heuristics tuning combination thereof For mathematical optimization recruitment historical experimental data needed infer causal model parameters identiﬁcation inference practice common control engineering 102 b infer parameters noncausal representations c iteratively adjust parameters based feedback reinforcement learning The objectives constraints choice parameters constitute semantic intervention identiﬁcation speciﬁc objects relates forms meaning inherited active behavior stakeholders Therefore following challenges taken 1 assess extent limitations optimization criteria procedure translate respect speciﬁcations crystallized validationveriﬁcation tradeoff 2 codify validation procedure empirical criteria conforms stakeholders speciﬁc concerns addressing speciﬁcations covered mathematical optimization 3 adjudicate modify veriﬁcation validation strategies time indeterminacies featurization integration continue highlighted To declare safe process verifying validating functionality artifact integrated context 11 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 deployment This help engineers domain experts interface problem meant solve workings Here minimum requirements safe outcomes impartial assessments following questionsdilemma Veriﬁcation Does meet speciﬁcations right built Are needs prospective users met Is able predict determine meant Validation How perform empirical context built right Does behave safely reliably interaction systems human operators human agents Is risk strategic behavior manipulation unwarranted surveillance Are emergent biases overlooked speciﬁcations exter nalities This hard choice poses concrete challenges development First systems optimized design laboratory environment fall inherently short data fully capture context integration In develop ment safetycritical systems design issue acknowledged need minimize remaining errors practice feedback control 103 putting place failsafe procedures organizational measures promoting safety culture Second accounting interactions systems human agents taken lightly heavily undervalued current AI literature 104 For example overspeciﬁcation environments simulation popular development autonomous vehicles backﬁre optimization scheme overﬁts model features elements reﬂective context integration Third lack validation safeguarding systems practice result disparate impacts 105 failures This especially pertinent underrepresented undersampled groups properly represented AI design teams 106 For systems optimized wild reinforcement online learning techniques considerations acute recent efforts proposed hybrid methods switch learning safetycontrol prevent disasters 107 This tech nical point mirrors known biasvariance tradeoff sociotechnical moment choice optimization procedure interpreted standpoint jurisprudence applicable domain The cultivation stewardship needed reconcile technical problematics value alignment optimization procedures capable providing qualitative assurances particular sociotechnical stakes domain physi cal psychological social environmental System engineers internalize understanding ﬁnitude teams tools procedures bears urgency felt stakeholders objects sociotechnical concern compelling attention sparse team resources allocated complemented abstract notions accuracy eﬃciency Only way misfeaturization risks managed mitigated perverting intended stakeholders semantic moral commitments The team decide internal veriﬁcation strategies need order safeguard validations endorsed legal inquiry Here quality management elevated contestation adjudication possibly pluralist values operationalized compromising parity 45 Integration ontic incomparabilism Finally AI systems rapidly introduced new contexts new forms harm emerge meet standard deﬁnitions In addition diversity stakeholder expectations environmental contexts chal lenge specifying safety systems deployed different jurisdictions At minimum developing andor managing specify mechanisms identify contest mitigate safety risks affected communi ties responsible mitigating harms event accidents This general rules use cases safety hazards identify terms consent ensure interpretive understanding coercion outline failsafe mechanisms responsibilities Hence conditions spell technical mechanisms processes organizational measures responsibilities cultural norms required prevent failures minimize damage harm event accidents Here appropriate tradeoffs identiﬁed social theorists moral authority political powers social institutions 108 This dimension serves decisive ontic intervention kinds agency stakeholders possess far concerned To safeguard parity integration following challenges taken 1 assess kinds agency affected stakeholders fails crystallized exitvoice hard choice 2 establish open feedback channels stakeholders express values concerns terms 3 justify channels trustworthy regular public communication updates design andor governance Resolving challenges quires representative input mitigation issues following dilemma Exit Are stakeholders able withdraw fully participating Is risk Are competing products platforms systems use Have assurances given user data optimization certiﬁcation withdraws Voice Can stakeholders articulate proposals way makes certain concerns matter public Are clear proposal channels provided stakeholders given opportunity contribute regularly Are proposals highlighted frequently considered tested safety Are stakeholders kept informed regularly updated To extent proposed value hierarchies remain indeterminate featurization optimization sociotechnical integration challenges systems handle multiple objectives values priorities diverse stakeholders At stake unexpressed moral relationships subpopulations originally considered potential user base 12 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 bear cost function speciﬁcation forms agency animal environmental cybernetic alien implicated speciﬁcation creation At minimum administrators acknowledge users interpret agreement economic acting consumer political acting citizen The developments social media recent years taught roles seen mutually exclusive The increasing dependence public platforms AI systems strengthens need voice exit options increasingly diﬃcult unlikely Administrators cultivate public accountability deal challenges ensuring Voice Exit remain possible stakeholders criterion trustworthiness maintained That leave service contract want people choose remain believe ability express concerns needed Trustworthiness lies supporting stakeholders belief ability exert different kinds agency ﬁt dissenting current mode operation outside choosing active use This sociotechnical balance hold regardless speciﬁc commitment For example service providers specify channel vulnerable groups opt publiclyoperated facial recognition preserving Exit supply private contractors default user agreement relayed data preserving Voice Either way administrators ensure treat people respected consumers customer client operator treated black box citizens subject guaranteed rights right dissent relevant forms political power context terms integration Failure meaningful exit voice motivate collective action reshape power relationships 109 phenomenon recently manifested pushing harmful AI systems 110 5 Implications discussion HCAI serves systematic depiction normative risks sociotechnical gaps stake AI But developers respond examining particular proposed existing systems Here present normative implications HCAI terms practical recommendations existing governance performance standards We identify opportunities policymakers AI designers STS scholars learn insights adopt cohesive approach development decisions Expand boundary analysis include relevant sociotechnics systems organizations institutions Engineering science disciplines long tradition working control volumes mathe matical abstractions employed render problems solutions terms technical terms 111 In allow designer decontextualize depoliticize ignore history problem 112 While controlled context sociotechnical complexity normative stakes AI systems engaging sensitive social safety critical domains requires comprehensive lens An algorithm AI engage inherent normativity In contrast studies systems safety shown safety inherently emergent property arises interactions components 26 This requires perspective includes human agents interacting technology 113 situated respect organizational processes 114 cultural institutional norms 115 Such systems lens provides comprehensive starting point trolling safety imposing constraints behavior interactions components 26 This lens explains vulnerabilities AI systems originate components interactions corroborates insights security systems secured addressing technicalmathematical vulnerabilities 116117 Lastly broader systems lens vital understanding extent intended standards AI systems 13 lean general principles versus contextual needs stakes speciﬁc domain application AI developers lean long history systems engineering analyzing modeling designing sociotechnical systems handinhand multiactor approach 118 Confront choices assumptions AI Rather addressing limitations formalization honest encounter normative indeterminacy serves account normative assumptions implications Recently scholars advocated dangers abstraction AI systems 119 pointed dangers imposing abstractions reify inequities resulting institutional racism 120 harm marginalized communities 121 Put bluntly choice capturing terms AI model objective function political Cybernetic practices explicit boundary acceptable formalization lies forms feedback evaluation needed safeguard integration Apart role formalizing modeling choices come externalities An inverse rein forcement learning procedure inherently requires observation detailed human behavior violate privacy norms And deep learning architectures synonymous extensive data gathering challenges privacy environmental norms 122 Orient development governance multiactor approach problem solution spaces As De Bruijn Herder argue addition technorational systems lens needs account effects different intentions actors involved affected 118 As saw vagueness analysis 13 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 actors different lived realities languages epistemic perspectives result conﬂicting interests incom mensurable demands Generally speaking actor perspective acknowledges conceptualizes dependencies actors captured issue network 123 develops rules game governance mechanisms needed satisfy actors manage adequately While obvious actor perspective happen parallel conversation opinions vary integrated matter normative indeterminacy In paper argue diagnosing grappling normative indetermi nacy providing design space parity requires cybernetic feedback specify dynamical feedback actor level feedback renegotiate abstractions procedures necessary safeguard sys tem The iterative nature dealing emergent hard choices AI development requires iterative approach revisits stakes consensus reached actors As AI safety emerge reciprocal relationship development governance Complex multiactor problems called wicked problems especially subject normative inde terminacy Wicked problems incomplete contradictory changing requirements solutions diﬃcult recognize complex dependencies 118 Put differently rely elusive political judg ment resolution Not solution Social problems solved At best resolvedover The formulation wicked problem problem 124 At minimum safetycritical context requires honest account problem solution spaces elaborate different perspectives problem solution actors basis trying reach broad consensus 47 Acknowledge connections speciﬁcation political interests Because value hierarchy speciﬁed designed determine space actions available forecloses crucial acknowledge account power elevated status design work 125 This means recognizing developers tendencies prioritize certain actors networks Haraway 126 Harding 127 critical scholars argue escape having agenda researchers situated social world study As technology development inherently political requires forms accountability 128 Pioneers participatory design argue conﬂicts expected IT designers job cover try solve political conﬂicts surface job develop different design visions assess consequences affected parties 129 However recent concerns design methods participation form accountability increasingly coopted stripped essence 130131 However reducing political reﬂection role developer narrow adequately capture implica tions speciﬁcation Just like actors developers embedded network subject power differentials Understanding broader hierarchies power promote constrain certain problem formulations necessary determine viable strategies promoting safeguards Today AI research development implementation management computational software infrastructure hands small number technology companies As Gürses Van Hoboken argue tech companies offer software engineering tools data provision service libraries APIs development values design elusive task enabled new economic feedback loops implemented scale drive new forms inequality social groups 132133 We believe real success safeguarding highstakes systems require forms oversight dis sent support machine politics respond emergent safety hazards citizen deliberation especially AI systems developed deployed private sector state actors 6 Conclusion Our framework strongly inﬂuenced classic work Philip Agre aimed AI practitioners designers build better AI systems requiring split identity foot planted craft work design foot planted reﬂexive work critique While embrace spirit Agres work believe critical applications todays AI systems require new lens technical practices reframes inherently interdisciplinary practice AI development critical right Apart reﬂexivity critical practice includes forms feedback domain application asks The technical work AI practitioners plays necessary suﬃcient development It compensated efforts facilitate stakeholders ability active participants tools techniques dependent situations workplacesteering understanding different pluralistic perspectives think act 18 As prioritize label centering stakeholder safety concerns hard choices guide inform AI development cybernetic practices We view paper preliminary forms practices particular development domains pursue effort future work Our lodestar project intuition clarifying sociotechnical foundations safety requirements lay groundwork developers distinct dissent channels proactively risks posed AI systems technically politically insurmountable We anticipate cybernetic practices need included training engineers data scientists designers qualiﬁcations operation management advanced AI systems wild Ultimately public educated assumptions abilities limitations systems informed dissent desirable attainable systems deployed Deliberation 14 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 goal AI Safety procedure ensured We endorse approach computationally underdetermined semantically indeterminate politically obfuscated value hierarchies continue deﬁne di verse social orders future Democratic dissent necessary systems safeguard possibility parity development allow users deﬁne contours values To paraphrase Reinhold Niebuhr 134 AIs capacity speciﬁcation makes hard choices possible inclination misspeciﬁcation makes necessary Declaration competing The authors declare known competing ﬁnancial interests personal relationships appeared inﬂuence work reported paper Acknowledgements We wish thank Michael Dennis Joan Greenbaum Iason Gabriel Rashida Richardson Elizabeth Kaziunas David Krueger Íñigo Martínez Rituerto Troya Seda Gürses Alva Noë constructive feedback earlier versions paper TK Gilbert funded Center HumanCompatible AI Newcombe Fellowship R Dobbe partly supported AI Now Institute References 1 AJ Hawkins Serious safety lapses led Ubers fatal selfdriving crash new documents suggest The Verge httpswwwtheverge com 2019 11 6 20951385 uberself driving crash death reason ntsb dcouments 2 J Henley R Booth Welfare surveillance violates human rights Dutch court rules GuardianSection technology httpwwwtheguardian com technology 2020 feb 05 welfare surveillance violates human rights dutch court rules 3 K Hill Wrongfully accused algorithm New York times New York Times httpswwwnytimes com 2020 06 24 technology facial 4 A Harmon As cameras track Detroits residents debate ensues racial bias New York times New York Times httpswwwnytimes com recognition arrest html 2019 07 08 detroit facial recognition cameras html 5 K Hao Facebooks adserving algorithm discriminates gender race MIT technology review MIT Technology Review httpswww technologyreviewcom 2019 04 05 1175 facebookalgorithm discriminates ai bias 6 K Hao He got Facebook hooked AI Now ﬁx misinformation addiction MIT technology review MIT Technology Review https wwwtechnologyreviewcom 2021 03 11 1020600 facebookresponsible ai misinformation 7 MS Ackerman The intellectual challenge CSCW gap social requirements technical feasibility HumComput Interact 15 23 8 D Schiff J Borenstein J Biddle K Laas AI ethics public private NGO sectors review global document collection IEEE Trans Technol Soc 2 1 2021 3142 httpsdoi org 10 1109 TTS 20213052127 9 L Andersen Human rights age artiﬁcial intelligence Tech rep Access Nov 2018 httpswwwaccessnoworg cms assets uploads 2018 2000 179203 11 AI Human Rights pdf 10 Getting future right artiﬁcial intelligence fundamental rights Tech rep European Agency Fundamental Rights Nov 2020 https fra europa eu en publication 2020 artiﬁcial intelligence fundamental rights 11 B Mittelstadt Principles guarantee ethical AI Nat Mach Intell 1 2019 501507 httpsdoi org 10 1038 s42256 019 0114 4 https 12 Recommendation Council Artiﬁcial Intelligence OECDLEGAL0449 Tech rep OECD 2021 httpslegalinstruments oecd org en instruments wwwnature com articles s42256 019 0114 4 OECD LEGAL0449 13 Proposal Regulation laying harmonised rules artiﬁcial intelligence Artiﬁcial Intelligence Act Shaping Europes digital future Tech rep European Commission Brussels Apr 2021 httpsdigital strategyec europa eu en library proposal regulation laying harmonised rules artiﬁcial intelligence artiﬁcial intelligence 14 T Gebru J Morgenstern B Vecchione JW Vaughan H Wallach H Daumé III K Crawford Datasheets datasets arXiv1803 09010 cs 15 M Mitchell S Wu A Zaldivar P Barnes L Vasserman B Hutchinson E Spitzer ID Raji T Gebru Model cards model reporting Proceedings Conference Fairness Accountability Transparency 2019 pp 220229 arXiv1810 03993 16 ID Raji J Buolamwini Actionable auditing investigating impact publicly naming biased performance results commercial AI products Proceedings 2019 AAAIACM Conference AI Ethics Society 2019 pp 429435 17 B Green S Viljoen Algorithmic realism expanding boundaries algorithmic thought Proceedings 2020 Conference Fairness Accountability Transparency FAT 20 Association Computing Machinery New York NY USA 2020 pp 1931 18 J Greenbaum M Kyng Design Work Cooperative Design Computer Systems L Erlbaum Associates Inc 1992 19 P Agre PE Agre Computation Human Experience Cambridge University Press 1997 20 HL Dreyfus Skillful Coping Essays Phenomenology Everyday Perception Action OUP Oxford 2014 21 L Winner Do Artifacts Have Politics Daedalus 1980 pp 121136 22 J McCarthy ML Minsky N Rochester CE Shannon A proposal Dartmouth summer research project artiﬁcial intelligence August 31 1955 23 S Milli D HadﬁeldMenell A Dragan S Russell Should robots obedient preprint arXiv1705 09990 24 D HadﬁeldMenell S Milli P Abbeel SJ Russell A Dragan Inverse reward design Advances Neural Information Processing Systems 2017 AI Mag 27 4 2006 12 pp 67656774 25 S Russell Provably beneﬁcial artiﬁcial intelligence Exponential Life Next Step 26 NG Leveson J Moses Engineering Safer World Systems Thinking Applied Safety MIT Press Cambridge United States 2012 httpebookcentral proquest com lib delft action docID 3339365 27 J Greenbaum M Kyng Design Work Cooperative Design Computer Systems L Erlbaum Associates Inc 1992 28 K Shilton Values ethics humancomputer interaction foundations trends HumComput Interact 12 2 2018 107171 15 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 2009 245273 29 J Halloran E Hornecker M Stringer E Harris G Fitzpatrick The value values resourcing codesign ubiquitous computing CoDesign 5 4 30 N Wiener The Human Use Human Beings Cybernetics Society No 320 Da Capo Press 1988 31 H Von Foerster Understanding Understanding Essays Cybernetics Cognition Springer Science Business Media 2007 32 G Pask Conversation Theory Applications Education Epistemology Elsevier 1976 33 J Dewey The reﬂex arc concept psychology Psychol Rev 3 4 1896 357 34 W Wallach G Marchant Toward agile comprehensive international governance AI robotics point view Proc IEEE 107 3 2019 35 P Cihon Standards AI governance international standards enable global coordination ai research development Future Humanity 505508 Institute University Oxford 2019 Ethics Society 2018 pp 95101 Cham 2017 3152676 36 OJ Erdélyi J Goldsmith Regulating artiﬁcial intelligence proposal global solution Proceedings 2018 AAAIACM Conference AI 37 K Klonick The Facebook oversight board creating independent institution adjudicate online free expression Yale Law J 129 2019 2418 38 P Voigt A Von dem Bussche The EU General Data protection Regulation GDPR A Practical Guide vol 10 1st ed Springer International Publishing 39 NA Smuha From race AIto race AI regulation regulatory competition artiﬁcial intelligence Law Innov Technol 13 1 2021 5784 40 R Zwetsloot H Toner J Ding Beyond AI arms race America China dangers zerosum thinking Foreign Aff 16 2018 41 K Yeung hypernudge big data mode regulation design Inf Commun Soc 20 1 2017 118136 42 N Seaver J Vertesi D Ribes Knowing algorithms digitalSTS Princeton University Press 2019 pp 412422 43 T Gillespie The relevance algorithms Media Technologies Essays Communication Materiality Society vol 167 2014 p 167 44 R Chang Incommensurability Incomparability Practical Reason Harvard University Press 1997 45 R Chang The possibility parity Ethics 112 4 2002 659688 46 R Chang Hard choices J Am Philos Assoc 3 1 2017 121 47 A Haan P Heer Solving Complex Problems 1st edn 2015 48 HG van der Voort AJ Klievink M Arnaboldi AJ Meijer Rationality politics algorithms Will promise big data survive dynamics public decision making Gov Inf Q 36 1 2019 2738 httpsdoi org 10 1016 j giq 2018 10 011 httpswwwsciencedirect com science article pii S0740624X17304951 49 E Anderson The epistemology democracy Episteme 3 1 2006 822 50 R Glanville The purpose secondorder cybernetics Kybernetes 33 910 2004 13791386 httpsdoi org 10 1108 03684920410556016 51 P Agre Toward critical technical practice Lessons learned trying reform AI Social Science Technical Systems Cooperative Work Beyond Great Divide Erlbaum 1997 52 T Williamson Vagueness Routledge 2002 53 R Chang The possibility parity Ethics 112 4 2002 659688 httpsdoi org 10 1086 339673 httpswwwjstororg stable 10 1086 339673 54 S Schiffer The epistemic theory vagueness Philos Perspect 13 1999 481503 55 M GómezTorrente Two problems epistemicist view vagueness Philos Issues 8 1997 237245 56 W MacAskill Practical ethics given moral uncertainty Utilitas 31 3 2019 231245 57 N Soares B Fallenstein Aligning superintelligence human interests technical research agenda Machine Intelligence Research Institute MIRI technical report 8 58 N Soares The value learning problem Machine Intelligence Research Institute Berkley 59 W MacAskill Normative uncertainty voting problem Mind 125 500 2016 9671004 60 J Von Neumann O Morgenstern Theory Games Economic Behavior commemorative edition Princeton University Press 2007 61 M Hildebrandt Privacy protection incomputable self agnostic agonistic machine learning Theor Inq Law 20 1 2019 83121 62 D HadﬁeldMenell GK Hadﬁeld Incomplete contracting AI alignment Proceedings 2019 AAAIACM Conference AI Ethics 63 G Irving A Askell AI safety needs social scientists Distill 4 2 2019 e14 64 D HadﬁeldMenell SJ Russell P Abbeel A Dragan Cooperative inverse reinforcement learning Advances Neural Information Processing Society 2019 pp 417422 Systems 2016 pp 39093917 65 S Russell Human Compatible Artiﬁcial Intelligence Problem Control Penguin 2019 66 E Barnes JRG Williams A theory metaphysical indeterminacy 67 W MacAskill The infectiousness nihilism Ethics 123 3 2013 508520 68 O Keyes Counting countless Why data science profound threat queer people Real Life 2 69 C Mouffe Deliberative democracy agonistic pluralism Soc Res 1999 745758 70 K Crawford Can algorithm agonistic Ten scenes life calculated publics Sci Technol Hum Values 41 1 2016 7792 71 AL Hoffmann Where fairness fails data algorithms limits antidiscrimination discourse Inf Commun Soc 22 7 2019 900915 72 V Eubanks Automating Inequality How HighTech Tools Proﬁle Police Punish Poor St Martins Press 2018 73 W James The Will Believe And Other Essays Popular Philosophy Longmans Green Company 1896 74 J Dewey Public problems 75 R Benjamin Race technology abolitionist tools New Jim Code Social Forces 76 B Krais Gender symbolic violence female oppression light Pierre Bourdieus theory social practice Bourdieu Critical Perspectives 77 M Heidegger J Macquarrie E Robinson Being Time Harper New York 1962 78 L Stark Facial recognition plutonium AI XRDS crossroads ACM Mag Stud 25 3 2019 5055 79 R Benjamin Race technology abolitionist tools New Jim Code Soc Forces 98 4 2020 13 httpsdoi org 10 1093 sf soz162 80 P Garcia T Sutherland M Cifor AS Chan L Klein C DIgnazio N Salehi No critical refusal feminist data practice Conference Companion Publication 2020 Computer Supported Cooperative Work Social Computing 2020 pp 199202 81 L Wittgenstein Philosophical Investigations Basil Blackwell Oxford 1953 82 L Lessig Code And laws cyberspace ReadHowYouWant com 2009 83 G Gerla Comments theories fuzzy computation Int J Gen Syst 45 4 2016 372392 84 A Narayanan FAT tutorial 21 fairness deﬁnitions politics httpsdocs google com document d 1bnQKzFAzCTcBcNvW5tsPuSDje8WWWY SSF4wQm6TLvQ edit usp sharing usp embed _facebook Feb 2018 85 IABW Group Proceedings IEEE algorithmic bias working group 86 S Rea A survey fair responsible machine learning artiﬁcial intelligence implications consumer ﬁnancial services Available SSRN 3527034 87 S CorbettDavies S Goel The measure mismeasure fairness critical review fair machine learning preprint arXiv1808 00023 16 1993 pp 156177 2009 977994 Institute New York NY 2019 v JiBQeIMItp0 t 933s Feb 2021 pp 5015024 R Dobbe T Krendl Gilbert Y Mintz Artiﬁcial Intelligence 300 2021 103555 88 R Binns Fairness machine learning lessons political philosophy Conference Fairness Accountability Transparency PMLR 2018 pp 149159 89 E Trist The Evolution SocioTechnical Systems A Conceptual Framework Action Research Program Ontario Ministry Labour 1981 90 P Eckersley Impossibility uncertainty theorems AI value alignment AGI utility function preprint arXiv 190100064 91 PE Agre Surveillance capture models privacy Inf Soc 10 2 1994 101127 92 S Amrute Of technoethics technoaffects Feminist Rev 123 1 2019 5673 93 B Friedman H Nissenbaum Bias systems ACM Trans Inf Syst 14 3 1996 330347 94 R Dobbe S Dean T Gilbert N Kohli A broader view bias automated decisionmaking reﬂecting epistemology dynamics preprint arXiv180700553 95 RM Unger The critical legal studies movement Harvard Law Rev 1983 561675 96 L Irani J Vertesi P Dourish K Philip RE Grinter Postcolonial computing lens design development Proceedings SIGCHI Conference Human Factors Computing Systems 2010 pp 13111320 97 J Achiam D Held A Tamar P Abbeel Constrained policy optimization preprint arXiv1705 10528 98 R Choudhury G Swamy D HadﬁeldMenell AD Dragan On utility model learning HRI 2019 14th ACMIEEE International Conference 99 L Yu T Yu C Finn S Ermon Metainverse reinforcement learning probabilistic context variables Advances Neural Information Processing HumanRobot Interaction HRI IEEE 2019 pp 317325 Systems 2019 pp 1177211783 100 H Dreyfus SD Kelly All Things Shining Reading Western Classics Find Meaning Secular Age Simon Schuster 2011 101 EP Baumer MS Silberman When implication design technology Proceedings SIGCHI Conference Human Factors Computing Systems 2011 pp 22712274 102 R Guo L Cheng J Li PR Hahn H Liu A survey learning causality data problems methods preprint arXiv1809 09337 103 KJ Åström RM Murray Feedback Systems An Introduction Scientists Engineers Princeton University Press 2010 104 R Parasuraman V Riley Humans automation use misuse disuse abuse Hum Factors 39 2 1997 230253 105 S Barocas AD Selbst Big datas disparate impact Calif Law Rev 104 2016 671 106 SM West M Whittaker K Crawford Discriminating systems Gender race power AI AI Now Institute 2019 pp 133 107 JF Fisac AK Akametalu MN Zeilinger S Kaynama J Gillula CJ Tomlin A general safety framework learningbased control uncertain robotic systems IEEE Trans Autom Control 64 7 2018 27372752 108 T Flew The citizens voice Albert Hirschmans exit voice loyalty contribution media citizenship debates Media Cult Soc 31 6 109 AO Hirschman Exit Voice Loyalty Responses Decline Firms Organizations States vol 25 Harvard University Press 1970 110 K Crawford R Dobbe T Dryer G Fried B Green E Kaziunas A Kak V Mathur E McElroy AN Sánchez et al AI 2019 report AI Now 111 TM Li The Will Improve Governmentality Development Practice Politics Duke University Press 2007 112 K Kadir Engineering justice Rethinking engineering positions engineers world better place httpswwwyoutube com watch University Press 2020 p 141 Publisher Institute New York University New York NY USA Dec 2019 1902 06705 cs stat 981992 httpsdoi org 10 1109 TSMCA2009 2025452 Atlanta GA USA 2019 httpspapers ssrn com abstract 3265913 113 B Green Y Chen The principles limits algorithmintheloop decision making Proc ACM HumComput Interact 3 CSCW 2019 114 G von Krogh Artiﬁcial intelligence organizations new opportunities phenomenonbased theorizing Acad Manag Discov 4 4 2018 404409 httpsdoi org 10 5465 amd 2018 0084 httpsjournals aom org doi abs 10 5465 amd 2018 0084 115 U Gasser C Schmitt The role professional norms governance artiﬁcial intelligence The Oxford Handbook Ethics AI Oxford 116 K Crawford R Dobbe T Dryer G Fried B Green E Kaziunas A Kak V Mathur E McElroy AN Sánchez AI Now Report 2019 Tech rep AI Now 117 N Carlini A Athalye N Papernot W Brendel J Rauber D Tsipras I Goodfellow A Madry A Kurakin On evaluating adversarial robustness arXiv 118 H Bruijn PM Herder System actor perspectives sociotechnical systems IEEE Trans Syst Man Cybern Part A Syst Hum 39 5 2009 119 AD Selbst d boyd S Friedler S Venkatasubramanian J Vertesi Fairness Abstraction Sociotechnical Systems Social Science Research Network 120 R Benjamin Race After Technology Abolitionist Tools New Jim Code John Wiley Sons 2019 121 EM Bender T Gebru A McMillanMajor S Shmitchell On dangers stochastic parrots language models big x1f99C Pro ceedings 2021 ACM Conference Fairness Accountability Transparency FAccT 21 Association Computing Machinery New York NY USA 2021 pp 610623 122 R Dobbe M Whittaker AI climate change theyre connected Tech rep AI Now Institute New York City Oct 2019 httpsmedium com AINowInstitute ai climate change howtheyre connected 6aa8d0f5b32c 123 TA Börzel Organizing BabylonOn different conceptions policy networks Public Adm 76 2 1998 253273 124 HW Rittel MM Webber Dilemmas general theory planning Policy Sci 4 2 1973 155169 125 LC Irani MS Silberman Stories tell labor turkopticon trouble design Proceedings 2016 CHI Conference Human Factors Computing Systems 2016 pp 45734586 126 D Haraway Situated knowledges science question feminism privilege partial perspective Fem Stud 14 3 1988 575599 127 SG Harding The Science Question Feminism Cornell University Press 1986 128 B Wagner Accountability design technology research Comput Law Secur Rev 37 2020 105398 httpsdoi org 10 1016 j clsr2020 105398 httpswwwsciencedirect com science article pii S0267364920300030 129 K Bødker F Kensing J Simonsen Participatory IT Design Designing Business Workplace Realities MIT Press 2009 130 S Bødker M Kyng Participatory design mattersx2014 facing big issues ACM Trans ComputHum Interact 25 1 2018 41431 httpsdoi org 10 1145 3152421 preprints socarxiv 9gy73 131 L Bannon J Bardzell S Bødker Reimagining participatory design Interactions 26 1 2018 2632 httpsdoi org 10 1145 3292015 132 S Gurses Jv Hoboken Privacy agile turn Tech rep SocArXiv type article May 2017 httpsdoi org 10 31235 osf io 9gy73 httpsosf io 133 B Kostova S Gürses C Troncoso Privacy engineering meets software engineering On challenges engineering privacy ByDesign preprint arXiv200708613 134 R Niebuhr The Essential Reinhold Niebuhr Selected Essays Addresses Yale University Press 1986 17