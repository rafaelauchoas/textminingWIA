Artiﬁcial Intelligence 173 2009 104144 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Coherence graphs Enrique Miranda Marco Zaffalon b Rey Juan Carlos University Department Statistics Operations Research CTulipán sn 28933 Móstoles Spain b IDSIA Galleria 2 CH6928 Manno Lugano Switzerland r t c l e n f o b s t r c t Article history Received 23 April 2008 Received revised form 14 August 2008 Accepted 4 September 2008 Available online 11 September 2008 Keywords Walleys strong weak coherence Coherent lower previsions Graphical models Probabilistic logic Satisﬁability We study consistency number probability distributions allowed imprecise To treatment general possible represent probabilistic assessments collection conditional lower previsions The problem proving Walleys strong coherence assessments In order maintain generality analysis assume given nearly information numbers lower previsions collection Under condition investigate extent global task decomposed simpler local ones This introducing graphical representation conditional lower previsions coherence graph coherence graph allows isolate subsets collection coherence suﬃcient coherence assessments provide polynomialtime algorithm ﬁnds subsets eﬃciently We implications results focusing models problems Bayesian credal networks prove coherence provide optimal graphical decomposition compatibility problem probabilistic satisﬁability intractable instances instead solved eﬃciently exploiting coherence graphs 2008 Elsevier BV All rights reserved 1 Introduction We focus studying consistency number conditional unconditional distributions variables In order treatment general possible going represent probabilistic assessments theory coherent lower previsions developed Walley 33 based Finettis work subjective probability 1011 This allows study case distributions imprecise actually closed convex set precise distributions includes particular case assessments precise probabilities It allows work type variable placing restrictions admissible possibility spaces ﬁnite countable continuous The approach Walley includes particular cases imprecise probability models appearing literature Studying consistency problem important theoretical applied reasons On theoretical shown Finetti subjective theory precise probability Bayesian theory founded single axiom consistency Williams 35 later Walley shown continues hold theory generalised handle imprecision probability In theories proving consistency necessary step exploit tools provide Bayes rule generalisations The application tools Corresponding author Email addresses enriquemirandaurjces E Miranda zaffalonidsiach M Zaffalon 00043702 matter 2008 Elsevier BV All rights reserved doi101016jartint200809001 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 105 hand necessarily lead selfconsistent inference case precise probabilities shown Walley On applied common requirement inference method rise inconsistencies This requirement present example probabilistic logic 26 check ﬁrst available assessments selfconsistent It present models methods designed rise joint distribution regarded feature ensures global consistency Exactly argument example support Bayesian networks versus rulebased systems time Pearls seminal work 27 But consistency subtle concept deal The following striking example adapted 33 Section 735 shows existence compatible joint good way rid inconsistencies Example 1 Let X1 X2 variables taking values 1 2 3 assume X1 3 X2 3 cases contradictory information X1 X2 X1 cid3 X2 We model conditional probabilities P X1 3 X2 3 1 P X2 3 X1 3 P X1 1 X2 1 1 P X1 2 X2 2 P X2 1 X1 2 1 P X2 2 X1 1 Despite contradiction checked assessments compatible joint mass function determined P X1 3 X2 3 1 sense joint induces conditionals Bayes rule conditioning events positive probability1 The key Bayes rule applied presence events zero probability technical issue prevents contradiction identiﬁed It follows order check consistency generally need stronger tools based existence compatible joint distribution Walleys notion coherence appears tool In fact Walley considers different consistency concepts conditional lower previsions called weak coherence strong coherence introduced Section 2 material Walleys theory What Section 3 number conditional lower previsions weakly coherent induced joint Bayes rule generalisation imprecise case marginalisations In words weak coherence generalisation imprecise probability consistency criterion based existence compatible joint Coherence hand strengthens weak coherence shown difference weak strong coherence related conditioning sets probability zero 21 Our goal paper simplify veriﬁcation weak strong coherence number assessments To achieve introduce Section 5 new graphical representation called coherence graphs We prove Section 6 coherence graphs allow decompose task verifying weak strong coherence number simpler tasks Speciﬁcally help determine partition set assessments property coherence resp weak coherence elements partition implies coherence resp weak coherence assessments We prove ﬁnest partition property case weak coherence Besides partition set assessments determined polynomialtime algorithm present Section 7 Then implications results artiﬁcial intelligence considering wellknown related research ﬁelds In Section 81 consider Bayesian networks 27 extension imprecise probability called credal networks 8 By joining coherence graphs notion probabilistic independence ﬁrst time large extent Bayesian credal networks coherent models In Section 82 focus called compatibility problem 9 references recent overview problem deciding number distributions compatible joint In case exploit results weak coherence deliver new graphical criteria enable optimally decompose problem general formulation Finally Section 83 relate results powerful form probabilistic satisﬁability based consistency recently proposed 34 In particular discuss probabilistic satisﬁability check consistency number possibly imprecise conditional unconditional mass functions outline task easily intractable consequence NPhardness problem 5 Moreover coherence graphs decompose task way makes possible solve instances problem intractable As said results general sense applicable variables taking values ﬁnite inﬁnite spaces consider precise imprecise representations We assumptions like logical independence variables studied representation assessments functional deﬁned suﬃciently large domain In Section 9 comment extent assumptions relaxed This important problem order relate work tightly areas research Finally conclude paper Section 10 additional discussion To paper easier read relegated proofs Appendix A 1 This consistency notion shall later paper weak coherence Note contradictory assessments X1 X2 X1 cid3 X2 modelled conditional probabilities satisfy consistency notion instance P X1 1 X2 1 1 P X1 2 X2 1 106 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 2 Coherent lower previsions Let short introduction concepts results behavioural theory imprecise probabilities shall use rest paper We refer 33 indepth study properties interpretation notions shall introduce Given possibility space Ω gamble bounded realvalued function Ω 2 This function represents random reward f ω depends priori unknown value ω Ω We shall denote LΩ set gambles Ω A lower prevision P real functional deﬁned set gambles K LΩ It represent subjects supremum acceptable buying prices gambles We consider supremum acceptable buying price gamble conditional subset Ω Given set B gamble f Ω lower prevision P f B represents subjects supremum acceptable buying price gamble f updated coming know unknown value ω belongs B If consider partition B Ω instance set categories shall represent P f B gamble Ω takes value P f B ω B The functional P B maps gamble f domain gamble P f B called conditional lower prevision Let reformulate concepts terms variables focus attention paper Consider variables X1 Xn taking values respective sets X1 Xn For subset J 1 n shall denote X J new variable X J X j j J takes values product space X J j J X j We shall use notation X n X1n This possibility space rest paper Deﬁnition 1 Let J subset 1 n let π J X n X J socalled projection operator operator drops elements vector X n correspond indexes J A gamble f X n called X J measurable x y X n π J x π J y implies f x f y There exists onetoone correspondence gambles X n X J measurable gambles X J We shall denote K J set X J measurable gambles Consider disjoint subsets O I 1 n Then P X O X I represents subjects behavioural dispositions gambles depend outcome variables Xk k O coming know outcome variables Xk k I As deﬁned set gambles depend values variables O I set KO I XO I measurable gambles X n When possible confusion variables involved lower prevision shall use notation P f x P f X I x The sets π 1 x x XI form partition X n Hence deﬁne gamble P f X I takes value P f x x XI This conditional lower prevision I This type conditional previsions going consider paper We refer 2233 general deﬁnitions following notions section terms partitions domains necessarily linear sets gambles A deﬁnition conditional previsions necessarily condition partition 35 The XI support S f gamble f cid2 S f π 1 I x x XI f I π 1 I x KO I given cid3 cid3 0 1 set conditioning events restriction f identically zero Here rest paper I A denote indicator function set A function value 1 elements A domain KO I conditional lower prevision P X O X I x XI 0 Also gamble f shall denote G f x gamble I x f P f x G f X I gamble takes value G f πI y π 1 y X n These assessments disjoint subsets O I 1 n uncommon model subjects beliefs ﬁnite number different conditional lower previsions Then verify sessments modelled conditional lower previsions consistent The ﬁrst requirement disjoint O I 1 n conditional lower prevision P X O X I deﬁned KO I separately coherent In case domain linear set gambles separate coherence holds following conditions satisﬁed x XI f g KO I λ 0 I SC1 P f x cid2 inf yπ 1 I x f y 2 Although deal paper bounded gambles extension theory unbounded gambles 30 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 107 SC2 P λ f x λP f x SC3 P f gx cid2 P f x P gx It shall interesting paper consider particular case I uncon ditional information variables X O We unconditional lower prevision P X O set KO XO measurable gambles Then separate coherence simply called coherence holds following conditions hold f g KO λ 0 C1 P f cid2 inf f C2 P λ f λP f C3 P f g cid2 P f P g In general separate coherence guarantee consistency lower previsions conditional lower previsions conditional values different variables verify assessments provide consistent separately Formally going consider shall collections conditional lower previsions X Im conditional lower previsions respective domains K1 Km Deﬁnition 2 Let P 1 X O 1 LX n K j set XO jI j measurable gambles3 j 1 m Then called collection X n j1 cid3 j2 1 m O j1 X I1 P m X O m cid3 O j2 I j1 cid3 I j2 This means different conditional lower previsions giving information set X Im conditional variables X O conditional set variables X I Given collection P 1 X O 1 lower previsions different ways guarantee consistency X I1 P m X O m X Im separately coherent conditional lower previsions We avoid Deﬁnition 3 Let P 1 X O 1 uniform sure loss X I1 P m X O m cid4 mcid5 j1 sup xX n cid6 G j f j X I j x cid2 0 f j K j j 1 m X I1 P m X O m Deﬁnition 4 Let P 1 X O 1 partial loss f j K j j 1 m B X Im separately coherent conditional lower previsions We avoid cid7 m j1 S j f j cid4 mcid5 sup xB j1 cid6 G j f j X I j x cid2 0 S j f j XI j support f j given Eq 1 2 The notions avoiding partial uniform sure loss minimal consistency requirements shall use Section 8 connect work probabilistic logic main focus paper stronger notions shall weak strong coherence Deﬁnition 5 Let P 1 X O 1 weakly coherent f j K j j 1 m j0 1 m f 0 K j0 z0 XI j0 X I1 P m X O m X Im separately coherent conditional lower previsions We cid4 mcid5 j1 sup xX n cid6 G j f j X I j G j0 f 0z0 x cid2 0 3 Under behavioural interpretation number weakly coherent conditional lower previsions present forms inconsistency 33 Example 735 example 33 Chapter 7 34 discussion Because consider stronger notion called joint strong coherence4 3 We use K j instead KO j I j order alleviate notation confusion possible variables involved 4 The distinction unconditional notion coherence mentioned clear context 108 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 Deﬁnition 6 Let P 1 X O 1 coherent f j K j cid7 X I1 P m X O m X Im separately coherent conditional lower previsions We z0 exists B π 1 I j0 f 0 K j0 z0 XI j0 j0 1 m j 1 m m j1 S j f j cid4 mcid5 j1 sup xB cid6 G j f j X I j G j0 f 0z0 x cid2 0 4 S j f j XI j support f j given Eq 1 The coherence collection conditional lower previsions implies weak coherence converse hold general particular case conditional unconditional lower prevision Note instance conditional previsions Example 1 Introduction coherent sider f 1 I1122 f 2 I2112 G f 1 X2 G f 2 X1 0 union supports set 1 1 1 2 1 3 2 1 2 2 2 3 3 1 3 2 In section prove number results help better understand differences weak strong coherence But introduce special case conditional linear previsions We conditional lower prevision P X O X I set KO I linear sepa rately coherent P f gx P f x P gx x XI f g KO I When separately coherent conditional lower prevision P X O X I linear shall denote P X O X I unconditional case shall use notation P X O A separately coherent unconditional linear prevision corresponds expectation operator Dunford integral 4 respect ﬁnitely additive probability If consider conditional linear previsions P 1 X O 1 X Im domains K1 Km coherent avoid partial loss weakly coherent avoid uniform sure loss 33 Section 71 page 347 X I1 Pm X O m A conditional lower prevision P X O X I separately coherent lower envelope closed weak topology convex set dominating conditional linear previsions P X O X I said dominate P X O X I XO I measurable gamble f P f x cid2 P f x x XI consequence 33 Sections 672 674 We shall denote set dominating conditional linear previsions MP X O X I Finally interesting particular case given unconditional lower prevision P LX n conditional lower prevision P X O X I KO I Then weak strong coherence equivalent hold XO I measurable f x XI JC1 P G f X I cid2 0 JC2 P G f x 0 If P P X O X I linear previsions coherent XO I measurable f P f P P f X I holds Before concluding section important remark lower prevision P coherent conditional lower prevision P B P satisfy property conglomerability discussed 33 Section 68 This property points disagreement Walleys Finettis 13 approach conditional previsions 3 Weak strong coherence The following theorem gives new characterisation weak coherence conditional lower previsions P 1 X O 1 X I1 P m X O m X Im Theorem 1 P 1 X O 1 j 1 m X I1 P m X O m cid8 P G j f X I j cid2 0 f K j P G j f x 0 f K j x XI j X Im weakly coherent coherent lower prevision P LX n In particular conditional linear previsions P 1 X O 1 prevision P X n P f P P j f X I j f K j j 1 m X I1 Pm X O m X Im weakly coherent exists coherent Remark 1 When conditional previsions linear spaces X1 Xn ﬁnite deduce j 1 m equivalent existence Theorem 1 weak coherence conditional previsions P j X O j linear prevision ﬁnitely additive probability X n inducing conditional previsions means Bayes rule This conditional previsions coherent conditions deal problem conditioning sets probability zero For instance conditional previsions Example 1 weakly X I j E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 109 coherent compatible linear prevision determined assessment P X1 3 X2 3 1 We shall come Section 82 From theorem easily deduce following results relate weak strong coherence existence unconditional lower prevision weakly strongly coherent collection X I1 P m X O m Proposition 1 Let P 1 X O 1 coherent unconditional lower prevision P LX n P P 1 X O 1 X Im conditional lower previsions They coherent X I1 P m X O m X Im coherent Corollary 1 The conditional lower previsions P 1 X O 1 ent lower prevision P LX n P P 1 X O 1 X I1 P m X O m X I1 P m X O m X Im weakly coherent coher X Im weakly coherent These results allow understand bit better conceptual difference weak coherence strong coherence Corollary 1 Theorem 1 weak coherence amounts existence joint pairwise coherent conditional lower previsions Proposition 1 coherence means joint coherent conditional lower previsions taken This difference easier grasp particular case deal ﬁnite spaces linear ditional previsions In case weak coherence equivalent existence linear prevision expectation respect ﬁnitely additive probability induces conditional previsions means Bayes rule But guarantee conditional previsions coherent joint mentioned coherent considered That conditional previsions provoke behavioural inconsistencies taken induced joint This fact joint gives zero probability set B conditional prevision P B coherent joint 4 Collection templates With paper like deliver tools prove coherence suﬃciently general applied situations To assume little conditional lower previsions subject study In particular going assume numbers lower previsions produce separately coherent assessments We require separate coherence minimal requirement selfconsistency conditional lower prevision Abstracting away numbers implies lower prevision know apart separately coherent variables sides conditioning bar This regarded form conditional lower prevision template following lower previsions X n We template X O j1 Deﬁnition 7 Let P j1 I j2 The class lower previsions X n template called lower prevision O j2 I j1 O j1 template X n generic lower previsions class We denote lower prevision template way denote lower prevision distinction clear context P j X O j P j2 X I j X O j2 X I j2 X I j1 We identify template disjoint pair indices A collection template determined ﬁnite number pairs This formalised following deﬁnition Deﬁnition 8 Two collections lower previsions X n template contain number m lower j 1 m previsions possible order elements collection way respective jth lower previsions template The class collections X n template called collection template X n generic collection class We denote collection template way denote collection lower previsions distinction clear context P 1 X O 1 X I1 P m X O m X Im An equivalent way look collection template collection lower prevision templates For reason shall refer lower prevision templates collection template The deﬁnitions introduced allow state task paper precisely characterise know coherence collection separately coherent lower previsions know template To extent useful introduce graphical characterisation collection template This section 5 Coherence graphs In section introduce graphical representation collection templates based directed graphs We start recalling terminology graph theory 110 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 A directed graph structure set nodes set directed arcs nodes Two nodes connected arc called endpoints A sequence nodes pair adjacent nodes arc graph called directed path ﬁrst node sequence called origin destination respectively When origin destination coincide path directed cycle cycle short If cycle contain proper cycle said elementary Note path uniquely identiﬁes sequence arcs reason abuse terminology shall refer arcs path It useful introduce notion strong component directed graph This maximal strongly connected subgraph strongly connected graph path ordered pair nodes A strong component said trivial single node The predecessors node nodes directed path given node The predecessors directed path single arc called parents The indegree node number parents A node indegree equal zero called root Similarly successors node nodes reached given node following directed paths The successors directed path single arc called children The outdegree node number children A node outdegree equal zero called leaf The union set parents children node called set neighbours The union graphs graph created taking union nodes arcs respectively Now ready deﬁne important graphical notion paper Deﬁnition 9 Consider ﬁnite sets Z X1 Xn D D1 Dm socalled actual dummy nodes respec tively Call N Z D set nodes given A N N set arcs The triple cid9Z D Acid10 called coherence graph Z following properties hold CG1 Z nonempty CG2 All neighbours dummy nodes actual nodes vice versa CG3 The set parents children dummy node intersection CG4 Dummy nodes leaves CG5 Different dummy nodes parents children Fig 1 displays coherence graph assessments P 1 X1 P 9 X10 X13 P 2 X4 X1 P 3 X6 X5 P 4 X7 X2 P 5 X7 X3 P 10 X11 X7 P 11 X12 X8 P 12 X13 X14 P 6 X8 X3 P 13 X14 X6 X10 P 7 X8 X4 P 8 X9 X1 X5 P 14 X15 X16 X9 X12 X13 Here actual nodes X1 X16 Note graphs easier represent dummy nodes simpliﬁed way labels represent simply black solid circle create problem CG5 dummy node univocally identiﬁed neighbours dummy node exactly parent child represent arrow entering dummy node going cause ambiguity Next onetoone relationship coherence graphs Z X1 Xn collection templates X n To extent useful isolate notion Dstructure coherence graph Deﬁnition 10 Given dummy node D coherence graph Dstructure subgraph nodes D neighbours arcs connecting D neighbours At point consider functions ﬁrst shall denote Γ maps collection template X Im related variables X1 Xn Z coherence graph Z dummy P 1 X O 1 nodes D1 Dm This mapping determined following procedure X I1 P m X O m Fig 1 The coherence graph P 1 P 14 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 111 Γ 1 Let Z X1 Xn set actual nodes Γ 2 Let D D1 Dm set dummy nodes Γ 3 Let A Γ 4 For j 1 m i1 I j i2 O j add arcs Xi1 D j D j Xi2 A The second function denote Γ 1 maps coherence graph Z X1 Xn dummy nodes D1 Dm collection template cid2 P 1 X O 1 X I1 P m X O m cid3 X Im related variables X1 Xn This mapping determined following procedure Γ 11 Set collection lower prevision templates equal set Γ 12 For j 1 m add P j X O j children parents D j respectively X I j collection template O j I j set indexes The idea functions simple identifying lower prevision templates collection Dstructures related coherence graph vice versa This makes functions inverses established following proposition elementary proof omitted Proposition 2 There onetoone relationship coherence graphs collection templates This proposition enables graphically display basic conﬁgurations collection templates problematic respect coherence collection One conﬁguration created collection templates coherence graph contains actual node parent X8 Fig 1 In case different condi tional lower previsions P 6 X8 X3 P 7 X8 X4 express knowledge X8 In situation possible deduce coherence collection taking template account The reason possible ﬁnd speciﬁc instance lower previsions given template incoherent This claim based template valid deﬁnition collections lower previsions considered 1 x3 X3 2 X8 deﬁne gamble f X8 P 6 f x3 f x8 template For instance consider x8 1 2 x4 X4 This speciﬁc choice corresponds use precise degenerate distributions P 7 f x4 f x8 2 respectively irrespective conditioning events It follows P 6 X8 X3 probability mass x8 implies X8 x8 1 P 7 X8 X4 X8 x8 2 contradiction5 1 x8 cid3 x8 Another problematic conﬁguration arises collection templates coherence graph contains cycle case actual nodes X10 X13 X14 Fig 1 In case create contradiction deﬁning lower previsions involved cycle follows Consider x10 1 2 X13 Let 2 X14 x13 2 X10 x14 cid3 x13 cid3 x10 cid3 x14 1 1 cid8 P 9 f x13 P 13gx6 x10 cid8 P 12hx14 x13 x13 f x10 1 1 f x10 2 cid8 x10 x10 gx14 1 1 gx14 2 x14 x14 hx13 1 2 hx13 2 2 words P 9 X10 X13 models fact X10 x10 arbitrary gambles f X10 g X14 h X13 These deﬁnitions correspond use degenerate precise distributions example P 9 X10 X13 corresponds distribution puts probability mass x10 1 X13 x13 1 x10 1 holds probability assuming 2 probability Analogously P 13 X14 X6 X10 known X13 x13 states X14 x14 1 ﬁnally P 12 X13 X14 1 resp X10 cid3 x10 X13 x13 1 X13 cid3 x13 1 resp X14 x14 2 hold probability provided X10 x10 2 hold probability provided X14 x14 2 resp X14 cid3 x14 2 1 resp X13 x13 1 X10 x10 At point easy cycle gives rise contradiction Assume X13 x13 siderations implies probability X10 x10 1 X14 x14 1 ﬁnally X13 x13 1 Using 2 contradiction 5 In example proofs Appendix A use 01 valued probabilities things simpler equivalently 2 x3 X3 P 7 f x4 use probabilities degenerate In example instance deﬁne P 6 f x3 01 f x8 1 x4 X4 This corresponds probability masses x8 01 f x8 2 equal 01 09 09 01 respectively irrespective conditioning events To conditional previsions compatible joint mass function P X34 note given P deduce hand P x8 09 contradiction Also following example based 1 cycles reworked additional complications nondegenerate probabilities 01 P x8 1 2 09 f x8 1 09 f x8 1 x8 112 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 Repeating argument starting X13 cid3 x13 1 obtain X13 x13 1 contradiction In summary cycle speciﬁc choice lower previsions codes contradictory statement X13 equal different values And able ﬁnd speciﬁc lower previsions given template inco herent deduce coherence considering related coherence graphjust contains cycle These considerations motivate following deﬁnitions introduce graphbased terminology directly relevant subsequent results Deﬁnition 11 We actual node coherence graph potential source contradiction parent belongs cycle More formally actual node Xcid7 parent means 1 cid3 i1 cid3 i2 cid3 m O i2 On hand fact Xcid7 belongs cycle implies involved elementary cid7 O i1 cycle different j1 j p 1 m O j1 I j2 cid3 O j2 I j3 cid3 O j p I j1 cid3 cid7 belonging nonempty intersections 5 Deﬁnition 12 A coherence graph sources contradiction said type A1 acyclic maximum indegree actual nodes equal The corresponding collection template said representable graph type A1 simply A1representable The graph Fig 1 obviously type A1 ﬁve sources contradiction X7 X8 parents X10 X13 X14 cycle An example A1 graph given Fig 2 This subgraph Fig 1 eliminated number elements creating sources contradiction This shows A1 graphs complicated forms When sources contradiction coherence graph useful isolate special subgraphs related blocks Deﬁnition 13 Given source contradiction Z block Z B Z subgraph obtained taking union Dstructures dummy nodes predecessors Z The reason introduce blocks capture idea area inﬂuence certain source contradiction This easy case actual node parent X8 Fig 1 In case 1 P 7 X8 X4 forces X4 use degenerate distributions way P 6 X8 X3 forces X8 certain value x8 1 X4 x4 certain value x4 1 In case exploiting source contradiction force speciﬁc value node X1 far away source This useful proofs use source contradiction actually create contradiction example instance deﬁne P 1 X1 force X1 value different x1 1 originating contradiction X1 The situation bit complicated cycles effect eventually 1 turn P 2 X4 X1 forces X1 certain value x1 1 X8 x8 It useful study bit situations sketched For going introduce notion constraining subblock actual node block This subset previsions block property assign certain values unique value actual node compatible In previous example constraining subblock X1 determined previsions P 6 X8 X3 P 7 X8 X4 P 2 X4 X1 Fig 2 An example A1 coherence graph E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 113 In constraining subblock shall Proposition 3 information ﬂows possibly opposite directions arcs eventually force actual node chosen value This property Theorem 4 decompose task verifying weak coherence optimal way Consider ﬁrst block B Z originated actual node Xs parent Then exist 1 cid3 O i2 For actual node Xcid7 B Z exists path leading Xcid7 node Xs i1 cid3 i2 cid3 m s O i1 originating block Hence i1 p 1 m s O i1 cid3 cid7 I p Note assume loss generality nodes i1 p different establish cycle path Xcid7 Xs eliminating cycles obtain shorter path going Xcid7 Xs indices different We shall refer set indices i1 p cid3 cid7 I p constraining subblock Xcid7 block generated Xs s O i1 Note subblock necessarily unique cid3 I p1 cid3 I p1 O i2 I i2 O i2 I i2 O p O i3 O p O i3 Consider block B Z generated cycle Then cycle corresponds strong component coherence graph sense nodes Xs1 Xs2 component path going Xs1 Xs2 going Xs2 Xs1 Xs1 Xs2 belong cycle Again possibilities node Xs block B Z belongs strong component block predecessor strong component In ﬁrst case Xs belongs elementary cycle meaning exist j1 j p 1 m satisfying Eq 5 s O j1 I j2 Consider hand predecessor Xcid7 source contradiction Then Xcid7 predecessor nodes elementary cycle denote Xs cycle Let j1 j p indices previsions cycle meaning satisfy Eq 5 s O j1 I j2 Then exist k1 kr cid7 O k1 cid3 kr indices Ik3 cycle instance kr j1 cid3 O kr1 Ik2 O k2 Ikr The indices j1 j p different cycle elementary Moreover assume indices k1 kr1 different j1 j p eliminate indices common path Xcid7 cycle Finally assume loss generality indices k1 kr1 different able establish cycle eliminating cycles obtain shorter path Xcid7 cycle We shall refer indices k2 kr1 j1 j p constraining subblock Xcid7 block associated source contradiction Xs Again constraining subblock unique Remark 2 Note constraining subblock possibilities O kr1 Ikr O j p parent k2 kr1 kr j p constraining subblock Xcid7 example Fig 3 cid3 particular O kr1 cid3 Then Xcid7 predecessor node O j p If O kr1 Ikr O j p Xcid7 predecessor dummy node cycle precedes actual nodes cycle dummy node example Fig 4 The distinction cases simplify proofs subsequent results As mentioned previously reason deﬁned notion constraining subblock determine value variable Xcid7 This stated following proposition Fig 3 Constraining subblock X6 block associated source contradiction node predecessors Fig 4 Constraining subblock X6 block associated source contradiction case cycle 114 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 Fig 5 The areas delimited closed lines denote blocks superblocks coherence graph Proposition 3 Let consider block B Z actual node Xcid7 belongs B Z Consider x Xcid7 1 If Xcid7 source contradiction block B Z let j1 element 1 m cid7 O j1 Then weakly satisﬁes X Im prevision P coherent P j1 X O j1 X I1 Pm X O m X I j1 coherent previsions P 1 X O 1 P x 1 2 If Xcid7 source contradiction B Z let j1 jk indices previsions constraining subblock Xcid7 X Im weakly coherent prevision P coherent P ji X O ji X I1 Pm X O m X I ji Then P 1 X O 1 1 k satisﬁes P x 1 An important consequence proposition blocks happen share actual node possible create contradiction node forcing certain value block different value block This suggests blocks share actual nodes considered single structure separate ones order avoid contradictions reason following deﬁnition Deﬁnition 14 Call superblock coherence graph union blocks share actual node Fig 5 displays different blocks coherence graph consideration block X7 block X8 X14 equivalently X10 X13 The blocks X7 X8 node common X3 union superblock shown ﬁgure The superblock graph B X14 Observe conﬁgurations blocks superblock superblock single block block case blocks coincide instance B X14 coincides B X10 B X13 included share nodes B X7 B X8 ﬁgure It useful observations point The ﬁrst intuition notion superblock different blocks delimit joint area inﬂuence multiple sources contradictions belong different blocks connected actual nodes The second formal concerns actual nodes different blocks I O actual nodes relation superblocks fact block B Z consider set A Z cid3 B Z1 B Z2 belong superblock It follows consider involved B Z A Z1 different superblocks B 1 B2 I O I j O j B1 j B2 A Z2 iB Z cid7 Now use notion superblock order build partition dummy nodes The point similarly case blocks sources contradictions extend inﬂuence actual node superblock opportune deﬁnition lower previsions involved Because possible prove coherence lower previsions superblock simply inspecting coherence graph prove necessary know bare collection template It follows superblocks kind core entities prove coherence collection template ﬁrst able prove coherence lower previsions superblock Those core entities constitute elements partition deﬁned lower previsions belong superblock Deﬁnition 15 Call minimal partition dummy nodes coherence graph partition elements sets dummy nodes superblock singletons remaining dummy nodes The corresponding partition 1 m denoted B simply called minimal partition Note B refers partition related collection template given onetoone correspondence dummy nodes lower prevision templates With respect graph Fig 5 obtain following partition related collection template E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 115 cid2cid2 cid3 P 1 X1 P 2 X4 X1 P 4 X7 X2 P 5 X7 X3 P 6 X8 X3 P 7 X8 X4 cid3 P 3 X6 X5 P 9 X10 X13 P 12 X13 X14 P 13 X14 X6 X10 cid3 P 8 X9 X1 X5 cid3 P 11 X12 X8 cid3 P 10 X11 X7 cid2 cid2 cid2 P 14 X15 X16 X9 X12 X13 cid2 cid2 cid3cid3 Moreover note A1representable collection templates minimal partition entirely singletons coherence graph sources contradiction m elements We conclude section remarking consider B 1 B2 minimal partition B 1 1 B2 1 B1 associated superblock B 2 A1 component coherence graph O I j O j B2 j B1 O O j cid3 node parent belong associated superblock O I j cid3 predecessor j predecessor source contradiction block j Nevertheless I I j O j cid3 j B1 This important proofs results formulate section 6 Coherence graphs tools prove coherence This section formally relates graphical notions introduced previous section notions weak strong coherence gives important results paper In particular following theorem gives conditions coherence subsets collection conditional lower previsions implies coherence elements collection It shows suﬃcient conditional lower previsions indices belong element B coherent Theorem 2 Let P 1 X O 1 B associated minimal partition If P j X O j P 1 X O 1 X I1 P m X O m X I1 P m X O m X Im coherent X Im collection separately coherent conditional lower previsions let X I j jB coherent B B conditional lower previsions The intuition proof theorem include Appendix A following We exploit prop erties coherence graph create total order set coherent lower previsions tightly related collection template That order allows use generalisation marginal extension theorem established 23 lower previsions set coherent derive coherence P 1 X O 1 X I1 P m X O m X Im It easy similar result holds work weak coherence instead coherence Theorem 3 Let P 1 X O 1 B B P j X O j X I1 P m X O m X Im collection separately coherent conditional lower previsions X I j jB weakly coherent Then P 1 X O 1 X I1 P m X O m X Im weakly coherent Next investigate sense partition B given Deﬁnition 15 minimal For like know partitions 1 m use end meaning coherence conditional lower previsions elements partition guarantees coherence collection template A ﬁrst positive result respect partition B minimal studying problem weak coherence Theorem 4 Let Bcid12 implies weak coherence P 1 X O 1 X I1 P m X O m partition 1 m assume B Bcid12 X Im B ﬁner Bcid12 P j X O j cid12 X I j jBcid12 weakly coherent Then The suﬃciency proposition actually Theorem 3 The idea necessity X Im weakly necessary condition fails create conditional linear previsions P 1 X O 1 coherent B X I1 Pm X O m X I j jBcid12 weakly coherent P j X O j Bcid12 cid12 However similar result Theorem 4 apply coherence instances collection templates coherence elements partition coarser B guarantees coherence One case given following example Example 2 Let consider collection template associated conditional lower previsions P 1 X1 P 2 X2 X1 P 3 X2 X3 X1 Its coherence graph given Fig 6 minimal partition B associated graph 1 2 3 However deduce coherence collection template smaller subset For let herence P 2 X2 X1 P 3 X2 X3 X1 implies actually equivalent fact X1 X2measurable gamble f 0 x1 X1 P 2 f 0x1 P 3 f 0x1 6 To apply Eq 4 P 2 X2 X1 P 3 X2 X3 X1 j0 2 z0 x1 X1 f 2 0 f 3 f 0Ix1X23 116 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 Fig 6 Coherence graph P 1 X1 P 2 X2 X1 P 3 X2 X3 X1 cid9 cid10 G 20 X1 G 3 f 0Ix1X23 X1 G 2 f 0x1 cid10 G 3 f 0Ix1X23 x1 G 2 f 0x1 cid10 f 0 P 3 f 0x1 f 0 P 2 f 0x1 cid9 0 cid3 sup B sup π 1 1 x1 cid9 sup π 1 1 x1 P 3 f 0x1 P 2 f 0x1 P 2 f 0x1 cid2 P 3 f 0x1 The converse inequality P 2 f 0x1 cid3 P 3 f 0x1 follows repeating argument j0 3 z0 x1 f 2 f 0Ix1X2 f 3 0 At point assume P 2 X2 X1 P 3 X2 X3 X1 coherent Eq 6 holds Consider expression prove coherence previsions P 1 X1 P 2 X2 X1 P 3 X2 X3 X1 cid11 G 1 f 1 G 2 f 2 X1 G 3 f 3 X1 G j0 f 0x1 G 1 f 1 G 2 f 2 X1 G 3 f 3 X1 G j0 f 0 j0 2 3 j0 1 j 1 2 3 f j K j j0 1 2 3 f 0 K j0 x1 X1 verify G 2 replaced G 3 6 As result obtain conditional lower previsions P 1 X1 P 2 X2 X1 P 3 X2 X3 X1 coherent P 1 X1 P 3 X2 X3 X1 But P 1 X1 P 3 X2 X3 X1 coherent marginal extension theorem 33 Theorem 672 coherence P 2 X2 X1 P 3 X2 X3 X1 implies coherence collection template It remains open problem stage determine partition property coherence elements guarantees coherence collection template minimal sense ﬁner partition property In respect interesting particular case conditions minimal partition equal X Im separate coher 1 m deduce coherence P 1 X O 1 X Im ence We deduce Theorem 2 coherence graph associated P 1 X O 1 type A1 separate coherence previsions implies coherence Using Theorem 4 prove type A1 necessary property X I1 P m X O m X I1 P m X O m Proposition 4 Consider collection P 1 X O 1 lowing equivalent X I1 P m X O m X Im separately coherent conditional lower previsions The fol 1 The separate coherence P 1 X O 1 2 The separate coherence P 1 X O 1 3 The coherence graph collection template type A1 X I1 P m X O m X I1 P m X O m X Im implies coherence X Im implies weak coherence We like conclude section remarking collection template A1representable following sensitivity analysis interpretation Theorem 5 Consider collection separately coherent conditional lower previsions If coherence graph A1 lower previsions lower envelopes family coherent linear previsions Hence coherence graph A1 interpret coherent conditional lower previsions model imprecise knowledge precise coherent conditional linear previsions The result lies fact lower envelopes family coherent conditional linear previsions coherent conditional lower previsions converse hold general exist instances coherent conditional lower previsions domi nated family coherent conditional linear previsions 33 Section 66106 A suﬃcient condition converse 6 The previsions example given section written language P X1 X2 P X2 X1 Note belong block consequently coherence graph A1 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 117 hold spaces X1 Xn ﬁnite 33 Theorem 8110 This theorem shows coherence graph A1 coherent conditional lower previsions lower envelopes coherent conditional linear previsions matter cardinality spaces 7 An algorithm ﬁnd minimal partition In order exploit coherence graphs tools check coherence able compute minimal partition coherence graph This set following algorithm ﬁnd minimal partition discuss computational complexity showing eﬃciency algorithm The rationale algorithm simple We start visit graph source contradiction ing backwards respect direction arrows identify related block This recursive procedure tags nodes visit assigning different tags blocks originated different sources contra diction The complication blocks nonempty intersection consequence regarded single superblock When happens tags different blocks regarded To extent implement data structure acts dictionary maps tags blocks superblock unique tag referred true tag regarded class equivalence tags The dictionary ﬁlled procedure visits graph time node intersection blocks Below algorithm precisely Clike language opposed C assume ﬁrst element array index 1 code simpler read To things simpler assume nodes graph reindexed 1 m n ﬁrst m nodes D1 Dm following ones actual nodes We assume result previous computations following global data structures available integer numbers m n corresponding number dummy actual nodes respectively An array called node size m n generic element nodei structure contains following com ponents related node integer called nodeinParents containing number parents node integer array called nodeiparent size nodeinParents containing indexes parents node integer called nodeitag initialised 0 denote node tagged An integer called nContradictions containing number actual nodes sources contradictions An integer array called contradiction size nContradictions containing indexes actual nodes sources contradictions An integer array called minPartition size m implements dictionary Fig 7 reports software code ﬁnd minimal partition based data structures The code procedures findMinPartition main subroutine findBlock param eters currentTag mergeBlocks parameters tagFound currentTag subroutine findBlock The purpose findMinPartition assign tags dummy nodes ﬁll array minPartition way j1 j2 1 m j1 j2 belong element minimal partition tags minPartitionnodej1tag minPartitionnodej2tag coincide findMinPartition works steps In ﬁrst including line 07 procedure enumerates sources contradiction tagged calls findBlock tag predecessors identifying block findBlock takes care means mergeBlocks merge blocks nonempty intersec tion superblock properly ﬁlling array minPartition line 08 findMinPartition superblocks identiﬁed In second step line 08 onwards procedure simply considers dummy nodes superblock tags new increasing values currentTag identifying remaining elements minimal partition The way findBlock works complicated Its main purpose tag actual node predecessors currentTag recursive way It happen nodes visit graph tagged happens line 25 node dummy line 29 actual In case true tag different current findBlock calls mergeBlocks merge blocks related different tags mergeBlocks identifying tags Let recall point condition computing minimal partition methods ﬁll global data structures mentioned beginning section running findMinPartition These methods actually trivial implement apart solves problem identifying actual nodes involved cycles A key observation address problem node belongs cycle directed graph belongs nontrivial strong component graph This implies identifying strong components enables 118 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 fori1imi enumerate dummy nodes ifnodeitag tagged superblock int j k ifnodeitag node tagged nodeitagcurrentTag newly created tag minPartitioncurrentTagcurrentTag update dictionary findBlockcontradictionlcurrentTag tag nodes block minPartitioncurrentTagcurrentTag update dictionary int currentTag0 l forl1lnContradictionsl enumerate sources contradiction ifnodecontradictionltag contradiction tagged 01 void findMinPartition identify blocks superblocks 02 03 04 05 06 07 08 09 10 11 12 13 14 15 void findBlockint int currentTag identify block given actual node 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 void mergeBlocksint tagFound int currentTag tags 31 32 33 34 35 nodenodeiparentjtagcurrentTag tag fork1knodenodeiparentjnParentsk enumerate parents findBlocknodenodeiparentjparentkcurrentTag recursion ifminPartitionnodenodeiparentjtagcurrentTag tagged int l forl1lcurrentTagl enumerate existing true tags nodeitagcurrentTag tag forj1jnodeinParentsj enumerate parents mergeBlocksminPartitionnodeitagcurrentTag merge blocks ifminPartitionnodeitagcurrentTag tagged minPartitionlcurrentTag mapped currentTag ifnodenodeiparentjtag parent tagged mergeBlocksminPartitionnodenodeiparentjtagcurrentTag merge ifminPartitionltagFound tag l previously mapped tagfound Fig 7 The software code Clike language ﬁnd minimal partition coherence graph ﬁnd actual nodes involved cycle Fortunately task identifying strong components known eﬃciently tackled Tarjans algorithm 29 problem addressed easily The complexity overall procedures including methods ﬁll global data structures given following theorem Theorem 6 The worstcase complexity compute minimal partition procedures Fig 7 bounded O m n m n Note bound derived implicit assumption input problem coherence graph usually start collection template This problematic lower prevision templates collection onetoone correspondence Dstructures corresponding coherence graph stated Section 5 converting collection template coherence graph takes linear time increase complexity bound derived 8 Applications Now main results paper presented naturally relate impor tant models tools known artiﬁcial intelligence In Section 81 shall use results prove ﬁrst time coherence large extent graphical models called Bayesian credal networks In Section 82 shall estab lish tight relationship weak coherence socalled compatibility problem checking number assessments admits compatible joint probabilistic model In case shall coherence graphs allow optimally decompose compatibility problems smaller ones general version problem Finally Section 83 focus recently proposed coherencebased version probabilistic satisﬁability enhances extends similar problems probabilistic logic In case ﬁrst new results connection traditional approaches Walleys theory Then coherence graphs case decompose important instances probabilistic satisﬁability smaller ones E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 119 81 Coherence Bayesian credal networks Let focus proving coherence graphical models called Bayesian nets extension imprecise probability called credal nets Although surprising ﬁrst models shown coherent strong sense What known models rise joint coherent lower prevision language means assessments models pairwise coherent joint For example Bayesian net equivalent joint mass density function considered variables credal net equivalent closed convex set joint mass functions joint coherent lower prevision lower envelope expectations computed mass functions This implicitly taken evidence models consideration self consistent But shown Theorem 1 existence joint equivalent weak coherence weak coherence leaves room inconsistencies Bayesian credal nets express inconsistent beliefs know In Section 812 case mentioned models satisfy Walleys notion strong coherence We coherence graphs additional developments introduced Section 811 needed nect coherence graphs socalled notion strong product generalisation stochastic independence imprecise probability The connection necessary strong product underlies models consideration Finally Sec tion 813 discuss extensions presented results general models credal nets major statistical applications 811 Relating A1 graphs strong product In section summarise results connect A1 graphs notion probabilistic independence called strong independence 824 introduced 37 We start lemma7 shows A1 graphs naturally entail notion order corresponding lower previ sions particular possible permute indexes lower previsions way admissible paths dummy nodes index origin precedes destination8 Lemma 1 See 37 Lemma 1 If coherence graph associated collection template P 1 X O 1 assume loss generality k 1 m O k k1 i1 I cid7 X I1 P m X O m X Im A1 Note result depends properties coherence graph applicable dealing precise conditional previsions Now restrict attention special case A1 graphs originated collections separately coherent conditional lower previsions O 1 O m forms partition 1 n This means variable exactly lower prevision expressing beliefs Let type graphs A1 From Lemma 1 collection template representable assume loss generality I1 Let deﬁne P 1 X O 1 X Im A1 X A j I j given set H j X A j1 A1 A j measurable gambles X I1 P m X O m j1 i1 I O j 2 m 1 j 1 m let P cid12 j X O j cid7 cid12 j f z P j P cid12 cid13 f z πI j z z X A j I j f H j Since P j X O j X A j I j More thanks Lemma 1 requirement O 1 O m forms partition 1 n sets indices cid12 X AmIm form increasing sequence m X O m conditioning variables previsions P satisfy hypotheses generalised marginal extension theorem established 23 Theorem 4 As consequence P X I j separately coherent j 1 m P cid12 1 X O 1 P X AmIm coherent cid12 1 X O 1 P A similar reasoning shows j 1 m conditional linear prevision P X A j I j set H j X AmIm jointly coherent Moreover taking account dominates P O 1 O m partition 1 n Theorem 3 Ref 23 implies prevision P X n coherent assessments P X A j I j P cid12 1 X O 1 P cid12 m X O m cid12 m X O m cid12 j X O j cid12 j X O j cid12 j X O j P f P cid12 1 cid12 cid12 cid12 1 X O 1 P cid12 cid12 X AmIm m X O m cid13cid13 cid13 cid12 m f X AmIm cid12 m X O m cid12 P 2 cid12 1 X O 1 P P In words P checked P prevision associated probability mass function 7 X AmIm rise unique joint lower prevision When X1 Xn ﬁnite P x mcid14 j1 cid13 cid12 πO j xπ A j I j x cid12 j P At point ready deﬁnition lower envelope model 8 7 This lemma section proofs Appendix A reasons Lemma 6 8 This order notion similar graphtheoretic notion topological ordering applied dummy nodes 120 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 Deﬁnition 16 Suppose λ Λ collection conditional lower previsions P λ X O 1 P λ X O m cid12 cid12 j X O j j X O j st The coherent P λ X O 1 P λ X O m X AmIm j 1 m P λ X O j X A j I j lower prevision P deﬁned P minλΛ P λ P λ coherent prevision determined X AmIm Eq 7 called lower envelope model X A j I j minλΛ P λ X O j X A j I j dominates P X A j I j P Intuitively lower envelope model joint lower prevision built number conditional uncondi tional assessments The lower envelope models arises common practise build joint models smaller conditional unconditional ones use joint model draw conclusions Lower en velope models abstract procedure constructing joint models general case coherent lower previsions As particular cases lower envelope models consider following 1 If j 1 m consider P λ X O j X A j I j set MP marginal extension P cid12 cid12 m X O m 1 X O 1 P X A j I j set extreme points MP 2 If j 1 m P λ X O j X AmIm cid12 j X O j ditional requirement P λ X O j strong product P 1 X O 1 P m X O m z P λ X O j X Im z cid12 πI j z πI j z cid12 X A j I j ad j X O j cid12 lower envelope model P called X A j I j lower prevision P The marginal extension represents conservative lower envelope model built assessments deﬁned 7 The strong product conservative lower envelope model built assessments additional assumption strong independence instance 37 additional information Theorem 7 See 37 Theorem 2 Consider A1 lower envelope model associated Then P P 1 X O 1 P m X O m representable collection template P 1 X O 1 P m X O m X Im coherent X Im let P Note result concerned original assessments deﬁned 7 In particular implies representable collection This main tool coherent build strong product A1 shall use following 812 Bayesian credal networks A Bayesian net 27 directed acyclic graph nodes onetoone correspondence variables X1 Xn wellknown example Bayesian net given Fig 8 The arcs graph represent stochastic indepen dences variables means socalled Markov condition fact variable independent nondescendant nonparents given parents Let X j generic node net denote I j set indexes parents Let assume variables values ﬁnite spaces In case node network associated set conditional mass functions language correspond conditional linear previsions P j X j X I j Fig 8 The Asia network model artiﬁcial medical problem related presence dyspnea The nodes correspond variables names parentheses 01 valued example E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 121 Fig 9 The coherence graph obtained Asia Bayesian network Note m n Bayesian nets Specifying Bayesian net equivalent Markov condition specifying joint mass function variables interest9 P x ncid14 j1 cid13 cid12 π jxπI j x P j x X n 9 Credal networks extension Bayesian nets imprecise probabilities 8 The extension achieved case socalled separately speciﬁed credal nets focus allowing generic node X j replace mass functions closed convex hull ﬁnite number conditional mass functions In words linear prevision P j X j X I j replaced coherent lower prevision P j X j X I j nodes X j net As example Asia network turned credal net replacing local conditional probabilities probability interval closed convex set mass functions equivalent probability interval case binary variable A credal net equivalent set Bayesian nets chooses precise mass function local closed convex set net credal net Bayesian net compatible credal net In language coherent lower previsions means graph choice linear prevision P j X j X I j cid2 P j X j X I j node j 1 n Bayesian net Therefore credal net regarded set Bayesian nets originated X j choosing dominating linear previsions possible ways Call P set joint mass functions obtained applying Eq 9 compatible Bayesian net Credal nets rendered consistent Walleys theory coherent lower previsions notion strong extension deﬁned K P CHP symbol CH denotes operation taking closed convex hull Since K P convex extreme points mass functions K P expressed convex combinations ones K P Let denote set extreme points extK P Usually deﬁnition credal networks requires subset ﬁnite It known case extK P P means extreme points correspond subset compatible Bayesian nets For reason credal net usually regarded equivalent ﬁnite set Bayesian nets P inﬁnitely elements Note Bayesian net special case credal net In case strong extension singleton containing joint mass function coded Bayesian net Eq 9 The strong extension equivalent representation coherent lower prevision P X1 Xn connection Walleys theory To enforce connection inferences credal nets usually respect strong extension initial set P This controversial inference credal nets usually taken computation lower upper posterior expectations stay irrespective fact uses P K P extK P At point ready credal nets consequently Bayesian nets coherent models To aim coherence graph Fig 9 example strong suﬃcient credal net leads A1 extension credal net coincides strong product related coherence graph theorem Theorem 8 The local conditional lower previsions P 1 X1 X I1 P n Xn X In credal network A1 strong product coincides strong extension network representable Their We apply Theorem 7 straightforward way obtain wanted result immediate corollary previous theorem 9 Note Expression 9 symbol π refers projection operator Deﬁnition 1 confused symbol denote parents node Bayesian network 122 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 Corollary 2 Let P 1 X1 X I1 P n Xn X In local conditional lower previsions credal network let P X1 Xn strong extension Then P 1 X1 X I1 P n Xn X In P X1 Xn coherent 813 Some concluding remarks There reasons Corollary 2 important One credal Bayesian nets general important models important know coherent theoretical practical reasons Actually exploiting tools presented 37 possible stronger result coherence preserved socalled updating credal net general conditions This means possible produce inconsistencies building repeatedly credal net The second reason implicit generality theorem Remember basic limitations traditional deﬁnition credal nets focused far strong extension assumed ﬁnite number extreme points variables ﬁnitely possible values Both related deﬁnition strong extension useful necessary second question extend deﬁnition What natural way extend view adopting place deﬁnition strong product given Section 811 This choice allows propose ﬁrst time deﬁnition credal nets general spaces allows Theorems 7 8 immediately prove coherence credal nets general case kind possibility spaces involved possibly inﬁnitely extreme points generalised strong extension appears important outcome More generally speaking like point approach prove coherence credal nets replayed opportune changes important contexts For example recent work 37 exploited coherence graphs strong product prove coherence general statistical models shown impreciseprobability based forms statistical inference generalised parametric inference pattern classiﬁcation coherent These models generalise Bayesian inference sets priors model prior knowledge correspond condition nearignorance use sets likelihood functions model ﬂexibly possible presence process responsible missing values Also case coherence graphs key tool prove relatively easy way coherence mentioned models despite generality complexity A ﬁnal point particularly worth statistical case credal nets coherence graphs naturally originated type A1 Remember A1 graphs lead coherence irrespective numbers related lower previsions provided separately coherent words case A1 graphs coherence structural component collection With general graphs necessarily case related collection longer coherent small changes numbers making lower previsions way check coherence problematic numerical instabilities Therefore interesting observe commonly models artiﬁcial intelligence statistics naturally selected property coherence relatively insensitive mentioned instabilities On hand conﬁrms importance A1 graphs 82 Compatibility marginal conditional probabilistic assessments The results paper allow provide new insight solutions problem compatibility collection marginal conditional previsions This problem received longstanding literature seminal works Boole 6 Hoeffding 16 Fréchet 14 Vorobev 32 See 9 references recent works subject It related Sklars theorem notion copulas 28 applications economics 25 Consider variables X1 Xn taking values respective sets X1 Xn Consider I j O j 1 n I j X I j j 1 m As mentioned XiiO j If O j j 1 m conditional lower previsions P j X O j XiiI j provides variable X O j X I j models information variable X I j P j X O j particular I j P j X O j simply marginal information variable X O j We formulate compatibility problem general way studying extension P X n X Im In case marginal marginal conditional lower previsions collection P 1 X O 1 lower previsions means obviously P extension set gambles The situation conditional lower previsions bit involved shall interpret compatibility P P X O X I coherence lower previsions sense considered paper note remarked Section 2 particular case conditional unconditional assessment weak strong coherence equivalent X I1 P m X O m Note study lower previsions course valid particular case assessments X I j j 1 m In case precise linear conditional unconditional previsions P j X O j look precise joint linear prevision compatible assessments Coherence implies ﬁnite case equivalent fact joint P induces conditionals means Bayes rule conditioning event positive probability instance 2 Chapter 10 The traditional formulation problem special case previous formulation obtained restricting attention marginal previsions amounts study compatible joint P X n O j marginal P X O j j 1 m Our ﬁrst important result general compatibility problem Theorem 1 Remark 1 X Im compatible weakly X I1 P m X O m theorem know lower previsions P 1 X O 1 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 123 coherent This makes weak coherence general characterisation compatibility We aware work given characterisation general case consider similar result given 20 particular situation unconditional linear previsions ﬁnite sets X1 Xn Theorem 1 key result allows exploit direct way outcomes paper obtained weak coherence case compatibility problems For instance use Proposition 4 deduce weak X Im coherence compatibility implied separate coherence P 1 X O 1 information numbers previsions coherence graph associated collection template A110 This means collection lower previsions A1representable immediately know compatible gives graphical criterion suﬃcient compatibility The criterion easier obvious focus simpler compatibility problem unconditional lower previsions In case coherence graph possess cycles A1 actual nodes parent turn means sets O 1 O m pairwise disjoint X I1 P m X O m The graphical criteria course met practice case study speciﬁc problem hand order able check compatibility Yet going numbers lower previsions advantage coherence graphs optimally decompose compatibility problem simpler ones related subsets graphs minimal partition Actually situation coherence graphs prove helpful having potential greatly reduce complexity original task Also knowledge appears original avenue compatibility problems Let stress results general compared ones established classical works com patibility problem applied marginal conditional lower previsions instead linear Hence valid situations ambiguous scarce information use precise probability model possible adequate Furthermore case inﬁnite spaces X1 Xn work based ﬁnitely additive probabilities class subsets XI j O j j 1 m allows avoid topological measurability assumptions domains 83 Coherencebased probabilistic satisﬁability The compatibility problem close different wellknown problem called probabilistic satisﬁability 1517 A major difference usually deﬁned relative variables ﬁnite support deﬁned respect events In following shall assumption Let consider precise probabilities moment In case probabilistic satisﬁability consists checking number precise conditional unconditional probabilities consistent joint This usually algorithms based linear programming Probabilistic satisﬁability tightly related probabilistic logic 26 In fact check ﬁrst necessary step able compute linear programming probabilistic implications initial assessments new events goal probabilistic logic Probabilistic satisﬁability extended deal imprecise probabilistic assessments lower upper previsions recent work Walley Pelessoni Vicig 34 refer paper WPV short This work somewhat atypical based coherencebased view probability rarely employed approach similar spirit 5 probabilistic logic And authors paper relying coherence key ﬁx problems probabilistic logic develop truly general powerful methods These characteristics WPV natural candidate bridge results probabilistic satisﬁability To aim Section 831 ﬁrst consider WPV In particular consider speciﬁc notions consistency new results easy forth notions traditional ones probabilistic logic Moreover extend theory coherence graphs decompose Section 832 instances consistency problem WPV smaller ones This important result probabilistic satisﬁability NPhard problem 5 coherence graphs allow reducing problem smaller ones immediately obtain possibility solve bigger problem instances possible For alternative possibly complementary approach 3 case focus heuristic considerations reduce computational burden 831 Suﬃcient conditions avoiding partial uniform sure loss The WPV work ﬁrst related satisﬁability problem second extension assessments new events variables In language paper ﬁrst problem checking assessments avoid uniform loss second natural extension assessments These notions taken seminal work Williams 35 lower previsions In setup shall consider equivalent related ones Walley 33 Section 71 From follows avoiding uniform 10 Moreover proven coherence graph collection template type A1 deduce previsions weakly coherent strongly coherent This allows behavioural interpretation terms betting rates works Walley 33 Finetti 13 connects compatibility problem naturally decision making 124 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 loss weaker requirement strong coherence We recall case ﬁnite spaces possibilities considering avoiding uniform loss equivalent notion avoiding partial loss introduced Section 2 The conclusion follows coherence deﬁned strengthening avoiding partial loss At ﬁrst look surprising WPV focuses consistency notion weaker coherence leaves room inconsistencies original assessments The reason related second work natural extension Walley shows natural extension deﬁned necessary original assessments avoid partial loss Remember natural extension procedure allows compute tight probabilistic implications original assessments new event gamble particular original ones In case procedure automatically corrects possible inconsistencies left original assessments making strongly coherent In WPV coherence words byproduct natural extension WPV discusses different points relationship approaches especially based probabilistic logic pointing problems Here key understand difference approaches different notion loss Unlike WPV based avoiding uniform loss avoiding partial loss approaches based weaker notion avoiding uniform sure loss given Deﬁnition 3 To connection mentioned approaches explicit following proposition equivalent formulation avoiding uniform sure loss based existence dominating conditional lower previsions weakly coherent X Im collection separately coherent conditional lower previsions If Proposition 5 Let P 1 X O 1 spaces X1 Xn ﬁnite avoid uniform sure loss exist weakly coherent dominating conditional linear previsions P 1 X O 1 X I1 P m X O m X I1 Pm X O m X Im This proposition easily given intuitive meaning The existence dominating linear previsions means precise probabilities feasible set determined constraints conditional unconditional probabilities deﬁne satisﬁability problem words feasible set nonempty But fact weakly coherent means Theorem 1 Remark 1 joint mass function derive Bayes rule marginalisations precise probabilities Stated differently use number conditional lower previsions means express bounds conditional probabilities property avoiding uniform sure loss equivalent existence joint mass function satisﬁes bounds This clear avoiding uniform sure loss implicit condition traditional approaches probabilistic satisﬁability try test questions discussed length 34 Section 24 There point It possible probabilistic satisﬁability problem avoiding uniform loss avoiding uniform sure loss coincide lower probabilities involved conditioning events positive This related existence joint mass function mentioned fact joint mass function related conditional assessments problem Bayes rule turns relation Bayes rule applied lower probability conditioning event zero It follows avoiding uniform sure loss capture speciﬁc inconsistencies original assessments arise zero probabilities example presented Introduction This particular source criticism WPV approaches based avoiding uniform sure loss 34 Section 37 discussion point It considerable feature WPV approach suffer kinds inconsistencies draw wrong conclusions them11 At point insight WPV approach relationship work closely relationship coherence graphs WPV Our ﬁnal aim able use coherence graphs simplify check avoiding uniform loss WPV The following result need reach goal Theorem 9 Let P 1 X O 1 associated minimal partition given Deﬁnition 15 X I1 P m X O m X Im collection separately coherent conditional lower previsions let B 1 If P j X O j X I j jB avoid partial loss B B conditional lower previsions P 1 X O 1 X I1 P m X O m X Im avoid partial loss 2 If P j X O j P m X O m X Im avoid uniform sure loss X I j jB avoid uniform sure loss B B conditional lower previsions P 1 X O 1 X I1 This theorem states properties coherence graphs investigated case weak strong coherence hold similarly case losses consideration The similarity goes discussed remark 11 For instance 34 Section 38 Example 10 presented case mentioned inconsistencies lead traditional probabilistic logic deduce given event certain posteriori methods WPV correctly deduce complete ignorance posterior probability event lies interval 0 1 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 125 Remark 3 In particular case coherence graph A1 follows Theorem 9 deduce conditional lower previsions avoid partial uniform sure loss separate coherence A1 necessary property suﬃces notice counterexamples proof Theorem 4 linear conditional previsions weak coherence equivalent avoiding uniform sure loss coherence equivalent avoiding partial loss Hence partition minimal case A1 coherence graphs For general necessarily A1 coherence graphs partition minimal want deduce avoid ing partial loss condition consider previsions Example 2 diﬃcult P X2 X1 P X2 X3 X1 avoid partial loss avoid partial loss P X1 With respect avoiding uniform sure loss previsions counterexamples proof Theorem 4 linear conditional previsions follows partition minimal deduce avoiding uniform sure loss condition 832 Bridging coherence graphs probabilistic satisﬁability We ﬁnally exploit coherence graphs WPV We focus particular WPV extent checking X Im separately coherent lower previsions avoids uniform loss Recalling collection P 1 X O 1 considering ﬁnite spaces possibilities rephrased WPV check collection closed convex conditional unconditional sets mass functions avoids uniform loss X I1 P m X O m This task particularly onerous WPV Let recall WPV checks assessments avoid uniform loss running linear program But probabilistic satisﬁability NPhard problem This means practice size linear program corresponding 34 Eq 1 grows exponentially large size input In setup consider consequence number linear constraints program grows according size joint possibility space X n exponential function n Consider example collection lower previsions gives rise graph Fig 1 Say sixteen variables consideration takes values set elements Then number constraints program 43 millions prohibitive But know apply Theorem 9 point Theorem 9 allows decompose linear problem smaller ones according superblocks Fig 5 superblock variables ﬁve That linear problems 700 240 constraints respectively In example coherence graphs possible solve eﬃciently intractable This isolated case time coherence graph allows proper superblocks isolated size largest linear program decreases according exponential function number variables contained largest superblock similarly happens case Bayesian nets computation longer exponential global feature model number variables local potential lead eﬃcient solutions number realworld problems There advantage smaller linear programs reduces risks originated numerical instabilities involved collections general A1 mentioned end Section 812 strictly related kinds linear problems needed check avoiding uniform loss reported 34 9 Some possible extensions results This work focused problem coherence collection closed convex sets distributions The formalism introduced consequently based constant related features One work variables Another joint space possibilities X n variables product spaces individual variables A ﬁnal lower prevision consider deﬁned set gambles relative involved variables Although setup general aims general consider In section brieﬂy investigate extent results extended general setups This useful particular problems probabilistic satisﬁabilitylogic In fact ﬁeld uncommon focus problems lower previsions deﬁned gambles problems joint space possibilities X n product space socalled logical constraints possible values variables consideration joint values impossible This holds WPV traditional approaches artiﬁcial intelligence 1931 approaches based coherent probabilities 7 Actually problems probabilistic satisﬁability usually expressed language previsions condi tional variables considered paper deﬁned events Nevertheless diﬃcult consider variables values conditioning events order express language Let example Example 3 Let consider events A B C assume given probabilities P AB P C A B P BC Deﬁne variables X1 X2 X3 X1 takes values B Bc X2 takes values A B Ac B A Bc Ac Bc X3 takes values C C c In language paper assessments expressed P X2 X1 P X3 X2 P X1 X3 previsions deﬁned respectively I A IC IB In case associated coherence graph Fig 10 Since cycle coherence graph know 126 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 Fig 10 Coherence graph P X2 X1 P X3 X2 P X1 X3 assessments coherent Note given probabilities P AB P C A B P B expressed terms variables P X2 X1 P X3 X2 P X1 Their associated coherence graph A1 consequence coherent The following sections investigation remaining problems Section 91 deals case lower X I j j 1 m deﬁned domains H j subsets sets K j XO jI j measurable gam previsions P j X O j bles Section 92 discusses problem logical dependence We report possible extension Section 93 concerned case know coherence subsets collection lower previsions subsets partition assumed far Finally concluding remarks Section 94 91 Considering smaller domains X Ii One assumptions paper domain conditional lower prevision P X O set Ki XO Ii measurable gambles set gambles depend value variables X Ii subset Kcid12 Ki extend Ki X O X Ii Although domain P X O procedure natural extension think discuss case To simplify reasoning going assume Kcid12 linear subset Ki It diﬃcult extend reasoning case Kcid12 nonlinear set instance ﬁnite set work 22 The ﬁrst important thing remark suﬃcient conditions paper coherence weak coherence avoiding partial uniform sure loss Theorems 2 3 9 hold domains smaller For suﬃces consider assumptions domains proofs f Kcid12 subset A XIi gamble f I A Kcid12 assumed loss generality consequence separate coherence 33 Lemma 624 With respect necessary condition establish Theorem 4 deducing weak coherence generalise conditional lower previsions arbitrary linear domains think instance conditional lower previsions deﬁned constant gambles coherent soon separately coherent soon satisfy P iμ X Ii μ constant μ R This holds irrespective coherence graph need A1 If want Theorem 4 hold general situation need impose additional constraints Kcid12 It checked results hold 1 n P X O X Ii satisﬁes following conditions SD1 For subset A XO Ii indicator function I A belongs Kcid12 SD2 For gambles f Kcid12 subsets A XO Ii gamble f I A belongs Kcid12 Note P X O X Ii separately coherent assume loss generality domain Kcid12 includes constant gambles In case condition SD1 consequence SD2 Note SD2 seen consequence separate coherence I A depend conditioning variables conditional ones The proof Theorem 4 implies conditions SD1 SD2 hold partition deﬁne minimal allows deduce property avoiding uniform sure loss 92 Adding logical dependence considerations Another important issue applicability results logical independence In paper sumed variables X1 Xn logically independent meaning consider combination x1 xn X n possible value joint variable Xn It uncommon consider variables satisfy kind logical dependence assumption end imply elements X n structurally impossible values joint variable X1 Xn removed joint possibility space With respect ﬁrst observation partition conditional lower previsions associated superblocks deduce weak strong coherence avoiding partial uniform sure loss addition logical dependence considerations happen ﬁnite spaces precise conditional previsions following example Example 4 Consider binary variables X1 X2 previsions P X2 P X1 determined P X2 1 1 P X1 0 These previsions coherent associated coherence graph A1 incompatible logical dependence assumption X1 X2 compatible model P satisfy P X1 0 X2 1 1 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 127 One way model fact joint values X n impossible use unconditional lower previsions giving upper probability zero impossible combinations If know instance variables X1 X2 assume values subset A X12 assessment P A 1 This expressed unconditional lower prevision P X1 X2 K12 given P f infω A f ω We discuss use method coherence graphs There cautionary note strictly speaking fact joint values given zero upper probability general implication logical dependence sense converse necessarily true event upper probability zero need regarded structurally impossible In following shall refer case joint values given upper probability zero practical impossibility distinguish logical dependence The following discussion leads suﬃcient conditions check coherence loss notions practical impossibility When focus logical dependence instead difference practical impossibility enforced applications results regarded necessary conditions Whether suﬃcient conditions general logical dependence open problem considered future work impossibility combinations values additional unconditional As said model practical cid12 cid12 1 P lower previsions P k Then like verify coherence weak coherence assessments cid12 cid12 P 1 P n P 1 P k For apply reasoning paper build associated coherence graph Its superblocks produce partition set previsions property suﬃces verify coherence resp weak coherence avoiding partial loss avoiding uniform sure loss elements partition immedi ately deduce coherence resp weak coherence avoiding partial loss avoiding uniform sure loss assessments Note order ﬁrst thing verify working collection previsions cid12 X1 X2 If practical impossibility assumption expressed terms unconditional P assessment P X1 X2 check P X1 X2 satisﬁes assumption assessments coherent If need include P cid12 X1 X2 set assessments Since working assessments superblocks coherence graph bigger general associated partition coarser In worst cases practical impossibility cid12 X1 Xn previsions assumption involves variables expressed unconditional P belong superblock In case coherence graphs help simplify veriﬁcation coherence The extreme case practical impossibility assumptions involve variables superblock following example Example 5 Assume variables X1 X5 assessments P 1 X1 X2 P 2 X2 X1 P 3 X5 X3 P 4 X5 X4 Their associated coherence graph given Fig 11 If assumptions X1 X2 X3 cid3 X4 included graph means unconditional previsions P 5 X1 X2 P 6 X3 X4 The new coherence graph Fig 12 We P 1 X1 X2 P 2 X2 X1 P 3 X5 X3 P 4 X5 X4 coherent compatible practical impossibility assumptions P 1 X1 X2 P 2 X2 X1 coherent compatible X1 X2 hand P 3 X5 X3 P 4 X5 X4 coherent compatible X3 cid3 X4 Hence cases need verify practical impossibility assumptions superblocks able deduce coherence We expect number cases situation intermediate extreme ones presented superblocks grow adding practical impossibility considerations biggest coincide entire graph In cases coherence graphs useful permit decompose original problem smaller ones degree The situation bit simpler focus weak coherence instead coherence Assume num ber weakly coherent conditional lower previsions practical impossibility considerations imply values A X n acceptable joint variable X1 Xn It checked unconditional lower prevision E deﬁned proof Theorem 1 smallest coherent lower prevision weakly coherent X Im 21 If satisﬁes E A 1 deduce assessments compatible P 1 X O 1 X I1 P m X O m Fig 11 Coherence graph collection P 1 X1 X2 P 2 X2 X1 P 3 X5 X3 P 4 X5 X4 Fig 12 The coherence graph Fig 11 modiﬁed add considerations practical impossibility 128 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 practical impossibility considerations alternative easier suﬃcient condition check Using Propo sition 5 possible simplify study compatibility avoiding uniform sure loss condition practical impossibility considerations 93 Making nondisjoint assumptions coherence In paper focused problem deducing coherence number conditional lower previsions coherence previsions belong sets In formulation assumed given partition set conditional lower previsions We proven tool verifying coherence weak coherence compare partition minimal partition derive superblocks coherence graph It interesting consider case information given terms partition said sets conditional lower previsions coherent sets disjoint For instance consider assessments P X1 X2 P X2 X1 P X1 X2 told assessments coherent That know P X1 X2 P X2 X1 coherent P X1 X2 P X1 X2 coherent implies assessments weakly coherent P X2 X1 P X1 X2 coherent like know deduce joint coherence P X1 X2 P X2 X1 P X1 X2 Such situation considered instance 33 Section 791 One way results consider partitions ﬁner information given compare minimal partition This provide suﬃcient condition deducing coherence Nevertheless approach fruitful example able derive coherence established 33 Section 791 A thorough study matter main open problems consider future 94 Concluding remarks We summarise main outcomes previous sections The ﬁrst positive answer extension problems based smaller domains coherence graphs decompose problems What lose general optimality decomposition case weak coherence critical especially regard coherence resp avoiding partial loss consistency notion focus weak coherence resp avoiding uniform sure loss The second outcome concerns called statements practical impossibility concept related logical dependence In case include kind statements coherence graph know general affect topology graph minimal partition It possible partition stays resulting graph A1 grows worst case coincides entire graph Therefore cases coherence graphs prove useful considerations practical impossibility prospect fully exploit considerations open problem time It open problem extend results case know subsets assessments coherent form partition 10 Discussion Coherence regarded essence theory personal probability But working directly coherence particularly onerous The present paper attempt deal diﬃculty case Walleys important notion strong coherence deliver tools easier check We inspired lesson graphical models deﬁned new graphical model called coherence graph Coherence graphs means render explicit structure notion coherence We shown structure induces minimal partition available collection lower previsions characteristic coher ence set partition implies coherence overall collection This result general holds lower previsions cardinality possibility spaces involved In particular holds lower previsions applicable determine coherence collection conditional linear previsions useful precise context The generality results enabled apply problems diverse proving coherence Bayesian credal networks decomposing problems compatibility probabilistic satis ﬁability smaller ones On hand generality needed proofs somewhat long technically involved This fact graphs naturally models distributed computation clashes global nature coherence This presented results easy exploit practise provided polynomialtime algorithm computes minimal partition coherence graph eﬃciently On theoretical level results appear shed light speciﬁc aspects coherence thanks especially herence graphs type A1 These graphs correspond collections separately coherent lower previsions coherent irrespective numerical values They related generalisation marginal extension E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 129 theorem established 23 relationship arises A1 condition establish total order conditional lower previsions collection template order allows use generalised marginal extension theorem In way given easy graphical characterisation extent theorem applied A1representable collection templates Moreover associated coherence graph A1 conditional lower previsions template lower envelopes coherent linear previsions This hold collections coherent conditional lower previsions shown 33 Section 66 So remarkable results lead naturally Bayesian sensitivity analysis interpretation collection conditional lower previsions Remember shown important conceptual differences notions weak strong coherence proposed Walley Weak coherence equivalent existence joint lower prevision coherent assessments In particular case conditional linear previsions ﬁnite spaces equivalent existence joint mass function inducing conditionals means Bayes rule The introduction notion strong coherence needed conditional lower previsions common joint clearly incoherent Remarkably happens linear ﬁnite case mentioned Taking account ﬁnd noteworthy problem tackled weak strong coherence exhibit similar behaviour number assessments know separately coherent guarantee weakly coherent exactly conditions deduce joint coherence need graph representing collection template A1 More generally established partition graph weak coherence inside implies weak coherence proven strong coherence inside partition implies strong coherence assessments It useful recall completely analogous considerations hold consider loss notions avoiding partial uniform sure loss We recall differences example shown minimal partition obtained coherence graph minimal case weak coherence necessarily strong coherence There important open problems related paper One possibility fully exploit coherence graphs considerations logical dependence proposed partial solution problem It extend proposal necessary hand investigate theoretical properties hand specialise models paper This example strengthening notion collection template insert knowledge numbers lower previsions collection focusing coherence graphs special topologies dealing variables taking values ﬁnite sets binary variables These considerations simplify problems probabilistic logic different considered paper As topic future research respect suggest study optimisation compatibility problem 1534 looks smallest joint compatible number assessments We think functional E deﬁned proof Theorem 1 play important role One possible extension discussed consider inﬁnite set variables assessments ﬁnite number conditional lower previsions think possible use coherence graphs determine coherence weak coherence making compact representations variables The prob lem complicated consider inﬁnite number variables assessments case ﬁrst generalise coherence notions 33 inﬁnite number assessments generalisation immediate Acknowledgements We grateful Gert Cooman encouraging study problems presented paper helpful comments We like thank Renato Pelessoni Paolo Vicig instructive discussion joint work Peter Walley cited references Reinhard Diestel Gregory Gutin drawing attention strong components way simplify algorithm compute minimal partition ﬁnally referees useful suggestions comments We acknowledge ﬁnancial support MCYT project TSI200766706C0401 Swiss NSF grants 2000211138201 2000201166741 Hasler Foundation grant 2233 Appendix A Proofs Proof Theorem 1 This proof similar Walley gives 33 Theorem 818 coherence For reason brief sketch X I1 P m X O m X Im weakly coherent Let deﬁne lower prevision E LX n cid6 Assume P 1 X O 1 cid15 cid8 cid4 E f sup α f j K j j 1 m st sup xX n G j f j X I j f α x 0 mcid5 j1 To E welldeﬁned suﬃces note sup f cid2 E f cid2 inf f gamble f given α sup f X Im gambles f 1 fm satisfying equation contradict weak coherence P 1 X O 1 α inf f f 1 fm 0 It easy E satisﬁes conditions C1C3 X Im weakly coherent consequence coherent lower prevision Let E P 1 X O 1 X I1 P m X O m X I1 P m X O m 130 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 satisfy Eq 3 Consider f LX n gambles f j K j j 1 m Consider cid10 0 Then deﬁnition E implies g j K j j 1 m cid4 mcid5 j1 sup xX n cid6 G jg j X I j G f cid10 2 0 G f f E f consider α E f cid10 2 deﬁnition E Hence G f m j1 G jg j X I j cid10 2 There possible cases Eq 3 j0 1 m case case b cid16 Consider f 0 K j0 z0 XI j0 j0 1 m Then Eq A1 superadditivity P j X O j j 1 m weak coherence P 1 X O 1 X I1 P m X O m cid6 cid4 X Im deduce A1 X I j G j f j X I j G f G j0 f 0z0 x mcid5 G j f j X I j mcid5 j1 G jg j X I j cid10 2 G j f j g j X I j cid10 2 G j0 f 0z0 cid6 G j0 f 0z0 x cid6 x cid2 cid10 2 sup xX n mcid5 j1 cid4 cid2 sup xX n cid2 sup xX n cid4 j1 mcid5 j1 cid4 mcid5 j1 sup xX n Since holds cid10 0 deduce supxX n b Take f 0 LX n Then Eq A1 cid6 G j f j X I j G f G f 0 x cid2 cid10 cid16 m j1 G j f j X I j G f G j0 f 0z0x cid2 0 cid4 mcid5 cid4 j1 mcid5 cid4 j1 mcid5 j1 0 sup xX n cid2 sup xX n cid2 sup xX n cid6 G j f j X I j G f G f 0 cid10 x G j f j X I j mcid5 j1 G jg j X I j G f 0 cid10 cid6 2 cid6 x G j f j g j X I j G f 0 cid10 2 x second inequality follows Eq A1 superadditivity conditional lower previsions P j X O j 2 contradicts deﬁnition E Since holds cid10 0 deduce supxX n X I j j 1 m But means raise value E f 0 cid10 j1 G j f j X I j G f G f 0x cid2 0 cid16 m Hence E P 1 X O 1 X I j weakly coherent From 33 Section 65 deduce j 1 m X Im weakly coherent consequence j 1 m E f K j x XI j X I1 P m X O m P j X O j EG j f X I j cid2 0 EG j f x 0 Take f j K j j 1 m f 0 K j0 z0 XI j0 j0 1 m Take g j G j f j X I j j 1 m g0 G j0 f 0z0 Then deduce assumption P g j cid2 0 j 1 m P g0 0 g j G j f j X I j cid2 Gg j g j P g j j 1 m g0 G j0 f 0z0 Gg0 g0 P g0 As consequence cid4 mcid5 j1 sup xX n cid6 cid6 G j f j X I j G j0 f 0z0 x cid2 sup xX n Gg j Gg0 x cid2 0 cid4 mcid5 j1 second inequality follows coherence P We deduce P 1 X O 1 coherent X I1 P m X O m X Im weakly For second statement let P 1 X O 1 X Im weakly coherent conditional linear previsions Use 33 Section 655 deduce linear prevision P dominates coherent lower prevision P exists ﬁrst theorem satisfy P G j f X I j 0 j 1 m f K j P f P P j f X I j The converse implication follows trivially ﬁrst theorem cid2 X I1 Pm X O m E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 131 Proof Proposition 1 The direct implication consequence Theorem 818 33 taking account include family unconditional lower prevision P deﬁned constant gambles The converse implication trivial cid2 Proof Corollary 1 The direct implication established proof Theorem 1 The converse implication trivial cid2 Before prove Proposition 3 going lemmas constrain probability actual node block The ﬁrst lemmas applied blocks associated node parent Lemma 4 employed dealing blocks associated cycle Lemma 2 employed notion weak coherence veriﬁed smaller parts Theorem 4 1 xi Lemma 2 Let consider xi 2 K1 Km by12 P j f f xi Xi 1 n Deﬁne previsions P 1 X O 1 1iO j I j y xi cid8 P j f y f xi f xi 1iO j y 2iO j y 1iI j X I1 Pm X O m X Im respective domains I j cid3 j 1 m y XI j f K j Then previsions P 1 X O 1 X I1 Pm X O m X Im coherent Proof First follows immediately previsions satisfy conditions SC1SC3 Section 2 separately coherent Moreover linear coherence equivalent avoiding partial loss Eq 2 Hence prove f j K j m j1 S j f j j 1 m equal 0 exists B cid7 mcid5 j1 sup xB G j f j X I j x cid2 0 A2 order simplify notation case I j use G j f j X I j denote G j f j If j 1 m I j f j cid3 0 S j f j X n Eq A2 mcid5 j1 sup xX n G j f j X I j x cid2 0 condition holds trivially considering x xi 1i1n terms sum equal 0 Let assume I j cid3 j 1 m dealing conditional linear previsions Note assume loss generality f j cid2 0 j 1 m suﬃces consider j X I j G j f j X I j gamble f cid12 j f j inf f j cid2 0 satisﬁes G j f For j 1 m let deﬁne sets A j π 1 O j I j cid3cid13cid3 cid2 A cid2 cid2 cid3 cid12 j cid12 j cid12 j A xi 1iO jI j xi 2iO j cid12 XI j xi 1iI j gambles g j f jI A j I A j indicator function A j Since f j I A j XO jI j measurable deduce g j belongs K j Moreover given y XI j cid8 P jg j y g jxi g jxi y xi 1iO j y 2iO j y 1iI j P jg j X I j P j f j X I j Since g j cid3 f j j 1 m f j cid2 0 implies G jg j X I j cid3 G j f j X I j j Moreover given y A j G jg j X I j y 0 y A j G jg j X I j y P jg jπI j y P j f jπI j y cid3 0 taking account gamble f j nonnegative assumption Now g j 0 j 1 m G jg j X I j x 0 Since G j f j X I j cid2 G jg j X I j deduce G j f j X I j x cid2 j 1 m considering element union supports j 1 m 0 x X n Eq A2 holds Assume g j cid16 cid3 0 j 1 m Since xi 11cid2icid2n A j cid7 11cid2icid2n 0 Hence B m j1 S jg j xi 11cid2icid2n B Eq A2 holds m j1 S jg j let j1 smallest integer g j1 B1 y1 X I c j1 cid3 0 Consider B1 S j1 g j1 Then m j1 G jg j X I j xi If xi 11cid2icid2n B B cid7 y1 XI j1 12 We use onetoone correspondence gambles XO j I j gambles K j 132 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 m X I j1 2iI c j1 Let z1 y1 xi 1iI j1 z1 0 If xi cid16 j1 G jg j X I j z1 cid2 0 deduce Eq A2 holds If z1 0 Since G j2 g j2 2 Note y1 cid3 xi xi G j1 g j1 j2 1 m G j2 g j2 deduce existence B 2 S j2 g j2 z1 B2 For B2 y2 XI j2 y2 X 1iI j2 ith component ith component z1 I j2 xi Moreover 1 n ith component z1 xi deﬁne mapping h X n 0 n hz number πiz equal xi hz2 cid2 hz1 If hz2 hz1 z2 z1 z1 A j2 G j2 g j2 Hence hz2 hz1 cid16 B1 That ith component z1 ith component y1 I j1 equal 11cid2icid2n B1 contradiction As consequence z1 A j1 j1 G jg j X I j z1 0 z 0 z outside S j2 g j2 B2 denote element X n z2 0 X I j2 2 ith component z2 deﬁnition 2 z1 0 contradiction reasoning Let z2 y2 xi 2 Then z2 A j2 G j2 g j2 Note y2 cid3 xi 2iI c j2 X I j2 X I j2 X I j2 I c j2 cid16 m m j1 G jg j X I j z2 cid2 0 deduce Eq A2 holds If sum negative j3 z2 0 We deﬁne z3 element X n ith component ith component z2 2 Then belongs element S j3 g j3 z2 hz3 hz2 If follow procedure obtain sequence elements zn union supports g j hzn hzn1 n But 0 cid3 hz cid3 n z X n process ﬁnite If stop z hz n cid16 j1 G jg j X I j z cid2 0 On hand stop z means z cid7 hz n z xi m j1 S jg j belongs cid16 j1 G jg j X I j z 0 This shows m A j j P 1 X O 1 m j1 S jg j 21cid2icid2n means xi 21cid2icid2n belongs cid16 j1 G j f j X I j z cid2 m j1 G jg j X I j z 0 As consequence X Im coherent cid2 X I1 Pm X O m cid16 cid7 m m Again X I j3 G j3 g j3 I j3 xi Xi 1 n Let deﬁne previsions P 1 X O 1 X I1 Pm1 X O m1 X Im1 respective 1iO j I j cid3 xi Lemma 3 Take xi 2 1 domains K1 Km1 P j f f xi cid8 y xi f xi f xi P j f y 1iO j y 2iO j y I j cid3 y XI j f K j Let Pm X O m f xi 1iI j 1iO m y y XIm f Km Im cid3 Then P 1 X O 1 X I1 Pm X O m X Im weakly coherent X Im given P m f f xi 1iO m f Km Im Pm f y Proof It easy previsions satisfy conditions SC1SC3 Section 2 separately coher ent Since linear weakly coherent f j K j j 1 m mcid5 j1 sup xX n G j f j X I j x cid2 0 Now G j f j X I j y 0 y xi P 1 X O 1 X I1 Pm X O m X Im weakly coherent cid2 1i1n j 1 m deduce Eq A3 holds A3 Next value parent dummy node cycle cycle determined previsions cycle Lemma 4 Consider indices j1 j p satisfying Eq 5 determining cycle let k I j1 weakly coherent previsions P 1 X O 1 1 p satisﬁes P x 1 X I1 Pm X O m X Im joint prevision P coherent P ji X O ji O j p Then x Xk X I ji Proof Take cid7i I ji consider xi 1 cid3 xi O ji1 1 p simplicity notation j0 j p For 1 n let 2 Xi xk 1 x Let deﬁne P 1 X O 1 X I1 Pm X O m X Im domains K1 Km cid8 P j1 f y f xi f xi 2iO j1 1iO j1 y cid71 1 y cid3 xi πcid71 y x 1iI j1 y y XI j1 f K j1 cid8 P js f y f xi f xi 1iO js 2iO js y πcid7s y xcid7s 1 y E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 133 y XI js f K js s 2 p let deﬁne j j1 j p P j f f xi cid8 1iO j f K j I j P j f y f xi f xi y xi 1iO j y 2iO j y 1iI j I j cid3 y XI j f K j These previsions satisfy conditions SC1SC3 Section 2 separately coherent Moreover weakly coherent For f j K j j 1 m Eq A3 holds But easy G j f j X I j y 0 y xi 1i1n j 1 m Next joint P coherent conditional previsions P j1 X O j1 X I j1 second equal 0 In order prove going use 2 p 1 I j1 We going ﬁrst terms P j p X O j p cid12 X I j p cid13 cid7i x 1 cid12 cid12 cid13 1 1 For note ﬁrst 1 p satisfy P xk cid12 cid7i X I ji1 x 1 1 1 p In particular 1 P ji1 P ji1 P cid7i x 2 cid7i x 2 cid13cid13 cid13cid13 cid12 cid12 P P P cid7i P ji1 x 1 cid13 X I ji1 X I ji1 cid71 cid71 1 πiz xi z πcid71 z x x 2 second equality holds P xi 1 xi equal P xi cid7i P ji1 x 2 cid12cid2 X I ji1 cid12 P 1 P P cid71 x 1 cid12 cid13 2 1iI j1 I j1 cid3cid13 P cid12 cid13 cid71 x 2 1 xi 2 cid12cid2 P z X n πcid7i1 z cid3 πcid7i z cid3cid13 cid12cid2 cid12 P P cid7i cid7i πcid7i1 z cid3 πcid7i z z πcid7i z x 1 x 2 cid7i cid7i z πcid7i z x 1 x 2 cid3 πcid7i1 z cid3 πcid7i z cid12cid2 P ji cid3cid13 cid13 cid12 cid12 cid13 P P 0 2 p notation cid7p1 cid71 Hence cid7i1 cid7i1 cid7i cid7i 1 x 2 x x x 1 2 cid7i cid7i 1 valid 1 p The equality P x implies P x 1 x 2 cid7i cid7i cid72 1 πcid7i z x 3 p Take z πcid72 z x 1 x 2 cid7i 1 πcid7i1 z x 2 p 1 πcid7i z x cid7i cid72 1 P x 1 i2p A completely similar argument shows P x P x cid71 cid71 cid71 2 P x Now P x 2 x 2 x cid13 cid13 cid12 cid7p cid71 2 x x 1 cid72 cid71 cid72 2 P P j1 x 2 x 2 cid12 cid12 cid72 cid71 2 x x 1 0 P x X I j1 cid13 cid12 cid7i x 1 cid71 2 x 0 P P cid3 P cid71 x 2 P cid13 cid13 cid12 i2p P x Eq A4 P x cid72 cid71 cid71 1 z P x 2 P x 1 z x cid12 cid13 cid12 cid13 cid12 cid71 1 z x cid72 cid71 1 z x x 2 P P P cid71 2 0 Consider hand z XI j1 cid72 cid71 cid71 cid72 0 Hence 1 P P j1 x 1 z x 1 z x 1 cid12 cid12 cid7i x 2 X I j1 cid13 cid7p cid71 1 x x 2 cid71 1 z x 0 cid3 P cid13 cid13 i2p cid71 Eq A4 Hence P z πcid71 z x 1 πiz xi P xi In particular P xk 1 1 cid2 1iI j1 cid13cid13 X I ji P 0 0 A4 cid7i cid7i cid72 cid72 1 πcid7i z x 1 P z πcid72 z x 1 x 2 cid7i 3 p z cid3 x 1 i2p Then cid7i1 Eq A4 implies P z 0 We deduce 2 cid7i cid72 2 P x 2 i2p cid71 cid72 cid71 cid72 2 P x 1 P x 2 x 2 x cid72 1 As consequence cid71 different xi 1iI j1 cid71 Then 1 xi 2 I j1 P xi 1iI j1 1 P x cid71 cid71 2 1 P x Proof Proposition 3 Let Xcid7 source contradiction Then source contradiction parents coherence graph exists i1 1 m cid7 O i1 Apply Lemma 2 xcid7 x Then obtain xcid7 2 satisﬁes P x X Ii1 set coherent conditional linear previsions joint P coherent P i1 X O i1 P P i1 x X Ii1 Consider node Xcid7 predecessor source contradiction x Xcid7 We following possi P 1 1 1 bilities O p cid3 cid7 I p Apply Lemma 3 m i1 xcid7 X Ii1 1 Assume ﬁrst successor Xs node Xcid7 parent Let consider cid3 constraining subblock Xcid7 block different i1 p 1 m s O i1 I p1 x joint P coherent 1 P P i2 xs 1 P P i1 xs X Ii1 P i1 X O i1 O i3 A similar reasoning allows P xs 1 xi 1iIi2 1iIi2 1 1 Hence case 1 following procedure deduce P xcid7 P xi deﬁne weakly coherent conditional previsions P 1 Pm prevision P coherent P i1 X O i1 1 As consequence 1 P xs 1 1 t I i2 satisfy P xs P xi 1 particular P xt P p X O p satisﬁes P xcid7 O i2 I i2 1 1 1iIi3 O i3 X Ii2 X Ii1 X Ii p 1 1 1 134 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 2 Consider case successors Xcid7 parent Then Xcid7 belong block originated cycle In particular Xcid7 predecessor node elementary cycle block If Xcid7 parent dummy node cycle cycle result follows Lemma 4 If previous possibilities holds path graph connecting Xcid7 dummy node elementary cycle We consider constraining subblock Xcid7 block associated cycle Take cid3 k1 kr 1 n I j3 j1 j p 1 m O j1 k1 kr1 1 n j1 j p cid7 O k1 cid3 kr j1 Let consider Ikr Ik2 O k2 ti O ki X Im deﬁned Take xi 1 proof Lemma 4 Then previsions weakly coherent prevision P coherent X I j1 1 P j1 X O j1 I j1 1 P xtr 1 1 tr1 Ikr 1 1 1 t Ikr1 particular P xt following procedure deduce P xcid7 1iI j1 P P kr1 xtr 1 P xi O kr2 A similar reasoning allows P xi tr1 1 As consequence P x 1 X Ikr1 1iIkr1 1 n let consider previsions P 1 X O 1 Iki1 2 r 1 cid3 xi 2 I j1 cid3 O kr1 cid3 O j p Ik3 X I1 Pm X O m 1iIkr1 1iIkr2 P j p X O j p satisﬁes P xi P xtr 1 cid3 O j2 X I j p I j2 Xi xi 1 1 1 1 1 P coherent P k1 X O k1 X Ik1 P kr1 X O kr1 X Ikr1 P j1 X O j1 X I j1 P j p X O j p X I j p This completes proof cid2 In order simplify proofs Theorems 2 3 going establish couple results Lemmas 5 6 common proofs Lemma 5 Let consider nonempty subset J 1 m Let B1 partition J deﬁne C B1 set B C cid7 jC I j O j Then sets B C C B1 pairwise disjoint13 following statements hold X I j jC coherent C B1 lower previsions P j X O j X I j jC weakly coherent C B1 lower previsions P j X O j X I j j J coherent X I j j J weakly coherent 1 If P j X O j 2 If P j X O j Proof 1 Consider f j K j j J f 0 K j0 z0 XI j0 j0 J Assume I j cid3 j f j cid3 0 result follows second statement reduction theorem 33 Theorem 715 Let C0 element B1 includes j0 The coherence P j X O j I c j0 X I j jC0 implies existence D C0 jC0 S j f j z0 X cid17 cid5 cid18 G j f j X I j G j0 f 0z0 x cid2 0 sup xD C0 jC0 cid10 0 xC0 cid18 G j f j X I j G j0 f 0z0 cid17 cid5 xC0 cid2 cid10 D C0 jC0 On hand C cid3 C0 B1 D C cid5 jC sup xD C G j f j X I j x cid2 0 cid7 jC S j f j given cid10 0 xC D C cid5 jC G j f j X I j xC cid2 cid10 A5 A6 Let consider element z X n satisfying πB C z πB C xC C B1 element exists sets B C C B1 pairwise disjoint Then deduce Eqs A5 A6 cid17cid5 cid18 G j f j X I j G j0 f 0z0 z cid2 B1cid10 j J 13 This assumption means given C1 cid3 C2 B1 subgraphs associated B C1 B C2 connected E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 135 z D C C B1 particular Since cid10 0 deduce conditional lower previsions P j X O j X I j j J coherent 2 Using similar reasoning notations previous point deduce cid10 0 xC0 cid17 cid5 jC0 cid18 G j f j X I j G j0 f 0z0 xC0 cid2 cid10 On hand C cid3 C0 B1 xC cid5 jC G j f j X I j xC cid2 cid10 Now sets B C C B1 pairwise disjoint deduce equations element z X n πB C z πB C xC C B1 cid17cid5 cid18 G j f j X I j G j0 f 0z0 z cid2 B1cid10 j J Again cid10 0 deduce conditional lower previsions P j X O j coherent cid2 X I j j J weakly cid7 X Im separately coherent collection template graph A1 Let I non j1 O j let x XI Then f j K j j 1 m j0 1 m f 0 m Lemma 6 Let P 1 X O 1 subset 1 n disjoint K j0 z0 XI j0 X I1 P m X O m cid6 cid4 mcid5 j1 sup yπ 1 I x G j f j X O G j0 f 0z0 y cid2 0 A7 Proof We going assume gamble G j0 f 0z0 identically equal zero result G j0 f 0z0 0 k1 follows corollary From Lemma 1 assume O k j1 I j k 1 m For k let X IIk Ak1 class Hk XI Ak measurable gambles deﬁne set Ak s1O s I s previsions Q X O k cid7 k cid7 k cid13 f x πIk x Note welldeﬁned I Ak1 O k f x P k Q cid12 k k X O k For k 1 m Q X I1 P m X O m follows separate coherence P 1 X O 1 creasing sequence variables Applying marginal extension theorem variables 23 conclude Q coherent14 X IIk Ak1 satisﬁes conditions SC1SC3 separately coherent This X Im On hand conditional Consider f j K j j 1 m j0 1 m f 0 K j0 z0 XI j0 π 1 j01 j1 G j f j X I j h2 x belong H j follows g j H j j 1 j0 1 Moreover set E XII j A j1 support g j included π 1 g j X II j A j1 y f j y P j f j X I j y We deduce coherence Let deﬁne gambles h1 x j 1 j0 1 Then f j I G j f j X I j G j0 f 0z0 Let deﬁne g j f jI Q 1 m m j j0 π 1 cid16 cid16 I I I Q x Besides y π 1 Q I E cid6 j01 1 x g j y Q j01 j1 S jg j cid7 j cid4 sup yE j01cid5 j1 g j Q g j X II j A j1 j y cid2 0 cid4 j01cid5 cid6 f j P j f j X I j I x sup yπ 1 h1 y sup yπ 1 y sup yπ 1 j1 x Consider cid10 0 let y1 E satisfy h1 y1 cid2 cid10 Let E1 π 1 vanishes following equations E 1 π 1 x I I I A j0 cid4 j01cid5 j1 cid6 g j Q g j X II j A j1 j y cid2 0 y1 Note j0 1 simply h1 0 1 x There possibilities I 14 For note domain Hk Q measurable gambles partitions conditioning increasingly ﬁner X O k k X IIk Ak1 set XI Ak measurable gambles included set XIIk1 Ak 136 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 If E1 π 1 I j0 z0 let deﬁne g j f jIE1 j j0 m Then g j H j element support g j included E1 We deduce coherence Q E2 m j0 j j0 m Q m j j0 S jg j cid4 mcid5 cid6 sup yE2 j j0 cid4 mcid5 sup yE1 j1 g j Q g j X II j A j1 y cid2 0 A8 cid6 f j P j f j X I j G j0 f 0z0 y sup yE1 cid4 mcid5 cid6 f j P j f j X I j j1 y sup yE1 h1 y h2 y cid2 cid10 taking account Eq A8 gamble h1 identically equal h1 y1 E1 sup yE1 sup yE2 h2 y cid2 0 As consequence h2 y cid2 sup yπ 1 I x h1 y h2 y cid2 sup yE1 h1 y h2 y cid2 cid10 cid10 0 deduce Eq A7 holds If E1 π 1 1 z1 Note E2 π 1 z0 cid3 consider z1 intersection let y2 πII j0 II j0 I j0 E1 π 1 z0 Let consider gambles g j f jIE2 j j0 m It follows coherence Q I j0 E3 A j0 cid7 m j j0 S jg j π 1 II j0 A j0 1 A j0 y2 1 Q m j0 y2 cid6 g j Q g j X II j A j1 G j0 g0 y1 y cid2 0 A9 note follows deﬁnition gambles g j j j0 m y1 E3 E2 consequence E3 E1 π 1 mcid5 x Hence cid4 I cid4 mcid5 j j0 sup yE3 sup yπ 1 I x cid2 sup yE3 sup yE3 sup yE3 cid6 f j P j f j X I j G j0 f 0z0 y j1 cid4 mcid5 cid4 j1 mcid5 j1 cid6 f j P j f j X I j G j0 f 0z0 y cid6 g j Q j g j X II j A j1 G j0 g0 y1 y h1 y h2 y cid2 cid10 taking account gamble h1 identically equal h1 y1 E1 superset E3 Eq A9 Since cid10 0 deduce Eq A7 holds This completes proof cid2 X Im separately coherent collection template graph A1 Then Corollary 3 Let P 1 X O 1 f j K j j 1 m j0 1 m f 0 K j0 z0 XI j0 X I1 P m X O m cid6 cid4 mcid5 sup yB B G j f j X O j G j0 f 0z0 y cid2 0 j1 cid7 m j1 S j f j π 1 I j0 z0 Proof The result follows reasoning previous proof I The main difference π 1 x X n g j f j j 1 j0 1 By repeating arguments conclude cid4 cid6 I mcid5 sup yE2 j1 G j f j X O j G j0 f 0z0 y cid2 0 E2 included B cid7 m j1 S j f j π 1 I j0 z0 cid2 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 137 Proof Theorem 2 Let consider gambles f j K j j 1 m cid6 j0 1 m f j0 K j0 z0 XI j0 let G j f j X O j G j0 f 0z0 x cid2 0 A10 cid4 mcid5 j1 cid7 sup xE E m j1 S j f j π 1 I j0 z0 Let B1 subset B given sets C C 1 associated superblocks Assume B1 cid3 B1 result follows Corollary 3 For C B1 let consider set B C jC I j O j Then follows deﬁnition superblocks sets B C C B1 pairwise disjoint subsets 1 n Let deﬁne j J c G j f j X I j I J c j0G j0 f 0z0 J j J S j f j j J G j f j X I j I J j0G j0 f 0z0 h2 X I j j J coherent As consequence E From Lemma 5 previsions P j X O j C Deﬁne gambles h1 CB1 cid16 cid16 cid7 cid7 cid7 I J j0π 1 I j0 z0 h1x cid2 0 sup xE Consider cid10 0 let x1 E satisfy h1x1 cid2 cid10 Let consider I h1 XI measurable π 1 y1 included E I j I j J CB1 The coherence graph previsions P j X O j X I j j J c A1 belong superblock Moreover j J c I O j comments end Section 5 Hence apply Lemma 6 deduce cid7 B C y1 πI x1 Note gamble I cid5 sup xπ 1 h2x sup xπ 1 I y1 y1 Since h1 identically equal h1x1 cid2 cid10 π 1 j J c I G j f j X I j I J c j0G j0 f 0z0x cid2 0 y1 h2x cid2 cid10 y1 included E deduce supxE h1x h2x cid2 cid10 Since similar reasoning y1 h1x h2x cid2 cid10 supxπ 1 y1 supxπ 1 I I I π 1 cid10 0 deduce Eq A10 holds cid2 I Proof Theorem 3 We proceed way proof Theorem 2 The main difference instead Eq A10 need prove cid4 mcid5 j1 sup xX n cid6 G j f j X I j G j0 f 0z0 x cid2 0 A11 f j K j j 1 m j0 1 m f 0 K j0 z0 XI j0 Using notations previous proof B1 result follows Corollary 3 Assume B1 cid3 We deduce Lemma 5 previsions P j X O j X I j j J weakly coherent As consequence cid10 0 exists x1 X n h1x1 cid2 cid10 Let y1 πI x1 XI Now coherence graph previsions P j X O j X I j j J c A1 belong superblock apply Lemma 6 deduce sup xπ 1 I y1 h2x sup xπ 1 y1 j J c I cid5 G j f j X I j I J c j0G j0 f 0z0x cid2 0 h1 identically equal h1x1 cid2 cid10 π 1 I similar reasoning cid10 0 deduce Eq A11 holds cid2 y1 supxπ 1 y1 h1x h2x cid2 cid10 supxπ 1 I I y1 h2x cid2 cid10 Since Proof Theorem 4 The suﬃciency consequence Theorem 3 Let necessity cid12 Bcid12 Assume ex absurdo B ﬁner Bcid12 Then exists B B nonempty intersection It follows B set indices lower previsions superblock coherence graph B cardinality B 1 We shall identify subset B 1 m corresponding superblock coherence graph Then B union ﬁnite number different blocks B Z1 B Zk originated different sources contradiction We shall denote J set indexes lower previsions represented block B Z 1 k One following possibilities hold cid12 2 Bcid12 There exists 1 k J nonempty intersections different B 1 B cid12 B b Condition hold i1 cid3 i2 1 k J i1 2 different B cid12 1 J i2 B cid12 cid12 1 B cid12 2 Bcid12 In case possibilities block associated J points a1 a2 corresponds cycle points a3 a4 related node parent 138 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 We going prove cases collection separately coherent conditional linear previsions X I j jBcid12 weakly X Im weakly coherent B X I1 P m X O m P j X O j Bcid12 cid12 P 1 X O 1 coherent Assume J nonempty intersections different B Then following possibilities cid12 1 B cid12 2 Bcid12 cid12 1 cid3 B cid12 2 Consider ys hold a1 There exists actual node Xs B Z parents corresponding lower previsions different O i2 Fig 13 Formally holds i1 cid3 i2 J s O i1 elements Bcid12 cid12 cid12 i1 B cid3 ys 1 i2 B 2 B Deﬁne coherent particular weakly coherent conditional previsions P 1 X O 1 means Lemma 2 P i1 ys 1 herent P i1 X O i1 deﬁne coherent P X Im identically equal 1 joint P weakly ys ys 1 Apply Lemma 2 xs 2 cid12 ys constant gamble 1 2 i2 2 1 Deﬁne conditional previsions X Ii1 satisﬁes P ys X I1 P joint P weakly coherent P Q 1 X O 1 X Im P X Ii2 X I1 Q m X O m X I1 Pm X O m cid12 m X O m cid12 X O i2 i2 1 1 use xs satisﬁes P ys X Ii1 cid12 1 X O 1 2 Xs xs 2 xs 2 X Ii2 1 1 1 Q j X O j X I j cid8 X Im X I j X I j j B P j X O j cid12 j X O j P cid12 1 X I j jBcid12 These previsions separately coherent B weakly coherent Given coherent prevision P LX n P f P Q j f X I j f K j 2 j 1 m P ys 2 1 contradiction Using Theorem 1 deduce P Q i2 ys 2 Q 1 X O 1 1 P ys X Im weakly coherent X Ii2 X I1 Q m X O m 1 hand P ys 1 P ys previsions Q j X O j 1 P Q i1 ys X Ii1 1 cid12 Bcid12 a2 Assume node Xs block B Z parent previsions corresponding parents belong element Bcid12 Then actual node Xcid7 graph predecessor node Xs parent previsions constraining subblock Xcid7 block associated Xs belong element B arc pointing Xcid7 associated prevision belongs B Formally holds i1 p p1 J s O i1 cid3 I p O p Consider xcid7 1 joint P weakly coherent P j X O j cid12 1 X O 1 P Deﬁne Q 1 X O 1 O p1 i1 p B 2 Xcid7 Use Proposition 3 deﬁne weakly coherent P 1 X O 1 X Im 1 1 Apply Lemma 2 deﬁne coherent X Im joint P coherent P j1p satisﬁes P xcid7 See Fig 14 example X I1 Pm X O m O p1 cid3 xcid7 cid3 I p1 satisﬁes P xcid7 cid12 1 p1 B X I1 P cid3 cid7 I p O i2 I i2 X Im 1 Bcid12 1 Bcid12 cid12 m X O m X O p1 X Ii p1 2 1 O i3 X Ii j cid12 p1 cid3 B cid12 2 cid12 2 cid12 cid12 X I1 Q m X O m cid8 Q j X O j X I j P j X O j cid12 j X O j P j B X I j X I j cid12 1 X I j jBcid12 Then previsions separately coherent B weakly coherent Now given coherent prevision P LX n st P f P Q j f X I j f K j Q j X O j cid12 Bcid12 Fig 13 An example graphical situation considered point a1 In case X7 parents different sets Bcid12 create contradiction inducing different marginals different parent previsions We use dashed line denote parent previsions element Bcid12 element Fig 14 An example graphical situation considered point a2 In case create contradiction X1 Xcid7 inducing different marginals parent X3 constraining subblock connecting X1 X3 X8 Xs We use dashed line denote prevision having X1 conditional belong constraining subblock E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 139 Fig 15 An example graphical situation considered point a3 In case create contradiction parent X14 different element Bcid12 compared previous dummy node elementary cycle denoted dashed lines j 1 m P xcid7 conditional previsions Q 1 X O 1 X I1 Q m X O m 1 1 P xcid7 X Im weakly coherent 2 contradiction Using Theorem 1 deduce cid12 1 B a3 Both a1 a2 hold This means block B Z set indices J nonempty intersections cid12 2 generated actual node parent cycle Take different B elementary cycle cycle Assume ﬁrst dummy nodes elementary cycle belong element Bcid12 adjacent dummy nodes elementary cycle belong different elements Bcid12 Fig 15 example That assume existence different j1 j p J O j1 cid12 j1 B 2 Take cid7i I ji j0 j p Consider xi 1 1 yi Deﬁne yi cid8 Xi 1 n apply Lemma 2 deﬁne coherent P 1 X O 1 2 Xi 1 n cid8 cid71 xi 2 xi 1 cid3 O ji1 1 p simplicity notation cid71 xi 1 xi 2 This implies X I1 Pm X O m cid3 O j p cid12 1 j2 B cid3 O j2 X Im yi 1 cid3 xi 2 I j2 I j3 I j1 yi 2 Apply Lemma 2 values deﬁne coherent conditional previsions P deﬁne conditional previsions Q 1 X O 1 X I1 Q m X O m X Im cid12 1 X O 1 X I1 P cid12 m X O m X Im Q j X O j X I j j B X I j X I j cid12 1 cid8 P j X O j cid12 j X O j P X I j1 Let Q j1 X O j1 Then Theorem 1 coherent prevision P coherent Q j1 Q j p For 1 p cid12 weakly coherent assume exabsurdo Q j p X O j p cid13cid13 cid13cid13 cid12 cid12 cid13 cid13 cid12 cid12 cid12 X I j p P cid7i x 1 P cid7i x 2 P Q ji1 cid7i x 1 X I ji1 P Q ji1 cid7i x 2 X I ji1 1 cid7i P ji1 x 1 cid7i X I ji1 Q ji1 x 1 cid12cid2 X I ji1 cid7i Q ji1 x 2 P X I ji1 cid7i P ji1 x X I ji1 2 1 1 p Hence 2 p X I ji1 cid3cid13 cid3cid13 X I ji1 P cid7i x 1 cid7i x 2 cid12 ji1 cid12 ji1 cid12cid2 cid3 cid2 P z X n πcid7i1 z cid3 πcid7i z P P cid12 z πcid7i z cid12cid2 Q ji z πcid7i z cid7i cid7i 1 x x 2 cid2 cid7i cid7i 1 x x 2 πcid7i1 z cid3 πcid7i z cid3 cid3 πcid7i1 z cid3 πcid7i z cid13cid13 X I ji P 0 0 1 1 p notation cid7p1 cid71 Hence cid12 cid13 cid12 cid13 P 0 P cid7i1 cid7i 2 x x 1 cid7i cid7i 2 1 valid 1 p 1 P x cid7i1 cid7i 1 x x 2 2 p cid72 cid72 1 πcid7i z 1 P z πcid72 z x The equality P x cid7i cid7i cid7i cid7i cid7i cid72 x 1 πcid7i z x 1 p Take z πcid72 z x 1 p z cid3 x 1 x 1 x 1 i1p 2 2 cid7i1 cid7i Then 2 p πcid7i z x 1 πcid7i1 z x Eq A12 implies P z 0 We 2 cid7i cid7i cid72 cid72 1 P x 2 P x 1 i1p A completely similar argument shows P x deduce P x 2 i1p cid7i cid72 cid71 cid72 cid72 0 consequence P x 1 i1p 0 A completely 1 P x 1 P Q j1 x 1 x Now P x 1 cid7i cid72 cid72 2 i2p 0 But implies 1 2 P x 2 0 P x weakly coherent Q j p X O j p X I j1 a4 Assume dummy nodes elementary cycle chosen previous point belong cid12 2 Fig 16 cid12 1 predecessor Xcid7 dummy nodes belongs B similar argument shows P x P x cid72 cid72 2 0 contradiction Hence Q j1 X O j1 1 P x implies P x X I j1 cid71 2 x X I j p cid71 1 x A12 B example 140 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 Fig 16 An example graphical situation considered point a4 In case dummy nodes elementary cycle belong element Bcid12 dummy predecessor elementary cycle belongs different element denoted dashed line We create contradiction Xl X6 inducing marginal parent different marginal induced elementary cycle Fig 17 An example graphical situation considered point b In case create contradiction Xl X3 node shared adjacent blocks denoted dashed lines The contradiction obtained inducing marginal block different marginal block Ik3 I j3 I j2 cid3 O j2 Ik2 O k2 cid3 O j p cid3 I j1 j1 j p 1 m O j1 Consider different 1 m assume Xcid7 predecessor dummy node j1 Then k1 kr k1 kr1 1 m j1 j p cid7 O k1 cid3 kr j1 That dices k2 kr1 j1 j p determine constraining subblock Xcid7 block associated elementary cycle Assume j1 j p k2 kr1 B cid3 B tion 3 deﬁne weakly coherent conditional previsions P 1 X O 1 X I j j j1 j p k2 kr1 satisﬁes P xcid7 P j X O j cid12 cid12 m X O m 1 X O 1 herent conditional lower previsions P 2 1 Let consider Q 1 X O 1 P cid12 1 2 Xcid7 Then use Proposi X Im P coherent 1 1 Similarly use Lemma 2 deﬁne X Im joint P coherent X I1 Q m X O m cid12 1 Take xcid7 X I1 Pm X O m X Im deﬁned cid12 1 k1 B cid3 O kr1 satisﬁes P xcid7 X I1 P cid12 2 B j B X O k1 X Ik1 Ikr cid3 xcid7 cid12 k1 cid8 cid12 2 1 Q j X O j X I j P j X O j cid12 j X O j P X I j X I j follows B Bcid12 prevision P coherent satisfy P xcid7 X Im weakly coherent Hence Q 1 X O 1 previsions Q j X O j X I1 Q m X O m X I j jBcid12 weakly coherent However coherent 1 1 hand P xcid7 2 B B cid12 1 J i2 cid12 2 blocks B Z i1 b If hold 1 k set indices associated block B Z included B cid12 Bcid12 Since B nonempty intersection different elements Bcid12 deﬁnition B implies block B Z1 B block B Z2 B B Z1 B Z2 share actual node deduce 1 cid3 i1 cid3 i2 cid3 k B Z i2 share actual node Xcid7 start block B J i1 adjacent blocks arrive included element Bcid12 The result follows fact adjacent blocks share actual node See Fig 17 example Consider different values xcid7 1 Pm X O m satisﬁes P xcid7 The proposition guarantees existence weakly coherent conditional previsions P joint P weakly coherent P 2 1 Deﬁne conditional previsions Q 1 X O 1 X Im weakly coherent joint weakly coherent P j X O j 1 1 2 Xcid7 Then applying Proposition 3 conditional previsions P 1 X O 1 cid12 j X O j X I1 Q m X O m X I1 X I j j J i1 X I j j J i2 X Im X I1 P satisﬁes P xcid7 cid12 m X O m cid12 1 X O 1 cid3 xcid7 X Im cid8 Q j X O j X I j P j X O j cid12 j X O j P j B X I j X I j cid12 1 X I j jBcid12 weakly Then previsions separately coherent B coherent Now given coherent prevision P LX n coherent conditional previsions X Im P xcid7 2 contradiction Using Theorem 1 deduce Q 1 X O 1 weakly coherent cid2 Q j X O j X I1 Q m X O m 1 1 P xcid7 cid12 Bcid12 Proof Proposition 4 It trivial ﬁrst statement implies second That second statement implies follows Theorem 4 remark coherence graph type A1 minimal partition B 1 m Finally Corollary 3 guarantees statement implies ﬁrst cid2 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 141 Proof Theorem 5 For 1 m separate coherence conditional lower prevision P X O implies lower envelope family separately coherent conditional previsions Mi P X O Now plate P 1 X O 1 P 1 X O 1 X Ii X Ii 1 m belong collection tem X Im Proposition 4 implies jointly coherent X Im lower envelope family coherent conditional previsions cid2 select conditional prevision Mi X I1 P m X O m X I1 P m X O m Proof Theorem 6 We start deﬁning bound number arcs coherence graph Remember coherence graph regarded union Dstructures Since Dstructure n arcs deduce number arcs coherence graph bounded m n It useful consider number different blocks coherence graph block identiﬁed sources contradiction originates source contradiction actual node number different blocks bounded number actual nodes n Now consider effect interplay findMinPartition findBlock visit entire graph This means arcs traversed visit worstcase complexity O m n given previous bound number arcs This complexity takes account fact findBlock stops visit certain node tagged preventing arc visited To ﬁnd overall complexity procedures consider second effect jointly produced findMinPartition findBlock mergeBlocks ﬁll array minPartition This array scanned time new different block Since size array m number different blocks bounded n said ﬁlling array minPartition worstcase complexity O m n Overall deduce findMinPartition findBlock mergeBlocks joint worstcase complexity given O m n considering remaining calculations complexity dominated expression Finally order deﬁne complexity ﬁnd minimal partition consider procedures based global data structures described beginning Section 7 Therefore calculate complexity create structures In case computation dominates respect computational complexity identiﬁcation sources contradiction Identifying actual nodes parent easy takes O n Finding nodes belong cycle graph complicated Yet stated end Section 7 immediate byproduct identiﬁcation strong components graph task Tarjans algorithm 29 solves time O m n m n This complexity dominates arising findMinPartition findBlock mergeBlocks obtain complexity ﬁnd minimal partition O m n m n cid2 Proof Theorem 8 We ﬁrst consider convert graph credal net related coherence graph suﬃcient node X j credal net insert dummy node D j X j parents X I j D j parent X j child X I j remove arcs X I j X j It immediate conversion procedure coherence graph resulting credal net A1 coherence graph acyclic graph credal net actual node X j exactly parent Another immediate consequence procedure permuting indexes conditional lower previsions coherence graph Lemma 1 simply making consistent partial order entailed graph credal net Therefore assume loss generality set A j deﬁned Section 811 Lemma 1 indexes exactly nondescendant nonparents X j j 1 n Now ready strong extension credal network strong product related coherence graph coincide Consider prevision P dominating strong extension obtained deﬁnition strong product applying X A j I j synthetic ex cid12 Eq 8 collection P 1 X O 1 pression set separately coherent conditional previsions P j X O j P j X O j X AnIn Here generic element P j X O j cid12cid12 For x X n holds z z X A j I j P j X O j X A1I1 Pn X O n z extMP cid12 j X O j z z cid12cid12 πI j z ncid14 cid12 πI j z cid13 cid12 πO j xπ A j I j x P j P x j1 cid13 cid12 π jxπI j x P j ncid14 j1 A13 ﬁrst passage Eq 8 second depends considerations The ﬁrst O j indexes variable X j deal coherence graph obtained Bayesian net The second important X j depend stochastically nondescendant nonparents X A j given parents X I j This follows know chosen element MP z values X A j deﬁnition z extreme point P j X O j MP j X O j cid12 j X O j πI j z depends X I j X A j I j deﬁnition P X A j I j extreme point MP cid12 j X O j cid12 j X O j It follows Eqs 9 A13 coincide selected element P dominating strong product corre sponds joint mass function Bayesian net obtained choosing assessments P j X j X I j cid2 P j X j X I j j 1 n 142 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 compatible Bayesian net Therefore P linear prevision dominates strong extension Since holds previsions P deﬁnition strong product strong product dominates strong extension Now consider extreme point strong extension equivalently joint linear prevision P It known 1 Proposition 1 proof P obtained applying Eq 9 mass functions corresponding ex equivalently collection P 1 X1 X I1 Pn Xn X In treme points local conditional credal sets P j X jz extMP j X jz z XI j j 1 n From deﬁning new collection conditional previsions X AnIn deﬁnition strong product applying Eq A13 P 1 X O 1 element strong product coincides P Since holds extreme points strong extension strong extension dominates strong product cid2 X A1I1 Pn X O n m X I1 P m X O m X Im avoid Proof Proposition 5 We start proving direct implication Assume P 1 X O 1 uniform sure loss Given f j K j j 1 m implies supxX n j1 G j f j X I j x cid2 0 Let deﬁne D G j f j X I j f j K j j Applying 33 Lemma 332 deduce existence linear prevision P satisfying P G j f j X I j cid2 0 f j K j j 1 m particular P G j f jx cid2 0 f j K j x XI j j 1 m Let prove existence j 1 m x X j linear conditional prevision P j X O j x dominating x P Ix f P j f x 0 f K j taking account spaces ﬁnite shall X I j coherent P X Im dominating conditional lower P j X O j deduce existence conditional linear prevision P j X O j j 1 m consequence weakly coherent P 1 X O 1 previsions X I j dominates P j X O j X I1 Pm X O m cid16 x uniquely determined P Bayes rule To dominates P j X O j Consider j 1 m x XI j There possibilities P x 0 conditional linear previ x assume exabsurdo P j f x P j f x Then follows 0 cid3 P Ix f P j f x x sion P j X O j existence gamble f K j P Ix f P j f x 0 contradiction Finally P x 0 simply consider linear conditional prevision P j X O j dominates P j X O j x automatically coherent P The converse implication follows realise weakly coherent conditional previsions particular avoid uniform sure loss ii conditional lower previsions dominated avoid uniform sure loss avoid uniform sure loss cid2 The lemma needed proof Theorem 9 It counterpart avoiding partial uniform sure loss Lemma 5 Lemma 7 Let consider nonempty subset J 1 m Let B1 partition J deﬁne C B1 set B C cid7 jC I j O j Then sets B C C B1 pairwise disjoint following statements hold X I j jC avoid partial loss C B1 lower previsions P j X O j X I j jC avoid uniform sure loss C B1 lower previsions P j X O j X I j j J avoid partial loss X I j j J avoid uniform sure loss 1 If P j X O j 2 If P j X O j Proof 1 Consider f j K j j J f 0 K j0 z0 XI j0 j0 J Assume I j cid3 j f j cid3 0 result follows second statement reduction theorem 33 Theorem 715 For C B1 D C jC S j f j cid7 cid5 jC sup xD C G j f j X I j x cid2 0 given cid10 0 xC D C cid5 jC G j f j X I j xC cid2 cid10 A14 Let consider element z X n satisfying πB C z πB C xC C B1 element exists sets B C C B1 pairwise disjoint Then deduce Eq A14 cid17cid5 cid18 G j f j X I j z cid2 B1cid10 j J z D C C B1 particular Since cid10 0 deduce X I j j J avoid partial loss conditional lower previsions P j X O j 2 Using similar reasoning notations previous point deduce cid10 0 C B1 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 143 xC G j f j X I j xC cid2 cid10 cid5 jC Now sets B C C B1 pairwise disjoint deduce equation element z X n πB C z πB C xC C B1 cid17cid5 cid18 G j f j X I j z cid2 B1cid10 j J Again cid10 0 deduce conditional lower previsions P j X O j uniform sure loss cid2 X I j j J avoid Proof Theorem 9 We shall prove result avoiding partial loss proof avoiding uniform sure loss analogous Let consider gambles f j K j j 1 m let G j f j X O j x cid2 0 A15 cid6 cid4 mcid5 j1 cid7 sup xE E m j1 S j f j Let B1 subset B given sets C C 1 associated superblocks Assume B1 cid3 B1 result follows Corollary 3 For C B1 let consider set B C jC I j O j Then follows deﬁnition superblocks sets B C C B1 pairwise disjoint subsets 1 n Let deﬁne J C Deﬁne gambles h1 j J G j f j X I j h2 j J c G j f j X I j X I j j J avoid partial loss As consequence exists E From Lemma 7 previsions P j X O j j J S j f j CB1 cid16 cid16 cid7 cid7 cid7 h1x cid2 0 sup xE cid7 B C y1 πI x1 Note gamble Consider cid10 0 let x1 E satisfy h1x1 cid2 cid10 Let consider I h1 XI measurable π 1 y1 included E I j I j J CB1 I The coherence graph previsions P j X O j X I j j J c A1 belong superblock Moreover j J c I O j comments end Section 5 Hence apply Lemma 6 deduce sup xπ 1 h2x sup xπ 1 I y1 y1 Since h1 identically equal h1x1 cid2 cid10 π 1 j J c I cid5 G j f j X I j x cid2 0 y1 h2x cid2 cid10 y1 included E deduce supxE h1x h2x cid2 cid10 Since similar reasoning y1 h1x h2x cid2 cid10 supxπ 1 y1 supxπ 1 I I I π 1 cid10 0 deduce Eq A15 holds cid2 I References 1 A Antonucci M Zaffalon Decisiontheoretic speciﬁcation credal networks A uniﬁed language uncertain modeling sets Bayesian net works International Journal Approximate Reasoning 49 2 2008 345361 2 B Arnold E Castillo JM Sarabia Conditional Speciﬁcation Statistical Models Springer 1999 3 M Baioletti A Capotorti S Tulipani B Vantaggi Elimination Boolean variables probabilistic coherence Soft Computing 4 2000 8188 4 KPS Bhaskara Rao M Bhaskara Rao Theory Charges Academic Press London 1983 5 V Biazzo A Gilio T Lukasiewicz G Sanﬁlippo Probabilistic logic coherence Complexity algorithms Annals Mathematics Artiﬁcial Intelligence 45 12 2005 3581 6 G Boole An Investigation Laws Thought Which Founded Mathematical Theories Logic Probabilities Walton Maberley London 1854 Reprinted Dover New York 1961 7 A Capotorti B Vantaggi Locally strong coherence inference processes Annals Mathematics Artiﬁcial Intelligence 35 14 2002 125149 8 FG Cozman Separation properties sets probabilities C Boutilier M Goldszmidt Eds Uncertainty Artiﬁcial Intelligence Proceedings Sixteenth Conference Morgan Kaufmann San Francisco 2000 pp 107115 9 C Cuadras J Fortiana JA RodriguezLallena Distributions Given Marginals Statistical Modelling Kluwer Academic Publishers 2002 10 B Finetti Sul signiﬁcato soggettivo della probabilità Fundamenta Mathematicae 17 1931 298329 11 B Finetti La prévision ses lois logiques ses sources subjectives Annales lInstitut Henri Poincaré 7 1937 168 English translation 18 12 B Finetti Teoria delle Probabilità Einaudi Turin 1970 13 B Finetti Theory Probability vol 1 John Wiley Sons Chichester 1974 English translation 12 14 M Fréchet Sur les tableaux correlation dont les marges sont donns Ann Univ Lyon Section A Series 3 14 1951 5377 15 P Hansen B Jaumard M Poggi Aragão F Chauny S Perron Probabilistic satisﬁability imprecise probabilities International Journal Approx imate Reasoning 24 23 2000 171189 144 E Miranda M Zaffalon Artiﬁcial Intelligence 173 2009 104144 16 W Hoeffding Masstabinvariante korrelationtheorie Schriften des Mathematischen Instituts und des Institud für Angewndte Mathematik der Universität Berlin 5 1940 181233 17 B Jaumard H Hansen M Poggi Aragão Column generation methods probabilistic logic ORSA Journal Computing 3 1991 135148 18 HE Kyburg Jr HE Smokler Eds Studies Subjective Probability Wiley New York 1964 Second edition new material 1980 19 T Lukasiewicz Probabilistic deduction conditional constraints basic events Journal Artiﬁcial Intelligence Research 10 1999 199241 20 F Mauch On existence probability distributions given marginals Theory Probability Applications 48 3 2004 541548 21 E Miranda Updating coherent previsions ﬁnite spaces Technical Report TR 0804 Rey Juan Carlos University Technical Reports Statistics Decision Sciences 2008 22 E Miranda G Cooman Coherence independence nonlinear spaces Technical Report TR 0510 Rey Juan Carlos University Technical Reports Statistics Decision Sciences 2005 23 E Miranda G Cooman Marginal extension theory coherent lower previsions International Journal Approximate Reasoning 46 1 2007 188225 24 S Moral A Cano Strong conditional independence credal sets Annals Mathematics Artiﬁcial Intelligence 35 14 2002 295321 25 R Nelsen An Introduction Copulas Springer New York 1999 26 NJ Nilsson Probabilistic logic Artiﬁcial Intelligence 28 1986 7187 27 J Pearl Probabilistic Reasoning Intelligent Systems Networks Plausible Inference Morgan Kaufmann San Mateo CA 1988 28 A Sklar Fonctions répartition à ndimensions et leurs marges Publications lInstitute Statistique lUniversité Paris 8 1959 229231 29 RE Tarjan Depthﬁrst search linear graph algorithms SIAM Journal Computing 1 1972 146160 30 MCM Troffaes G Cooman Extension coherent lower previsions unbounded random variables Intelligent Systems Information Pro cessing For Information Applications North Holland Amsterdam 2003 pp 277288 31 LC van der Gaag Computing probability intervals independency constraints PP Bonissone M Henrion LN Kanal JF Lemmer Eds UAI 90 Proceedings Sixth Annual Conference Uncertainty Artiﬁcial Intelligence Elsevier 1991 pp 457466 32 NN Vorobev Consistent families measures extensions Theory Probability Applications VII 2 1962 147163 33 P Walley Statistical Reasoning Imprecise Probabilities Chapman Hall London 1991 34 P Walley R Pelessoni P Vicig Direct algorithms checking consistency making inferences conditional probability assessments Journal Statistical Planning Inference 126 2004 119151 35 PM Williams Notes conditional previsions Technical report School Mathematical Physical Science University Sussex UK 1975 Reprinted 36 36 PM Williams Notes conditional previsions International Journal Approximate Reasoning 44 3 2007 366383 37 M Zaffalon E Miranda Conservative inference rule uncertain reasoning incompleteness 2008 submitted publication