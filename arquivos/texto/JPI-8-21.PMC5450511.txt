Research Article Training Nuclei Detection Algorithms Simple Annotations 1Fraunhofer Institute Medical Image Computing MEVIS 28359 Bremen Germany 2Department Applied Information Technology Chalmers University Technology 41258 Gothenburg 3Sectra AB 58330 Linköping Sweden 4Center Medical Image Science Visualization Linköping University 58183 Linköping Sweden Henning Kost1 André Homeyer1 Jesper Molin234 Claes Lundström34 Horst Karl Hahn1 Received 10 January 2017 Accepted 17 March 2017 Published 15 May 2017 Abstract Background Generating good training datasets essential machine learningbased nuclei detection methods However creating exhaustive nuclei contour annotations derive optimal training data infeasible Methods We compared different approaches training nuclei detection methods solely based nucleus center markers Such markers contain accurate information especially regard nuclear boundaries produced easier greater quantities The approaches use different automated sample extraction methods derive image positions class labels nucleus center markers In addition approaches use different automated sample selection methods improve detection quality classification algorithm reduce run time training process We evaluated approaches based previously published generic nuclei detection algorithm set Ki67stained breast cancer images Results A Voronoi tessellationbased sample extraction method produced best performing training sets However subsampling extracted training samples crucial Even simple class balancing improved detection quality considerably The incorporation active learning led increase detection quality Conclusions With appropriate sample extraction selection methods nuclei detection algorithms trained basis simple center marker annotations produce comparable quality algorithms trained conventionally created training sets Keywords Active learning machine learning nuclei detection training set generation IntroductIon Many pathological assessments depend quantification cell nuclei In cancer diagnosis instance quantification nuclei expressing Ki67 protein widely method determine proliferation rate tumor Furthermore quantification lymphocytic infiltrates shown strong prognostic importance1 Another important application determination progesterone estrogen receptor status The arguably important predictive biomarker exists today2 In clinical routine evaluations usually manually estimating counting small number nuclei highly subjective reproducible3 Consequently ability automatically detect different types nuclei larger regions increasingly important Varying staining tissue preprocessing conditions different nuclear types pathologies lead huge variability appearance nuclei making automatic detection challenging Recent approaches employ Quick Response Code Access article online Website wwwjpathinformaticsorg DOI 104103jpijpi_3_17 trainable algorithms address issue including traditional machine learning46 deep learning methods79 Trainable detection methods come advantage adaptable refinable different training datasets Generating good training dataset essential methods Most methods learn kind pixelwise distinction nuclear nonnuclear regions469 create intermediate segmentation probability map Hence optimal training data consist exhaustive manual segmentations nuclei histological images Unfortunately creating annotations requires expert accurately draw contour lines nucleus making tedious timeconsuming task Address correspondence Mr Henning Kost Fraunhofer Institute Medical Image Computing MEVIS Am Fallturm 1 28359 Bremen Germany Email henningkostmevisfraunhoferde This open access article distributed terms Creative Commons AttributionNonCommercialShareAlike 30 License allows remix tweak build work noncommercially long author credited new creations licensed identical terms For reprints contact reprintsmedknowcom How cite article Kost H Homeyer A Molin J Lundström C Hahn HK Training nuclei detection algorithms simple annotations J Pathol Inform 2017821 Available FREE open access httpwwwjpathinformaticsorgtext asp20178121206227 2017 Journal Pathology Informatics Published Wolters Kluwer Medknow 1 Annotation marks nuclear centers constitute alternative kind reference data Center annotations created effort require expert mark nuclei single click This makes marking process faster allows larger amounts images annotated Obviously annotations comprise information segmentations Center marker annotations employed past The different approaches address insufficiency augmenting ways An iterative thresholding approach GulMohammed et al10 distinguish nuclear nonnuclear areas center markers In study Janowczyk Madabhushi9 distinction performed naive Bayesian classifier center positions nuclear training data randomly selected noncenter positions nonnuclear training data However approaches tie capability machinelearning algorithm capability previous step In studies Sirinukunwattana et al11 Xu et al8 assumption size nuclei incorporated supplement annotation data In study Sirinukunwattana et al11 regression trained distance center marker compute target value In study Xu et al8 nonnuclear training samples drawn positions away center marker given threshold content feature vector depends classification method trained It comprise handcrafted features case feature learning methods deep convolutional neural networks small image patches In cases training sample produced respect given position image All examined training set generation approaches consist main steps extraction selection training samples Given set training images labeled center markers extraction step needs identify image positions labeled nuclear nonnuclear regions derive training sample The main difficulty center markers obviously provide far information nuclear nonnuclear regions image especially regard boundaries The output extraction step forms valid training set However abundance training samples deteriorates analysis quality runtime performance training process classifier Depending type classifier runtime nuclei detection increased considerably Thus second step considered training set generation approaches selection optimal subsets training samples The quality mentioned approaches hard compare authors usually use different data sets different nuclear types different quality measures Training sample extraction We compare different methods extracting training samples given set images In study Vink et al4 nucleus detection method Her2stained breast tissue proposed The authors report detection rate equals recall 095 Breast tissue nuclei detected studies conducted Xing et al7 Xu et al8 The approaches work HEstained images yield f1measures 078 084 respectively In study conducted Arteta et al5 Janowczyk Madabhushi9 lymphocytic nuclei detected HEstained breast images They state f1measures 088 090 respectively Kårsnäs et al6 reported detection method Ki67positive nuclei breast tissue proposed The authors announce 10 missing objects 26 missing annotations 41 multiple annotations A nuclei detection method HEstained colorectal tissue described Sirinukunwattana et al11 f1measure 080 reported In paper perform systematic comparison different methods generating training sets solely center marker annotations In addition evaluate proposed center markerbased sample extraction methods compare manual segmentations Methods Training set generation A training set consists set training samples turn consist feature vector class label The Distancebased We assume positions close annotated center markers considered represent nuclear regions positions far away center marker likely represent nonnuclear regions Training samples extracted follows For position x y image compute distance closest center marker That distance index closest marker stored maps dx y mx y To designated nuclear region position away closest marker threshold called tnuc Thus positions x y dx y tnuc labeled nuclear region To designated nonnuclear region position closer marker threshold called tbg Consequently positions x y dx y tbg labeled nonnuclear region For experiments set tbg 15 pixels tnuc 3 pixels 20 resolution Voronoibased The distancebased approach drawback boundary positions nuclei considered Boundary positions informative shape decision boundaries classifier In case nuclear boundaries labeled nonnuclear region clustered nuclei separated classifier The Voronoibased extraction method augments distancebased method boundary samples 2 Journal Pathology Informatics J Pathol Inform 2017 121 httpwwwjpathinformaticsorgcontent8121 The marker map mx y equivalent Voronoi diagram center markers Assuming neighboring nuclei similarly sized Voronoi boundary nontouching nuclei crosses nonnuclear regions As soon nuclei touching Voronoi boundary crosses exactly touching point Consequently overlapping nuclei region overlap crossed Voronoi boundary The assumption valid leading Voronoi boundaries crossing nuclear regions rare case experiments Thus Voronoi boundaries suited extract nonnuclear samples Figure 1 illustrates sample extraction methods Training sample selection Selecting subset training samples extracted previous step beneficial Reducing samples leads decrease runtime training process For classifiers random forest runtime classification reduced Moreover subsets training samples result higher quality nuclei detection samples class imbalance The extraction methods generally produce samples nonnuclear regions nuclear regions relative area fractions image A small tnuc increases imbalance A classifier confronted substantial class imbalance deluged instances majority class leading ignore instances minority class Such imbalance wellknown issue field machine learning12 During training machinelearning classifier interesting regions feature space close decision boundary classifier Here classifier uncertain That samples near decision boundary informative samples far away The ratio samples high low informativeness training set strong influence resulting detection quality The samples extracted previous step addition class imbalance stated likely contain large uninformative instances Figure 1 Visualization sample extraction methods The left image shows original image overlayed center marker annotations The center image shows positions nonnuclear samples extracted gray nuclear samples extracted red blue positively negatively stained nuclei respectively The right image additionally shows Voronoi boundaries black nonnuclear samples extracted Voronoibased extraction method We investigated different sample selection methods addressing described issues Stratified random subsampling The straightforward way reduce samples achieve balance class labels stratified random subsampling From class samples randomly drawn target number reached samples class available This method advantage integrated sample extraction methods The subsampling applied image positions features calculated This leads better runtime performance subsampling samples separate step afterward Kdtree subsampling In study Pechenizkiy et al13 Kdtree subsampling suggested alternative supplementary method stratified random subsampling It reduces number samples retaining distribution feature space The general concept Kdtree explained Bentley14 For sample selection task Kdtree limited depth constructed extracted samples features dimensions In node splitting feature chosen maximum variance samples node median pivot suggested Omohundro15 Then single sample drawn randomly leaf tree The granularity resulting samples controlled adjusting depth limit tree To address class imbalance apply Kdtree subsampling independently classes join sample sets afterward Active learning Active learning16 selects samples respect informativeness classifier A classifier trained subset S available samples Then iteratively remainder samples classified classification confidence sample considered The samples confident classifications added S iteration The iterations terminated soon size S reaches target number By following uncertainty sampling approach informative samples chosen training set In implementation produce training set n samples subset generated randomly choosing n10 samples available samples n100 samples added iteration In contrast previous methods active learning address class imbalance sample set The training sample selection methods applied samples extracted single image set extracted samples They combined utilize different strengths Experimental setup The different sample extraction selection methods compared image data study described Molin et al17 In study pathologists asked select Journal Pathology Informatics 3 J Pathol Inform 2017 121 httpwwwjpathinformaticsorgcontent8121 circular hotspot regions containing approximately 200 nuclei digitized Ki67stained breast tumor slides From hotspots areas containing staining scanning errors overlapping areas removed resulting set 101 hotspots 24 different slides cases The digitized slides downsampled necessary magnification 20 hotspot subimage containing region extracted Center marker annotations nuclei circular hotspot regions created trained expert verified experienced breast pathologist Figure 2 examplary shows annotated hotspot regions The evaluation based nuclei detection method described Kost et al18 A random forest assigns probability value input image pixel close center nucleus The feature set comprises The normalized H S V color channels The box filtered S channel An approximation difference Gaussian S channel box filters The radial symmetry S channel The box filtered radial symmetry Then optimized gray scale watershed algorithm separate individual nuclear regions The algorithm configured include positions probability values 05 nuclear regions lower values indicate likely position belongs background nucleus Another random forest uses H S V color channels classify staining nuclear regions performs majority vote decide nucleus Ki67 positive negative To train second classifier modified versions sample extraction methods For position x y dx y tnuc additional training sample second classifier generated The class label training sample set depending m x y corresponds center marker Ki67 positive negative nucleus This way training set produced classifier The selection methods applied sets individually parameters The quality nuclei detection assessed comparing results center marker annotations Each detected Figure 2 Visualization center marker annotations different images The circle scaled contain approximately 200 nuclei Inside circle nuclei annotated nucleus assigned closest center marker provided distance positions sufficiently close A threshold 10 pixels adequate It corresponds approximate radius nuclei images A onetoone match considered true positive TP detected nucleus matching annotation considered false positive FP annotation matching detected nucleus considered false negative FN In case multiple detected nuclei matched center marker considered TP counted FP Based values precision recall f1measure computed overall quality measures For experiments combined sample extraction selection methods ways produce different training sets The nuclei detection algorithm trained sample sets quality detection assessed To produce robust results experiments performed 5fold crossvalidation The folds created way images originating slide assigned fold This way training set tested slide created For experiments folds ensure comparability The quality measures individual folds averaged obtain final measures results Experiment 1 Comparison sample extraction selection combinations For following experiment setups distinct sample sets extracted distancebased Voronoibased method Then different combinations sample selection methods applied sample sets To obtain comparable results experiments 1a incorporates selection method produce training set containing 2000 samples This produce adequate results keeping processing time classifier acceptable level For experiments involving selection methods applied input image leaving 256 samples image The applied total remaining samples No selection As base experiment outputs extraction methods directly train nuclei detection algorithm b Random The extracted samples subjected stratified random subsampling selection method c Kdtree The extracted samples subjected Kdtree subsampling selection method d AL The extracted samples subjected active learning selection method e Random AL The random subsampling selection method applied image The final training set selected remaining samples active learning selection method f Kdtree AL The Kdtree subsampling selection method applied image The final training set 4 Journal Pathology Informatics J Pathol Inform 2017 121 httpwwwjpathinformaticsorgcontent8121 selected remaining samples active learning selection method best results obtained combinations include class balancing active learning g AL random The effect inverting order experiment e examined The active learning selection method applied image followed stratified random subsampling selection method h AL Kdtree The effect inverting order experiment f examined The active learning selection method applied image followed Kdtree subsampling selection method Kdtree random In experiment class balancing methods combined The Kdtree subsampling selection method applied image stratified random subsampling selection method applied remaining samples afterward j AL AL In experiment active learning selection method applied perimage remaining samples Table 1 shows results described experiment setups First state Voronoibased extraction method yields quality measures slightly superior distancebased method experiment setups Looking selection methods experiments comprise class balancing method lead far worse quality measures This observed experiments 1d 1j consist active learning especially experiment 1a selection performed The The tested sample extraction methods produce highly imbalanced training sets On average 609 554 samples belong nuclear class distancebased Voronoibased extraction respectively The imbalance affects resulting classification negative way This observed experiment 1a The detection quality unprocessed training sets low The usage active learning shown experiments 1d 1j improve detection quality slightly yields results inferior experiments This indicates active learning suited deal large imbalances stems way active learning selects new samples When nonnuclear samples choose uncertain samples likely imbalanced nonnuclear samples For reason proper balancing samples advisable The absence class balancing experiments 1a 1d 1j results strong bias classifier observed considerable difference precision recall values In experiment 2 precisionrecallcurves PRcurves analyzed examine issue The stratified random subsampling Kdtreebased selection equally suited balancing Table 1 Quality measures proposed sample extraction methods combined different sample selection methods Ki67positive nuclei Ki67negative nuclei All nuclei TP FP FN TP FP FN TP FP FN Precision Recall f1measure Distancebased 6508 No selection 7168 b Random 7216 c Kdtree 6886 d AL 7328 e Random AL 7326 f Kdtree AL 7062 g AL random h AL Kdtree 7158 Kdtree random 7182 j AL AL 6834 Voronoibased 740 1568 1740 662 1612 1512 1186 1074 1922 766 1898 1238 1190 1520 1078 1080 1344 1248 1224 1572 8036 22206 22030 16580 22904 22466 21768 22028 21886 19642 2392 5006 5094 2320 5562 5350 4514 4604 5166 3694 20240 6070 6246 11696 5372 5810 6508 6248 6390 8634 6118 No selection 7460 b Random 7504 c Kdtree 6288 d AL 7618 e Random AL 7632 f Kdtree AL 7288 g AL random h AL Kdtree 7268 Kdtree random 7446 6948 j AL AL 666 2064 1926 508 1926 1880 1194 1204 1766 914 TP True positive FP False positive FN False negative AL Active learning 5850 23336 22942 15350 23648 23642 22106 21958 23148 17344 2288 946 902 2118 788 774 1118 1138 960 1458 1514 5584 5064 2080 5618 5760 4586 4440 5414 2882 22426 4940 5334 12926 4628 4634 6170 6318 5128 10932 14544 29374 29246 23466 30232 29792 28830 29186 29068 26476 11968 30796 30446 21638 31266 31274 29394 29226 30594 24292 3132 6574 6834 2982 7174 6862 5700 5678 7088 4460 2180 7648 6990 2588 7544 7640 5780 5644 7180 3796 22138 7308 7436 13216 6450 6890 7852 7496 7614 10206 24714 5886 6236 15044 5416 5408 7288 7456 6088 12390 0823 0817 0811 0887 0808 0813 0835 0837 0804 0856 0846 0801 0813 0893 0806 0804 0836 0838 0810 0865 0396 0801 0797 0640 0824 0812 0786 0796 0792 0722 0326 0840 0830 0590 0852 0853 0801 0797 0834 0662 0530 0806 0801 0740 0814 0810 0807 0813 0795 0781 0467 0817 0819 0711 0826 0825 0815 0814 0819 0747 Journal Pathology Informatics 5 J Pathol Inform 2017 121 httpwwwjpathinformaticsorgcontent8121 comparison quality measures experiments 1b 1c 1e 1f 1g 1h indicates However stratified random subsampling simpler improves runtime performance integrated extraction step preferred Kdtreebased approach The best results achieved experiment setup 1e combination Voronoibased extraction stratified random subsampling active learning Two example outputs visualized Figure 3 Another interesting approach 1b solely applied stratified random subsampling It simple yields good results good runtime performance integrability sample extraction step However general differences methods use balancing small In contrast differences methods balancing major Experiment 2 Precisionrecallcurves As described section 22 cutoff value 05 experiments natural threshold twoclass problem However interesting investigate different cutoff values influence precision recall For approach described experiment 1 cutoff value altered 16 steps 0 1 step precision recall determined Figure 4 shows PRcurves approaches overview graph In subsequent graphs curves reduced grouped highlight different aspects Furthermore axes scaled interesting quadrant graph In Figure 5 PRcurves divided approaches contain sample selection method approaches case 1a curves It clearly visible application basic sample selection methods improves quality nuclei detection considerably This case sample extraction methods Figure 6 shows approaches contain sample selection grouped according sample extraction methods Here apparent Voronoibased extraction leads better results distancebased extraction This especially case recall In Figure 7 approaches Voronoibased sample extraction plotted We approaches consisting subsequent sample selection methods incorporating active learning perform especially These approaches highlighted figure Active learning image followed selection performs class balancing 1g 1h leads best results extraction methods The PRcurves shown section unusual shape Normally cutoff values lower precision declines recall grows 1 In case recall increase certain value decreases The reason behavior watershed algorithm nuclei detection method This limits number detected nuclei With low cutoff value pixel positions Figure 3 Example results experiment 1e The red blue markers Ki67 positive negative nuclei detected algorithm respectively Figure 4 Overview plot precisionrecallcurves training approaches distancebased dist Voronoibased voro sample extraction The labels 1a1j correspond notation experiment 1 Figure 5 Precisionrecallcurves showing quality improvements sample selection method blue compared approaches sample extraction gray considered algorithm Nevertheless likely assigned existing nuclear region instead constituting new region Another effect nuclear 6 Journal Pathology Informatics J Pathol Inform 2017 121 httpwwwjpathinformaticsorgcontent8121 regions segmented watershed algorithm larger The nuclear positions computed center points nuclear regions positivity nuclei derived staining classification results nuclear regions When regions unreasonably large nuclear positions positivity incorrect This effect causes decrease recall low cutoff values Experiment 3 Impact training set size The impact training set size quality nuclei detection evaluated experiment 3 Training sets different sizes produced Voronoibased extraction method followed selection method described 1b 1e appeared interesting approaches experiment 1 For approach active learning parametrized select 10 samples selected stratified random subsampling comparable ratio experiments The overall f1measure training sets assessed compare learning curves methods Training set sizes 100 5000 samples evaluated offset 100 15000 samples offset 1000 Figure 8 shows results experiment 3 Both learning curves approximately asymptotic shape They rise steeply 2000 samples ascend slowly afterward Nevertheless learning curve approach containing active learning shows superior quality values training set sizes The experiment shows number 2000 samples training set reasonable choice Although samples slightly increase quality nuclei detection consider good compromise quality runtime performance Experiment 4 Comparison extraction methods manual segmentations To assess quality sample extraction methods compared manual nuclei segmentation proposed distance Voronoibased extraction methods To produce training set segmentation annotations nonnuclear samples generated positions outside nuclear regions Since trained method yield maximum nucleus probability center nuclei nuclear samples generated centers nuclei equally extraction methods proposed As selection method stratified random subsampling image followed active learning 1e appeared achieve best results experiment 1 We images exhaustive nuclei segmentation annotations belong image set experiment 13 Samples extracted annotations pixel To compare samples described extraction methods segmentation annotations reduced center markers computing center gravity segment For experiment perform crossvalidation tested resulting training sets image set described The Figure 6 In cases approaches Voronoibased sample extraction blue lead better detection quality distancebased sample extraction gray Figure 7 Most approaches combine multiple selection methods contain active learning blue yield better quality measures gray shown approaches Voronoibased sample extraction Figure 8 In experiment 3 training sets different sizes produced approaches described experiment 1b 1e The graph plots f1measures nuclei detection trained sets size Journal Pathology Informatics 7 J Pathol Inform 2017 121 httpwwwjpathinformaticsorgcontent8121 experiment repeated times average randomness algorithms Table 2 shows results experiment 4 It appears manual extraction yields marginally better results approaches based center markers Since quality segmentationbased samples certainly better proposed methods low difference methods unexpected However produced training sets subject selection process quality differences manifest noticeable final results conclusIons The quality machine learningbased nuclei detection methods fundamentally dependent training data Ideally training data generated manual segmentations large number nuclei timeconsuming tedious task In paper proposed compared approaches produce training sets easy generate center marker annotations We divided training set generation sample extraction sample selection step The samples extracted distancebased Voronoi boundarybased method Training sets selected resulting sample sets different combinations stratified random subsampling Kdtree subsampling active learning For evaluation trained nuclei detection method training sets assessed resulting detection quality measures In addition investigated influence cutoff value measures For cutoff value 05 default threshold twoclass problems class balancing largest positive impact detection quality Independent cutoff value best results obtained training sets produced Voronoibased sample extraction sample selection methods incorporate active learning We evaluated influence training set size detection quality The quality increased quickly approximately 2000 samples moderate afterward In fourth evaluation comparison revealed f1measures obtained proposed extraction methods reached values obtained samples generated manual segmentations We conclude usage center marker annotations conjunction appropriate sample extraction selection Table 2 Quality measures obtained different extraction methods Extraction Precision Recall F1measure Distancebased Voronoibased Manual segmentation 0791 0783 0787 0818 0831 0829 0804 0806 0807 methods represents valid alternative conventionally produced training sets In manner effort creation annotations greatly reduced In addition machine learningbased nuclei detection methods usually trained training samples available study shows subselecting samples improve detection quality considerably additional cost terms execution time complexity nuclei detection method In future work evaluate general applicability proposed approaches different image datasets detection algorithms especially area deep learning Financial support sponsorship This work financially supported Sectra AB Linköping Sweden Part work conducted QuantMed project funded Fraunhofer Society Munich Germany Conflicts There conflicts references 1 Mahmoud SM Paish EC Powe DG Macmillan RD Grainge MJ Lee AH et al Tumorinfiltrating CD8 lymphocytes predict clinical outcome breast cancer J Clin Oncol 201129194955 2 Speirs V Walker RA New perspectives biological clinical relevance oestrogen receptors human breast J Pathol 2007211499506 3 Tang LH Gonen M Hedvat C Modlin IM Klimstra DS Objective quantification Ki67 proliferative index neuroendocrine tumors gastroenteropancreatic A comparison digital image analysis manual methods Am J Surg Pathol 201236176170 4 Vink JP Van Leeuwen MB Van Deurzen CH De Haan G Efficient nucleus detector histopathology images J Microsc 201324912435 5 Arteta C Lempitsky V Noble JA Zisserman A Learning detect cells nonoverlapping extremal regions In Medical Image Computing ComputerAssisted InterventionMICCAI 2012 Berlin Heidelberg Springer 2012 p 34856 6 Kårsnäs A Dahl AL Larsen R Learning histopathological patterns J Pathol Inform 20112S12 7 Xing F Xie Y Yang L An automatic learningbased framework robust nucleus segmentation IEEE Trans Med Imaging 20163555066 8 Xu J Luo X Wang G Gilmore H Madabhushi A A Deep Convolutional Neural Network segmenting classifying epithelial stromal images Neurocomputing regions 201619121423 histopathological 9 Janowczyk A Madabhushi A Deep learning digital pathology image analysis A comprehensive tutorial selected use cases J Pathol Inform 2016729 10 GulMohammed J ArgandaCarreras I Andrey P Galy V Boudier T A generic classificationbased method segmentation nuclei 3D images early embryos BMC Bioinformatics 2014159 11 Sirinukunwattana K Raza S Tsang YW Snead D Cree I Rajpoot N Locality sensitive deep learning detection classification nuclei routine colon cancer histology images IEEE Trans Med Imaging 2016351196206 12 Chawla NV Japkowicz N Kotcz A Editorial Special issue learning imbalanced data sets SIGKDD Explor Newsl 2004616 8 Journal Pathology Informatics J Pathol Inform 2017 121 httpwwwjpathinformaticsorgcontent8121 13 Pechenizkiy M Puuronen S Tsymbal A The impact sample reduction PCAbased feature extraction supervised learning In Proceedings 2006 ACM Symposium Applied Computing SAC ACM New York USA 2006 p 5538 14 Bentley JL Multidimensional binary search trees associative searching Commun ACM 19751850917 15 Omohundro SM Efficient algorithms neural network behavior Complex Syst 19871273347 16 Settles B Active Learning Literature Survey Computer Sciences Technical Report 1648 University WisconsinMadison Madison USA 2009 17 Molin J Bodén A Treanor D Fjeld M Lundström C Scale Stain MultiResolution Feature Enhancement Pathology Visualization ArXiv Prepr arXiv161004141 2016 18 Kost H Homeyer A Bult P Balkenhol MC van der Laak JA Hahn HK A generic nuclei detection method histopathological breast images In Medical Imaging 2016 Digital Pathology Bellingham Washington USA 2016979197911E1 97911E7 Journal Pathology Informatics 9 J Pathol Inform 2017 121 httpwwwjpathinformaticsorgcontent8121