ELSEVIER Artificial Intelligence 97 1997 169193 Artificial Intelligence Defaults relevance modelbased reasoning Roni Khardonv Dan Roth b2 Aiken Computation Laboratory Harvard University Cambridge MA 02138 USA b Department Applied Mathematics Computer Science Weizmann Institute Science Rehovot 76100 Israel Received September 1995 revised May 1996 Abstract representations Reasoning modelbased intuitive paradigm shown theoretically sound possess computational advantages reasoning formulabased representations knowledge This paper studies representations substantiates claim advantages In particular modelbased representations shown efficiently support reasoning presence varying context information handle efficiently fragments Reiters default logic provide useful way integrate learning reasoning Furthermore results closely related notion relevance The use relevance information best exemplified filtering process involved algorithm developed reasoning context The relation defaults relevance viewed notion context agent plausible context information default rules This view yields efficient algorithms default reasoning Finally argued results support incremental view reasoning natural way notion relevance environment captured Learning Reason framework discussed 1997 Elsevier Science BV Keywords Knowledge representation Commonsense reasoning Learning reason Reasoning models Context Default reasoning Corresponding author Email ronidasharvardedu Research supported AR0 grant DAALOS 92G01 15 ONR grant NOOOl496I0550 An earlier version paper appears Proceedings International Joint Conference Articial Intelligence IJCAI95 Email danrwisdomweizmannacil Research supported Feldman Foundation Part work Harvard University supported NSF grant CCR9200884 DARPA AFOSRF496292J0466 ONR grant NOOO149610550 00043702971700 1997 Elsevier Science BV All rights reserved PISOOO437029700044l 170 R Khardon D RothArtificial Intelligence 97 1997 169193 1 Introduction A considerable work theoretical foundations artificial intelligence devoted capturing intuitive notions human reasoning An introspective view suggests notion relevance central human reasoning Many commonsense reasoning situations characterized abundance po tentially relevant information sources Yet humans pick relevant information ignore irrelevant This ability account speed reasoning performed everyday situations In paper relevance viewed notion reduce computational cost reasoning focusing information pertains situation task hand ignoring information bear situation We study tasks framework logi cal reasoning relevance information useful In particular performing reasoning modelsnamely reasoning formed considering examples world reason aboutrelevance information efficiently tackle reasoning tasks The generally accepted framework study reasoning intelligent systems knowledgebased approach The idea store knowledge representation language defined meaning assigned sentences The sentences stored knowledge base KB combined reasoning mechanism determine inferred sentences KB Various knowledge representations represent knowledge knowledgebased Different representation systems set logical rules probabilistic network associated corresponding reasoning mechanisms 14181 Given logical knowledge merits range applications base example reasoning abstracted deduction task determine sentence assumed capture situation hand logically implied knowledge base It widely agreed large everyday reasoning involves arriving entailed theory world Many conclusions conclusions derived absence information sufficient imply This type reasoning naturally nonmonotonic evidence force revise conclusions Several formalizations trying capture situation studied particular theories reasoning defaults 20 In approach true knowledge world augmented set default rules meant capture typical cases The quest reasoning given query responds way agrees know world default assumptions time supports intuition plausible conclusion Computational considerations render approach inadequate common sense reasoning This true task deduction forms reasoning developed All shown harder compute original formulation 23251 This holds particular formalizations default reasoning 61726 increase complexity clearly odds intuition reasoning defaults reduce R Khardon D RothArtificial Intelligence 97 1997 169193 171 complexity expressiveness paper modelbased abovementioned results difficulties reasoning This remains true severely knowledge base default rules queries allowed representations overcome notion relevance useful deriving restrict In We incorporate notion relevance study reasoning introducing completes situation task reasoning context normally We model contextspecific additional formalize availability easier restricting performs modelbased efficient constraining reasoning It argued lot missing context augmenting agents knowledge information answering queries real life situations 121 world task base We deduction knowledge information Reasoning context information added task problem reasoning varying context The intuition task information reason As agent easily yields information context additional domain needs reasoning context reasoning reasoning reasoning assignments presented In modelbased 59 examples It hard motivate modelbased set models knowledge base represented world logical formula describing satisfying query When query models cognitive point view proponents approach cognitive 3411 J alluded psychologists examples qualitative basis In AI community Levesques notion vivid framestheory notion reasoning approach seen example Minskys 151 work casebased 12131 somewhat performed evaluating related lo reasoning reasoning approach Given modelbased representation task deciding KB implies straightforward way Evaluate LY models model KB satisfy KB Clearly definition But representing KB explicitly holding modelbased approach representation modelbased approach verifies support correct deduction feasible reasoning knowledge base KB query cy denoted KB performed If models KB Y KB c representation representation conclude contains implication yields correct deduction possible models plausible A KB replaced small modelbased The theory modelbased representations developed 91 generalizing ory developed languages tion It shown based setting propositional efficient reasoning 5 case Horn expressions propositional modelbased representations cases modelbased variables domain Thus representation obtained deduction support efficient deduction abduc formula number setting correct cases algorithm known small modelbased polynomial NPhard When reasoning context general knowledge additional easy natural constraints implementation relevant current modelbased world combined task The situation This representations characterizes 172 R Khardon D RothArtcial Intelligence 97 1997 169193 simply background filters models consistent context representation relevant algorithm current context models information The remaining models reasoning models The filtering process speeding performed simple reasoning We characterize algorithm works correctly efficiently We note reasoning models essential advantage reasoning context The filtering providing algorithm context information performed reasoning formulas context changes languages necessarily task easier propositional process computational additional default reasoning Intuitively conflicting generalization task default aims capturing standard knowledge weed nonrelevant default notion rele cases focus vance enforces additional constraints typical cases In default reasoning 191 agent given representation rules assess world set query q concluded reasoning default rules We default reasoning rules conflicting Namely text reasoner context default rules express explicitly relevant context cases ignored new implicitly source computational rules compatible In case agent use subset rules deriv subsets To ing conclusions reach conclusion called extensions default time In sense conclusion computational possibilities agent enumerate perform contexts context order derive reasoning possible contexts possible relative odds notion relevance source additional scenarios While nontypical introduced default reasoning need default reasoning capture plausible choosing information search difficulty difficulty representations cases modelbased In particular accessible Nevertheless cases modelbased computational difficulty tations capture possible contexts contexts use subroutine task We efficient algorithms tasks classes world knowledge default cases cases results provide knowledge base represented formulas task diagnosis solutions efficient reasoning context credulous skeptical form Thus enumerate perform inference default reasoning rules queries We techniques Our solvable performed similar known provide way represen Our notion relevance higher context situation example restricted order based representations approximations information prune possible known language support correct approximation way reduce computational relevance tusk While level knowledge representation prune representation queries presented KB relative reasoning queries This relative agent come language general cost reasoning relevance particular task For sufficient idea formalized model capture reasoning In fact Here notion upper bound approximations 927 reasoning context default use notion relevance R Khardon D RothArtcial Intelligence 97 1997 169193 173 representations essential formulabased representations modelbased approximations representation support efficient agent construct representation views reasoning Our results knowledge holds specific context avail reason correctly view pasting notion able form modelbased context Therefore treatment reasoning context supports intelligent narrower relevance tation This intuitive son framework Learning relevant construct represen sense supports correct reasoning Rea results order exploit idea formalized 71 discussed framework general setting 8223 11 We discuss different contexts This suggests environment Namely agent incrementally world incrementally reasoning process use modelbased environment Learning relevant representations information Reason paper studies reasoning modelbased computational advantages representations claim information representations To summarize substantiates modelbased varying context provide useful way integrate suggest computational relevant We discuss based representations cost reasoning current situation useful In particular aspects relevance shown efficiently support reasoning handle efficiently fragments Reiters default learning reasoning On philosophical view results notion relevance information reduced general task performed environment use enabled model In particular presence logic level 1 The use relevance involved algorithm 2 The relation defaults information best exemplified reasoning context relevance viewed filtering process notion context resulting efficient algorithms 3 Relevance restricting 4 The Learning knowledge information attention Reason representation default reasoning level global sufficient information allows framework relevant environment task incrementally task priori constructing The rest paper organized follows In Section 2 introduce notation theory reasoning models context present efficient modelbased discuss default discuss knowledge Section 7 briefly present relevance definitions paper In Section 3 briefly present results task reasoning In Section 5 In Section 6 task In relation diagnosis relevant reasoning models application Section 8 concludes summary In Section 4 discuss approximations Learning capturing information Reason framework algorithm 2 Preliminaries We consider problems reasoning world tion W 0 1 4 0 1 We use interchangeably terms propositional modeled Boolean func expression 174 R Khardon D RothArtijcial Intelligence 97 1997 169193 Boolean functions We denote classes Boolean likewise function propositional language class Boolean functions 7 G functions fg attribute LetXxr mappings 0 1 associated conjunction world Assignments xi V EJ A xg V 37 V x4 literals DNF formula literals CNF formula number 1 bits assignment value 1 0 indicate natural mapping Assignments denotes x set variables associated worlds X 0 l treat 0 1 x clauses CNF formula clauses A term terms For example monotone Horn clause kquasimonotone DNF attribute true false elements denoted x y z weightx A clause disjunction For example conjunction xl AX V x3 AZfiA x4 DNF formula terms A CNF formula literals positive k positive k negative literals k negative Every Boolean CNF representation mean CNF size f denoted representation clause A DNF formula literals term function possible particular DNF f 1 CNF literal A CNF formula clause It kquasireversedHorn DNF representation By DNF size f denoted number terms DNF representation unnegated A CNF formula CNF f 1 minimum number clauses positive f Similarly kquasiHorn disjunction representations minimum literals f An assignment literature f fx 1 assignment x E 0 1 satisfies model f If f theory world satisfying referred mean confusion f equivalent f g model f model g Throughout arise identify Boolean connective implies subset equal f k g paper f set models k Boolean C subsets 0 1 That assignment f possible world By f implies g denoted connective 1 Observe x called f C g functions function 3 Reasoning models In section briefly present results monotone functions section appeared For detailed discussion theory reasoning models 2 91 59 All results theory Boolean Consider propositional strategy The modelbased implication uses set models algorithm evaluates ax 0 algorithm Clearly models large making modelbased satisfying relation model evaluation Fig 1 describes knowledge deduction problem W cy try verify base W let LY propositional query algorithm MBR base When presented query cy x r If counterexample r knowledge Y models returns No Otherwise solves approach W However assignments procedure computationally inference problem set r set models approach infeasible A modelbased returns Yes R Khardon D RorhArcial Inrelligence 97 1997 169193 115 Algorithm MBR r Test set A set r 2 W possible assignments Test If element x E r satisfy return No Otherwise return Yes Fig 1 MBR modelbased reasoning useful test set perform reasonably good inference possible use fairly small set models In rest section general conditions An example technical notions presented given end section 31 Monotone theory Definition 1 Order We denote 6 0 l induced order 0 1 That xy E 0 l x y Vi x 3 b y b xi yi For assignment Here bitwise addition modulo 2 We x y x y x y b E 0 1 define x y usual partial order lattice Intuitively bi 0 order relation ith bit normal order bi 1 order relation reversed 1 b 0 The monotone extension z E 0 1 respect b defined MbZ x 1 x ab z The monotone extension respect b defined Mbf x 1 x z z E f treat function Notice respect notation b defined f set satisfying natural The set minimal assignments f assignments mjnf z 1 z E f Vy E f z Definition 2 Basis A set B basis f class functions F basis functions F f jjbEB Mb f B basis The importance definitions 2 Boolean function basis B represented follows f jJf B j v Mbz bEB zEminbf 1 176 R Khardon D RothArtijicial Intelligence 97 1997 169193 This 0 1 satisfies representation f yields necessary sufficient condition describing x E Corollary 3 Let B basis f x E 0 ln Then fn basis element b E B exists z E minb f x b z 1 It known 2 DNF representation representation 1 CNF f Some important CNF size function b size minb f Further set assignments falsify clause bounded size CNF f basis size bounded function classes small fixed basis irrespective f basis f Therefore l Horn formulas A basis class BH u E 0 1 weightu n falsified assignment l BH Clearly JJ n 1 l kquasiHorn formulas BH u E 0 1 1 weightu 3 n k basis Horn clause class Clearly formulas IBHI 0 nk Similarly basis kquasireversedHorn construction l lognCNF formulas A Boolean clauses contain Ologn combinatorial set assignments assumes n kuniversal k log n construct function CNF representation literals A basis class derived called n k universal set C 0 1 subset k variables clause length k sets size 0 n3 forms basis class kCNF formulas set An n k universal set includes falsifying aiS It easy 2k possible n log n universal It known assignments assignment 1161 IBIcNFI Wn3 l Common queries A function common clause CNF representation taken classes The union bases classes basis Bc common queries functions We refer class class common 32 Deduction We characterize modelbased knowledge base algorithm MBR successful Definition 4 For function set minimal assignments f E F set I r f respect characteristic models f set B c 0 1 Formally r Uz E mpf bEB If addition B basis class G functions modelbased representation f respect common queries bound size modelbased result theory reasoning models queries basic 9 The following representation application ry theorems R Khardon D RothArtiJicial Intelligence 97 1997 169193 171 cr E 0 Theorem 5 Khardon B basis 6 Then f k cr u E r au 1 That Let f Boolean Roth function 91 modelbased deduction TT correct Corollary 6 Khardon common query f k u E TF Roth 9 Let f Boolean function Then uu 1 That model based deduction rf correct Theorem 7 Bshouty size modelbased 2 Let f Boolean function B basis Then representation We note bound tight sense functions functions exponentialsize DNF linearsize modelbased compare It allow exponential required 91 It interesting DNF Namely representation size representations Horn CNF cases exponentially representation properties characteristic models 93 functions Examples representation formula size representation 5 small modelbased large vice versa For discussion issues size gap cases Example Let f CNF representation function The satisfying assignments f 3 OOOOOOOl 00101101 f 12 16 possible satisfying assignments The non able If want answer possible Horn queries respect use Horn basis BH 11111110110110110111 f Each models need minb f b For 1111011110111110 b 1101 minimal lattice checking satisfying assignments f minimal This yields mint tot f 1100111110010101 0101 1110 Note includes 7 12 satisfying assignments f satisfies elements drawing We rf 11110111101111001001 corresponding modelbased f Furthermore counterexample deduction Horn query f makes 1 1011 deduce Clearly general rH 2 f queries mistakes xi A x3 x2 reasoning correctly f al We note general implied rf f k LY coNPcomplete given f Y Horn query CNF representation solving problem 3 An element 0 I denotes assignment variables xt xn 0011 means xt x2 0 andqx41 178 R Khardon D RothArtificial Intelligence 97 1997 169193 4 Reasoning context It argued real life situations normally completes lot miss ing context information answering queries 121 For example asked conference long takes drive airport probably assume specified question refers city conference held place live airport times This corresponds assigning value true attribute purpose answering question Sometimes need expressive language assumptions current context assume rule applies 261 For example assume conference context car rental car Thus reasoning context viewed deduction task additional constraining information added knowledge base Our use context closely related notion rele vance use context information order concentrate relevant knowledge ignore irrelevant Intuitively reasoning task easier Indeed holds formal sense modelbased reasoning Let W Boolean function describes knowledge world A principle way formalize intuition following want deduce query Y W Y inferred W given query refers current context Namely instances W relevant query satisfy context condition d conjunction literals rules We denote question W kd Notice possible W kd cy W p satisfying assignments W satisfy cr satisfy d Formalized way problem W bd equivalent problem W A d k Thus theorem proving approach reasoning necessarily provide computational advantage solving reasoning problem Let W E 3 cr E 6 let B basis 9 From Theorem 5 clear given set characteristic models W A d modelbased reasoning GA solve reasoning problem W A d k However consider general problem given rg interested performing inference according d context condition d vary From modeltheoretic definition connective bd clear models W filtering models satisfy d performing test remaining models answers W A d correctly The algorithm CMBR presented Fig 2 set r modelbased The following theorems conditions compact modelbased representation behaves like complete set models theory Namely filtering algorithm CMBR provides correct reasoning Theorem 8 Given rg W kd d B basis d algorithm CMBR correctly solves reasoning problem R Khardon D RothArtificial Intelligence 97 1997 169193 179 Algorithm CMBRT d Test set Consider Test If element satisfy Y return No elements r satisfy d Otherwise return Yes Fig 2 CMBR modelbased reasoning context d Therefore 5 B basis modelbased Models W satisfy d useless counterexamples Proof Clearly W d cr E W A d k LY E W b z V E W b Theorem reasoning d cx holds correct answer test set Algorithm CMBR produces d l 0 Theorem 9 The following correct reasoning context conditions B d guarantee CMBR supports Let cr kquasiHorn query B BH basis k rquasiHorn represented rquasimonotone B basis d In particular k 1 r 0 theories If d Boolean function DNF holds Horn formula LY monotone Boolean function d theories query B basis 2lognCNF ii Let Y lognCNF If d B basis conjunction d logn arbitrary rules disjunctions Proof Assume CNF expression AjEJcj In case d given DNF expression Viclti cy given A iVCj iEIiEJ case k 1 r 0 Since d monotone For case consider DNF expression d monotone general term d contribute k positive For case ii d CNF expression logn clauses written DNF expression literals Therefore V Cj 2 log n literals r positive K V Cj k rquasiHorn q V Cj Horn disjunction literals cj contribute 5 V Cj Therefore term logn term In literals Finally notice need d DNF expression The analysis uses desired class algorithm evaluates filtering algorithm expression d Y directly d cy belongs representation given 0 180 R Khardon D RothArtificial Intelligence 97 1997 169193 It interesting note size expression large However d described analysis algorithm Rather filtering examples appears expression proof exponentially We actually compute d sufficient according definition Notice particular characteristic models set ultimately context depends basis B This filtered models confusing class queries possible basis choice B arbitrary However note basis class queries models This similar Boolean different minimal class set characteristic reason queries knowledge formulas ways unique queries based captures information class example functions Boolean situation function representations representation arises representing represented CNF form represent general needed The approach presented representation section viewed process augmenting r set rules Given modelbased representation W help answering queries modelbased r W rule holds filter assignment hold W augmenting W modifies shown representation respect deductive case slightly basis larger W redundant However rules set conclusions As context order reason context need maintain modelbased basis pure 41 Context relevance Our treatment context information appeals information intuitive notion relevance The d filter irrelevant irrelevant base The information algorithm CMBR uses context knowledge correspond current context facilitates filtering elements algorithm context changes This way reasoning faster time evaluation models current context required efficient representation A natural approach perform background current context The use modelbased requires evaluating information set models representation case filtering This contrasted formulabased information computational conjuncted formula W theorem proving necessarily representation adding context task There formula d Since W A d reason W task general easier necessarily simpler help 5 Default reasoning models Default rule captures conditions reasoning formal framework arguing idea reminiscent normal context information satisfied circumstances assume typical cases A default certain In default reasoning R Khardon D RothArtificial Intelligence 97 I 997 169l 93 181 combines conclusions partly aimed capturing obvious context This suggests option viewed generalization set rules default reasoning context given Intuitively default notion relevance ignoring rules conclusions conflicting As result correct context reasoning query agent search correct context reasoning reasoning nontypical reasoning problem reasoning correct context Nevertheless representations enumerating cases Therefore easier However default deductive search results cases modelbased difficulties traced abovementioned form solution context time efficient capture possible contexts contexts concentrating computational use defaults actually harder accessible expected irrelevant reasoning We concentrate special case Reiters default logic 191 applied propositional logic logic default rules form y read CL In Reiters default assume p conclude 7 The case p y called holds consistent normal defaults CY called prerequisite The discussion considers normal In case denote D set defaults prerequisites Boolean treat collection rules conjunction That Dx 1 means AdED dx 1 functions p D set default rules We denoted b 2 Definition 10 For normal defaults prerequisites rule simple The rule positive literal The rule positive LI positive p single simple literal f define A default function p monotone Notice theory diagnosis 211 closed world defaults 191 described simple defaults theory rules W D W D set default expression An extension D W defined fixed point operator simpler theorem gives alternative following pair A default propositional 191 For special definition case The operator Th R denotes theorem closure R 21 p 881 Let D set normal defaults pre Theorem 11 Reiter requisites E extension D W E Th W A S maximal subset4 S D W A S consistent Using theorem definition subset S extension E We denote W extension E includes q 191 knowledge original base defined formalization extension identify maximal consistent subset SE Since SE consistent W A SE b q In imply query 4 To avoid confusion emphasize rule added additional function S2 conjunction S D considered sense preserving consistency W Thus S1 C S2 Boolean sets rules S maximal rules S2 SI 182 R Khardon D RothArtificial Intelligence 97 1997 169193 extension default reasoning skeptical default reasoning query holds Following case extensions 629 task credulous called taken consideration Formally D W propositional given default exists extension E D W q E E credulous default reasoning task CDEF D W q defined follows expression q decide theory The skeptical default reasoning task SDEF D W q defined follows given D W propositional q decide expression theory default extensions E D W q E E Clearly W consistent set rules subset S D contains rules In case context general case W skeptical default earlier The main difficulty arises reasoning D reasoning reduce consistent maximal credulous D discussed consistent D results default reasoning represen results present hold known efficient solution reasoning formulas The case There randomized reasoning modelbased 9 deductive somewhat subtle efficient Next present positive problems representation relation solutions presented given formulabased NPhard literals tation As case deductive cases exact complexity efficient reductions task soning positive algorithm representation expression Thus strictly speaking prove advantage results provide efficient algorithms knowledge base single positive class problems polynomial This representation case example 28 query cases exponential problems reduction size Horn 281 special case Nevertheless known exist NPhard In current case default Horn default rea rules literal Our results provide size modelbased We present algorithms CDMBR SDMBR handle skeptical default algorithm5 abduction reasoning developed tasks respectively Both algorithms 151 91 51 Credulous default reasoning credulous similar r When We start describing representation receives algorithm CDMBR presented W The monotone basis defined Fig 3 Let r later r D query q input It starts enumerating TW modelbased The algorithm CDMBR models sets S set rules D model satisfies The algorithm tests W A S k q calling If answer model finds model z query holds q z 1 decide W bs q test r scanned good extension Yes algorithm If models r algorithm returns Yes procedure CMBR continues says No 5 Our results inspired connections abduction default reasoning developed 1251 R Khardon D RothArtificial Intelligence 97 1997 169193 183 Algorithm CDMBRT D q Do models z E r q z 1 Let S d E D 1 dz 1 If CMBR r S q answers Yes return Yes EndDo Return No I No extension I Fig 3 CDMBR default reasoning modelbased representation Assume algorithm q The following run modelbased r rf query conditions B D characterize representation presented cases algorithm successful Condition 12 B basis 5 f q S c D Condition 13 For S G D u SU 1 prime t S basis element b E B tu tb 1 implicant Theorem 14 Given rk task CDEF D W q correctly Condition 12 Condition 13 hold algorithm CDMBR solves credulous default reasoning Proof We need prove returns Yes desired extension exists algorithm extension ii For Condition W A S k q By construction maximal clearly W A S k W A S k q required extension exists 12 holds Theorem 8 implies contains q algorithm subset D respect S subset D WA S consistent CMBR returns Yes correct property consistency W If S S For ii assume extension E contains q By definition existence E implies WA SE q Thus assignment qu 1 Condition 13 implies exists subset SE C D W A SE consistent u E W SEU 1 exists prime b E B SEU tu tb 1 Thus u b agree literals appear t w u u E W w like exists W A SE q qw 1 t SE basis element z z U t z SEZ 1 Thus w E I SEW 1 implicant Now consider set S algorithm CDMBR uses iteration algorithm compute includes SE SEW 1 returned CMBR correctly correct Condition 0 By construction clearly answer algorithm SE The set The 12 Theorem 8 Therefore exactly SE SE maximal responds Yes set w E r identical The following lemmas identify cases required conditions hold 184 R Khardon D RothArtcial Intelligence 97 1997 169l 93 Lemma 15 If set D defaults consists positive defaults ii simple defaults 6 r negative literals iii log n default rules small basis satises Condition 13 basis contains negative term b 1 satisfies condition That Condition implicant S 2 D 13 holds Proof For D set positive defaults prime monotone 1 For ii subset S G D conjunction monotone includes implicant literals S single prime literals S assigned 0 literals assignment assigned 1 satisfies Condition literals D contains r negative subset S basis tr suffices For iii subset S D CNF expression logn clauses DNF expression u satisfies S u satisfies term logn literals Thus prime basis B 13 holds t satisfy contains n log n universal elements Thus basis set Condition literals Therefore t 13 In particular monotone implicant logn 0 The following definition captures cases modelbased default reasoning correct Definition 16 The D r cases 7D following guarantee efficient solution tractable defaults cases simultaneous classes default reasoning problem We denote restrictions D set positive defaults class kquasiHorn queries The corre sponding modelbased representation r r ii D set simple defaults r negative literals class k quasiHorn queries The corresponding modelbased representation r Fr iii D set logn default rules disjunctions Q class lognCNF queries The corresponding modelbased representation r r31w K Lemma 17 Condition 12 Condition 13 satisfied D r TD Proof Condition 12 holds direct consequence Theorem 9 Condition 13 holds direct Lemma 15 For 1 E But For ii BH C BH iii B2 togn_cr contains n log n universal set implication 0 Using Theorem 14 Lemma 17 Corollary 18 The algorithm CDMBR solves credulous default reasoning task CDEF D W q correctly q E Q D T TV R Khardon D RothArtificial Intelligence 97 1997 169193 185 Algorithm SDMBRI D q If models z E r q z 0 return No Do models z E r q z 1 LetSdEDdzl S max Do d E D S Consider S potential maximal subset exists y E r Wy 1 Sy 1 dy 1 S EndDo If S max CMBR r S q answers No return No EndDo Return Yes I All extensions good I Fig 4 SDMBR default reasoning modelbased representation 52 Skeptical default reasoning extension credulous maximal The difference A legitimate respond affirmatively rules For credulous default reasoning sets considered considered skeptical includes S satisfies W A SE q Therefore presented Fig 4 tests maximal reasoning need skeptical query holds sufficient important tasks reasoning extensions subset set D default maximal sets affect response algorithm For subset S subset SE main stage algorithm SDMBR sets consistent nonmaximal maximal satisfy W A S q maximal candidates maximal guarantee identify subsets representation It starts enumerating IV The algorithm SDMBR models Let r Tw modelbased consistent W In consistent r D query q input finds model z rules maximal sufficient ignored algorithm W s q If answer look maximal D Yes qz l D model satisfies The algorithm query holds subset checking correctness proof algorithm test condition elements r If S maximal algorithm goes assignment tests WA S b q calling No algorithm procedure CMBR returns No set S If models tested bad extension r corresponding r When receives sets S set tests S superset S decide continues subsets says r Otherwise algorithm Theorem 19 Given r algorithm SDMBR solves skeptical default reasoning task SDEF D K q correctly Condition 12 Condition 13 hold 186 R Khardon D RothArtijicial Intelligence 97 1997 169193 Proof The proof similar Theorem 14 We need prove algorithm extensions returns Yes extensions contain q algorithm ii case The proof Theorem 14 shows extension S Consider loop considered test SDMBR That superset S consistent W Therefore extensions CMBR gives correct answer Thus z E r Since extension S maximal returns Yes extensions subroutine contain q algorithm returns Yes passed inner passes contain q For ii extensions contain q Assume exists z E Z step goes flagged max extensions algorithm passes extensions Assume loop We argue loop subsets S identified correspond q z 1 inner inner d S S A d consistent W Consider loop inner know S detect know required d candidate u E W added s u 1 But Condition y E r satisfies S Thus S maximal S Since S consistent W 13 holds algorithm fact set nomax ignore S required As case says Yes answers CMBR correct algorithm iteration We prove assumed exists z E rk extensions Notice extension E exists x E W A SE A q As assumption holds y E ri contain q extensions satisfying implies 0 particular q z 1 Using Theorem 19 Lemma 17 Corollary 20 The algorithm SDMBR solves skeptical default reasoning task SDEF D W q correctly q E D Q r TV 53 Application Diagnosis models One useful applications default logic problem circuit diagnosis example 211 Consider gate gate In order diagnose possible problems gate new variable denoting correspond variables circuit d A b e d V c composed circuit add In example Ni new gate N2 correspond circuit described operating normally gate Using functionality W Nlab dNld f aNld bNzc f eNzd eNze cvd Under normal conditions want assume This captured general having rule gates normality example set positive simple default rules D 2 variable gates operating normally In absence evidence considering default problem gates operating normally extension D This interpreted W D reveals stating R Khardon D RothArtificial Intelligence 97 1997 169l 93 187 Algorithm DiugMBRT 0 D q Let ro z E r 1 Oz 1 Call SDMBR ro D q answer way Fig 5 DiagMBR modelbased diagnostic reasoning Suppose observe c 1 e 0 In case circuit reasoning problem default W W A cZ need consider It easy case extension includes N1 described W 0 include N2 This interpreted stating minimal explanation fault gate number 2 faulty case observations exactly determine Of course fault observe 1 b 1 e 0 In case In extension Ni N2 possible scenarios example circuit Suppose W W rabZ W D extensions N2 Nt This identifies caused correctly skeptical default following fault It easy answer If want know interpretation circuit fault circuit gate gate functioning implies d makes sense use reasoning paradigm W D query d This specifics d deduced knowing No case Ni 0 We apply positive results default reasoning problem problem diagnosis knowledge world varies diagnosis Observe observations Therefore On normality gates This suggests The algorithm context algorithm SDMBR information support Then observations default serve kind context rules capture algorithm DiagMBR Fig 5 0 serve uses set filtered models knowledge base assumptions described information uses filtering CMBR observations As following theorem shows strategy succeed sufficient expression 0 S q supported query characteristic models Theorem 21 The algorithm DiagMBR solves diagnosis task correctly long 0 includes r observations q kquasiHorn expression I l set observation Proof Given 0 SDEF D W A 0 q As Theorem considered algorithm properly requirement 19 need subroutine solve default extensions reasoning context task Let SE extension WA 0 Namely model u E WA 0 A SE Since SE subset D includes positive 0 r literals BH includes assignment literals Also conditions theorem r negative b agrees 0 SE literals Thus z E r z b u z agrees b u literals literals This assignment implies 188 R Khardon D RothArticial Intelligence 97 1997 169193 SE 0 The assignment extension SE properly extension maximal existence z z survive identified Note maximal filtering stage algorithm algorithm claims detected test When extension S identified algorithm SDMBR uses subroutine question q follows given context S In case CMBR W A 0 A S k q Using question Theorem 8 answered correctly long B basis 5 V 3 V q Since S monotone 0 r literals W A 0 ks q holds case equivalent 0 54 Default reasoning relevance The use defaults reasoning motivated desire presence incomplete given respect typical cases decisionmaking information relevant current situation Moreover intuitively contribute allow efficient information The goal exploit rules relevant cases default process identifying reducing complexity reasoning However turns default logic default reasoning goal missed While rule representation set default task defined default tries capture plausible scenarios logic traced search possible scenarios relation rules framework local assumption scenarios default reasoning constitutes In fact computational difficulties As shown relation defaults relevance viewed reasoning notion context Namely default reasoning context use default cases capture possible extensions consider context time use filtering relevant contexts This default reasoning rules We shown information algorithms viewed generalization information representations modelbased context accessible form In cases order focus yield efficient technique shown agent plausible 6 Relevance task The view commonsense reasoning complex world omniscient tasks Given complete description perform partial relax requirements world hard represent exactly Luckily perform fairly wide restricted agent function question order reason correctly respect information relevant agent need set agent needs task One way computational prune prune knowledge perform study issue notion relevancea way reduce cost reasoning While relevance context information knowledge representation particular situation representation relative general task agent possible supposed R Khmdon D RothArtificial Intelligence 97 1997 169193 189 Consider deduction problem suppose agent wander queries restricted form belong agent needs answer correctly queries wrong queries Q going language queried world This means potentially known In case incomplete support correct deduction This formalized notion upper bound representation introduced Kautz Selman 271 Intuitively In 8 W belong capture conclusions support exact deduction respect queries approximations description world sufficient approximations shown 9 Q earlier class queries Thus results use modelbased In fact modelbased representations approximations relative notion relevance task Moreover essential exploit form example representation based efficiently relevance supports task answering upper bound W respect representation suppose lognCNF task The reason efficient solutions reasoning problem For reason feasible The existence compact model reasoning upper bound enables perform lognCNF queries Given CNF representation NPhard paper capture implicitly use representations representation 7 Learning reason sections support incremental modelbased representation view reasoning The results presented previous natural way We shown reason correctly additional This relevant complete context information knowledge augments constraining agents knowledge context aids information deriving context We topdown solution assumes base uses parts depending supplied conclusions agent current It conceivable agent models specific context d In case results context approach This approach come agent reasons correctly bottomup construct narrower reason correctly supports possible contexts experienced models context We agent supports complete knowledge base incrementally In views different contexts pasting agent intelligent eventually representation world guaranteed constructs view This intuitive approach cast general learn nature reasoning task world inductive performs learning This intuition There agent wanders unknown distribution D governs captured In systems supplies distribution framework emphasizes agent world agent information theory 301 free model learning world observing examples drawn world Then occurrences instances 190 R Khardon D RothArtijicial Intelligence 97 1997 169193 classify task instances The agent arbitrary world agent perform err set instances Thus measure formulations world depend world functions deductions allowed long measure set D small learning phase supplies later This intuition captured early description way arbitrary agent exact formulabased performance agents performance ability reasoning CNF formula information traditionally defined In 71 general study reasoning learning ideas access favorite interact performance reasoning queries cy query W implies cy interface In framework framework Learning Reason defined intelligent interface given grace period representation6 agent given KB world W The measured period agent presented world answer incorporates construct language relevant This framework formal study manifestation allows way reduce computational relevance relevance environment Namely measured criterion shown 7 additional reasoning power cost reasoning performance notion In case agent Indeed truly gains depends world agent functions agent interaction world We briefly focus relevant results rely use modelbased results emphasize information gain framework agents As representations A sampling approach Suppose access W conference samples according W A d It shown answer correctly evasive Formally random examples distribution D governs certain context d world context discussed This allow random instances random examples questions length p evasive A statement falsified rarely 71 sample m pe occurrences ln lS implied world practice Y evasive W A d w cr PrD W A d A Z E This exemplifies notion relevance environment interacts nonevasive defined distribution D queries environment defined relative environment agent agent cares Notice framework set models supports exact reasoning probablyapproximatelycorrect usage modelbased reasoning context Now instead having fixed defined random set require representations reasoning queries similar h Note framework need distinguish world W agents representation KB R Khardon D RothArtQicial intelligence 97 1997 169193 191 Theory approximation restricted queries The utility knowledge approximations capturing information relevant task Section 6 We note use approximations advantageous discussed reasons In 7 bound approximations appropriate task relevance environment shown exact learning functions reach learn modelbased representations functions Thus learn approximations upper ideas relevance use reasoning environment combining 8 Conclusions Reasoning models intuitive paradigm In paper presented evidence shown theoret utility modelbased representations restricted cases default rea support efficient reasoning notion relevance naturally successfully In particular ically sound representations presence varying context soning We argued utilized reasoning models information varying efficiently directly The basic computational context We modeled task considered situation world contextspecific modelbased representation information augmenting problem reasoning knowledge task algorithm showed solve filtering Our solution information possibly conflicting relation defaults default reasoning In default implements idea ignoring irrelevant agent contexts As shown different acquired vance viewed viewed generalization plausible der certain accessible rithms form exploited restrictions modelbased representations information context notion context Namely default reasoning context reasoning agent use default rules Furthermore capture possible scenarios yield efficient default reasoning rules rele algo The significance results achieved natural extensions reasoning deductive tation support efficient reasoning hold cases traditional formulabased represen Moreover shown results support incremental framework view reasoning notion natural way discussed shown relevance manifested modelbased discussed learned efficiently This combined context specific default rules acquired rote learning learning processes work plausible way In particular framework representations Learning Reason 24 These results viewed providing theoretical style reasoning set typical cases casebased representation More work needed issues support usefulness knowledge order gain deeper understanding 192 R Khardon D RothArtificial Intelligence 97 1997 169193 We believe effective use relevant information important efficient solution reasoning serve good example natural way task In respect modelbased representations allow exploit aspects relevance Acknowledgments We thank anonymous reviewers comments helped improve presen tation paper References 1 I N Alon J Bruck J Naor M Naor R Roth Construction asymptotically good lowrate error correcting codes pseudorandom graphs IEEE Trans Inform Theory 38 1992 509516 2 NH Bshouty Exact learning monotone theory 1form Comput 123 1995 146153 31 PN JohnsonLaird Mental Models Harvard University Press Cambridge MA 1983 4 PN JohnsonLaud RMJ Byrne Deduction Lawrence Erlbaum London 1991 S H Kautz M Kearns B Selman Horn approximations empirical data Arttjkial Intelligence 74 1995 129145 6 H Kautz B Selman Hard problems simple default logics Artificial Intelligence 49 1991 243279 7 1 R Khardon D Roth Learning reason Proceedings AAAI94 Seattle WA 1994 682687 8 R Khardon D Roth Learning reason restricted view Workshop Computational Learning Theory 1995 301310 9 R Khardon D Roth Reasoning models Artificial Intelligence 87 1996 187213 101 J Kolodner CaseEased Reasoning Morgan Kaufmann Los Altos CA 1993 111 SM Kosslyn Image Mind Harvard University Press Cambridge MA 1983 121 HJ Levesque Making believers computers Arttficial Intelligence 30 1986 81108 131 HJ Levesque Is reasoning hard Proceedings 3rd NIX Research Symposium 1992 141 J McCarthy PJ Hayes Some philosophical problems standpoint artificial intelligence B Meltzer D Michie eds Machine Intelligence Vol 4 Edinburgh University Press Edinburgh 1969 15 1 M Minsky A framework representing knowledge PH Winston ed The Psychology Computer Vision McGrawHill New York 1975 RJ Brachman HJ Levesque Readings Knowledge Representation Morgan Kaufmann Los Altos CA 1985 161 J Naor M Naor Smallbias probability spaces Efficient constructions applications SIAM I Compuf 22 1993 838856 171 CH Papadimitriou On selecting satisfying truth assignment Proceedings 32nd Annual IEEE Symposium Foutuiations Computer Science 1991 181 J Pearl Probabilistic Reasoning Intelligent Systems Networks Plausible Inference Morgan Kaufmann Los Altos CA 1988 191 R Reiter A logic default reasoning Artcial Intelligence 13 1980 81132 201 R Reiter Nonmonotonic reasoning Annual Reviews Computer Science Annual Reviews Inc Palo Alto CA 1987 147188 21 R Reiter A theory diagnosis principles Artificial Intelligence 32 1987 5795 221 D Roth Learning reason nonmonotonic case Proceedings IJCAI95 Montreal Que 1995 1178l 184 23 D Roth On hardness approximate reasoning Arttficial Intelligence 82 1996 273302 1241 D Schuurmans R Greiner Learning default concepts Proceedings IOth Canadian Conference Artificial Intelligence CSCSI94 Banff Alta 1994 R Khardon D RothArtcial Intelligence 97 1997 169193 193 25 B Selman Tractable default Toronto Ont 1990 reasoning PhD Thesis Department Computer Science University 261 B Selman H Kautz Modelpreference 1271 B Selman H Kautz Knowledge compilation 281 B Selman HJ Levesque Abductive default default theory approximation theories Artificial Intelligence 45 1990 287322 J ACM 43 1996 193224 core Proceedings computational reasoning AAAI90 Boston MA 1990 343348 291 DS Touretzky multiple inheritance JF Horty RH Thomason A clash intuitions current state nonmonotonic systems Proceedings IJCAI87 Milan Italy Morgan Kaufmann Los Altos CA 1987 301 LG Valiant A theory learnable Comm ACM 27 1984 1134l 142 3 1 LG Valiant Rationality Workshop Computational Oarning Theory 1995 314