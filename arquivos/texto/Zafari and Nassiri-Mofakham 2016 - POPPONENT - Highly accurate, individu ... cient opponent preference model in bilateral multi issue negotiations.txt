Artiﬁcial Intelligence 237 2016 5991 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint POPPONENT Highly accurate individually socially eﬃcient opponent preference model bilateral multi issue negotiations Farhad Zafari ab Faria NassiriMofakham Department Information Technology Engineering Faculty Computer Engineering University Isfahan 8174673441 Hezar Jerib Avenue Isfahan Iran b Faculty Science Engineering Technology Swinburne University Technology Melbourne VIC 3122 Australia r t c l e n f o b s t r c t Article history Received 4 December 2014 Received revised form 27 March 2016 Accepted 1 April 2016 Available online 8 April 2016 Keywords Bilateral multi issue negotiation Opponent modeling Bidding strategy Acceptance strategy Perceptron Multi bipartite gradient descent In automated bilateral multi issue negotiations intelligent automated agents negotiate behalf owners issues order reach agreement Modeling opponent excessively boost performance agents increase quality negotiation outcome State art models accomplish considering assumptions opponent restricts applicability models real scenarios In study restricted technique perceptron units POPPONENT applied modeling preferences opponent proposed This model adopts Multi Bipartite version Standard Gradient Descent search algorithm MBGD ﬁnd best hypothesis best preference proﬁle In order evaluate accuracy performance proposed opponent model compared state art models available Genius repository This results devised setting approves higher accuracy POPPONENT compared accurate state art model Evaluating model real world negotiation scenarios Genius framework conﬁrms high accuracy relation state art models estimating utility offers The ﬁndings indicate proposed model individually socially eﬃcient This proposed MBGD method adopted practical areas Artiﬁcial Intelligence 2016 Elsevier BV All rights reserved 1 Introduction Negotiation science art resolving kind disputes reaching consensus human parties In automated bilateral multiissue version negotiations intelligent agents engage cooperative process behalf beneﬁciaries different contradicting interests objective achieving agree ment issues Recently emergence ANAC annual international Automated Negotiating Agents Competition 23 new negotiation strategies developed Most existing sophisticated negotiation strategies typically consist set ﬁxed modules In general observed Fig 1 main components distin Corresponding author Tel 98 031 3793 4510 fax 98 031 3668 2887 Email addresses fzafarienguiacir fzafariswineduau f_z_uutyahoocom F Zafari fnasirienguiacir fnasirimofakhamyahoocom F NassiriMofakham URL httpenguiacirfnasiri F NassiriMofakham httpdxdoiorg101016jartint201604001 00043702 2016 Elsevier BV All rights reserved 60 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 Fig 1 The negotiation ﬂow adapted BOA framework 1 guished negotiating agent work BOA framework accomplish negotiation task collaborative manner 1 1 Bidding Strategy module interact opponent model component sending candidate offers opponent model receive estimated utility offers utility space opponent Next bidding strategy component decides offers selected candidate offer sent opponent proposal 2 Opponent Model module constructs model preference proﬁle opponent learning technique This model takes number offers generates estimated utilities 3 Acceptance Strategy component receives incoming offer opponent outgoing offer chosen bidding strategy component determines incoming offer acceptable agent If received offer opponent good accepted accept message provided sent opponent response Otherwise outgoing offer previously chosen bidding strategy component forwarded opponent response1 According BOA framework negotiation strategy functions follows soon agent receives new offer2 opponent bidding history opponent model immediately updated steps 1 2 This process assures agent updated information opponent Then turn bidding strategy module generates number candidate bids similar utilities agent sends opponent model The oppo nent model calculates estimated utilities received bids renders bidding strategy component response steps 3 4 Next bidding strategy component chooses candidate bids according oppo nent model strategy example best bid chosen forwards bid acceptance strategy module step 5 Finally acceptance strategy decides accept newly received bid opponent step 1 send bid recently received bidding strategy component step 5 Identifying offers mutually beneﬁcial avoiding nonagreement offers earlier agreements beneﬁts applying opponent modeling 7 Despite variety opponent modeling techniques current models rely small common set learning techniques 7 It believed restricting nature negotiation problem The core opponent modeling learning technique Moreover traditional learning techniques mainly comprised nonoverlapping learning classiﬁcation prediction phases Since single negotiation session bids training examples available time advance traditional learning techniques easily applied An opponent model able learn incrementally update new training examples offers arrive negotiation session necessity These learning techniques collectively referred adaptive models 8 aforementioned phases performed parallel Another problem negotiation setting training instances lack output variable variable contains utility values received bids opponents view That agent aware preference proﬁle opponent calculate values output variable Therefore speciﬁc opponent models required capable modeling preferences opponent need value output variable Strictly speaking model use unsupervised learning technique preestimate utility values received bids opponent 1 An elaborated analysis state art acceptance strategies performance optimal acceptance mechanisms carried Baarslag et al 45 Baarslag Hindriks 6 respectively 2 The terms offer bid interchangeably article F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 61 use estimated values output label training examples In order overcome limitation existing opponent models use subset following 13 assumptions extract preferences opponent 9 Assumption 1 The bidding strategy opponent follows concession based pattern That bidding strategy agent generates sequence bids order agents preference bids This assumption reduces opponent modeling problem problem estimating utility bids outcome space estimated utilities close real utilities possible Assumption 2 The ﬁrst bid sent opponent highest possible utility opponents utility space That opponent sends preferable bid beginning negotiation session The ﬁrst bid embodies best possible values negotiable issues As rational agents try maximize utilities surprising assumption holds true rational agents Assumption 3 There inverse relation importance issue number times value changes negotiation session In words agents rarely change value issues great importance important issue lower tendency agents change value 1011 Obviously validity assumption depends agents bidding strategy domain Assumption 4 There direct relation importance issue value number times offered Here agents seek offer issue value greater importance greater evaluation value successive offers send negotiation session Here validity assumption depends agents bidding strategy domain Assumption 5 The evaluation functions negotiation issues deﬁned number functions predeﬁned shapes model proposed Hinkriks Tykhonov 12 Clearly objective applying assumption limit number hypotheses opponents hypothesis space Assumption 6 The negotiation issue weight values simply calculated according rankings negotiation issue weights model proposed Hinkriks Tykhonov 12 Obviously like Assumption 5 objective reduce opponents hypothesis space size Assumption 7 The utility values bids offered opponent negotiation session distributed constant speciﬁc number 1 Since rational agents objective maximize utilities assumption assumed valid rational agents Assumption 8 All negotiation issues equal importance opponent In words negotiation issues equal weight values 13 Obviously purpose making assumption limit size opponents hypothesis space Assumption 9 The negotiation issues conﬂicting agents Here evaluation negotiation issue value opponent given 1 minus evaluation negotiation issue value agent models proposed Jazayeriy et al 14 Zhang et al 15 Obviously objective assumption limit space size opponents hypothesis Assumption 10 The utility values offers received opponent known agent models proposed Hinkriks Tykhonov 12 Williams et al 16 Assumption 11 The utility function opponent completely known agent In words agent perfect information preference proﬁle opponent Assumption 12 The utility value offer received opponent equals minus utility offer agent In words preference proﬁle opponent opposite agents preference proﬁle Assumption 13 The utility value offer opponent equals utility offer agent In words preference proﬁle opponent agent Another diﬃculty modeling opponents preferences bilateral negotiations related time factor In discounted negotiations 2317 utility offer decreased negotiation time passes reaching agreement early possible extreme importance Since constructing opponent model costly computa tional sense agent tradeoff nonapplication opponent model saving time 62 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 applying increasing utility gained opponent model In words nonapplication agent save time better explore outcome space looking agreement result gain utility On hand applying opponent model assist agent appropriate agreements This tradeoff referred timeexploration tradeoff 9 The post event analysis ANAC tournaments 2317 conﬁrms computational complexity opponent models poor accuracy main factors degrade performance agents applying models 9 In particular time factor paramount importance online opponent models In models participating agents usually exchange limited number offers negotiation deadline met contain information accurately train opponent model 1218 Consequently ability model extract information possible training bids receives highly essential Due time restriction limited number offers agents exchange negotiations proper opponent model following features 1 Functionality based assumptions robust opponents following assumptions 2 Having lowest possible computational cost timeexploration tradeoff 3 Extracting information bids especially important online opponent models 4 Incremental training capability To learn issue weight values individual utility function layered architecture essential Thus order overcome aforementioned diﬃculties justify features outlined new model based perceptron units proposed agent incomplete information order model preference proﬁle opponent bilateral multi issue negotiations Moreover applicable real world negotiations fewer realistic assumptions state art models applied study This obtained proposing opponent model named POPPONENT based adapted version standard gradient decent search named Multi Bipartite Gradient Decent Search applies fewer assumptions The model shows success practical AI area modeling users preferences bilateral multi issue negotiations incomplete information The remainder paper organized follows Section 2 contains literature review Section 3 general negotiation setting described Section 4 mathematical concepts underlying perceptron based learning proposed opponent model based perceptron units introduced Section 5 experimental setup evaluating proposed model carriedout examination discussed accuracy compared proposed model classic state art opponent models Next eﬃciency model practice real examples presented Finally Section 6 paper concluded 2 Literature review In section opponent models general technical perspectives reviewed Sections 21 22 respectively State art opponent models currently available Genius3 Repository discussed Section 23 21 General classiﬁcation opponent models There aspects related opponent learnt negotiation session Actually opponent considers attributes based try learn existing opponent modeling techniques These gener ally categorized following 7 Category 1 Models try estimate reservation value opponent 1920 Category 2 Models try estimate deadline opponent 1920 Category 3 Models try estimate order opponents preferences different negotiation issues exact value order issue weights 14152122 Category 4 Models try estimate order opponents preferences different negotiation outcomes exact value order utilities offers 12162326 Category 5 Models try learn opponents bidding strategy 202729 Category 6 Models try learn opponents acceptance strategy 3031 The function models ﬁrst category based assumption agents usually stop conceding close reservation values minimum acceptable utility agent exhibit behavior approaching negotiation deadline This means beginning negotiation agents offer bids F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 63 far greater utilities reservation values 7 For example model proposed Gwak Sim 19 simple single issue negotiation based price Bayesian method adopted estimate reservation price opponent They assume reservation prices negotiation deadlines agents private knowledge In model number hypotheses form r v v considered possible values v reservation price r v opponent Next Bayesian learning process applied update probability values hypotheses hypothesis space3 offers received opponent negotiation session Then weighted average hypotheses calculated considered estimated reservation value opponent In model bidding strategy opponent assumed follow kind concession function Using opponents estimated reservation price reservation value buyerseller bidding prices generated ascendingdescending order Assuming opponent uses preknown bidding strategy illustrated agent easily compute opponents reservation price given deadline vice versa Given value estimations agent able determine optimal bidding strategy In model opponent assumed discrete reservation prices fraction difference maximum minimum possible prices considered negotiation This model adopted real world real world negotiations complex contain issues price issue Furthermore agents complex domains exhibit complicated behavior simply following typical concession strategy accordingly need design model operate complex realistic scenarios As example model proposed Yu et al 20 similar model Gwak Sim 19 opponent model learning reservation value deadline opponent assumed private information single issue bilateral negotiation In article model proposed based Bayesian learning regression analysis This shows method adopted adapting agents strategy opponent Similar previous model model assumes opponent follows preknown concession based strategy unknown parameters model applicable realistic scenarios multiple issues subject negotiation opponent follows complex bidding strategies The second category run models try estimate deadline opponent Obviously models speciﬁcally adopted scenarios opponent private deadline However famous settings like ANAC assumed negotiating parties common deadline reach agreement For example models proposed Gwak Sim 19 Yu et al 20 category The category includes models try learn order opponents preferences different negotia tion issues In words try estimate weights issues according opponents view Faratin et al 21 believe obtaining information preference order negotiation issues opponents perspec tive suﬃcient improve outcome negotiation session Therefore problem learning opponents utility function simply reduced learning order issue weights opponents context In models possible permutation issue weight order considered hypothesis hypothesis space Bayesian formula applied update probability hypothesis new bid received opponent For example models devised Niemann Lang 22 Jazayeriy et al 14 Zhang et al 15 fall category These mod els assume restricted types bidding behaviors opponent For example model proposed Jazayeriy et al assumes opponent follows following concession strategies 1 Boulware 2 Fixed Concession 3 Conceder Moreover assume agent knows aforementioned strategies opponent follows Here assumed negotiation issues monotonic conﬂicting meaning increasing util ity value agent issue cause opponents utility issue decline Obviously assumptions generally hold true real world negotiations Contrary model presented Jazayeriy et al 14 assumes issues conﬂicting model Gwak Sim 19 assumed agents announce preference direction acceptable value ranges issue starting negotiation session In words agents preference directions considered common knowledge information negotiation For example buyer agent announces range acceptable prices 100 200 It declares inverse relation price utility In words higher price values lower utility values vice versa consequently negotiating parties know conﬂicting issues negotiate issues That agents able easily pick values maximum utilities nonconﬂicting issues Thus need negotiate values issues It assumed opposite correlation weight issue number times value changed In model proposed Zhang et al 15 agent analyzes history containing offers received opponent applies Bayesian Learning learn opponents preferences negotiation issues The learnt orders issue weights incorporated counter offer proposition algorithm enable agent propose offers mutually beneﬁcial agent opponent Similar model proposed Jazayeriy et al 14 model assumed issues conﬂicting With assumption hypothesis space possible utility functions limited possible orders negotiation issue weights It assumed opponent follows timedependent concession strategy 33 known parameters The counteroffer proposition mechanism agent compensates issues high impor tance opponent By tradeoff mechanism agent tries ﬁnd bids greater utilities 3 The term hypothesis space Anderson et al Machine Learning book 32 reference space containing hypotheses 64 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 agent opponents target utilities In words agent try propose offers mutually acceptable agent opponent It obvious assumptions necessarily hold true real world opponent follow assumptions models prone failure The models fourth category estimate preference order existing bids outcome space opponents view In fact models category try estimate utility function opponent use function calculate utility given bid opponents utility space Some models 12162326 based Bayesian formula 34 classiﬁed category These models consider hypothesis space preference order negotiation issues evaluation values negotiation issue They update probability hypothesis Bayesian formula consecutive manner offer received opponent negotiation session For example model proposed Hindriks et al 12 fact basic model underlying Bayesian models 162426 estimates utility function opponent includes estimated values weights negotiation issues estimated evaluation values negotiation issue value Bayesian formula This model extremely similar model proposed Zhang et al 15 different ways ﬁrst hypothesis space contains evaluation functions orders issue weights However model proposed Zhang et al 15 hypothesis space reduced assuming negotiation issues conﬂicting possible ranking issue weights assumed hypothesis space Second model proposed Hindriks et al 12 normal distribution calculate probability observing bid given condition hypothesis holds P Dh model proposed Zhang et al 15 receipt new offer best hypothesis accurately estimates utility new offer calculated resultant value estimate value P Dh hypotheses The ﬁfth category comprises models try learn bidding strategy opponent The bidding strategy deﬁned speciﬁc function maps negotiation state bid 7 In words bidding strategy generates sequence successive bids going presented opponent round negotiation This function time dependent behavior dependent imitative function 33 The strategy proposed Krimpen et al 10 example time dependent function bidding strategy presented Fatima et al 35 Moreover bidding strategy Baarslag et al 24 behavioral function types compensates nice opponent The models category classiﬁed classes 1 Regression analysis models 2 Time series forecasting models 7 Regression analysis models assume bidding strategy opponent deﬁned formula unknown parameters problem estimating bidding strategy opponent easily reduced regression analysis utility values received offers opponent agents utility space The model proposed Yu et al 20 falls category On hand time series forecasting models bidding strategy opponent totally unknown agent information bidding strategy formula Therefore agent uses time series order forecast utility values upcoming received offers agents utility space In words models receive list timely ordered utility values input generate output probable utility values For example models devised Williams et al 2729 Carbonneau et al 28 fall category The models sixth category try estimate acceptance strategy opponent The acceptance strategy agent deﬁned Boolean function receives typical bid input produces Boolean value showing bid acceptable agent It important agent learn function improving negotiation outcome determine best bid agent acceptable opponent 7 One works deals proposing acceptance strategy learning method article Lau et al 30 In model offers sent agent opponent considered unacceptable bids offers received opponent considered acceptable ones These bids fed Bayesian learning model training examples probability accepting candidate bid opponent determined The model proposed Aydogan Yolum 31 falls category This model estimates acceptability model inductive learning In model sent offers considered negative instances received offers considered positive instances applied learning target function 22 Technical classiﬁcation opponent models In general classiﬁcation models classiﬁed based aspects opponent learnt However according underlying scheme applied extract opponents preferences existing state art opponent models use common negotiation setting estimating preference order negotiation outcomes designed implemented Genius framework 3637 ANAC tournaments categorized following 38 1 The Bayesian models estimate preference proﬁle opponent generating set candidate proﬁles hy potheses Bayesian learning update probabilities hypothesis The models assumptions bidding strategy opponent 2 The Frequency models estimate issue weights evaluation values considering changing frequency value issue successive bids frequency issue value offered respectively Unlike F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 65 Bayesian models strong assumptions bidding strategy opponent models group assumptions value distribution issues opponents preference proﬁle impose weak restrictions bidding strategy opponent 9 3 The Value models frequency models assume equal constant values issue weights focus estimating evaluation values issue value instead Though assuming constant equal values issue weights degrade models accuracy agent free need estimating issue weights Bayesian opponent modeling techniques allegedly prominent popular probabilistic approaches opponent modeling 7 generate hypotheses opponents preferences Upon receiving new offer opponent update probabilities associated hypotheses 912 These models based ﬁrst assumption models strong assumptions bidding strategy opponent On hand frequency models value models reliant fourth assumptions cases second assumption rely ﬁrst assumption That models usually sumptions value distribution issues opponents preference proﬁle depend opponents bidding strategy However clear opponent stick underlying assumptions models Therefore uncertainty validity assumptions negotiations different opponents modeling techniques potentially subject failure strongly count opponent follow subset assumptions 9 23 State art opponent models All classes technical classiﬁcation try estimate utility function opponent correspond fourth category general classiﬁcation Section 21 In article frequency models value models differentiated value models considered frequency models In fact frequency models value models extract issue weight values opponents behavioral verbal reﬂection In Section 5 accuracy newly proposed model compared state art frequency value models Bayesian classic models available Genius repository These models brieﬂy explained 1 AgentLG Freq Model evaluation value simply estimated based frequency value offered Issue weights simply assumed uniform 3637 2 AgentX Freq Model complex variant HardHeaded Freq model tendency opponent repeat bids concern The weight issue computed based number times value changes 3637 3 CUHKAgent Freq Model evaluation values computed based frequency offered The utility value bid estimated calculating sum evaluation values issues bid dividing best possible score normalize utility value Only ﬁrst 100 unique bids model estimation Issue weights simply assumed uniform 39 4 HardHeaded Freq Model evaluation values calculated based frequency offered The weight issue calculated based number times value changes 10 5 InoxAgent Freq Model evaluation values calculated based frequency offered The important issue value repeated successive bids The weight issue calculated based number times value changes The higher importance issue unchanged value remained 3637 6 Nash Freq Model computes evaluation values based frequency offered The weight issue calculated based number times best assumed value issue changed 3637 7 Smith Freq Model evaluation values computed based frequency offered The weight issue calculated based distribution values issue 11 8 The Fawkes Freq Model evaluation values determined based frequency successive bids The issue weights determined based number times value changes This model similar InoxAgent Freq Model slight difference unchanged issue values determined comparing values ﬁrst bids received opponent 40 9 IAMHaggler Bayes Model eﬃcient implementation Bayesian Scalable model similar Scalable Bayesian model assumed opponent uses particular timedependent concession function 16 10 TheNegotiatorReloaded Bayes Model similar IAMHaggler Bayes Model slight difference uses differ ent parameters supposed concession function opponent 40 11 Scalable Bayes Model issue weights evaluation values estimated Bayesian learning First initializes hypothesis space possible preference proﬁles opponent Next repeatedly updates probability value based assumption opponent concedes according linear function 12 12 Perfect IAMHaggler Bayes Model IAMHaggler Bayes Model equipped perfect infor mation 16 13 Perfect Scalable Bayes Model Scalable Bayes Model equipped perfect information 12 66 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 Table 1 Classiﬁcation state art opponent models Genius repository Opponent model Type Estimating Issue weights Evaluation values Assumptions AgentLG Freq AgentX Freq CUHKAgent Freq HardHeaded Freq InoxAgent Freq Nash Freq Smith Freq TheFawkes Freq IAMHaggler Bayes TheNegotiatorReloaded Bayes Scalable Bayes Perfect IAMHaggler Bayes Perfect Scalable Bayes Perfect Model No Model Worst Model Opposite Model Note F B C stand Frequency based Bayesian Classic Fa F F F F F F F B B B B B C C C C No Yes No Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes 8 4 4 3 8 4 4 3 4 3 4 3 2 4 3 4 3 2 6 5 1 6 5 1 6 5 1 10 6 5 1 10 6 5 1 11 13 11 12 14 Perfect Model The agent perfect knowledge preferences opponent In words oppo nents utility function known agent 3637 15 No Model agent model estimated utility given bid equals utility bid opponents utility space 3637 16 Worst Model This model opposite Perfect Model utility given bid Worst Model equals 1 minus real utility bid obtained Perfect Model 3637 17 Opposite Model assumed estimated utility given bid equals 1 minus utility bid agents utility space 3637 All models Genius repository assumptions adopts modeling opponents preferences tabulated Table 1 Section 1 As observed seventeen opponent models Frequency based Moreover AgentLG CHUKAgent estimate evaluation values issue weights estimate issue weights evaluation values With respect technical classiﬁcation Section 22 newly proposed model ﬁt categories Hence new class deﬁned named PerceptronBased Models proposed model ﬁt More proposed model ﬁts best fourth category described general classiﬁcation Section 21 Nonetheless best knowledge proposed model fourth category speciﬁcally uses neural networks neuron units underlying learning technique Our model ﬁrst proposed model fourth category uses perceptron units underlying mathematical basis opponent modeling 3 Negotiation setting The negotiation setting corresponds state art models setting ﬁeld automated negotiations 13173638 ANAC 201020134 Automated agents alternatively exchange offers compete reach joint agreement set issues bilateral negotiations The issues possible values issue constitute domain For domain preference proﬁles negotiation domain construct negotiation scenario The interaction negotiating parties regulated negotiation protocol deﬁnes rules proposals exchanged 17 In setting alternating offers protocol applied 42 Negotiation bilateral exactly parties negotiating set issues Each issue associated set possible values The agents repeatedly exchange offers successive rounds reach mutually acceptable outcome The negotiation deadline reached speciﬁed number rounds N passed This type negotiation setting commonly referred round based setting Each agent tries advantage party gaining maximum utility A negotiation breakoff causes negotiating parties obtain reservation values Therefore agents try reach agreement deadline A negotiation session takes place negotiation scenario consists negotiation domain alternatively outcome space preference proﬁles alternatively utility space negotiating agent 4 In 2014 setting added negotiations nonlinear utilities ultra large domains ANAC 2015 considered multiparty negotiations 41 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 67 The negotiation domain Ω speciﬁes possible offers ω agents send receive Each offer possible outcome vector cid4ω1 ωncid5 component mapping issue value ωi v i1 v imi mi number possible values issue 1 n 17 A preference proﬁle cid4ω U ωcid5 ω Ω ω maps possible offer ω Ω value 0 1 range based hand consists utility function U overall relative value offer agent In multiissue negotiations common assumption utility offer computed weighted sum utilities associated values issue 124347 Accordingly negotiation setting agents use linear additive utility function shown Equation 15 deﬁned set weights w corresponding evaluation functions evaluation values evaliωi 1 n issue value ωi given offer ω ω U ncid2 i1 w ievaliωi 1 In words preference proﬁle agent modeled linear combination set weights measures relative importance negotiation issues number individual utility functions evaluation functions calculate utility possible value negotiation issue Unlike negotiation domain publicly known negotiating parties preference proﬁle private agent agents aware weights evaluation values associated preference proﬁle Without losing applicability newly proposed model sake simplicity negotiation setting assumed issue value ωi offer takes ﬁnite set discrete values This negotiation setting online agent allowed use offers exchanged single negotiation session model preferences opponent learning sessions authorized Unlike oﬄine opponent models negotiation information different negotiation sessions similar opponents applied modeling preferences opponent online models 1012 history previous negotiations provided opponent model 79 4 POPPONENT perceptronbased opponent model As explained Section 2 state art models fall categories Frequencybased Bayesian models suffer dependency categorybased restricting set assumptions model opponent In study eﬃcient model designed based perceptron units dependent assumptions opponent In fact unlike nonclassic state art models Table 1 depend number restricting assumptions model relies assumption 1 10 In real negotiation problems training examples bids given advance gradually acquired time Therefore model required updated right bid encountered For purpose proposed perceptronbased opponent model POPPONENT adopts incremental gradient descent stochastic gradient descent algorithm eﬃciently learn preference proﬁle opponent linear scenarios The mathematical details approach presented Section 41 The algorithm perceptronbased opponent model proposed Section 42 41 Mathematical justiﬁcations 411 Perceptronbased learning In order enable agent learn preference issue weight values individual utility functions opponent negotiation session bilateral multiissue negotiations standard simple perceptron units adopted basic units construct ANN 324850 Fig 2 A simple perceptron unit takes vector real valued inputs x1 xn calculates linear combination values linear additive function Equation 3 cid3 O x1 xn w 0 w 1x1 w 2x2 wnxn 0 1 1 3 edge weights w real valued parameters determine contribution inputs xi perceptron output O quantity w 0 speciﬁc threshold 0 When inputs received perceptron unit weighted inputs combination exceeds threshold perceptron produces 1 output produces 1 The weights known advance adjusted training instances speciﬁc learning algorithm like gradient descent speciﬁc training rule like delta rule 32 The error real 5 In discounted scenarios 2317 utility offer decreases time according discount factor Discounted utility U D follows U D ω U ω dt d 0 d 1 t 0 t 1 discount factor negotiation time respectively 2 68 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 Fig 2 A simple unit perceptron 32 Fig 3 The Perceptron unit learn issue weights b learn evaluation values output output produced perceptron unit minimized giving training example training set perceptron unit adjusting edge weights according training rule like delta rule successive manner 412 Multi bipartite incremental gradient descent search priorities evaluations evalOP ωi corresponding possible value ωi v i1 v imi As mentioned Section 3 bilateral multiissue negotiations preference proﬁle opponent private agent Therefore agent learn offers training instances received opponent speciﬁc learning algorithm In linear scenarios preference proﬁle comprised number negotiation issue weights mi w OP number possible values issue 1 n Since issue weights evaluations opponents preference proﬁle unknown agent proposed model applies types perceptron units 32 learning opponents preferences multi bipartite incremental gradient descent search The constituting parts algorithm execute separate overlapping steps ﬁrst step Fig 3a evaluation values issue weights assumed inputs perceptron unit weight vector elements perceptron respectively Next gradient descent applied adjust issue weights perceptron type 1 second step shown Fig 3b issue weights evaluation values assumed inputs multiple copies perceptron unit weight vector perceptron units respectively Next evaluation values adjusted feeding issue weight values input perceptron units perceptron type 2 In words objective perceptron units eﬃciently learn issue weight values w OP 1 ω1 1 issue given negotiation domain issue evalOP ωi v i1 v imi mi possible evaluation values issue This means total number perceptron units type 2 learning evaluation values calculated Equation 4 n ωn possible values ωi v i1 v imi evaluation values evalOP w OP n n2 ncid4 i1 mi 4 Moreover order learn negotiation weight values perceptron unit type 1 suﬃce total n2 1 perceptron units needed learn preference proﬁle opponent Here types perceptrons work manner given time perceptron type 1 works single perceptron type 2 Upon receipt new offer cid4ω1 ωncid5 opponent perceptron unit calculates utility offer perceptron learning algorithm learn preference proﬁle opponent By inserting training example perceptron algorithm tries estimate real preference proﬁle opponent minimizing error produced real output adjusting weight vector values perceptron unit iterative manner The learning problem Fig 3a determines weights w OP 1 n sense training error learnt hypothesis vector weight values minimized The learning problem Fig 3b determines evaluation values evalOP ωi sense training error learnt hypothesis vector evaluation values minimized w OP F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 69 Fig 4 Moves locating global minimum plane error values associated different hypotheses weight vectors gradient descent b incremental gradient descent 32 The hypothesis space possible weights w 1 w 2 sample 2issue domain associated error values presented Fig 4 To ﬁnd minimum point ﬁrst incremental gradient descent stochastic gradient descent optimization algorithm begins initial point error surface repeatedly updates weight values weight vector search directed steepest descent error surface In algorithm weight values updated right single training example encountered incremental manner This process continues global local minimum achieved The error modeling opponents preference proﬁle formulated follows k E cid2 k Ed dωD 5 Ed k individual error training instance dω value calculated Equation 6 Ed k cid4 td od2 evalOPcid5 opponent preference proﬁle n ωncid5 ωi v i1 v imi k 1 2 dω w OP 1 n set training examples td target output dω cid4evalOP 1 ω1 evalOP dω The real output value training example n vnmn cid5 contains evaluation values n vn1 evalOP vector possible values issues The set training examples D includes evaluation values possible offers outcome space cardinality calculated Equation 4 dω od output linear unit training example cid5 issue weights vector D evalOP cid4evalOP 1 v 1m1 evalOP 1 v 11 evalOP w OP cid4w OP 1 w OP 6 n According function delivers utility value bid Equation 1 utility value given training instance dω calculated Equation 7 od ncid2 i1 evalOP ωiw OP By inserting Equation 7 6 6 5 Equation 8 yielded E k 1 2 cid2 dωD cid5 td ncid2 i1 cid62 evalOP ωiw OP 7 8 represents training error training examples In Equation 8 ωi value issue training instance dω The objective minimize error E searching best preference proﬁle yields minimum error estimated offer utility values according bidding behavior opponent td estimated offer utility values according current values preference proﬁle opponent cid7 n i1 evalOP ωiw OP 70 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 training examples D The direction steepest descent error surface determined computing gradient derivative E respect component opponent proﬁle vector k This derivative vector respect vector k calculated Equation 9 E k E cid8 w OP evalOP cid9 cid10 cid11 E w OP E evalOP 9 Since gradient calculated based Equation 9 speciﬁes direction yields steepest increase E negative value yields direction steepest decrease The training rule gradient descent search expressed Equation 10 k k η E k cid5 k 10 k cid5 positive constant η learning rate determines step size gradient descent search Writing Equation 10 componential form yield ki ki cid5ki 11 cid5ki η E ki cid7 n 1 issues total number components vector total possible values issues evalOP Provided component ki weight value following equations yielded evaluation values vector i1 mi n mi number possible values issue n number negotiation k equals total number negotiation issues n plus w OP k Equation 11 contains issue weights vector cid7 n i1 mi The vector cid5w OP η E w OP wOP w OP cid5w OP In order achieve steepest descent component w OP weight vector w OP proportion E wOP 12 altered Applying Equation 8 gradient E respect w OP Equation 12 calculated Equation 13 cid2 1 td od2 E w OP w OP 2 cid2 dωD w td od2 2td od w OP td od td od w OP td od w OP cid8 td od evalOP td od cid5 ncid2 td i0 cid9 ωi 1 2 dωD cid2 1 2 dωD cid2 dωD cid2 dωD cid2 dωD cid6 evalOP ωiw OP Now combining Equations 12 13 training rule updating weight values obtained follows w OP w OP η td odevalOP ωi cid2 dωD Once provided component ki evaluation value Equation 11 modiﬁed cid5evalOP v j η E evalOP v j evalOP v j evalOP v j cid5evalOP v j 13 14 15 j 1 mi mi number possible values issue 1 n n number issues Similar Equation 13 training rule applied learning evaluation values expressed Equation 16 E evalOP v j evalOP v j 1 2 cid2 dωD td od2 16 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 71 evalOP v j td od2 2td od evalOP v j td od cid2 1 2 dωD cid2 1 2 dωD cid2 td od dωD cid2 dωD td od evalOP v j evalOP v j td od cid5 td ncid2 i0 cid6 evalOP ωiw OP If exists dω D ωi v j Equation 17 yielded E evalOP v j cid2 cid8 td od w OP cid9 dωD If Equation 18 yielded E evalOP v j 0 Combining Equations 15 17 18 yield evalOP v j cid12 evalOP evalOP v j η v j cid7 dωD td odw OP dω D ωi v j 17 18 19 Equation 19 means evaluation value value v j evalOP v j remains unchanged long met training example At point deduced order movement steepest descent direction error surface values according Equations 14 19 respectively different preference proﬁles calculating evalOP suﬃce updating opponent preference proﬁle v j w OP When suﬃciently small learning rate η gradient descent search assures convergence vector minimum error regardless training examples linearly separable If η large search approach risk exceeding vector minimum error error surface Therefore appropriate learning rate essence 32 This gradient descentbased opponent modeling algorithm subject major drawbacks 1 verging local minimum slow 2 multiple local minima error surface guarantee procedure ﬁnd global minimum 32 Besides real world negotiation problems offers training examples provided advance If training examples available advance reaching global minimums mean obtaining 100 percent accuracy zero error predicting output values input values set available training instances These diﬃculties alleviated incremental stochastic version gradient descent As mentioned non v j values separately training instances w OP applies v j values respectively Equations 14 19 However incremental values updated right offer received according incremental gradient descent ﬁrst calculates cid5w OP target values provided current evaluation values vector evalOP calculating w OP stochastic gradient descent evalOP following delta equations evalOP weight vector v j w OP cid5evalOP cid12 evalOP v j w OP w OP evalOP evalOP v j ηtd odw OP v j ηtd odevalOP ωi ωi v j 20 21 Equation 20 reveals incremental gradient descent evaluation values updated met training instance dω Equation 20 rewritten Equation 22 e valOP ωi e valOP ωi ηtd odw OP 22 Now order ﬁnd best preference proﬁle incremental gradient descent algorithm training dω met Equations 21 22 applied evaluation values values observed instance bid cid4ω1 ωncid5 weight values updated Having introduced mathematical basics algorithm Section 42 present algorithm based incremental gradient descent learning extract preference proﬁle opponent 72 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 42 POPPONENT algorithm The newly introduced multi bipartite incremental gradient descent stochastic gradient descent search Section 412 applied learn preference proﬁle opponent linear scenarios To serve purpose learns issue ωi possible values ωi v i1 v imi priorities weight values w OP 1 mi number possible values issue negotiation issues 1 n negotiation domain This proposed algorithm incremental version perceptronbased learning method Section 41 applies parameters η N input Parameter η represents learning rate determines step size gradient descent search Parameter N represents number training repeats training instance This algorithm includes separate functions initializer updater n evaluation values evalOP w OP The ﬁrst function invoked model generated essential parameters proposed model importantly preference proﬁle opponent issue weights w OP ωi issue values initialized By trying different initial points realized 05 midpoint hypothesis space 1 n Algorithm line 13 Similarly best point initializing evalOP weight values w equal weights 1 ωi values ωi v i1 v imi The second function receives offer vector ω speciﬁes issue values negotiation issues new offer recently received opponent That soon new offer received opponent function invoked update model based newly received bid It updates estimated preference proﬁle opponent adjusting evalOP ωi w values Algorithm lines 18 21 Whenever new offer received opponent ω function perceptron learning delta rules Algorithm lines 18 21 repeated N times The EstimatedUtilityOP receives offer input returns estimated utility value offer opponents utility space output n chosen issues Algorithm line 14 evaluations evalOP In algorithm instead updating evalOP values training examples met evalOP value modiﬁed training delta rules right single training instance met incremental manner Algorithm lines 18 21 Therefore algorithm easily applied realistic negotiation scenarios training examples opponent offers gradually met time value calculating cid5w cid5evalOP ωi w OP ωi w OP The algorithm Algorithm Perceptronbased opponent model ω ω1 ωn offer vector containing values new offer received opponent 1 Where 2 η learning rate 3 N maximum number training repeats training instance 4 5 n number issues 6 mi number possible values ith issue 7 ωi denotes possible value ith issue 8 w OP weight ith issue 9 10 ωi value ith issue offer ω 11 PerceptronUtilityOP evaluation function opponent ith issue evalOP ω estimated utility offer ω opponents utility space obtained feeding offer perceptron unit getting output value 12 EstimatedUtilityOP ω function receives offer ω input returns estimated utility bid opponents utility space output This function value calculated estimated bidding behavior opponent Initializer 13 14 ωi 05 ωi v i1 v imi Initialize evaluation values evalOP 1 Initialize weight value w OP n 1 n For evaluation value evalOP Updater 15 Repeat following process N times 16 17 18 19 20 21 For issue weight value wi Do ωi Do Input instance ω unit compute output PerceptronUtilityOP evalOP ω PerceptronUtilityOP ωi ηEstimatedUtilityOP ωi evalOP ω ω w OP Input instance ω unit compute output PerceptronUtilityOP w OP ω PerceptronUtilityOP ηEstimatedUtilityOP ω evalOP ωi w OP ω F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 73 This proposed model supervised algorithm needs output labels training instances The problem preference modeling bilateral multi issue negotiations supervised learning methods separated subproblems 1 estimating utility values opponents offer history history offers received opponent negotiation session 2 extracting estimated utility function preference proﬁle opponent opponents offer history By solving ﬁrst problem opponents offer history contains ω function deals estimated offer utilities offer opponents offer history The EstimatedUtilityOP ﬁrst subproblem estimated according perceived bidding behavior opponent In article different values constant 06 08 1 adaptive applied order estimate utilities offers proposed opponent Applying constant values estimating utility value bids received opponent simplistic ﬁrst actually As explained Section 1 opponent modeling problem negotiation speciﬁc type learning problem training examples provided advance provided negotiation session incremental manner In fact designing preference model able update incremental manner important challenges modeling user preferences bilateral multi issue negotiations More importantly models number bids agents exchange reaching deadline limited 2 important challenge opponent model overcome Although estimating utilities bids received opponent constant function best choice reasonable assumption rational agents try reach highest utility following concessionbased bidding strategy 2 For example 1 assuming bids opponent sends negotiation session utilities value 1 unreasonable assumption 2 Scalable Bayesian Model proposed Hindriks et al 2 assume utility bids sent opponent follow 1 005t 0 t 1 function places utility bids received opponent 095 1 interval Obviously assumption different assuming opponent sends bids utility value 1 For fourth value use adaptive method agent estimates bids opponent offer future based opponents bid history 5155 At time t opponent offer bid utility targett value calculated based Equations 23 24 emaxt μt cid8 targett 1 cid9 cid8 1 μt dt cid9 tα 1 emaxt 23 24 emaxt estimates maximum utility bid opponent offer future μt average utility bids proposed opponent agents utility space dt determines width bids received opponent calculated based deviation Similar approach applied CHUKAgent Section 2 39 adaptive model applies ﬁrst 1000 instead 5000 unique bids negotiation session estimation order prevent accuracy decline Section 531 The computational complexity POPPONENT Algorithm linear O n analyzed Appendix A 5 Experiments To evaluate proposed POPPONENT model separate experimental settings applied assessing accuracy performance real world negotiation examples compared available opponent models 51 Experimental setting As reviewed Section 2 different settings measures applied researchers evaluating proposed models The Genius framework provided ANAC considers measures available ﬁeld Appendix B presents extensive comprehensive settings The Genius framework facilitates development evaluation negotiation agents constituting components repository largest comparable set models consistent ANAC settings6 38 Accordingly similar experimental setting adopted assess accuracy performance POPPONENT model The ﬁrst setting introduced Section 511 evaluates accuracy POPPONENT Pearson Correlation measure The second setting introduced Section 512 evaluates proposed model measuring real performance agents applying model real world experimental negotiation scenarios 511 Experiment I evaluating accuracy POPPONENT The experimental setting applied Baarslag et al automated bilateral multi issue negotiations 38 applied evaluate accuracy proposed POPPONENT model versus state art opponent models 6 Baarslag et al proposed setting evaluating comparing accuracy performance set state art opponent models currently available Genius repository 38 74 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 According setting 5 variations POPPONENT Section 42 compared total 15 opponent models including 8 Frequencybased opponent models 5 Bayesian opponent models 1 classic model Opposite model7 No Model These models tabulated Table 1 Each 20 8 5 1 1 5 opponent models equipped bidding strategy compete opponent agent The bidding behavior opponent inﬂuenced opponent model agent manners ﬁrst opponent model helps agent better offers cause negotiation end earlier high quality agreement shorter agreement second applying opponent model change bidding sequence agent cause opponent change bidding behavior For example opponent applies kind imitative bidding strategy 33 different bidding sequences agent deﬁnitely result different bidding sequences opponent Therefore able compare different opponent models models trained circumstances conﬁrmed allow nonadaptive opponents applied training proposed opponent model models Here acceptance capability negotiation strategy opponent removed equal number bids exchanged sessions This ensures opponent modeling techniques actually executed conditions 5111 Bidding behaviors agents Once accordance setting suggested Baarslag et al 38 use classes different opponents different bidding behaviors applied follows 1 Conceding agents apply time dependent concession strategy 33 bids negotiation session target utility calculated Equation 25 cid9 cid8 ut P max 1 t1e 25 concession rate e different values 01 02 1 2 applied ﬁxed starting bid utility P max 1 2 Random agents generate bid utility ﬁxed threshold m random manner Four different values 0 025 05 075 selected threshold 3 Conceding agents offset timedependent agents start negotiation best bids For purpose linear concession rate e 1 different values 07 08 09 applied starting bid utility P max 4 Nonconceding agents begin minimum target utility increases maximum utility time The target utility calculated Equation 26 ut P min 1 P mint 26 different values 0 025 05 075 applied minimum acceptable utility P min agent In accordance values 4 types conceding agents 4 types random agents 3 types conceding agents offset 4 types nonconceding agents obtained Moreover worth noting ﬁrst class reveals predictable bidding behavior begins best offer concedes makes unique trace classes considered unpredictable random offers concede begin best offers From classes second contains opponents random nondeterministic behavior comprise deterministic opponents Consequently experiment involves total 15 opponents 4 opponents ﬁrst class predictable remaining 11 unpredictable As mentioned Section 1 existing models apply subset assumptions bidding strategy value distribution issues opponents preference proﬁle Here different opponents different bidding strategies applied training opponent model accurate opponent model actually assumptions hold true real world 5112 Negotiation scenarios According Baarslag et al 38 exist following features negotiation sce nario signiﬁcantly inﬂuence ability opponent model estimating opponents preferences accurate manner 38 1 The Domain size small medium large based total number possible offers depending parameters preference proﬁle 2 The Bid distribution relates average distance outcomes scenario nearest Pareto optimal offers In high bid distribution domain high percentage outcomes distanced far Pareto frontier8 7 ANAC organizers consider Perfect Model Worst Model setting clear Pearson Correlation values According deﬁnitions Perfect Model Worst Model yield accuracy values 1 1 respectively 8 Pareto frontier The collection Pareto Bids outcome space 445659 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 75 Table 2 Negotiation setting Experiment I Opponents Bidding behavior Conceding Deterministic predictable Parameters Four opponents e 01 02 1 2 Equation 25 Random Nondeterministic unpredictable Four opponents thresholds 0 025 05 075 1 Conceding offset Deterministic unpredictable Nonconceding Deterministic unpredictable Three opponents P max 07 08 09 e 1 Equation 25 Four opponents P min 0 025 05 075 1 Equation 26 Note L M H stand Low Medium High respectively Itex vs cypress Size Small Opposition L M Ha Bid Distribution L M H Employment Size Small Opposition L M H Bid Distribution L M H s o r n e c S Car Size Medium Opposition L M H Bid Distribution L M H Supermarket Size Large Opposition L M H Bid Distribution L M H Travel Size Large Opposition L M H Bid Distribution L M H 3 The Opposition deﬁnes competitiveness domain determined minimum distances points distance KalaiSmorodinsky point unique point Pareto Frontier equal utilities parties outcome space point perfect mutual satisfaction maximum utility parties Now order evaluate proposed model complete setting possible combinations features tested Due considerable computational limitations testing domains available literature Genius Baarslag et al 38 carefully selected 5 domains considered levels domain features The domains adopted aspects affecting performance opponent models considered For purpose 45 scenarios containing 3 opposition levels 3 bid distributions levels 5 domains applied The summary setting including 15 bidding strategies 5 negotiation domains applied interactions agents tabulated Table 2 5113 Interactions This proposed opponent model trained perform deterministic opponent agents 45 aforementioned scenarios total 495 11 45 negotiation sessions As random agents negotiation session repeated 5 times eliminate randomness results ensure results reliable Consequently total 900 5 4 45 negotiation sessions run 4 types random opponents making total 1395 negotiation sessions executed All negotiation sessions executed roundbased setting equal number 5000 rounds round contains exactly bids offer sent agent associated counter offer received opponent total 6975000 1395 5000 training bids fed 20 8 5 1 1 5 opponent models training purposes The interaction agents ﬁrst experiment BOA framework applied Section 1 presented Fig 5 Agents Side B include bidding strategy opponent model follow acceptance strategy In interaction opponent model equipped arbitrary bidding strategy acceptance strategy embedded agent Side A trained competing opponent agents Side B 45 scenarios Both sides actually acceptance module module accepts This accepted opponent model order trained training instances bids 6975000 order preserve equal conditions In negotiation sessions agent Side B applies 15 bidding strategies Table 2 bidding strategy agent Side A important applies arbitrary bidding strategy Table 2 The strategies chosen setting nonadaptive required models apply bid sequences If bidding strategy Side B adaptive change according bidding strategies Side A When models apply different training instances bids compared equal conditions Since bidding strategy Side B Opponent Side nonadaptive affected bidding strategy Side A uses 20 opponent models including POPPONENT variations Therefore actually important bidding strategy applied Pareto bid A point Pareto Bid possible Pareto improvement point Pareto improvement The movement bid outcome space bid increases utility agent decreasing utility agent 76 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 Fig 5 Opponent models learning process interactions Experiment I Side A effect opponent model applied Side A This serves objective experiment train opponent models Side A 512 Experiment II evaluating performance POPPONENT To evaluate real world performance proposed model realistic setting similar setting applied ANAC organizers 38 designed To accomplish BOA framework applied Section 1 embed opponent model agent framework bidding strategy associated acceptance strategy chosen state art agents Next average performance constructed agent assessed different types components competition 5121 Agents When settings model trained determined POPPONENT compared following 6 state art opponent models Perfect Model Worst Model No Model Section 23 applied Automated Negotiating Agents Competitions ANAC Agent X Freq Model Agent LG Freq Model CUHK Freq Model Smith Freq Model HardHeaded Freq Model InoxAgent Freq Model Perfect Model Worst Model No Model Regarding components bidding strategies associated acceptance strategies ANAC 2010 ANAC 2011 ANAC 2012 ANAC 2013 timedependent bidding strategies simple acceptance strategy collected The agents equipped strategies AgentK 51 Yushu 60 Nozomi 2 HardHeaded 10 Gahbonio 61 IAMHaggler2011 27 TheNegotiatorReloaded 40 BRAMAgent2 40 InoxAgent 62 Time Dependent Conceding Agents Experiment I Table 2 5122 Negotiation scenarios Each agent competed 5 times opponents seven scenarios Grocery 17 Thompson Employment 63 Travel 2 Small Energy Supermarket ANAC 20129 40 Camera 62 ItexVsCypress 2 The size opposition bid distribution values Section 5112 scenarios tabulated Table 3 sorted bid distribution 5123 Interactions This newly proposed model opponents AP P1 9 opponent models 6 state art Perfect Model Worst Model No Model evaluated according model Fig 5 competing 9 It worth noting agents participated ANAC 2014 ANAC 2015 respectively proposed models nonlinear multiparty scenarios fall outside scope paper F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 77 Table 3 Negotiation scenarios applied Experiment II Domain Grocery Energy small Itex vs cypress Camera Thompson Supermarket Travel Size 1600 15625 180 3600 3125 112896 188160 Issues Opposition Bid distribution 5 6 4 6 5 6 7 0806 0432 0431 0891 0267 0347 023 0191 0217 0222 0252 0325 0347 0416 Fig 6 Opponent models learning process interactions Experiment II sides A B Side A agents BOA modules agents Side B opponent model In sides agents apply 13 bidding acceptance strategies consisting 9 agents ANAC competitions 4 timedependent agents In Side A exist 7 opponent models combined 13 bidding acceptance strategies Each agent competes 5 times 7 negotiation scenarios preference proﬁles agent acts sides scenario model 11830 7 5 2 13 13 sessions executed In words total number 82810 11830 7 sessions executed second experiment evaluate newly proposed model state art opponent models fair realistic competition All sessions executed Genius 42 3637 roundbased protocol equal number 1000 rounds The interaction agents second experiment expressed Fig 6 BOA framework Section 1 52 Examples Before evaluating overall results experiment settings I II section example negotiations course agents including POPPONENT No Model presented The performance proposed POPPONENT model applied Linear Time Dependent Agent Section 5111 Liner Time Dependent No Model Figs 5 6 50 rounds negotiation deadline presented Fig 7 In ﬁgure especially shows agent applying POPPONENT performs negotiation session agent model How agent No Model performs agent kind shown Fig 7b Finally utility bids agent A sends A opponent B 1 applying POPPONENT 2 applying No Model shown Fig 7c When agent A applies POPPONENT rapid agreement achieved higher utility sides In Fig 8 MBGD search method seeks minimize Standard Error Equation 5 converging zero proposed POPPONENT model trained simple TimeDependent Agent total 5000 rounds As ﬁrst 1000 rounds indicate proposed model algorithm moves minimum point error surface Fig 4 53 Experimental results The detailed experimental results comparing accuracy performance POPPONENT state art models presented Sections 531 532 The major ﬁndings summarized Section 533 78 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 Fig 7 Performance gained time dependent agent agent equipped POPPONENT b No Model c Their bid utilities vs negotia tion round Fig 8 Standard error vs negotiation round training POPPONENT time dependent opponent 531 Experiment results I accuracy POPPONENT Based setting designed Experiment I Section 511 accuracy POPPONENT compared state art opponent models Pearson Correlation estimated real bid utilities Section B1 For model Pearson Correlation 11 points time equal distances 10 time slots The accuracies 20 models F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 79 Table 4 The list opponent models Abbreviation Opponent model Participated Rank P6 P8 P1 AP PP LGF XF CKF HHF IXF NF SF FF IHB PIHB NRB SB PSB OM NM PM WM Note F Q respectively stand ﬁnal qualifying rounds ANAC agent employing model participated Perceptron Based Model Constant 06 Perceptron Based Model Constant 08 Perceptron Based Model Constant 1 Adaptive Perceptron Based Model Perfect Perceptron Based Model AgentLG Frequency Model AgentX Frequency Model CUHKAgent Frequency Model HardHeaded Frequency Model InoxAgent Frequency Model Nash Frequency Model Smith Frequency Model The Fawkes Frequency Model IAMHaggler Bayesian Model Perfect IAMHaggler Bayesian Model The Negotiator Reloaded Bayesian Model Scalable Bayesian Model Perfect Scalable Bayesian Opposite Model No Model Perfect Model Worst Model ANAC 2012 Q Fa ANAC 2012 Q ANAC 2012 Q F ANAC 2011 Q F ANAC 2013 Q F ANAC 2010 Q F ANAC 2013 Q F ANAC 2010 Q F ANAC 2012 Q F 2F 13Q 1F 1F 6Q 7F 1F 4F 3F Fig 9 Average accuracy obtained models opponent agents including 5 variations POPPONENT Section 42 classic 13 state art models Section 511 No Model10 assessed The abbreviations models listed Table 4 The average accuracy respective standard deviations opponent models opponent agents pre dictable unpredictable opponents expressed Fig 9 perfect information state PP proposed model outperforms state art models large average accuracy As observed variations POPPONENT P6 P8 P1 PP outperform state art models respect average accuracy opponents Here unlike state art models accuracy model variations increases time monotonic manner The accuracies POPPONENT variations CKF highest closest accuracy compared POPPONENT variations compared Fig 10 This ﬁgure shows POPPONENT variations AP exceed CKF models terms average accuracy As observed Fig 9 state art models lose accuracy time handle later bids incorrect manner This unique Bayesian models models assumptions bidding behavior opponent invalid time passes Most frequency models value models subject phenomenon assumptions opponents preference proﬁle 10 As mentioned footnote 6 need execute Perfect Model Worst Model accuracies clear given deﬁnition 80 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 Fig 10 Average accuracy opponent agents obtained POPPONENT variations state art opponent model necessarily hold true However true CUHKAgent frequency model uses 100 initial unique bids received opponent order update The accuracy model change initial rounds 38 It obvious POPPONENT perfect information state PP affected later bids assumption opponent However constantvalue variations POPPONENT assumption opponents bidding behavior accuracy proposed model variations low compared PP state However states accuracy POPPONENT creases gradually This attributed fact compared models model works based lower number assumptions opponent value distribution issues opponents preference proﬁle At ﬁrst look surprising PP reaches great overall accuracy uses Perfect Information estimate utility values bids received opponent fact reasons First observed Fig 9 evident accuracy Perfect Information models PSB PIHB achieve comparison PP In fact PP doubles accuracy values PSB PIHB Second adding perfect information models PP PSB PIHB mean unsupervised learning problem converted supervised learning prob lem Obviously supervised learning problems challenging problems data mining machine learning Finally mentioned Section 1 automated negotiations agents usually exchange limited num ber bids reach deadline However observed ﬁgure challenge prevent PP achieving high accuracies By time 10 percent negotiation time passed accuracy PP exceeds 60 percent By comparing accuracy AP CKF Fig 10 revealed AP outperforms CKF It noticed accuracy AP trained bids receives negotiation session reaches maximum t 02 round 1000 begins decrease Similar approach applied CKF preventing decline accuracy 1000 initial bids train AP instead 5000 bids The accuracy models Experiment I terms different features domains Size Opposition Distri bution presented Fig 11 following properties induced Property 1 POPPONENT model works better medium large negotiation domains cid2 Property 2 Accuracy POPPONENT model improves increase distribution level negotiation scenario cid2 Property 3 Most models including POPPONENT variations generally perform better scenarios medium size high level opposition high level distribution cid2 532 Experiment results II performance POPPONENT The performance model measured revealed Experiment II according setting explained Sec tion 512 Six performance measures Avg Utility Avg Time Agreement Avg Pareto Distance Agreement Avg Kalai Distance Agreement Avg Nash Distance Agreement Avg Percentage Pareto Bids applied purpose details Ta ble B1 The values aforementioned performance measures ﬁnal accuracy accuracy ﬁnal round negotiation proposed POPPONENT model state art models Experiment II tabulated Tables C1 C7 Appendix C results presented Fig 12 The content Tables C1 C7 Fig 12 indicate POPPONENT accurate model compared models available This consistent results ﬁrst experiment accuracy F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 81 Fig 11 Summary results average accuracy models opponents terms different levels domain size b domain opposition c domain distribution POPPONENT exceeds state art models By considering content Tables C1C7 POPPONENT AP IXF models models outperform models domain respect performanceaccuracy measures proposed models properties consist Property 4 In terms Pearson Correlation measure average POPPONENT accurate opponent model linear bilateral multiissue negotiations types opponents cid2 Property 5 Among models Experiment II POPPONENT eﬃcient model domain respect measures cid2 533 Key ﬁndings The results Experiment I Section 531 tabulated Tables 5 6 These results accuracies POPPONENT variations nearest opponent models accuracy POPPONENT accuracy opponent models applied winners ANAC 2012 2013 As observed tables proposed POPPONENT model perfect information state PP column reaches higher accuracy levels state art models models 82 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 Fig 12 Summary results Experiment II Table 5 POPPONENTs accuracy compared state art ANAC winners opponent model different opponent agents Opponent category All opponents Predictable opponents Unpredictable opponents Random opponents Conceding opponents offset Nonconceding opponents Accuracy POPPONENT State art opponent model ANAC winner P6 P8 P1 AP PP Model Accuracy 03872 07961 02384 03858 07663 03895 08036 02389 03665 07899 03899 08077 02379 03533 08010 03885 07325 02634 03767 07644 07299 07645 07173 08457 07444 CKF CKF PSB LGF CKF 03848 070543 03317 05406 05991 2012 CKF 03848 07054 02682 04413 05992 2013 FF 03160 04618 02630 05135 01645 03048 03020 02997 02256 05686 OM 02158 01530 00864 ANAC agents Besides Table 5 shows proposed model P1 variation fourth column ranked second PP variation state art models This includes models applied ANAC 2012 2013 agents opponents predictable conceding opponents concedingopponentswithanoffset accuracies 03899 08077 08010 respectively However state art models PSB LGF OM accuracies 03317 05406 02158 ranked second unpredictable opponents random opponents nonconceding opponents respectively The opponent model applied Agent Fawkes FF weak accuracy meaning winner ANAC 2013 agent applying eﬃcient bidding strategy acceptance strategy compensate poor accuracy opponent model That proposed POPPONENT model PP variation highest accuracy terms different levels scenario features observed Table 6 Moreover scenario size medium high proposed model P6 P8 variations respectively ranked second models state art Another intriguing observation Table 6 fact levels scenario features CUHKAgent Freq Model excellent accuracy compared F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 83 Table 6 POPPONENTs accuracy compared state art ANAC winners opponent model different scenario features Scenario feature Feature level Size Distribution Opposition Low Mid High Low Mid High Low Mid High Accuracy POPPONENT State art opponent model ANAC winner P1 P6 P8 AP PP Model Accuracy 03573 04286 04031 02772 04055 04869 03157 04151 04388 03507 04423 03960 02781 04015 04818 03192 04067 04356 03552 04301 04034 02825 04052 04808 03224 04099 04361 03575 04299 03988 02930 04025 04700 03121 04110 04424 06757 08158 07412 06583 07531 07784 06734 07606 07557 PSB CKF CKF OM CKF NF PSB CKF CKF 04011 04236 03705 04442 03979 05243 03376 04141 04492 2012 CKF 03798 04236 03705 02567 03979 04999 02912 04141 04492 2013 FF 02990 03801 03010 01288 03137 05056 01935 03315 04231 Table 7 Summary Experiment I results accurate realistic model Against All opponents Predictable opponents P1 P8 AP P6 Size P8 P1 P6 AP Top model Scenario feature Feature level Top model Unpredictable opponents Random opponents NF LGF Distribution Conceding opponents offset Nonconceding opponents P1 P8 P6 AP OM Opposition Low Mid High Low Mid High Low Mid High CKF P6 P8 AP P1 P8 P1 AP P6 OM P1 P8 AP P6 NF CKF P1 CKF Table 8 Top performing real model domain performanceaccuracy measures Experiment II Domain Utility Pearson correlation Nash distance Pareto distance Kalai distance Time Perc Pareto bids Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average IXF LGF IXF AP IXF SF AP IXF HHF SF LGF SF IXF LGF IXF LGF P1 AP P1 AP P1 AP IXF AP P1 CKF P1 HHF P1 AP P1 AP IXF XF IXF HHF CKF LGF CKF IXF IXF AP CKF AP AP LGF IXF CKF XF IXF IXF HHF IXF SF AP CKF HHF IXF LGF SF IXF LGF IXF LGF IXF XF IXF CKF CKF LGF CKF IXF IXF AP CKF SF AP LGF IXF CKF XF AP AP XF CKF LGF SF LGF IXF HHF LGF HHF AP P1 LGF SF XF P1 XF LGF P1 AP LGF SF XF P1 LGF IXF IXF XF XF P1 state art models Since agent applied winner ANAC 2012 deduced success high accuracy opponent models module agent As tabulated Table 7 average POPPONENT P1 variation accurate model vs opponents Moreover observed ﬁve levels scenario features total POPPONENT exhibited excellent accuracy comparison models recommending application POPPONENT accurate model scenarios medium large size medium distribution low medium level opposition Both Experiments I II reveal POPPONENT undoubtedly accurate model counterparts Besides expressed Tables C1C7 POPPONENT achieves highest performance Grocery domain average utility measure AP highest performance Travel ItexVsCypress domains average time agreements measure AP highest performance ItexVsCypress Nash Kalai distance mea sures AP highest performance Grocery domain Pareto distance measure AP best performance Supermarket Travel Thompson Energy Camera ItexVsCypress Pearson Correlation measures P1 best performing model Thompson domain percentage Pareto bids measure P1 These results tabulated Table 8 According Tables C1C7 Table 8 observed P1 performed terms measures intriguing performance value Pearson Correlation high performance value Percentage Pareto Bids Although accurate model high Pearson Correlation value successful making Pareto Bids high Percentage Pareto Bids value successful obtaining favorable outcomes This phenomenon observed XF However AP lower Pearson Correlation Percentage Pareto Bids values successful getting favorable utilities concluded making Pareto Bids necessarily opponent 84 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 model successful Rather optimal point Percentage Pareto Bids measure guides agent achieve highest performance 534 Summary In brief considering PP POPPONENT accurate model predictable unpredictable random conced ing opponents offset nonconceding types opponents terms different levels scenario features size opposition distribution Excluding PP POPPONENT variations performing models op ponents predictable opponents conceding opponents offset POPPONENT variations rank ﬁrst scenarios medium opposition medium distribution medium large size The results Experiment II reveal measures POPPONENT reaches highest performance domains 6 Conclusions Negotiation science art resolving disputes reaching consensus human parties Automated bilateral multi issue negotiations special kind traditional negotiations intelligent automated negotiating agents undertake task making agreement multiple issues behalf human clients Each automated negotiating agent strategy following subcomponents 1 1 Opponent Modeling 2 Bidding Strategy 3 Acceptance Strategy Thus negotiation strategy thought larger component embodies aforementioned subcomponents manages eﬃcient collaboration interaction accomplish negotiation task Opponent modeling techniques constituent components negotiation strategy highly contributive success negotiating agent terms obtaining better individual utilities achieving higher social welfare values Therefore widely studied literature Automated Negotiations In article new technique proposed based perceptron units called POPPONENT order model pref erences opponent bilateral multi issue negotiations linear utility functions In fact POPPONENT successful implementation generalized version Standard Gradient Descent search algorithm GD referred Multi Bipartite Gradient Descent search MBGD practical AI problem The performance POPPONENT model compared state art models Genius repository 3637 The POPPONENT evaluated 5 separate states include perfect information state PP constant value states constant values 06 P6 08 P8 1 P1 Adaptive state AP In perfect information state revealed outperforms state art models average accuracy large margin accuracy measured opponents including predictable conceding opponents unpredictable random conceding opponents offset nonconceding It experiments accuracy POPPONENT constant value states exceeds accuracy accurate state art model opponents average scenarios Evaluating performance POPPONENT Genius indicates overcomes accurate state art opponent models The results indicate POPPONENT overcomes state art models domain performanceaccuracy measures In Experiment I constant values perfect information applied estimate utility received bid opponents utility space In Experiment II adaptive method applied estimate bidding behavior opponent It believed possibility improvements accuracy performance adaptive methods In future plan work estimation opponent bids utilities design implement highly eﬃcient adaptive methods order estimate bid utilities history bids received opponent incremental manner evaluate accuracy model employing adaptive methods Another interesting future study direction evaluation proposed model different parameter values learning rate number repeats It unknown accuracy performance model affected changes parameters model accuracy performance improved proper parameter values POPPONENT successful implementation new search method MBGD area preference modeling automated negotiations We interested applicability new method practical areas Artiﬁcial Intelligence Acknowledgements The authors like warmly thank Dr Tim Baarslag providing necessary scenario ﬁles experiments The authors like thank compassion continued support process research Appendix A Complexity POPPONENT algorithm Complexity analysis proposed POPPONENT algorithm run easily According Equations 21 22 receiving new bid opponent POPPONENT applies delta rules update current estimated preference proﬁle opponent Let n represent number negotiation issues N represent number training repeats F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 85 Table B1 Summary measures experiments Experiment I Pearson correlation Experiment II Avg Utility Avg Nash Distance Avg Kalai Distance Avg Pareto Distance dp uOP u cid10 OP cid7 ωΩ uOP cid13cid7 ωΩ uOP ωuOP u cid10 OP ωΩ u ωu cid10 OP cid10 OP ωu cid7 ωuOP 2 cid10 OP 2 AvgUtilityA cid7 N i1 utilityi A N AvgNashDist AB cid13 cid7 N i1 NashDisti N AB NashDisti AB utilityi A NashUtilityi A 2 utilityi B AvgKalaiDist AB cid13 cid7 N i1 KalaiDisti N AB KalaiDisti AB utilityi A KalaiUtilityi A 2 utilityi B AvgParetoDist AB cid13 cid7 N i1 ParetoDisti N AB NashUtilityi B 2 KalaiUtilityi B 2 ParetoDisti AB utilityi A ParetoUtilityi A 2 utilityi B ParetoUtilityi B 2 Avg Time AvgTime cid7 N i1 TimeOfAgreementi N Avg Perc Pareto Bids AvgPercOfParetoBids cid7 N i1 TotalParetoBidsi N TotalBidsOfferedi training example training instance delta rule Equation 22 Algorithm line 18 repeats n times delta rule Equation 21 Algorithm line 21 repeats n times process repeated N times training instance Algorithm line 15 total number executions delta rule ENDelta Rule Nn n 2Nn A1 Accordingly computational complexity algorithm depends number negotiation issues computational complexity algorithm linear O n Appendix B Measures This section explains different measures provided ANAC Genius framework 38 applied assess accuracy performance POPPONENT aforementioned experiments These measures tabulated Table B1 explained Sections B1 B2 B1 The measures applied Experiment I In setting adopted Experiment I Section 511 accuracy proposed model evaluated opponent models Pearson Correlation estimated real bid utilities 38 cid8 dp uOP u cid9 cid10 OP cid13cid7 cid7 ωΩ uOP ω uOPu cid10 OP ωΩ uOP ω uOP2 ωΩ u cid7 ω u cid10 OP cid10 OP ω u cid10 OP2 B1 uOP real utility space preference proﬁle opponent u proﬁle opponent uOP estimated utility negotiation outcome ω opponents utility space ω real utility negotiation outcome ω opponents utility space u cid10 OP estimated utility space preference ω cid10 OP Since measure evaluates extent model accurately predict ranking bids outcome space exact utilities best ﬁts purpose Awareness rankings bids outcome space suﬃcient bids Pareto Frontier11 close Pareto Frontier possible It worth noting order conceding moves approaching Pareto Frontier knowing exact utility values bids nonessential Instead need know best bid number bids equal utilities 11 See footnote 7 86 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 agent Isocurve bids If best bid known happen negotiation round close Pareto Frontier possible B2 The measures applied Experiment II In Experiment II Section 512 performance proposed model evaluated measuring real performance agents applying opponent models real world experimental negotiation scenarios For purpose performance measures 9 explained applied Average utility 12176465 agents designed setting computed Equation B1 cid7 AvgUtility A N i1 utilityi N A B2 N total number sessions AvgUtility A average utility agent A N sessions utilityi utility agent A ith session A Average Nash distance agreements 6566 speciﬁes average distance Nash point12 cid7 AvgNashDist AB N i1 NashDisti N AB B3 cid13 cid8 NashDisti AB utilityi A NashUtilityi A cid8 cid9 2 utilityi B NashUtilityi B cid9 2 N total number sessions AvgNashDist AB average Nash distance agreements agents A B N negotiation sessions NashDisti A utility Nash point agent A ith session NashUtilityi B utility Nash point agent B ith session AB Nash distance agreement ith session NashUtilityi The Average Kalai distance agreements 6566 speciﬁes average distance Kalai point13 cid7 AvgKalaiDist AB N i1 KalaiDisti N AB B4 KalaiDisti AB cid13 cid8 utilityi A KalaiUtilityi A cid8 cid9 2 utilityi B KalaiUtilityi B cid9 2 N total number sessions AvgKalaiDist AB average Kalai distance agreements agents A B N negotiation sessions KalaiDisti A utility Kalai point agent A ith session KalaiUtilityi B utility Kalai point agent B ith session AB Kalai distance agreement ith session KalaiUtilityi Average Pareto distance agreements 176566 speciﬁes average minimal distance agreements Pareto Frontier cid7 AvgParetoDist AB N i1 ParetoDisti N AB B5 cid13 cid8 cid8 cid9 2 cid9 2 AB utilityi A ParetoDisti ParetoUtilityi A utilityi B N total number sessions AvgParetoDist AB average Pareto distance agreements agents A B N negotiation sessions ParetoDisti A utility Pareto point agent A ith session ParetoUtilityi B utility Pareto point agent B ith session AB Pareto distance agreement ith session ParetoUtilityi ParetoUtilityi B The Average time agreement 165 speciﬁes average time reach agreement cid7 AvgTime N i1 TimeOfAgreementi N B6 12 Nash unique point Pareto Frontier product utilities parties maximized 435659 13 KalaiSmorodinsky point intersecting Pareto Frontier line linking Conﬂict point 0 0 Utopia Point 1 1 5758 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 87 N total number sessions AvgTime average time agreements N sessions TimeOfAgreementi time elapsed reaching agreement ith session Average Percentage Pareto Bids 3662 speciﬁes average percentage bids offered negotiation reside Pareto Frontier Equation B7 AvgPercOfParetoBids cid7 N i1 TotalParetoBidsi TotalBidsOfferedi N B7 N total number sessions TotalParetoBidsi TotalBidsOfferedi total number Pareto bids total number bids agent offered ith session The Nash Distance Kalai Distance Pareto Distance measures determine social eﬃciency model lower numbers socially eﬃcient model terms performance measures Appendix C Tabulated Experiment results II Table C1 POPPONENT average utility b standard deviation compared stateofthe art opponent models different domains Domain LGF CKF SF XF HHF IXF AP Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average 0573509 0647501 0538719 0696039 0297334 0647862 0514222 0559312 0568959 0649589 0538328 0697289 0299239 0647205 0513911 0559217 0569648 0649605 0540929 0697068 030033 0647522 0509994 05593 Domain LGF CKF Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average 0021368767 0011287649 0021494188 0003272382 0015129671 0005067326 0021513613 0014161942 0025083718 0015570161 0018236218 0002298787 001443495 0005288428 0016542951 0013922174 SF 0025362 001921 0023743 0003168 0014447 0004266 0019317 0015645 0586 0638958 0528138 0691276 0294104 0647475 0502188 0555448 XF 0023389 0022077 0023343 000411 0016717 0007161 0020531 0016761 b 0565695 0651974 0537564 0695758 030118 0645714 0509697 0558226 0580867 0656795 0541321 0698418 0300602 0644866 0516857 0562818 0571050296 0650498172 0535137574 0698718439 0297127466 0646040119 0511943972 0558645148 HHF IXF AP 0026293 0016814 0020075 0002325 0012761 000569 0017027 0014427 0026438 0020338 0019065 0002778 0013459 0005116 0020397 001537 0028204762 0019192385 0023571066 0002256075 0017596407 0006288319 0017874846 0016426266 P1 0569139 063812 0515908 0689838 0295067 0642942 0512119 0551876 P1 0027757 0019124 0023923 0006159 0014809 000633 0020225 0016904 Table C2 POPPONENT average time agreement b standard deviation compared state art opponent models different domains Domain LGF CKF SF XF HHF IXF AP Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average Domain Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average 0808724 076054 0835528 0608107 0773351 0637347 0850859 0753494 LGF 0007324 0005982 0006336 0006204 0010744 0009788 0005668 0007435 0810161 0759906 0835166 0609099 0774335 0639523 0851292 0754212 CKF 0007726 0006718 0005719 000662 0009376 0008842 0004243 0007035 0809534 0759773 083646 0607777 0773201 0640586 0851457 0754113 SF 0007778 0006245 0005978 0005722 0010404 0007387 0004235 0006822 0804034 0758998 0838632 0618218 0778995 0640841 0852534 0756036 XF 0006191 0007309 0006809 0007825 0010118 0009765 0004982 0007571 b 080866 075941 0838402 0611178 077264 0639089 0851107 0754355 0806934 0759364 0837165 0612435 0772588 0641449 0850214 0754307 0806424936 0757925506 0836101768 0614978513 0780173672 0641822083 0849201095 0755232511 HHF 0006907 0006322 0006068 0006449 0009639 000978 0004877 0007149 IXF 0007042 0006693 0006218 0006173 0011847 0008193 0003727 0007128 AP 0006146 000703 000574 0005165 0012291 0010582 0004849 00074 P1 0807854 0760031 0839077 0619999 0781178 0646237 0849606 0757712 P1 0005747 0005444 0006233 0006089 000984 0009451 0004239 000672 88 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 Table C3 POPPONENT average Nash Distance b standard deviation compared state art opponent models different domains Domain LGF CKF SF XF HHF IXF AP Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average Domain Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average 04428 039598 0457366 0195603 0427181 0195573 0437558 036458 LGF 0025064 0015679 0027038 0004842 0030315 0006846 002908 0019838 0449104 0389799 0456009 0194597 0424818 0193879 0439873 0364011 CKF 003004 002139 002437 0003124 0028886 000725 0022034 0019585 0447391 0390145 0457919 0195551 0424903 0194174 0443611 0364814 SF 0030687 0024804 0028723 0004646 0028073 0005527 0025028 002107 0436957 0409763 0480158 0209179 0431643 0202829 0462262 0376113 XF 0028139 0028405 0029527 0006004 0036176 0009397 0026597 0023464 b 0454414 0388411 0461135 019901 041975 0201405 0442742 0366695 0435619 0381927 0457773 0194792 0419263 0203392 0439208 0361711 0446968028 0396482824 0465870384 0196830137 0424612468 0200030498 0437223755 0366859728 HHF 0031151 0023234 0024818 0003458 0025967 000819 0021975 0019828 IXF 0032586 0026597 0023894 0004193 0026234 0007034 00253 0020834 AP 003396 0024961 0029372 0003613 0035326 0008469 002296 0022666 Table C4 POPPONENT average Pareto Distance b standard deviation compared state art opponent models different domains Domain LGF CKF SF XF HHF IXF AP Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average Domain Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average 0187234 0166809 0190255 0049098 024504 0018599 0168117 014645 LGF 0021219 0011541 0024243 000205 0025625 000042 0023175 0015468 0196962 0161085 0191763 0047864 023955 0019341 0169787 0146622 CKF 0026404 0016171 0019144 0000395 0025089 0001511 0016976 0015099 0195259 0160808 0189758 0048642 0238579 0018732 0174484 0146609 SF 0026157 0019836 0027377 000189 0024971 0000267 0020516 0017288 017587 0175792 0204219 005976 02482 0020988 0186501 0153047 XF 0024601 0020106 0025687 0002453 0032085 0003072 0021104 0018444 b 0202949 0159009 0190913 0051005 0234917 002142 0174247 014778 0182263 015325 0189265 0048415 023516 0023509 0166601 0142637 019170905 0163144761 0196355287 004782886 0237892409 0021636859 0172447519 0147287821 HHF 0028204 0016996 0019748 0000474 0021664 0000998 0017771 0015122 IXF 0027674 0021053 001879 0000786 0020435 0001244 0021537 0015931 AP 0031429 0019662 0024168 000043 0028861 0001062 0018315 0017704 Table C5 POPPONENT average Kalai Distance b standard deviation compared state art opponent models different domains Domain LGF CKF SF XF HHF IXF AP Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average 0415358 039598 0457366 0195603 0426142 0189814 0437558 0359689 0422711 0389799 0456009 0194597 0423733 0189249 0439873 0359425 0422281 0390145 0457919 0195551 0423705 018979 0443611 0360429 0413941 0409763 0480158 0209179 043042 01974 0462262 0371875 0428822 0388411 0461135 019901 0418411 0194916 0442742 0361921 041037 0381927 0457773 0194792 0418065 0196988 0439208 0357018 0424757548 0396482824 0465870384 0196830137 042309111 0196060175 0437223755 0362902276 P1 0468108 0420687 0515648 0215273 0439893 0211667 0461518 0390399 P1 0033023 0023043 003046 0009106 0030404 0008525 0024737 0022757 P1 0199027 017902 0228592 0063034 0246791 0028243 018098 0160812 P1 0030529 001764 0024088 0006147 0022982 0002088 0020995 0017781 P1 0446463 0420687 0515648 0215273 0438433 0205757 0461518 0446463 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 89 Table C5 continued Domain Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average LGF 0025549 0015679 0027038 0004842 0030146 000536 002908 0019671 CKF 0029285 002139 002437 0003124 0028889 000594 0022034 001929 SF 0030156 0024804 0028723 0004646 0028021 000425 0025028 0020804 XF 0027401 0028405 0029527 0006004 0036101 0007497 0026597 0023076 b HHF 0030556 0023234 0024818 0003458 0025865 0006767 0021975 0019525 IXF 0032266 0026597 0023894 0004193 0026084 0006377 00253 0020673 AP 0033389 0024961 0029372 0003613 0035141 0006808 002296 0022321 P1 0032131 0023043 003046 0009106 0030398 0007048 0024737 0032131 Table C6 POPPONENT average Pearson Correlation Bids b standard deviation compared state art opponent models different domains Domain LGF CKF SF XF HHF IXF AP Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average 0708262 0586256 057681 0799005 0691501 0801799 07685 070459 0758502 0608388 0677093 0824615 0735425 0805355 0807852 0745319 0741386 0623808 0604107 0825272 0710331 0807166 0768802 0725839 072082 0573111 063678 0796731 067537 0644701 0760716 068689 0732425 0621801 0607754 0837442 0700408 0822057 0760233 0726017 0730347 0613423 0605026 0849078 0695129 0816216 075148 0722957 0821774577 0684165935 0680735977 0847187627 0680266747 0821461418 0862496743 0771155575 Domain LGF CKF SF XF HHF IXF AP Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average 0003249 0003141 000241 0001468 000796 0002729 0002219 0003311 0002386 0002953 0002172 0001604 0003655 0002056 0001554 000234 0003046 0003104 0002695 0001485 000666 0001914 0001773 0002954 0013425 0014834 001101 00048 0015097 0009481 0008429 0011011 b 0008649 0009044 0008288 0003652 0009944 0008239 0007647 0007923 0011086 0011857 0009024 0005377 0014162 0009759 0012303 001051 0012384432 000896404 0020941602 0002967473 0030966949 0005869184 0012836845 0013561504 P1 0853468 0699424 0765818 0842055 0852173 0842427 0892469 0821119 P1 0005236 0005079 0004233 0003301 0004915 0003511 0003718 0004285 Table C7 POPPONENT average Percentage Pareto Bids b standard deviation compared state art opponent models different domains Domain Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average Domain Supermarket Travel Thompson Grocery Energy Camera ItexVsCypress Average LGF 0394825 0373331 0644955 0698418 0378452 0738829 0812633 0577349 LGF 0021432 0017361 0014005 0008898 0026258 0010874 0007182 0015144 CKF 0395804 0372682 0650202 0696347 0375572 0733052 0813282 0576706 CKF 0023384 0022211 0011695 0010165 0021565 0011328 0005427 0015111 SF 0398458 0372852 0649068 0696748 0386453 0733789 0813051 0578631 SF 0021473 0019032 0011886 0008992 0024716 0010319 0005512 0014561 XF 0462466 0376019 0647309 0689248 0440211 07123 0818836 0592341 XF 0027782 0023011 0013829 0010919 0027132 0011261 0007092 0017289 b HHF 0400153 0371945 0646974 0687082 0394558 0735578 0813848 0578591 HHF 0023061 0021339 0012629 0010622 0022433 0012254 0007257 0015656 IXF 0406819 0371299 0648322 0689335 0396635 0738423 0819694 0581504 IXF 0024289 0020696 0012791 001138 0021497 0012613 0004341 0015373 AP 0415159 0370899 0661895 0695065 0390569 072382 081304 0581492 AP 0021618 0022112 0013503 0007556 0020732 0015186 0006929 0015376 P1 0417763 0372523 0664335 0695124 0402541 0726447 0814807 0584791 P1 0024082 0022496 0013269 0007954 0023611 0012913 0005512 0015691 90 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 References 1 T Baarslag K Hindriks M Hendrikx A Dirkzwager C Jonker Decoupling negotiating agents explore space negotiation strategies Pro ceedings 5th International Workshop AgentBased Complex Automated Negotiations ACAN 2012 2 T Baarslag K Hindriks C Jonker S Kraus R Lin The ﬁrst automated negotiating agents competition ANAC 2010 T Ito M Zhang V Robu S Fatima T Matsuo Eds New Trends AgentBased Complex Automated Negotiations vol 383 Springer Berlin Heidelberg 2012 pp 113135 3 K Fujita T Ito T Baarslag K Hindriks C Jonker S Kraus et al The second automated negotiating agents competition ANAC2011 T Ito M Zhang V Robu T Matsuo Eds Complex Automated Negotiations Theories Models Software Competitions vol 435 Springer Berlin Heidelberg 2013 pp 183197 4 T Baarslag K Hindriks C Jonker Acceptance conditions automated negotiation T Ito M Zhang V Robu T Matsuo Eds Complex Automated Negotiations Theories Models Software Competitions vol 435 Springer Berlin Heidelberg 2013 pp 95111 5 T Baarslag K Hindriks C Jonker Effective acceptance conditions realtime automated negotiation Decis Support Syst 60 2014 6877 6 T Baarslag KV Hindriks Accepting optimally automated negotiation incomplete information presented Proceedings 2013 International Conference Autonomous Agents MultiAgent Systems St Paul MN USA 2013 7 T Baarslag MC Hendrikx K Hindriks C Jonker Learning opponent automated bilateral negotiation comprehensive survey opponent modeling techniques Auton Agents MultiAgent Syst 2015 150 20150907 8 SZ Li AK Jain Encyclopedia Biometrics IZ vol 2 Springer 2009 9 T Baarslag M Hendrikx K Hindriks C Jonker Measuring performance online opponent models automated bilateral negotiation M Thielscher D Zhang Eds AI 2012 Advances Artiﬁcial Intelligence vol 7691 Springer Berlin Heidelberg 2012 pp 114 10 T Krimpen D Looije S Hajizadeh HardHeaded T Ito M Zhang V Robu T Matsuo Eds Complex Automated Negotiations Theories Models Software Competitions vol 435 Springer Berlin Heidelberg 2013 pp 223227 11 N Galen Last Agent Smith opponent model estimation bilateral multiissue negotiation T Ito M Zhang V Robu S Fatima T Matsuo Eds New Trends AgentBased Complex Automated Negotiations vol 383 Springer Berlin Heidelberg 2012 pp 167174 12 K Hindriks D Tykhonov Opponent modelling automated multiissue negotiation Bayesian learning presented Proceedings 7th International Joint Conference Autonomous Agents Multiagent Systems Estoril Portugal 2008 13 A Frieder G Miller Value model agent novel preference proﬁler negotiation agents T Ito M Zhang V Robu T Matsuo Eds Complex Automated Negotiations Theories Models Software Competitions vol 435 Springer Berlin Heidelberg 2013 pp 199203 14 H Jazayeriy M AzmiMurad N Sulaiman N Izura Udizir The learning opponents approximate preferences bilateral automated negotiation J Theor Appl Electron Commer Res 6 2011 6584 15 J Zhang F Ren M Zhang Prediction opponents preference bilateral multiissue negotiation Bayesian learning Proceedings 2014 International Conference Autonomous Agents MultiAgent Systems Paris France 2014 pp 331338 16 C Williams V Robu E Gerding N Jennings IAMhaggler negotiation agent complex environments T Ito M Zhang V Robu S Fatima T Matsuo Eds New Trends AgentBased Complex Automated Negotiations vol 383 Springer Berlin Heidelberg 2012 pp 151158 17 T Baarslag K Fujita EH Gerding K Hindriks T Ito NR Jennings et al Evaluating practical negotiating agents results analysis 2011 international competition Artif Intell 198 2013 73103 18 K Sycara D Zeng Beneﬁts learning negotiation Proceedings 14th National Conference Artiﬁcial Intelligence 9th Innovative Applications Artiﬁcial Intelligence Conference AAAI97IAAI97 Menlo Park CA USA 1997 pp 3642 19 J Gwak KM Sim Bayesian learning based negotiation agents supporting negotiation incomplete information Proceedings Interna tional MultiConference Engineers Computer Scientists Hong Kong 2011 pp 163168 20 C Yu F Ren M Zhang An adaptive bilateral negotiation model based Bayesian learning T Ito M Zhang V Robu T Matsuo Eds Complex Automated Negotiations Theories Models Software Competitions vol 435 Springer Berlin Heidelberg 2013 pp 7593 21 P Faratin C Sierra NR Jennings Using similarity criteria issue tradeoffs automated negotiations Artif Intell 142 2002 205237 22 C Niemann F Lang Assess opponent Bayesian process preference observation multiattribute negotiations T Ito M Zhang V Robu S Fatima T Matsuo Eds Advances AgentBased Complex Automated Negotiations vol 233 Springer Berlin Heidelberg 2009 pp 119137 23 R Lin S Kraus J Wilkenfeld J Barry Negotiating bounded rational agents environments incomplete information automated agent Artif Intell 172 2008 823851 24 T Baarslag K Hindriks C Jonker A Tit Tat negotiation strategy realtime bilateral negotiations T Ito M Zhang V Robu T Matsuo Eds Complex Automated Negotiations Theories Models Software Competitions vol 435 Springer Berlin Heidelberg 2013 pp 229233 25 R Lin S Kraus J Wilkenfeld J Barry An automated agent bilateral negotiation bounded rational agents incomplete information Front Artif Intell Appl 141 2006 270274 26 L Serban G Silaghi C Litan AgentFSEGA time constrained reasoning model bilateral multiissue negotiations T Ito M Zhang V Robu S Fatima T Matsuo Eds New Trends AgentBased Complex Automated Negotiations vol 383 Springer Berlin Heidelberg 2012 pp 159165 27 C Williams V Robu E Gerding N Jennings IAMhaggler2011 Gaussian process regression based negotiation agent T Ito M Zhang V Robu T Matsuo Eds Complex Automated Negotiations Theories Models Software Competitions vol 435 Springer Berlin Heidelberg 2013 pp 209212 28 R Carbonneau GE Kersten R Vahidov Predicting opponents moves electronic negotiations neural networks Expert Syst Appl 34 2008 12661273 29 CR Williams V Robu EH Gerding NR Jennings Using Gaussian processes optimise concession complex negotiations unknown op ponents presented Proceedings TwentySecond International Joint Conference Artiﬁcial Intelligence Barcelona Catalonia Spain 2011 30 RYK Lau Y Li D Song RCW Kwok Knowledge discovery adaptive negotiation agents emarketplaces Decis Support Syst 45 2008 310323 31 R Aydogan P Yolum Learning opponents preferences effective negotiation approach based concept learning Auton Agents MultiAgent Syst 24 2012 104140 mann 1986 32 JR Anderson RS Michalski RS Michalski JG Carbonell TM Mitchell Machine Learning An Artiﬁcial Intelligence Approach vol 2 Morgan Kauf 33 P Faratin C Sierra NR Jennings Negotiation decision functions autonomous agents Robot Auton Syst 24 1998 159182 34 TM Mitchell Machine Learning vol 45 McGraw Hill Ridge IL 1997 35 SS Fatima M Wooldridge N Jennings Optimal negotiation strategies agents incomplete information JJ Meyer M Tambe Eds Intelli gent Agents VIII vol 2333 Springer Berlin Heidelberg 2002 pp 377392 36 R Lin S Kraus T Baarslag D Tykhonov K Hindriks CM Jonker Genius integrated environment supporting design generic automated negotiators Comput Intell 30 2012 4870 37 K Hindriks CM Jonker S Kraus R Lin D Tykhonov Genius negotiation environment heterogeneous agents presented Proceedings The 8th International Conference Autonomous Agents Multiagent Systems Budapest Hungary 2009 38 T Baarslag M Hendrikx K Hindriks C Jonker Predicting performance opponent models automated negotiation Proceedings 7th International Conference Advanced Information Technologies St Paul MN USA 2013 pp 5966 F Zafari F NassiriMofakham Artiﬁcial Intelligence 237 2016 5991 91 39 J Hao Hf Leung CUHKAgent adaptive negotiation strategy bilateral negotiations multiple items I MarsaMaestre MA Lopez Carmona T Ito M Zhang Q Bai K Fujita Eds Novel Insights AgentBased Complex Automated Negotiation vol 535 Springer Japan 2014 pp 171179 40 C Williams V Robu E Gerding N Jennings An overview results insights automated negotiating agents competition ANAC2012 I MarsaMaestre MA LopezCarmona T Ito M Zhang Q Bai K Fujita Eds Novel Insights AgentBased Complex Automated Negotiation vol 535 Springer Japan 2014 pp 151162 41 F Zafari F NassiriMofakham BraveCat iterative deepening distancebased opponent modeling hybrid bidding nonlinear ultra large bilateral multi issue negotiation domains N Fukuta T Ito M Zhang K Fujita V Robu Eds Recent Advances AgentBased Complex Automated Negoti ation vol 638 Springer International Publishing Switzerland 2016 pp 285293 42 A Rubinstein Perfect equilibrium bargaining model Econometrica J Econom Soc 50 1982 97109 43 G Weiss Multiagent Systems A Modern Approach Distributed Artiﬁcial Intelligence MIT Press 1999 44 H Raiffa The Art Science Negotiation Harvard University Press 1982 45 F NassiriMofakham MA Nematbakhsh N GhasemAghaee A BaraaniDastjerdi A heuristic personalitybased bilateral multiissue bargaining model electronic commerce Int J HumComput Stud 67 2009 135 46 F NassiriMofakham N GhasemAghaee MA Nematbakhsh A BaraaniDastjerdi A personalitybased simulation bargaining ecommerce Simul Gaming 39 2008 83100 47 F NassiriMofakham MA Nematbakhsh A BaraaniDastjerdi N GhasemAghaee R Kowalczyk Bidding strategy agents multiattribute combi natorial double auction Expert Syst Appl 42 2015 32683295 48 E Alpaydin Introduction Machine Learning MIT Press 2004 49 DT Larose Discovering Knowledge Data An Introduction Data Mining John Wiley Sons 2014 50 IH Witten E Frank Data Mining Practical Machine Learning Tools Techniques Morgan Kaufmann 2005 51 S Kawaguchi K Fujita T Ito AgentK compromising strategy based estimated maximum utility automated negotiating agents T Ito M Zhang V Robu S Fatima T Matsuo Eds New Trends AgentBased Complex Automated Negotiations vol 383 Springer Berlin Heidelberg 2012 pp 137144 52 S Kawaguchi K Fujita T Ito AgentK2 compromising strategy based estimated maximum utility automated negotiating agents T Ito M Zhang V Robu T Matsuo Eds Complex Automated Negotiations Theories Models Software Competitions vol 435 Springer Berlin Heidelberg 2013 pp 235241 53 S Kawaguchi K Fujita T Ito Compromising strategy based estimated maximum utility automated negotiation agents competition ANAC10 K Mehrotra C Mohan J Oh P Varshney M Ali Eds Modern Approaches Applied Intelligence vol 6704 Springer Berlin Heidelberg 2011 pp 501510 54 M Ikrashi K Fujita Compromising strategy weighted counting multitimes negotiations 2014 IIAI 3rd International Conference Ad 55 K Fujita Eﬃcient strategy adaptation complex multitimes bilateral negotiations 2014 IEEE 7th International Conference ServiceOriented vanced Applied Informatics IIAIAAI 2014 pp 453458 Computing Applications SOCA 2014 pp 207214 56 M Fasli Agent Technology ECommerce Wiley Press Chichester 2007 57 H Gimpel J Mäkiö Towards multiattribute double auctions ﬁnancial markets EM 16 2006 130139 58 E Kalai M Smorodinsky Other solutions Nashs bargaining problem Econometrica J Econom Soc 1975 513518 59 JF Nash Jr The bargaining problem Econometrica J Econom Soc 18 1950 155162 60 B An V Lesser Yushu heuristicbased agent automated negotiating competition T Ito M Zhang V Robu S Fatima T Matsuo Eds New Trends AgentBased Complex Automated Negotiations vol 383 Springer Berlin Heidelberg 2012 pp 145149 61 M Ben Adar N Sofy A Elimelech Gahboninho strategy balancing pressure compromise automated negotiation T Ito M Zhang V Robu T Matsuo Eds Complex Automated Negotiations Theories Models Software Competitions vol 435 Springer Berlin Heidelberg 2013 pp 205208 62 K Gal L Ilany The fourth automated negotiation competition K Fujita T Ito M Zhang V Robu Eds Next Frontier AgentBased Complex Automated Negotiation vol 596 Springer Japan 2015 pp 129136 63 L Thompson The Heart Mind Negotiator 3rd ed Prentice Hall Upper Saddle River New Jersey 2000 64 T Klos K Somefun H La Poutré Automated interactive sales processes IEEE Intell Syst 26 2011 5461 65 F Zafari F NassiriMofakham AZ Hamadani DOPPONENT socially eﬃcient preference model opponent bilateral multi issue negotiations J Comput Secur 1 4 2015 283292 66 K Hindriks CM Jonker D Tykhonov Negotiation dynamics analysis concession tactics outcomes presented Proceedings 2007 IEEEWICACM International Conference Intelligent Agent Technology Silicon Valley San Francisco CA USA 2007