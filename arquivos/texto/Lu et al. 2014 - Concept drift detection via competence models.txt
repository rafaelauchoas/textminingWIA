Artiﬁcial Intelligence 209 2014 1128 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Concept drift detection competence models Ning Lu Guangquan Zhang Jie Lu Decision Systems eService Intelligence DeSI Lab Centre Quantum Computation Intelligent Systems QCIS Faculty Engineering Information Technology University Technology Sydney PO Box 123 Broadway NSW 2007 Australia r t c l e n f o b s t r c t Article history Received 1 November 2012 Received revised form 16 October 2013 Accepted 9 January 2014 Available online 10 January 2014 Keywords Concept drift Competence model Casebase maintenance Incremental supervised learning Classiﬁcation Detecting changes concepts change customer preference telecom services important terms prediction decision applications dynamic environments In particular casebased reasoning systems important know concept drift effectively assist decision makers perform smarter maintenance operations appropriate time This paper presents novel method detecting concept drift casebased reasoning Rather measuring actual case distribution introduce new competence model detects differences changes competence Our competencebased concept detection method requires prior knowledge case distribution provides statistical guarantees reliability changes detected meaningful descriptions quantiﬁcation changes This research concludes changes data distribution reﬂect competence Eight sets experiments categories demonstrate method effectively detects concept drift highlights drifting competence areas accurately These results directly contribute research tackles concept drift casebased reasoning competence model studies 2014 Elsevier BV All rights reserved 1 Introduction Learning concept drift poses additional challenge existing learning algorithms Instead considering past training data making stationary distribution assumption 13 effective learner able track changes quickly adapt 4 Otherwise concept drifts induced pattern relevant new data 56 result increasing number errors 7 The issue concept drift refers change distribution underlying data 48 More formally problem framed follows If denote feature vector x class label y data stream inﬁnite sequence x y If concept drifts means distribution px y changing current data chunk yettocome data If decompose px y following parts px y px p yx sources concept drift px evolves time t written pxt p yx conditional probability feature x 2 Concept drift categorized basic types virtual concept drift drift data distribution real concept drift drift decision concepts 8 Other kinds concept drift deﬁned discussed example based extent drift Stanley 9 mentioned kinds drift sudden drift moderate drift slow drift Based class distribution Forman 10 classiﬁed concept drift categories shifting class distribution shifting distribution categories remaining stable given class shifting subclass distribution shifting distribution subclasses Corresponding author Email addresses NingLuutseduau N Lu GuangquanZhangutseduau G Zhang JieLuutseduau J Lu 00043702 matter 2014 Elsevier BV All rights reserved httpdxdoiorg101016jartint201401001 12 N Lu et al Artiﬁcial Intelligence 209 2014 1128 category remaining stable given subclass ﬁckle concept drift individual cases different ground truth labels different times Zhang et al 2 deﬁned analyzed kinds concept drift studies loose concept drifting genuine concepts remain relatively stable vision drift mainly caused biased observation instances rigorous concept drifting genuine concepts undergo continuous change changes worsen face biased observation Tsymbal et al 11 discussed special scenario concept drift called local concept drift mean change concept data distribution occurs regions instance space Based literature learning algorithms base models handle concept drift These include rulebased learning 4812 decision trees incremental versions 51314 infofuzzy networks 15 clustering 16 support vector machines 17 casebased reasoning CBR 111820 Among CBR method reported advantages handling concept drift problem 21 First CBR performs disjointed concepts Second CBR lazy learner easy update Third CBR allows easy sharing knowledge particular types problems making easier maintain multiple distributed casebases Therefore study focuses concept drift detection CBR According literature review 22 ﬁrst attempt handle concept drift casebased technique IB3 20 discards noisy outdated cases monitoring cases accuracy retrieval frequency IB3 criticized suitable gradual concept drift costly adaptation process 4 The Locally Weighted Forgetting LWF algorithm 23 reduces weights knearest neighbors new case discards case weight falls threshold θ believed best adaptive learning algorithms time Klinkenberg 17 later showed experiments instance weighting techniques tend overﬁt data perform poorly analogous instance selection techniques Elwell Polikar 24 presented ensemble learning algorithm non stationary environments LearnNSE assumes data incrementally acquired batches For incoming dataset Dt algorithm trains independent base classiﬁer ht forced emphasize misclassiﬁed data adjusted data weighting Then weight assigned base classiﬁer based performance latest dataset The ﬁnal classiﬁcation result determined weighted majority voting base classiﬁers Recent research development casebase maintenance CBM provides number methods updating knowledge containers 25 CBR Among competencebased CBM methods 192630 casebase mining technologies 31 empiri cally shown capable preserving competency CBR removing noisy redundant cases Few studies discussed trigger maintenance operations important consideration according Wilson Leakes CBM framework 32 In addition current methods incapable distinguishing noisy cases cases representing new concept Knowing concept drift happens help recognize obsolete cases conﬂict current concepts distinguish noise cases novel cases Moreover developing detection method able explain concept drifts facilitate decision capabilities suitable handling local concept drift problems 11 Motivated issues propose new method concept drift detection CBR systems compares case distributions existing cases newly available cases The proposed method requires prior knowledge case distribution estimates probability distribution detects change competence model Besides determining concept drift method quantiﬁes describes detected change terms competence model To best knowledge literature reported research uses competence model concept drift detection purposes Compared famous nonparametric methods detection method demonstrates following advantages 1 easily adopted multidimensional data maintaining similar results onedimensional data 2 stable achieves better results shown experiments especially small samples data share distribution contributions related competence areas splitting strictly cutting edges makes tolerable sample bias 3 able detected changes highlighting competence areas testiﬁed real world application The novelty main contribution paper lie endeavor discover difference inner nature competence group model proposed competence closure model The detailed deﬁnitions theorems afford researchers inside view casebase competence discussed literature The theoretical study provided paper reveals essential differences competence models identiﬁes important aspects competence closure model competence group model possess Compared previous work competencebased concept drift detection 33 aims investigate impact concept drift casebase competence assert possibility detecting change competence models paper additionally conducts tremendous number experiments thoroughly evaluate proposed concept drift detection approach This paper organized follows Section 2 discusses related works Section 3 proposes new competence model discusses relationship model current competence models Section 4 presents competencebased change detection method Section 5 determines critical region provides statistical guarantee proposed detection method Section 6 outlines results experimental evaluation Section 7 concludes study discussion future work N Lu et al Artiﬁcial Intelligence 209 2014 1128 13 2 Related work This section formally presents problem concept drift detection Section 21 analyzes pros cons established literature regard concept drift detection Section 22 21 Problem description Concept drift detection Concept drift detection formulated follows Suppose CBR listening data stream new observation represented ci xi yi xi xi1 xi2 xin X feature vector yi Y target label As unrealistic store history stream base concept drift detection algorithm twoslidingwindow paradigm Both windows contain number successive data points We assume data points window independent random samples taken unknown multidimensional nonparametric distributions identical The goal F F design proper statistical test able refuse H 0 true highlight local regions problem space H0 hold quantify difference F F When H0 true probability different fact α making error test says F F α usersupplied parameter respectively We deﬁne null hypothesis H 0 asserts F F cid4 cid4 cid4 cid4 A real world scenario application method spam ﬁltering As wellknown challenges spam ﬁltering domain handle concept drift problems In casebased spam ﬁltering emails continuously classiﬁed problem arises beneﬁt available feedback new cases improve accuracy Treating newest emails independent training set emails received month detect concept drift existing casebase assumed follow The correct unknown distribution F maintenance accordingly carried drift reported recent emails assumed follow unknown distribution F cid4 cid4 22 Change detection methods The popular trigger technique learner adaptivity change detection implicitly related sudden drift 34 This usually conducted statistical test monitors raw data distribution 3538 outputs error learners 3942 parameters learners 43 221 Detecting concept drift data distribution When comparing samples determining samples drawn distribution Wilcoxon test 44 KolmogorovSmirnov test 4546 famous nonparametric methods We assume data follows particular parametric distribution Section 21 real world applications data typically encounters arise standard distribution makes nonparametric tests practi cal However Wilcoxon test KolmogorovSmirnov test initially designed data dimension easily extended multidimensional data limits scalability 36 In sense intentionally omit methods designed onedimensional data 3738 Kifer BenDavid Gehrke 35 proposed modiﬁcation KolmogorovSmirnov test principle compares cumulative distribution functions samples possible orderings takes largest resulting test statistics They employed notation A distance test statistic fact relaxation total variation distance Their method reported advantages including able control rate false alarm false positive missed detection false negative quantify detected change Some technical challenges remain need overcome putting work practice determine interesting class sets A higher dimensions Dasu et al 36 suggested informationtheoretic approach change detection data streams resorts KullbackLeibler divergence measure difference given distributions They estimated measurement statistically signiﬁcant Percentile Bootstrap method 47 By partitioning problem space kdqtree method exhibited capability identifying regions greatest difference However kdqtree guarantee partition coincide real interesting concepts This means detected regions easily explained understood 222 Detecting concept drift learner outputs Gama et al 39 presented Drift Detection Method DDM traces controls online errorrate learning algorithm Treating error set examples random variable Bernoulli trails probability number errors sample n examples generalized Binomial distribution A signiﬁcant increase error algorithm suggests class distribution changing Their method declares new concept error reaches warning level new model learnt drift level exceeded Although independent learning algorithm method suitable rebuilding models updating existing model assesses 14 N Lu et al Artiﬁcial Intelligence 209 2014 1128 learner overall error rate In addition method criticized having diﬃculties change slowly gradual 40 BaenaGarcía et al 40 proposed Early Drift Detection Method EDDM improve detection presence gradual concept drift Their EDDM different DDM considers distance consecutive erroneous classiﬁcations instead error rate They assume signiﬁcant decrease distance suggests concept cid4 changing With calculated average distance errors p deﬁned thresholds α warning level β drift level When β cid2 p cid4 max stored p cid4 reaches maximum examples stored case possible change context value p cid4 2s max β new model learnt examples stored warning level triggered The values cid4 2s p cid4 p EDDM performs gradual changes good detecting drift noisy max s examples 48 cid4 standard deviation s cid4 max α p cid4 cid4 max reset cid4 max s 2 s 2s 2s p cid4 max cid4 max cid4 cid4 cid4 Yasumura Kitani Uehara 41 developed sensitive detection method concept drift measures number instances classiﬁed differently successive ensemble classiﬁers determines difference signiﬁ To suppress inﬂuence caused noise weighted instances taking inverse weights generated AdaBoost algorithm 49 method requires building new classiﬁer time new chunk arrives This apparently suitable nonensemble based algorithms handle concept drift Li et al 42 suggested tracking error rate classiﬁcation chunked data stream Considering observed error rate latest data chunk e f historical classiﬁcation result ﬁtted estimated error rate current chunk es Hoeffdings inequality provide statistical guarantee detection Nevertheless experienced problem occurred Gamas work 39 223 Detecting concept drift parameters To best knowledge attempt model concept drift change parameters Su Shen Xu 43 In framework dynamic probabilistic model framed pCkxt f wt v wt optimal parameter vector inferred continuously extended Kalman ﬁlter 50 v random variable represents uncertainty posterior distribution pCkxt Assuming expectation parameter wt1 wt concept drift model concept drift change parameter vector wt wt1 s s uncertainty caused concept drift For simplicity assume s v follow zero mean normal distributions isotropic covariance s N0 aI v N0 r I identity matrix single value controls variance parameter vector w r noise variance In implementation model degree concept drift aI noise variance r need estimated data Their framework modelling concept drift creative easily applied learning models Support Vector Machines SVM Regression Artiﬁcial Neural Networks ANN suitable knowledge based learner like CBR In addition optimal parameter vector organized userunderstandable way prohibits concept drift interpretation In section summarized existing concept drift detection methods categories As shown later sections proposed method belong ﬁrst category There research learning methods outlier anomaly detection 5152 The difference outlier detection concerned ﬁnding exceptional observations concept drift detection deals identifying shift underlying data distribution 53 3 A new competence model This study aims provide innovative solution concept drift detection compares data distribution competence measurement instead feature space Competence measurement CBR fulﬁlls goals As CBR problemsolving methodology competence usually taken proportion problems hand solved successfully 54 Because competence measures problemsolving capabilities CBR probability distribution change cases reﬂect competence This inspired research detect concept drift competence model The key idea measure distribution change cases regard competencies instead real distributions Smyth McKenna 262855 proposed series models measure competence CBR The deﬁnitions shown follows Deﬁnition 1 See 26 For case base CB c1 c2 cn given case c CB CoverageSetc c Solvesc c cid4 means c retrieved adapted solve c cid4 cid4 CB Solvesc c cid4 Deﬁnition 2 See 26 ReachibilitySetc c cid4 CB Solvesc cid4 c Deﬁnition 3 See 55 RelatedSetc CoverageSetc ReachibilitySetc N Lu et al Artiﬁcial Intelligence 209 2014 1128 Deﬁnition 4 See 55 For c1 c2 CB SharedCoveragec1 c2 iff cid2 cid3 RelatedSetc1 RelatedSetc2 cid8 φ 15 1 Deﬁnition 5 See 55 Let G c1 c2 cm CB G property CompetenceGroupG iff ci G exists c j G ci SharedCoverageci c j holds ck CB G exist cl G SharedCoverageck cl holds In competence model coverage case set problems case solve conversely reachability set cases solve case A cluster cases called competence group formed reachability coverage sets Based deﬁnitions forward following propositions Proposition 1 For G CB G property CompetenceGroupG G 1 Proof Obvious cid2 This makes diﬃcult competence group model measure detect noise cases distinguished close neighbors noise cases tend solve solved Proposition 2 Given G 1 G 2 CB G 1 G 2 property CompetenceGroupG 1 CompetenceGroupG 2 respectively G 1 G 2 property CompetenceGroupG 1 G 2 Proof For ci G 1 G 2 ci G 1 ci G 2 Without loss generality suppose ci G 1 Since G 1 property CompetenceGroupG 1 exist ck G 1 G 1 G 2 ck cid8 ci SharedCoverageck ci holds And c j CB G 1 G 2 CB G 1 exist cm G 1 SharedCoveragec j cm holds If exists cm G 2 c j CB G 1 G 2 CB G 2 contradiction G 2 property CompetenceGroupG 2 Therefore G 1 G 2 property CompetenceGroupG 1 G 2 cid2 Proposition 3 Given G 1 G 2 CB G 1 G 2 cid8 φ G 1 G 2 property CompetenceGroupG 1 CompetenceGroupG 2 respectively G 1 G 2 property CompetenceGroupG 1 G 2 Proof For ci G 1 G 2 ci G 1 ci G 2 Since G 1 property CompetenceGroupG 1 exist ck G 1 ck cid8 ci SharedCoverageck ci holds If ck G 2 ci G 2 contradiction G 2 property CompetenceGroupG 2 For c j CB G 1 G 2 c j CB G 1 c j CB G 2 Without loss generality suppose c j CB G 1 Since G 1 property CompetenceGroupG 1 exist cm G 1 G 2 G 1 SharedCoveragec j cm holds Therefore G 1 G 2 property CompetenceGroupG 1 G 2 cid2 Through Proposition 2 Proposition 3 prove competence group model fulﬁll claim com petence groups individually independent contribution global competence 56 To precise competence group model provides dichotomous partition casebase G CB G cases partition collectively independent contribution overall casebase competence The competence group model useful analyzing competence independent subset casebase inadequate deﬁcient First competence group model guarantee complete splitting casebase competence groups inadequacy words CB G necessarily competence group contains disjointed case related case Sec ond competence group split ﬁnd independent partitions ﬁnally lead smaller independent competence groups competence group model guarantee competence groups mutually independent deﬁciency As result competence group model inappropriate analyzing competence casebase composed disjointed partitions We propose new competence models Competence Closure Related Closure 33 current com petence models suﬃcient concept drift detection purposes existing competence models transfer inﬁnite case domain ﬁnite domain related sets solves diﬃculty measuring statistical distance case samples We demonstrate models superior existing models compar isons shown later section We intentionally omit proposed competence models LiabilitySet 19 Complexity model 2930 provide measurement solved problem space surely problems solved Deﬁnition 6 See 33 For G c1 c2 cm CB G cid8 φ G property CompetenceClosureG ci c j G ci cid8 c j exist ci1 ci2 cik G SharedCoverageci j ci j1 j 0 k holds ci ci0 c j cik1 ck CB G exist cl G SharedCoverageck cl holds 16 N Lu et al Artiﬁcial Intelligence 209 2014 1128 In words competence closure group cases connect series Shared Coverage relations case competence closure SharedCoverage relation cases competence closure Proposition 4 For G CB G 1 G property CompetenceClosureG G property CompetenceGroupG Proof Obvious cid2 Remark In Proposition 4 condition G 1 essential When G 1 G single case set G c1 property CompetenceClosureG exist ck CB G SharedCoveragec1 ck holds However G property CompetenceGroupG ﬁnd element c1 G Proposition 4 shows competence closure model fully compatible competence group model competence closure cases CompetenceGroup property competence group A single case point modeled competence group model Proposition 4 ensures method adopts competence group model ﬁtted competence closure model Theorem 1 For G 1 G 2 Gn CB cid4 n i1 G CompetenceGroup G 1 G property CompetenceClosureG cid4 n i1 G property Proof As Proposition 2 Proposition 4 cid2 Theorem 2 For G 1 G 2 CB G 1 cid8 G 2 f G 1 G 2 properties CompetenceClosureG 1 CompetenceClosureG 2 G 1 G 2 φ Proof As G 1 cid8 G 2 loss generality suppose exists c1 G 1 c1 G 2 If G 1 G 2 cid8 φ G 1 let c0 G 1 G 2 G 1 Since G 1 property CompetenceClosureG 1 exists ci1 ci2 cik SharedCoverageci j ci j1 j 0 k holds c0 ci0 c1 cik1 As c1 G 1 c1 G 2 c0 G 2 exist cim cim1 0 cid2 m cid2 k cim G 1 SharedCoveragecim cim1 holds However conﬂicts condition G 2 property CompetenceClosureG 2 cid2 G 2 cim1 G 2 cim1 Compared competence group model competence closure model permit sharing competence coverage competence closures truly makes independent contribution global competence We claim important characteristic partitioning space independently assists estimation empirical probability P A P B P A B A B mutually exclusive Corollary 1 For G 1 CB G 1 property CompetenceClosureG 1 exist G2 CB G 1 G 2 G 2 property CompetenceClosureG 2 Proof As Theorem 2 cid2 Corollary 1 proves later claim competence closure maximal set cases competence related Proposition 5 For G CB G 1 G G property CompetenceGroupG G 1 property CompetenceClosureG 1 Let G 2 G G 1 G 2 cid8 φ G 2 property CompetenceGroupG 2 Proof For ci G 2 G G 1 G property CompetenceGroupG exists c j G SharedCoverageci c j holds As G G 1 G 2 G 1 G 2 φ c j G 1 c j G 2 If c j G 1 conﬂicts G 1 property CompetenceClosureG 1 Therefore c j G 2 ci G 2 exists c j G 2 SharedCoverageci c j holds For c j CB G 2 CB G G 1 c j CB G c j G 1 If c j CB G G property CompetenceGroupG exist cm G 2 G SharedCoveragec j cm holds Or c j G 1 exists cm G 2 G G 1 SharedCoveragec j cm holds This conﬂict G 1 property CompetenceClosureG 1 cid2 Theorem 3 For G CB G property CompetenceGroupG G property CompetenceClosureG exists i1 G G G property CompetenceClosureG cid4 n Proof For ci G G property CompetenceGroupG property CompetenceClosureG exist c j G ﬁnd ci1 ci2 cik G SharedCoverageci j ci j1 j 0 k holds ci ci0 c j cik1 We continuously remove c j G ﬁnd c j construct G 1 G Since G N Lu et al Artiﬁcial Intelligence 209 2014 1128 17 Fig 1 Competence closure vs competence group property CompetenceGroupG exist ci ck G 1 SharedCoverageci ck holds G 1 cid8 φ Then cm G 1 exists cl G 1 SharedCoveragecm cl holds ci G 1 ﬁnd ci1 ci2 cik G 1 SharedCoverageci j ci j1 j 0 k holds cm ci0 cl ci1 ci cik1 Therefore cm G 1 conﬂicts cm G 1 So cm G 1 exist cl G 1 SharedCoveragecm cl holds We conclude G 1 G G 1 property CompetenceClosureG 1 Let G i1 G m 1 2 n 1 property CompetenceGroupG Gm1 G cid4 cid8 φ We construct Gm1 continuously G i1 G Gm1 property CompetenceClosureGm1 cid2 cid4 G G 1 according Proposition 5 G cid4 G cid4 G cid4 cid4 m m cid4 As entire casebase viewed competence group Theorem 3 certiﬁes casebase split set competence closures To sum competence closure model outweighs competence group model features follows First competence closure model able uniquely model entire casebase Considering casebase competence group according Theorem 3 casebase modeled set competence closures A suspicious case differs neighbors solves solved modeled competence group model This important suspicious cases likely behave like noisy novel cases 57 Second competence closure model provides smaller granularity competence group model Theorem 1 Theorem 3 This essential competenceguided case discovery 56 competence holes believed exist neighbor competence groups Third competence closure maximum set concerning series related problems Corollary 1 competence closures said independent terms related set Theorem 2 This facilitates narrowing analysis interesting subproblem space represented competence closures We differences competence closure model existing competence group model Fig 1 It seen competence closure deﬁned maximal set cases linked related sets competence group union competence closures competence closure case In Smyth McKennas 262855 competence model competence contributed certain case modeled coverage set Deﬁnition 1 Meanwhile existence case support cases solve words reachability set Deﬁnition 2 The related set provides measurement related competence single case Intuitively related set highlights set interesting target problems related case However related set overlaps related set certain case measurement problem space relates case In sense propose competence model related closure Deﬁnition 7 represent problem space relation certain case group cases terms related sets Deﬁnition 7 See 33 For c CB denote RelatedSetc regard CB RCBc deﬁne Related Closure c regard CB cid11CBc cid5 cid6 RCBci ci CB RCBci st c RCBci For group cases S CB deﬁne theRelated Closure S regard CB cid7 cid11CBS cid11CBc 2 3 cS Example 1 Let CB c1 c2 c3 c4 RCBc1 c1 c2 RCBc2 c1 c2 c3 c4 RCBc3 RCBc4 c2 c3 c4 The lated closure c3 set related sets regard CB contain case c3 That cid11CBc3 c1 c2 c3 c4 c2 c3 c4 We proposed new competence model We discussed properties Smyth McKennas 262855 competence model shown theoretically competence model 18 N Lu et al Artiﬁcial Intelligence 209 2014 1128 suitable change detection purposes In following section introduce metric measures distance case chunks based metric develop change detection method 4 Competencebase empirical distance When mining concept drifting data common assumption uptodate data chunk yettocome data chunk share identical considerably close distributions 1 This means newly available cases represent cept interested future In CBR considering cases existing case base newly available cases samples drawn probability distributions able identify concept drift detecting possible distribution change existing case base newly available case chunk This section proposes weighted approach measure difference case chunks weight related sets differently ac cording distribution cases The competencebased empirical distance case chunks deﬁned weights Given case base CB case sample sets S1 S2 CB obtain related closures cid11CBS1 cid11CBS2 In tuitively measure difference cid11CBS1 cid11CBS2 distance S1 S2 However represent distance competencies covered samples The relative distribution discrepancy competence missing This introduces problem compare case samples solve similar prob lems dramatically different distributions To address problem assign weight element cid11CBS1 cid11CBS2 represent relative density cases distributed related closures Deﬁnition 8 Let cid11CBS rCB n S cid11CB S rCB S deﬁne density rCB S regard S w cid8 cid9 rCB S 1 S 1 S rCB cid10 cid11CB 2 S rCB S cid11CBc j cid11CBc j c j S 4 Example 2 Let S c1 c4 case sample set taken case base Example 1 Therelated closure S set related sets contain element S We cid11CBc1 cid5 c1 c2 c1 c2 c3 c4 cid6 cid11CBc4 cid5 c2 c3 c4 c1 c2 c3 c4 cid6 cid11CBS c1 c2 c2 c3 c4 c1 c2 c3 c4 Let cid11CB cid11 cid8cid11 cid11 cid11 cid11cid11CB cid11cid11CBc1 cid11 cid11 1 S cid11CBc1 1 S c1 c2 weight c1 c2 regard S cid11 cid11 cid11 cid11cid11CBc4 cid11 cid11 1 S cid11CBc4 12 c1 c2 cid11 cid11cid11CB 14 w cid9 cid8 cid9 Theorem 4 The sum densities elements cid11CBS equals 1 cid11CBScid10 i1 w cid8 cid9 rCB S 1 Proof Substitute Eq 4 Eq 5 left 1 S cid11CBScid10 cid10 i1 c j S cid11CB S cid11CBc j cid11CBc j 1 S cid10 cid11CBScid10 c j S i1 cid11CB S cid11CBc j cid11CBc j 5 6 As cid11CB S cid11CB j S φ cid8 j cid11CBS cid11CBc j cid11CBS cid4cid11CBS i1 cid11CB S according deﬁnition related closure Deﬁnition 4 cid11CBScid10 i1 cid11CB S cid11CBc j cid11CBc j cid11CBS cid11CBc j cid11CBc j 1 Substitute Eq 7 Eq 6 left equals right cid2 7 From practical point view means cases sample S equally important regard contribution density elements cid11CBS matter related sets The density weights related set related closure degree sample cases distributed We deﬁne competencebased empirical weight case sample regard certain interesting subproblem space Deﬁnition 9 N Lu et al Artiﬁcial Intelligence 209 2014 1128 19 Deﬁnition 9 Given case base CB case sample set S CB denote power set cid11CBCB cid11CBCB Consid ering cid11CBCB measurable space A A A deﬁne thecompetencebased empirical weight S regard A CB S CB A cid12 Acid11CBS i1 rCB w rCB S S Acid11CBS cid12cid11CBS i1 wrCB S Acid11CBScid10 w cid8 cid9 rCB S i1 S Acid11CBS rCB 8 For case sample set S competencebased empirical weight provides reference degree case distribution competence area represented A subset cid11CBCB The higher weight larger proportion cases S support selected competence area Deﬁnition 10 For case sample sets S1 S2 CB deﬁne competencebased empirical distance S 1 S2 dCBS1 S2 2 sup AA cid11 cid11S CB 1 A S CB cid11 cid11 2 A Proposition 6 Given case base ﬁnite size CB case sample set S CB cid11CBS ﬁnite set Proof Since case c CB corresponds related set RCBc cases correspond related set size cid11CBCB equal size case base Again according deﬁnition related closure Deﬁnition 7 case sample set S CB cid11CBS cid11CBCB cid11CBS cid2 cid11CBCB cid2 CB As size case base ﬁnite cid11CBS ﬁnite set cid2 Remark This ensures solution A A exists deﬁned competencebased empirical distance A ﬁnite set Theorem 5 Given case base ﬁnite size CB competencebased empirical distance case sample S CB normalized quasidistance function dCB S S 0 1 satisﬁes following conditions S 1 S2 S3 CB 1 0 cid2 dCBS1 S2 cid2 1 2 dCBS1 S2 0 S1 S2 3 dCBS1 S2 dCBS2 S1 4 dCBS1 S3 cid2 dCBS1 S2 dCBS2 S3 Proof Condition 1 2 3 obvious For condition 4 assume exists A1 A Ai A 10 3 A1 existence A1 proven Proposition 6 Again cid11 cid11S CB 1 A1 S CB cid11 cid11 cid3 3 A1 cid11 cid11 3 Ai cid11 cid11S CB 1 Ai S CB 1 A1 S CB We dCBS1 S3 2 S CB A2 A3 A Ai A cid11 cid11S CB cid11 cid11S CB 1 A2 S CB 2 A3 S CB Clearly dCBS1 S2 cid3 2 S CB dCBS1 S2 2 dCBS2 S3 2 cid11 cid11 cid3 2 2 A2 cid11 cid11 cid3 2 3 A3 1 A1 S CB cid11 cid11S CB cid11 cid11S CB 1 Ai S CB 2 Ai S CB cid11 cid11 2 Ai cid11 cid11 3 Ai dCBS1 S2 dCBS2 S3 cid8cid11 cid11S CB 1 A1 S CB cid11 cid11S CB 1 A1 S CB cid3 2 cid3 2 cid11 cid11 cid11 cid11S CB 2 A1 cid11 cid11 dCBS1 S3 3 A1 cid11 cid9 cid11 2 A1 S CB 3 A1 cid2 9 11 12 13 2 A1 dCBS2 S3 cid3 2 S CB 2 A1 S CB 3 A1 Note S1 S2 suﬃcient condition dCBS1 S2 0 competencebased empirical distance compares distance case sets competencies real distribution Any pair case sets exhibit identical distribution regard competence result distance zero This easily proven constructing sample sets paired cases different related set We concept drift competencebased empirical distance current case base newly available case chunk greater ε Similar Kifer BenDavid Gehrkes work 35 set A depicts local competence area largest distribution discrepancy lies samples helps explain detected change The determination ε statistical guarantee detection method discussed Section 5 20 N Lu et al Artiﬁcial Intelligence 209 2014 1128 5 Statistical guarantee The choice distance function determine change aspect concept drift detection method provide statistical signiﬁcance detected change Given observation case samples achieve answering question How likely observation obtained null hypothesis H0 case concept drift occurs The smaller value socalled pvalue stronger evidence H0 This work resorts twosample nonparametric permutation test method 47 provide statistical guarantee detected change The permutation test easy implement free mathematical assumptions commonly theoretical distribution test statistic complicated unknown suits situation 51 Permutation test Recall problem description Section 21 case sets CB CB representing unknown distributions F CB F CB cid4 respectively We like perform hypothesis test determine F CB F CB cid4 identical In Section 4 deﬁned notation distance test statistic simplicity denote test statistic ˆθ Once observation ˆθ case calculation distance current case base incoming new case samples achieved signiﬁcance level ASL pvalue test deﬁned probability observing extreme observed ˆθ assuming null hypothesis true cid4 ASL P H0 cid5 ˆθ cid3 ˆθ cid6 null hypothesis distribution distri 14 quantity ˆθ ﬁxed observed value random variable ˆθ bution ˆθ H0 true 47 The permutation test clever way approximating ASL null hypothesis F CB F CB cid4 works follows Given case base n cases incoming new case sample m cases null hypothesis observed case come equally case sets We combine m n cases sample size n replacement represent case base remaining m cases constitute incoming case sample We compute test statistic permutation repeat process large number times N Finally estimate ASL permutation test Monte Carlo approach 58 ASLperm AˆSLperm ˆθ cid3 ˆθ N 15 Once ﬁx desired signiﬁcance level α compare α permutation ASL We concept drift ASLperm α For example choosing α 005 reject null hypothesis 5 level corresponding respectively 5 chance rejecting null hypothesis true false positive In fact permutation test relies sampling enumeration yield actual signiﬁcance level larger α Monte Carlo error 5960 52 Permutation sample size In real world applications obtaining exact ASL permutation test enumeration quickly unfeasible permutation sample space increases This raises question permutation replications N required As illustrated Efron Tibshirani 47 Opdyke 60 N ˆA follows binomial distribution BiN A ˆA AˆSLperm A ASLperm Using normal approximation BiN A 95 conﬁdence interval ˆA approximated 2 standard deviation ˆA If want Monte Carlo error A 196 σ σ A1 AN 1 affect estimation 30 σ A cid2 03 gives N cid3 100 A 01 The precision improved larger N Fig 2 6 Experimental evaluation Our evaluation proposed competencebased concept drift detection method consists sections experiments source code downloaded httpdecideitutseduauPhilipindexphp 1 We evaluate competencebased empirical distance compare test statistics twosample KolmogorovSmirnov test Experiments 13 2 We compare change detection method Dasu et al 36 We choose synthetic datasets ﬁrst parts need know change generated distribution advance In addition simulated data able control change easily detection method performs different types changes Experiments 47 N Lu et al Artiﬁcial Intelligence 209 2014 1128 21 Fig 2 Monte Carlo error vs permutation replication size Fig 3 Competencebased empirical distance normal distributed data varies μ Fig 4 Cumulated competencebased empirical distance normal data varies μ 3 We perform casebase editing method based results detection compare results real datasets original author 18 detection method aims identify change Experiment 8 61 Evaluating competencebased empirical distance In Section 4 proposed competencebased empirical distance measure difference distribution To establish varies according change generated distributions ran experiments generated artiﬁcial datasets following 1D normal distributions compared results test statistics twosample KolmogorovSmirnov test Two cases considered able mutually solve Euclidean distance smaller threshold dε All results calculated mean 100 independent tests Experiment 1 Varying mean μ In experiment compared distances data samples size 100 drawn 11 normal distributions ﬁxed standard deviation σ 02 moving mean value μ 02 006 1 ith distribution 1 2 11 When t 2 1 compared samples drawn ith distribution t 2 compared samples drawn ith 1st distribution Fig 3 shows competencebased empirical distance changes distributions vary Since extent difference depends mean values ﬁnd similar height peaks series Fig 3 We tried ﬁxing data sample moving order distance increases difference means increases Fig 4 It worth noting test statistics sample KS test sensitive change margin peaks valleys larger Fig 3 increases faster difference accumulates Fig 4 This competencebased empirical distance eliminates change happened problem space 22 N Lu et al Artiﬁcial Intelligence 209 2014 1128 Fig 5 Competencebased empirical distance normal data difference size Fig 6 Competencebased empirical distance normal distributed data varies σ cases considered similar CBR In return detection method reliable small samples shown Experiment 2 Experiment 2 Varying sample size In experiment compared distances data samples drawn N02 02 N044 02 respectively We increased sample size 100 1000 As shown Fig 5 test statistics sample KS test shrinks sample size increases competencebased empirical distances remain relatively steady Also seen sample size larger 800 distance remains series Experiment 3 Varying σ In experiment ﬁxed mean μ 05 varied standard deviation σ 01 002 1 ith distribution 1 2 11 Again t 2 1 compared samples drawn ith distribution t 2 compared samples drawn ith 1st distribution The sample size set 1000 As shown Fig 6 competencebased empirical distances larger margin peaks valleys means method sensitive smaller changes KS test change shrinks σ increases compared Experiment 1 Intuitively distribution concentrated relative distance smaller 62 Evaluating competencebased change detection method In experiments demonstrated competencebased empirical distance ﬂuctuates derlying distribution changes In order determine given measurement statistically suﬃciently signiﬁcant qualify concept drift plug permutation test estimate ASL described Section 5 Given desired signiﬁcance level α concept drift ASLperm α In following experiment aim compare change detection results Dasu et al 36 There main reasons choose method compar ison First resort similar approach concept drift detection adopting distance metric performing hypothesis test Second compared errorrate based detection methods methods depend classiﬁer broader application scope To fair comparison Dasu et al 36 set experimental environments includes following features strategy data source parameter For strategy adopt ﬁxsliding windows model keeping ﬁxed reference window concept drift reported moving windows Also detection late reported moving windows actual window contains change For data source implement artiﬁcial datasets Dasu et al 36 The detailed information artiﬁcial data source described experiment setup section We parameters permutation test comparing includes desired signiﬁcance level α 1 permutation size N 500 We N Lu et al Artiﬁcial Intelligence 209 2014 1128 23 Table 1 Change detection results different 2D normal data streams The detection results Dasu et al 36 shown brackets Stream M005 M002 C01 C015 C015 C02 Window size n 10000 10000 10000 10000 5000 5000 Detected 97 97 86 70 56 43 91 83 84 68 96 93 Late 0 1 6 20 8 18 2 10 7 14 1 5 False 4 4 5 4 4 3 5 4 11 17 10 15 Table 2 Change detection results different 2D Poisson distributed data streams The detection results Dasu et al 36 shown brackets Step size cid9 Window size n 01 02 10000 10000 Detected 88 67 99 98 Late 2 17 0 1 False 4 1 5 5 Missed 2 1 7 9 35 38 6 6 8 17 2 1 Missed 9 15 0 0 evaluate changed parameters effects shown proved Section 5 For experiments section parameter dε construct competence model chosen empirically similar partition size kdqtree Dasu et al 36 A practical solution constructing competence models real world applications described Section 63 Experiment 4 Normal distributions This experiment implements artiﬁcial datasets Dasu et al 36 Mcid9 stream varying mean μ1 μ2 independently 02 08 step size chosen randomly cid9 cid92 cid92 cid9 Ccid9 stream varying ρ starts 0 randomly walks 1 1 step size chosen randomly cid9 cid92 cid92 cid9 Each stream consists 5000000 twodimensional normal distributed points divided groups 50000 giving 99 changes total To construct competence model dε set 005 From results shown Table 1 method outperforms Dasu et al 36 Both methods achieve similar results M005 C02 stream performs signiﬁcantly better streams means method sensitive smaller changes compared Dasu et al 36 As expected overall detection accuracy increases window size increases Our method results dramatic decrease number late detections window size increases This probably proposed competencebased empirical distance allows different related cases share distribution contributions regard competence model cut exclusively regions improving robustness smaller samples The number false detections Dasu et al 36 In fact false detection rate largely depends desired signiﬁcance level α nature permutation test Our detection method depends appropriateness competence model In real world scenarios possible way constructing competence model use leaveoneout strategy shown Section 63 resort available information reasoning history experts Experiment 5 Poisson distributions In experiment compare detection results 2D discrete Poisson distribu tions data streams generated according X Y Poisson5001 ρ 5001 ρ 500ρ ρ starts 05 performs random walk 0 1 step size cid9 02 01 manner Experiment 4 We generated bivariate Poisson Trivariate Reduction 61 To construct competence model dε set 10 Experiment 6 Higher dimensions To test scalability performance scheme high dimensions C02 stream extend ddimensional streams adding dimensions data distributions Gaussian σ 02 change We standard deviation added dimensions C streams order maintain marginal distribution dimensions overall distance cases contributed dimension equally important In fact competence model depends distance cases large marginal stable distributions dominate calculation distance cases cause failure detection method However issue easily solved adopting weighted distance calculation To construct competence model dε set 015 4dimensional 03 6dimensional 05 10dimensional recall dε chosen similar partition size kdqtree The experimental results different dimensions listed Table 3 As expected stationary dimensions added harder detect real changes However detection method preserves power number dimensions increase This proof detection method sensitive smaller changes Also late detection robustness smaller sample method 24 N Lu et al Artiﬁcial Intelligence 209 2014 1128 Table 3 Change detection results ddimensional streams The detection results Dasu et al 36 shown brackets D 4 6 10 Window size n 10000 10000 10000 Detected 93 89 91 84 75 65 Late 0 1 5 10 5 12 False 4 7 4 8 5 6 Missed 6 9 3 5 21 22 Table 4 Running time different dimensions window sizes Dimension d Window size n Competence s kdqtree s 6 8 10 10 20 10000 10000 10000 20000 50000 0021 0025 0025 0042 0117 0021 0029 0035 0037 0069 Experiment 7 Eﬃciency The nature detection method consists parts space partition calculating test statis tics determining critical region We Dasu et al 36 able compute test statistics directly adopt permutation test determine critical region We compare cost ﬁrst maintenance competence model case vs updating kdqtree Dasus case We use standard approach updating competence model case addition 62 These running times obtained unoptimized C code laptop PC 23 GHz Intel i5 processor 4 GB memory The eﬃciency competencebased concept drift detection algorithm little affected number dimensions directly related window size While window size increases time grows linearly In fact maintenance cost proven estimated O n time new case added current casebase compared case casebase determine cases solve cases solve 62 To contrary updating cost kdqtree little affected window size exhibits linear relationship dimension This updating cost kdqtree proven O d log 1 δ 36 63 Evaluating description competencebased change detection method In order method help real world scenarios apply detection method real world concept drift datasets available httpdecideitutseduauPhilipindexphp Each dataset consists 10000 emails collected period approximately year individual A training set 1000 cases including 500 spam emails 500 legitimate emails set dataset The remaining data test algorithm time We perform realtime change detection incoming new email trigger maintenance operations competence areas identiﬁed undergoing changes For detailed information concept drift datasets refer Section 5 Delany et al 18 Experiment 8 We compare results original author dataset 18 recent work concept drift 24 In order compare fairly Delany et al 18 choose classiﬁer knearest neighbor k 3 unanimous voting Again weight features equally similarity cases measured proportion matched features The related set constructed leaveoneout classiﬁcation That case ci considered solved actually retrieved cases successfully solve ci bounded closest case c j fails solve ci For LearnNSE 24 build new casebase month criteria described base classiﬁer choose parameter values suggested paper 05 b 10 We aware fair choose parameter values different dataset method determining parameters provided values reported work scenarios attempted Our spam ﬁltering algorithm starts provided training set After classiﬁcation perform competence based change detection algorithm A maintenance operation triggered concept drift detected adapt quickly new concept tune future detections Our tuning mechanism hybrid PECS 23 BBNR 19 speciﬁcally adopted enhance PECS On hand concept drift BBNR prevents noisy case inclusion hand concept drift areas reported changing fact measured set A Deﬁnition 10 identify remove cases conﬂict new case The idea tuning strategy concept drift data stream old cases help identify noise improve accuracy concept drift new instances representative novel concept old cases conﬂict help N Lu et al Artiﬁcial Intelligence 209 2014 1128 25 Fig 7 Results concept drift dataset 1 As CBE method described Delany et al 18 considers competence enhancement competence preserva tion plugin redundancy removal operation removes cases uniformly competence space ensures removed cases correctly solved We 1500 cases dataset 1 2500 cases dataset 2 This limit determined according Delany et al 18 reports resulting size casebase data applied 10 months dataset 1 12 months dataset 2 1512 2518 respectively We incorporate redundancy removal operation LearnNSE 1 intend retain original methods 2 base classiﬁer LearnNSE relatively small meets speed storage requirements Since error rate good metric skewed datasets common performance metrics 63 spam ﬁltering N Legitimate TNFN FP means legitimate emails incorrectly classiﬁed spam FN means evaluate performance Legitimate Recall LR deﬁned LR TN Precision LP deﬁned LP TN spam emails incorrectly classiﬁed legitimate TN TNFP The classiﬁcation results month datasets shown respectively Fig 7 Fig 8 26 N Lu et al Artiﬁcial Intelligence 209 2014 1128 Fig 8 Results concept drift dataset 2 These results clearly demonstrate strategy effectively improved results LR LP datasets Our approach mainly improves LP This kNN unanimous voting As result mistakenly retaining noisy spam emails competence area affect classiﬁcation result legitimate email mistakenly retaining legitimate email dramatically affect classiﬁcation result spam email Compared CBE improvement LP statistically signiﬁcant datasets paired ttest 94 conﬁdence level This shows method accurately catch concept drift perform targeted reactions We observed LearnNSE worst months principally following reasons 1 The ensemble approach adopted LearnNSE performed postponed updating schema new base classiﬁer trained monthly As result advantage uptodate feedback timely adaptation It appear online learning schema suitable spam ﬁltering domain feature space large sparse concept drift changes rapidly 2 The weight base classiﬁer calculated log operator generate unlimited ﬁgure As result single base classiﬁer dominate ﬁnal prediction result In experiments time t base classiﬁer ht trained latest dataset Dt achieved best performance Dt Note weight base classiﬁer assigned based behavior Dt concept drifts N Lu et al Artiﬁcial Intelligence 209 2014 1128 27 incoming dataset Dt1 follow different distribution Dt Unfortunately Learn NSE incorporate drift detection mechanism cope situation 7 Conclusions studies The competence group model inadequate deﬁcient We consequently proposed deﬁned competence closure model This study conducts theoretical study competence group model ﬁnds guarantee complete splitting casebase competence groups inadequacy guarantee competence groups mutually independent deﬁciency This research deﬁnes competence closure model overcome problems reveals essential differences models It identiﬁes important aspects competence closure model competence group model possess 1 competence closure model able uniquely model entire casebase 2 competence closure model provides smaller granularity competence group model 3 competence closure maximum set concerning series related problems competence closures said independent terms related set Concept drift reﬂect competence measurement We presented method detect concept drift competence models requires prior knowledge distribution measures competence model The competencebased change detection method applied CBR systems new cases available sequentially time Empirical experiments report advantages proposed competencebased change detection method 1 high achieved detection rate 2 robustness small sample size 3 ability quantify changes detects makes highly suitable handling local concept drift problems We competencebased empirical weight provides rough estimation competence distribution cases Our attempt aim provide reliable competence distribution fuzzy probability theory Another improvement achieved drawing sample contains duplicates permutation test proven Opdyke 60 Finally paper work handling concept drift problems CBR Successive case base editing methods metric learning methods advantage change detection needed improve ﬁnal learning performance Acknowledgements The work presented paper supported Australian Research Council ARC Discovery Project DP110103733 We wish thank anonymous reviewers helpful comments References 1 J Gao W Fan J Han On appropriate assumptions data streams analysis practice Proceedings Seventh IEEE International Conference Data Mining Omaha October 2831 2007 pp 143152 2 P Zhang X Zhu Y Shi Categorizing mining concept drifting data streams Proceedings Fourteenth ACM SIGKDD International Conference Knowledge Discovery Data Mining Las Vegas Nevada USA August 2427 2008 pp 812820 3 Z Ouyang M Zhou T Wang Q Wu Mining conceptdrifting noisy data streams ensemble classiﬁers Proceedings International Conference Artiﬁcial Intelligence Computational Intelligence AICI China November 78 2009 pp 360364 4 G Widmer M Kubat Learning presence concept drift hidden contexts Mach Learn 23 1996 69101 5 G Hulten L Spencer P Domingos Mining timechanging data streams Proceedings Seventh ACM SIGKDD International Conference Knowledge Discovery Data Mining San Francisco California August 2629 2001 pp 97106 6 L Cohen G Avrahami M Last A Kandel Infofuzzy algorithms mining dynamic data streams Appl Soft Comput 8 2008 12831294 7 CP Wei IT Chiu Turning telecommunications details churn prediction data mining approach Expert Syst Appl 23 2002 103112 8 G Widmer M Kubat Effective learning dynamic environments explicit context tracking Proceedings European Conference Machine Learning ECML93 Vienna Austria April 57 1993 Lecture Notes Artiﬁcial Intelligence Springer 1993 pp 227243 9 KO Stanley Learning concept drift committee decision trees 2003 UTAITR03302 10 G Forman Tackling concept drift temporal inductive transfer Proceedings TwentyNinth Annual International ACM SIGIR Conference Research Development Information Retrieval Seattle Washington USA August 611 2006 pp 252259 11 A Tsymbal M Pechenizkiy P Cunningham S Puuronen Dynamic integration classiﬁers handling concept drift Inf Fusion 9 2008 5668 12 MA Maloof RS Michalski Incremental learning partial instance memory Artif Intell 154 2004 95126 13 WN Street Y Kim A streaming ensemble algorithm SEA largescale classiﬁcation Proceedings Seventh ACM SIGKDD International Conference Knowledge Discovery Data Mining San Francisco California August 2629 2001 pp 377382 14 H Wang W Fan PS Yu J Han Mining conceptdrifting data streams ensemble classiﬁers Proceedings Ninth ACM SIGKDD Interna tional Conference Knowledge Discovery Data Mining Washington DC August 2427 2003 pp 226235 15 M Last Online classiﬁcation nonstationary data streams Intell Data Anal 6 2002 129147 16 WF Hsiao TM Chang An incremental clusterbased approach spam ﬁltering Expert Syst Appl 34 2008 15991608 17 R Klinkenberg Learning drifting concepts Example selection vs example weighting Intell Data Anal 8 2004 281300 18 SJ Delany P Cunningham A Tsymbal L Coyle A casebased technique tracking concept drift spam ﬁltering KnowlBased Syst 18 2005 187195 19 SJ Delany P Cunningham An analysis casebase editing spam ﬁltering Proceedings Seventh European Conference Case Based Reasoning Madrid Spain AugustSeptember 2004 pp 128141 20 DW Aha D Kibler MK Albert Instancebased learning algorithms Mach Learn 6 1991 3766 21 P Cunningham N Nowlan SJ Delany M Haahr A casebased approach spam ﬁltering track concept drift Proceedings ICCBR03 Workshop LongLived CBR Systems Trondheim Norway June 2003 28 N Lu et al Artiﬁcial Intelligence 209 2014 1128 22 A Tsymbal The problem concept drift Deﬁnitions related work Department Computer Science Trinity College Dublin Ireland April 2004 TCDCS200415 23 M Salganicoff Tolerating concept sampling shift lazy learning prediction error context switching Artif Intell Rev 11 1997 133155 24 R Elwell R Polikar Incremental learning concept drift nonstationary environments IEEE Trans Neural Netw 22 2011 15171531 25 MM Richter Introduction M Lenz et al Eds CaseBased Reasoning Technology From Foundations Applications Springer Heidelberg 1998 pp 115 26 B Smyth MT Keane Remembering forget A competencepreserving case deletion policy casebased reasoning systems Proceedings Fourteenth International Joint Conference Artiﬁcial Intelligence San Francisco August 2025 Morgan Kaufmann 1995 pp 377382 27 J Zhu Q Yang Remembering add Competencepreserving caseaddition policies casebase maintenance Proceedings Sixteenth Inter national Joint Conference Artiﬁcial Intelligence IJCAI Stockholm Sweden July 31August 6 1999 pp 234241 28 B Smyth E McKenna Competence models maintenance problem Comput Intell 17 2001 235249 29 S Massie S Craw N Wiratunga Complexity proﬁling informed casebase editing Proceedings Eighth European Conference ECCBR Fethiye Turkey September 47 2006 pp 325339 30 S Craw S Massie N Wiratunga Informed case base maintenance complexity proﬁling approach Proceedings TwentySecond National Conference Artiﬁcial Intelligence vol 2 Vancouver British Columbia Canada July 2226 2007 pp 16181621 31 R Pan Q Yang SJ Pan Mining competent case bases casebased reasoning Artif Intell 171 2007 10391068 32 DC Wilson DB Leake Maintaining casebased reasoners Dimensions directions Comput Intell 17 2001 196213 33 N Lu G Zhang J Lu Detecting Change Competence Model Proceedings Eighteenth International Conference CaseBased Reasoning Research Development Alessandria Italy July 1922 2010 pp 201212 34 I Žliobait e Adaptive training set formation PhD thesis Vilnius University Vilnius 2010 35 D Kifer S BenDavid J Gehrke Detecting change data streams Proceedings Thirtieth International Conference Very Large Databases vol 30 Toronto Canada August 31September 3 2004 pp 180191 36 T Dasu S Krishnan S Venkatasubramanian K Yi An informationtheoretic approach detecting changes multidimensional data streams Pro ceedings ThirtyEighth Symposium Interface Statistics Computing Science Applications Interface 06 Pasadena CA May 2427 2006 pp 124 37 JP Patist Optimal window change detection Proceedings Seventh IEEE International Conference Data Mining Workshops ICDMW 07 Omaha NE USA Oct 2831 2007 pp 557562 38 A Bifet R Gavaldà Learning timechanging data adaptive windowing Proceedings Seventh SIAM International Conference Data Mining SDM07 Minneapolis MN USA Apr 2628 2007 pp 443448 39 J Gama P Medas G Castillo P Rodrigues Learning drift detection Proceedings Seventeenth Brazilian Symposium Artiﬁcial Intelli gence Sao Luis Maranhao Brazil September 29October 1 2004 pp 286295 40 M BaenaGarcía J CampoÁvila R Fidalgo A Bifet R Gavaldà R MoralesBueno Early drift detection method ECMLPKDD 2006 Workshop Knowledge Discovery Data Streams Berlin Germany Sep 18 2006 pp 7786 41 Y Yasumura N Kitani K Uehara Quick adaptation changing concepts sensitive detection Proceedings Twentieth International Confer ence Industrial Engineering Other Applications Applied Intelligent Systems Kyoto June 2629 2007 pp 855864 42 P Li X Hu Q Liang Y Gao Concept drifting detection noisy streaming data random ensemble decision trees Proceedings Sixth International Conference Machine Learning Data Mining Pattern Recognition Leipzig July 2325 2009 pp 236250 43 B Su YD Shen W Xu Modeling concept drift perspective classiﬁers IEEE Conference Cybernetics Intelligent Systems CIS 08 Chengdu China Sep 2124 2008 pp 10551060 44 F Wilcoxon Individual comparisons ranking methods Biom Bull 1 1945 8083 45 A Kolmogoroff Conﬁdence limits unknown distribution function Ann Math Stat 12 1941 461463 46 NV Smirnov Approximate laws distribution random variables empirical data Usp Mat Nauk 10 1944 179206 47 B Efron RJ Tibshirani An Introduction Bootstrap Chapman Hall New York 1993 48 K Nishida K Yamauchi Detecting concept drift statistical testing Proceedings Tenth International Conference Discovery Science DS 07 Sendai Japan Oct 14 2007 pp 264269 49 Y Freund RE Schapire A decisiontheoretic generalization online learning application boosting J Comput Syst Sci 55 2007 119139 50 G Welch G Bishop An introduction Kalman ﬁlter Technical Report TR95041 University North Carolina 1995 51 C Englund A Verikas A hybrid approach outlier detection offset lithographic printing process Eng Appl Artif Intell 18 2005 759768 52 F Angiulli RBE Zohary L Palopoli Outlier detection default reasoning Artif Intell 172 2008 18371872 53 A Dries U Rückert Adaptive concept drift detection Stat Anal Data Min 2 2009 311327 54 S Massie S Craw N Wiratunga What CBR competence BCSSGAI Expert Update 8 2005 710 55 B Smyth E McKenna Modelling competence casebases Proceedings Fourth European Workshop Advances CaseBased Reason ing Dublin Ireland September 1998 pp 208220 56 E McKenna B Smyth Competenceguided case discovery Proceedings TwentyFirst SGES International Conference Knowledge Based Systems Applied Artiﬁcial Intelligence Cambridge UK December 1012 2001 pp 97108 57 H Brighton C Mellish Advances instance selection instancebased learning algorithms Data Min Knowl Discov 6 2002 153172 58 E Koehler E Brown SJPA Haneuse On assessment Monte Carlo error simulationbased statistical analyses Am Stat 63 2009 155162 59 KJ Berry PW Mielke Moment approximations alternative F test analysis variance Br J Math Stat Psychol 36 1983 202206 60 JD Opdyke Fast permutation tests maximize power conventional Monte Carlo sampling pairwise multiple comparisons J Mod Appl Stat Methods 2 2004 2749 61 KV Mardia Families Bivariate Distributions Griﬃn London 1970 62 B Smyth E McKenna An eﬃcient effective procedure updating competence model casebased reasoners Proceedings Eleventh European Conference Machine Learning ECML 00 Barcelona Catalonia Spain May 31June 2 2000 pp 357368 63 KR Gee Using latent semantic indexing ﬁlter spam Proceedings Eighteenth Annual ACM Symposium Applied Computing SAC 03 Melbourne FL USA Mar 912 2003 pp 460464