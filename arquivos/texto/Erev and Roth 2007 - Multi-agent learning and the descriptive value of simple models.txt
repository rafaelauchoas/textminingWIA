Artiﬁcial Intelligence 171 2007 423428 wwwelseviercomlocateartint Multiagent learning descriptive value simple models Ido Erev Alvin E Roth b Technion Israel b Harvard University USA Received 25 April 2006 received revised form 20 October 2006 accepted 22 November 2006 Available online 26 January 2007 Abstract Behavioral research suggests human learning multiagent systems predicted surprisingly simple foresightfree models The current note discusses implications research relationship observation social interactions tend complicate learning 2007 Elsevier BV All rights reserved Keywords Reinforcement learning Fictitious play Equivalent Number Observations ENO Reciprocation 1 Introduction Shoham Powers Grenager 28 ask multiagent learning answer question Their search interesting questions focuses observation analysis learning multiagent settings tends complex analysis individual learning For example oneperson twoperson games opens door phenomena like role teaching reciprocation learning In comment try extend search interesting questions considering possibility increase number agents simplify task capturing human learning The basic idea multiagent interactions expected effect agent environment agents small In addition opportunity observe behavior agents reduces importance exploration Multiagent transportation games natural example Each agent games select transportation route The aggregate choices determine payoffs effect agent typically small And agents observe exploration important Each agent learn experience similar agents observe Our research suggests similar games multiagent learning usefully described predicted surprisingly simple foresightfree reinforcement learning models models ignore possibility current choices change environment andor provide information needed maximize long term outcomes The ﬁctitious play rule 25 example foresightfree learning model trial t agent selects action led best average outcomes ﬁrst t 1 trials A stochastic variant model considered In Section 2 review research help illustrate value simple learning models describing human behavior lab In Section 3 return Shoham et als question kinds questions Corresponding author Email addresses erevtxtechnionacil I Erev arothhbsedu AE Roth 00043702 matter 2007 Elsevier BV All rights reserved doi101016jartint200701001 424 I Erev AE Roth Artiﬁcial Intelligence 171 2007 423428 results optimistic answer We formulate questions study multiagent learning help answer involving speed learning converges equilibrium different strategic environments individual decision making oneshot tasks behavior natural settings 2 The value simple models human learning multiagent settings We focus descriptive agenda 28 consider learning models capture human behavior ob served laboratory As suggested Shoham et al increase number agents increases set feasible strategies complicate models learning Indeed experimental research suggests agents sider complex reciprocationrelated strategies twoperson games 24 Nevertheless argue number agents large simple descriptive models individual learning predict multiagent learning surprisingly We argue multiagent games simpler equilibria behavior large multiagent games captured simple models But preliminary evidence suggests interesting important multiagent environments behavior usefully approximated simple models Three observations support assertion presented 21 Reciprocation fouragent settings In classic book Rapoport Chammah 24 demonstrated human agents learn reciprocate certain repeated twoperson prisoner dilemma games In experiments participants played game Table 1 300 trials opponent immediate feedback trial knowing trials played The results showed low initial rate cooperation 30 second block 50 trials increase cooperation experience The cooperation rate block higher 50 It easy results captured simple learning model ignores teaching andor reciprocation 14 Such models predict decrease cooperation time To evaluate failure basic learning models Danieli 8 ran versions experiment described The ﬁrst computerized replication original study The participants run cohorts divided pairs Each pair interacted 300 times The results condition similar original results The proportion cooperation block 50 trials 65 The second condition identical ﬁrst exception participants cohort randomly rematched trial This change dramatic effect results The proportion cooperation block 50 trials dropped 15 These results suggest simple foresightfree models fail capture 2person interaction better job capturing 4person interaction The results suggest effect factors ignored models like reciprocation teaching quickly drop number agents increases We note number players important pattern interaction When players paired ﬁxed pairings periods reciprocation cooperation develop For example BerebyMeyer Roth 4 report experiment conditions reproduces effect earlier observed Selten Stoecker 27 Andreoni Miller 1 When subjects rematched play different counterparts 10period repeated prisoners dilemma number periods played partner common knowledge players learn experience cooperate high probability ﬁrst periods cooperate low probability ﬁnal periods repeated game BerebyMeyer Roth environmental factors affect speed learning large consequences cooperation achieved point return later Table 1 One prisoner dilemma games studied Rapoport Chammah 24 Player 1 C D Player 2 C 1 1 10 10 D 10 10 1 1 I Erev AE Roth Artiﬁcial Intelligence 171 2007 423428 425 22 The role exploration Evaluation descriptive value foresightfree learning models individual choice tasks 11 reveals high sensitivity feedback Foresightfree models ﬁt observed learning environment static feedback includes information concerning payoffs actually obtained foregone payoffs achieved actions werent chosen However models type tend fail feedback limited obtained payoffs When feedback limited simple foresightfree models tend predict strong hot stove effect learning prefer safer alternative 9 Human behavior exhibits weaker effect type This failure simple foresightfree models likely related exploration alternative actions Exploration little effect foregone payoffs known drive learning feedback limited Modeling human exploration exploratory behavior trivial It humans learn increase exploration rate exploration likely increase long term expected return Thus decision explore involves foresight This shortcoming foresightfree learning models appears relevant context multiagent games actions observable related arguments 57 When agents observe behavior outcomes similar agents observations provide information concerning foregone payoffs For example multiagent transportation games foregone payoffs inferred outcomes obtained agents 23 Generality predictive value In Erev Roth 13 examined basic foresightfree reinforcement learning models ignore dynamic features environment capture behavior games unique mixed strategy equilibrium The data consid ered paper included results published experiments apparently complex patterns In games studied experience quickly moved behavior equilibrium 23 games little cor respondence observed results equilibrium 29 Moreover studies nonmonotonic learning trends The lefthand Fig 1 presents ﬁve games analyzed paper The experimental results equilibrium predictions summarized lefthand column proportion A choices The righthand columns results simulations virtual agents behave according simple foresightfree learning models play games The virtual experiments run conditions original studies In particular included number trials original studies The results models presented Fig 1 capture main behavioral trends Good ﬁt models observed behavior obtained observed behavior near far equilibrium predictions It important emphasize high correspondence observed human behavior models result overﬁtting data Similarly good correspondence observed parameters learning models estimated set games predict behavior second set games A clear demonstration point provided 15 That paper uses stochastic variant ﬁctitious play model 1617 predict behavior randomly selected constant sum games The probability selecting alternative k trial t modeled Pkt eqktλst cid2 2 j 1 eqj tλst 1 qj t propensity select strategy j λ payoff sensitivity parameter St measure experi enced regret The adjusted propensity select alternative j trial t 1 qj t 1 1 wqj t w xj t 2 xj t payoff j trial t w parameter determines weight payoff The initial value qj 1 0 The level experienced regret St modeled weighted average difference obtained maximal payoff St 1 1 wSt w cid3 cid3 cid3 cid3maxt xj t 3 426 I Erev AE Roth Artiﬁcial Intelligence 171 2007 423428 Fig 1 Repeated 2 2 games 2129 In games payoff unit increases probability winning 16 SA2 18 SA8 110 SA3k SA3u In ML payoffs directly converted money Each cell lefthand column presents experimental results The proportion A choices subjects role grouped 5 8 blocks function time 200210 trials cases The righthand columns present models predictions format The equilibrium predictions presented righthand data cells Adapted 13 maxt maximal payoff obtained trial t 2 alternatives The initial regret level set equal S1 λ The parameters models estimated Ert Erevs 16 study individual decisions The estimated value w 045 λ 27 The value models predictions assessed computing models equivalent number observations ENO A models ENO estimate expected size experiment run mean observations accurate models predictions The estimated ENO learning model 167 That models prediction subjects behave given game accurate prediction based average behavior 16 pairs subjects observed playing game In comparison estimated ENO equilibrium prediction 117 That equilibrium provides better prediction pair I Erev AE Roth Artiﬁcial Intelligence 171 2007 423428 427 players play game observation single pair players playing game good prediction observing pairs players Additional studies good predictive value simple learning models limited twoperson games unique mixed strategy equilibrium Similar results observed extensive form games 26 Coordination games 12 team games 6 In papers learning models able predict human behavior games observed behavior converged quickly equilibrium games behavior remained persistently far equilibrium 3 Three questions Research reviewed suggests study learning multiagent systems shed light important questions One question environments human learning converge equilibrium behavior intermediate term That expect learning multiplayer economic environments proceed time scale allow equilibration occur faster big changes economic environment Or fast observe equilibration lab cf 26 The model presented data summarizes suggest answer important cases yes One environmental factor robustly slows learning games payoff variability 41822 This sistent observation psychology literature partial reinforcement adding randomness link action consequences holding expected payoffs constant slows learning This effect considerably magniﬁed multiplayer games repeated prisoners dilemma When slow learn cooperate beneﬁts cooperation reduced hampers cooperation That game learn depends learning BerebyMeyer Roth observed small change payoff environment changes speed individual learning large effect collective behavior These results suggest interesting comparative dynamics derived paying attention fact behavior learned experience Closely related question learned decisions decisions experience similar decisions based complete description incentive structure like decisions studied Kahneman Tverskys 19 classic work The answer Indeed deviations rational choice observed decisions experience opposite direction deviation rational choice captured prospect theory In particular prospect theory implies oversensitivity low probability outcomes decisions experience reﬂect sensitivity events 3 The high estimated weighting parameters w 045 reﬂect high sensitivity recent outcomes Therefore rare events likely occur recently receive cases little attention A question involves practical implications behavioral research considered Speciﬁcally study human learning lab shed light human behavior natural settings We believe answer question yes In respect encouraged robustness experimental results The fact wide set experimental conditions captured simple 2parameter model suggests observed behavior reﬂects general behavioral tendencies We similarly encouraged observations interesting empirical phenomena reﬂect underweighting rare events payoff variability effect review 10 An im portant example wont happen phenomenon observation people tend violate safety rules behavior impairs expected utility Finally able compare laboratory results behavior observe market participants learning ﬁeld environments 220 lab substantially reproduces ﬁeld 4 Summary Most studies multiagent learning focus fact social interaction complicates learning task Here highlight fact certain settings increase number agents reduces sensitivity learning process exploration environmentmodifying strategies One way think analogy environ ments player negligible effect environment people behave economists 428 I Erev AE Roth Artiﬁcial Intelligence 171 2007 423428 price takers essentially treating environment ﬁxed collective behavior produces plays large role shaping environment Early evidence suggests settings important aspects human behavior captured surprisingly simple foresightfree learning models While foresightfree models shed little insight human thinking believe shed light important behavioral questions people learn respond incentives environment They capture nontrivial properties human behavior References 1 J Andreoni JH Miller Rational cooperation ﬁnitely repeated Prisoners dilemma Experimental evidence The Economic Journal 103 1993 570585 2 D Ariely A Ockenfels AE Roth An experimental analysis ending rules Internet auctions RAND Journal Economics 36 4 2005 891908 3 G Barron I Erev Small feedback based decisions limited correspondence description based decisions Journal Behavioral Decision Making 16 2003 215233 4 Y BerebyMeyer AE Roth Learning noisy games Partial reinforcement sustainability cooperation American Economic Review 1 96 4 2006 10291042 5 C Bolton O Harris Strategic experimentation Econometrica 67 1999 349374 6 G Bornstein E Winter H Goren Experimental study repeated teamgames European Journal Political Economy 12 1996 629639 7 MW Cripps JC Ely GJ Mailath L Samuelson Common learning Working paper 2005 8 H Danieli Social dilemmas design simulators MSc Thesis Technion 2000 Hebrew 9 J Denrell JG March Adaptation information restriction The hot stove effect Organization Science 12 2001 523538 10 I Erev On weighting rare events economics small decisions SH Oda Ed Advances Experimental Economics Lecture Notes Economics Mathematical Systems vol 590 Springer 2007 press 11 I Erev G Barron On adaptation maximization reinforcement learning cognitive strategies Psychological Review 112 4 2005 912931 12 I Erev A Rapoport Magic reinforcement learning coordination market entry game Games Economic Behavior 23 1998 146175 13 I Erev AE Roth Predicting people play games Reinforcement learning games unique strategy equilibrium American Economic Review 88 1998 848881 14 I Erev AE Roth On simple reinforcement learning models reciprocation prisoner dilemma game G Gigerenzer R Selten Eds The Adaptive Toolbox MIT Press Cambridge MA 2001 pp 215232 15 I Erev AE Roth RL Slonim G Barron Learning equilibrium useful approximations Accuracy prediction randomly selected constant sum games Economic Theory 2007 press 16 E Ert I Erev Replicated alternatives role confusion chasing regret decisions experience Journal Behavioral Decision Making 2007 press 17 D Fudenberg D Levine Theory Learning Games MIT Press Cambridge MA 1998 18 E Haruvy I Erev D Sonsino The medium prizes paradox Evidence simulated casino Journal Risk Uncertainty 22 2001 251261 19 D Kahneman A Tversky Prospect theory An analysis decision risk Econometrica 47 1979 263291 20 JH Kagel AE Roth The dynamics reorganization matching markets A laboratory experiment motivated natural experiment Quarterly Journal Economics 2000 201235 21 D Malcolm B Lieberman The behavior responsive individuals playing twoperson zerosum game requiring use mixed strategies Psychonomic Science 12 1965 373374 22 JL Myers E Sadler Effects range payoffs variable risk taking Journal Experimental Psychology 60 1960 306309 23 B ONeill Nonmetric test minimax theory twoperson zerosum games Proceedings National Academy Sciences USA 1987 21062109 24 A Rapoport AM Chammah Prisoners Dilemma A Study Conﬂict Cooperation University Michigan Press Ann Arbor 1965 25 J Robinson An iterative method solving game Annals Mathematics 54 1951 296301 26 AE Roth I Erev Learning extensiveform games Experimental data simple dynamic models intermediate term Games Economic Behavior 8 1995 164212 27 R Selten R Stoecker End behavior sequences ﬁnite prisoners dilemma supergames A learning theory approach Journal Economic Behavior Organizations 7 1986 4770 28 Y Shoham R Powers T Grenager If multiagent learning answer question Artiﬁcial Intelligence 171 7 2007 365377 issue 29 P Suppes RC Atkinson Markov Learning Models Multiperson Interactions Stanford University Press 1960