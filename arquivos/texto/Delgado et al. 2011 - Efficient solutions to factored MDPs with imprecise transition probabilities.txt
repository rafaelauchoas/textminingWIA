Artiﬁcial Intelligence 175 2011 14981527 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Eﬃcient solutions factored MDPs imprecise transition probabilities Karina Valdivia Delgado Scott Sanner b Leliane Nunes Barros ac EACH Universidade São Paulo Av Arlindo Béttio 1000 Ermelino Matarazzo São Paulo SP Brazil b NICTA Australian National University Canberra ACT 2601 Australia c IME Universidade São Paulo Rua Matão 1010 Cidade Universitária São Paulo SP Brazil r t c l e n f o b s t r c t Article history Received 3 December 2009 Received revised form 31 December 2010 Accepted 31 December 2010 Available online 4 January 2011 Keywords Probabilistic planning Markov Decision Process Robust planning When modeling realworld decisiontheoretic planning problems Markov Decision Process MDP framework impossible obtain completely accurate estimate transition probabilities For example natural uncertainty arises transition speciﬁcation elicitation MDP transition models expert estimation data nonstationary transition distributions arising insuﬃcient state knowledge In obtaining robust policy transition uncertainty Markov Decision Process Imprecise Transition Probabilities MDPIPs introduced model scenarios Unfortunately solution algorithms exist MDPIPs require external calls optimization routines extremely time consuming practice To address deﬁciency introduce factored MDPIP propose eﬃcient dynamic programming methods exploit structure Noting key computational bottleneck solution factored MDPIPs need repeatedly solve nonlinear constrained optimization problems target approximation techniques drastically reduce computational overhead nonlinear solver producing bounded approximately optimal solutions Our results orders magnitude speedup comparison traditional ﬂat dynamic programming approaches order magnitude speedup extension factored MDP approximate value iteration techniques MDPIPs producing lowest error approximation algorithm evaluated 2011 Elsevier BV All rights reserved 1 Introduction Markov Decision Processes MDP 1 facto standard model decisiontheoretic planning problems great deal research recent years aimed exploit structure order compactly represent eﬃciently solve factored MDPs 25 However realworld problems simply impossible obtain precise representation transition probabilities MDP This occur reasons including imprecise conﬂicting elicitations experts b insuﬃcient data estimate reliable precise transition models c nonstationary transition probabilities insuﬃcient state information For example MDP traﬃc light control diﬃcult estimate turn probabilities traﬃc lane option going straight turning These laneturning probabilities change day year function traﬃc intersections based holidays special events general impossible Corresponding author Tels 55 11 73326036 55 11 30919878 fax 55 11 30916134 Email addresses kvduspbr KV Delgado ssannernictacomau S Sanner lelianeimeuspbr LN Barros 00043702 matter 2011 Elsevier BV All rights reserved doi101016jartint201101001 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1499 accurately model complex dependencies In case ideal traﬃc control policy optimized range turn probabilities order robust inherent nonstationarity turn probabilities To accommodate optimal models sequential decisionmaking presence strict uncertainty transition model MDP imprecise transition probabilities MDPIP introduced 67 While MDPIP poses robust framework realworld application decisiontheoretic planning general solution requires use computa tionally expensive optimization routines extremely timeconsuming practice To address computational deﬁciency extend factored MDP model MDPIPs proposing replace usual Dynamic Bayes Net DBN 8 factored MDPs Dynamic Credal Nets DCNs 9 support compact factored structure imprecise transition model factored MDPIPs Then propose eﬃcient scalable algorithms solving factored MDPIPs This leads following novel contributions work We introduce parameterized ADD PADD polynomial expressions leaves explain extend ADD properties operations PADDs We extend decisiondiagram based SPUDD APRICODD algorithms MDPs 34 MDPIP algorithms exploit DCN structure PADDs As shown experimental evaluation generalization SPUDD APRICODD MDPIPs PADDs ﬁrst step obtaining eﬃcient solutions Observing key computational bottleneck solution MDPIPs need repeatedly solve nonlinear constrained optimization problems target approximations drastically reduce computational overhead nonlinear solver producing provably bounded approximately optimal solutions As results demonstrate contributions obtain orders magnitude speedup comparison traditional ﬂat dynamic programming approaches 6 In addition best approximate factored MDP IP solver yields order magnitude speedup direct generalization stateoftheart approximate factored MDP solvers 4 factored MDPIPs implemented work consistently produces lowest error approxi mate solution algorithms evaluated 2 Markov decision processes Formally MDP deﬁned tuple M cid3S A P R T γ cid4 110 cid5s conditional probability reaching state s S ﬁnite set fully observable states A ﬁnite set actions P s R S A R ﬁxed reward function associated state action T time horizon number decision stages remaining decisionmaking γ 0 1 discount factor reward obtained t stages future discounted sense multiplied cid5 S action A taken state s S γ t A stationary policy π S A indicates action π s state s regardless stage The value stationary policy π deﬁned expected sum discounted rewards inﬁnite horizon T starting state s0 stage 0 following π V π s Eπ cid4 cid4 s0 s γ t Rt cid5 cid2 cid3 t0 1 Rt abbreviation Rt st π st reward obtained stage t agent state st takes action π st 1 decomposed rewritten recursively based values possible successor states s cid6 cid5 S follows cid3 cid6 cid6 cid7 2 V π s R cid7 s π s γ cid7 cid5s π s cid5 V π s P s scid5S Our objective ﬁnd optimal policy π yields maximal value state s π cid5 V π s cid2 V π cid5 s A wellknown algorithm solve MDP value iteration 1 For t 0 constructs series tstagetogo value functions V t Starting arbitrary V 0 value iteration performs value updates states s computing V t based V t1 The Qvalue state s action Q ts Rs γ cid6 P cid5s s cid7 V t1 cid7 cid6 cid5 s cid3 scid5S best value attainable decision stage t state s 3 1500 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 Fig 1 A credal set example represented gray region The credal set deﬁned triplets P x1 P x2 P x3 belong region V ts max A Q ts We deﬁne greedy policy πV wrt V follows cid8 πV s arg max A Rs γ cid6 P cid5s s cid7 cid6 V cid5 s cid9 cid7 cid3 scid5S At inﬁnite horizon value function provably converges cid4 cid4 cid4V ts V t1s cid4 0 max s lim t 4 5 6 leading stationary deterministic optimal policy π πV 1 For practical MDP solutions concerned cid4optimality If terminate MDP following condition met cid4 cid4 cid4V ts V t1s cid4 max s cid41 γ 2γ guarantee greedy policy πV t π 1 3 MDPs imprecise transitions loses cid4 value inﬁnite horizon comparison 7 As described introductory traﬃc example necessary work imprecise probabilities order represent incomplete ambiguous conﬂicting expert beliefs transition probabilities An MDP imprecise transition probabilities MDPIP1 speciﬁcally designed setting simply extension MDP transition probabilities imprecisely speciﬁed That instead probability measure P s state space S set probability measures For example let P X probability density function X x1 x2 x3 deﬁned following constraint set cid10 C P x1 cid3 23 P x3 cid3 23 2P x1 cid2 P x2 P x1 P x2 P x3 1 cid11 8 The twodimensional region probability measures satisfy C shown gray region Fig 1 This referred credal set set probability measures set distributions random variable 11 We denote credal set distributions variable X K X Next slightly specialize deﬁnition credal set specify uncertainty MDPIP transition probabilities 1 The term MDPIP proposed White III Eldeib 7 Satia Lave Jr 6 adopt instead term MDP Uncertain Transition Probabilities KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1501 Deﬁnition 31 Transition credal set A credal set containing conditional distributions state s action referred transition credal sets 11 denoted K s deﬁne imprecisely speciﬁed transition probabilities given state s cid5s Thus P s K s cid5 We assume credal sets closed convex assumption literature cid5s cid5s cid5s selected corresponding credal sets timedependent encompasses practical applications 12 We assume stationarity transition credal sets K s cid5s nonstationary note require P s depend stage t While K s stationary MDPIP distributions P s manner 13 Formally MDPIP deﬁned MIP S A K R T γ This deﬁnition identical MDP M transition distribution P replaced transition credal set K We represent K implicitly set transition probabilities consistent set linear inequality constraints C like 8 probability parameters There optimization criteria deﬁne value policy MDPIP In context discounted inﬁnite horizon setting focus work deterministic stationary policy cid5s maximin optimal 6 policy achieve greater value assumption Natures selects P s adversarially minimize value given assumption A ﬁnite credal set K closed policy induces optimal value function unique ﬁxedpoint solution cid12 V s max A min P K Rs γ cid6 P cid5s s cid7 cid6 cid5 s V cid13 cid7 cid3 scid5S 9 There algorithms solving ﬂat enumerated state MDPIPs based dynamic programming 67 In work build ﬂat value iteration solution MDPIPs 6 cid12 V ts max A min P K Rs γ cid6 P cid5s s cid7 V t1 cid6 cid5 s cid13 cid7 cid3 scid5S 10 Value iteration MDPIPs given 3 4 MDPs state s optimize action choice A wrt worstcase distribution P K minimizes future expected value Thus ensure resulting value function policy robust worst outcome Nature choose light future value V t1s cid5 expect achieve As noted Natures true transition function P nonstationary Nature choose different P K action state s decision stage t As example nonstationarity occur practice previously discussed traﬃc scenario observed traﬃc turn probabilities differ holidays versus normal weekdays embedded traﬃc controller explicitly aware holiday state description However long transition nonstationarity bounded P K convergence properties MDPIP value iteration 10 hold 13 In 149 shown MDPIP solutions formulated bilevel multilinear programming problem In paper interested extending dynamic programming solution MDPIPs 67 outlined eﬃciently solve problems factored state description discuss 4 Factored MDP MDPIPs 41 Factored MDP In MDPs natural think state assignment multiple state variables transition function compactly speciﬁes probabilistic dependence variables state subset variables current state Such approach naturally leads deﬁne Factored MDP 2 S cid10x Here cid10x x1 xn state variable xi 0 12 The deﬁnition actions A unchanged MDPs factored MDPs reward simply speciﬁed Rcid10x The transition probabilities factored MDP encoded Dynamic Bayesian Networks DBNs 8 A DBN directed acyclic graph DAG layers layer represents variables current state layer cid5 represents state Fig 2a Nodes xi x refer respective current state variables The connection layers deﬁnes dependences state variables wrt execution action A Directed edges allowed nodes ﬁrst layer second layer nodes second layer cid5 cid5 parents x edges termed synchronic arcs We denote paax graph action The graph cid5 encodes standard Bayes net conditional independence assumption variable x conditionally independent nondescendants given parents incidentally DBN encodes Markov assumption current state 2 While extensions necessarily restricted binary state variables restriction simplicity notation 1502 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 cid5 Fig 2 A Dynamic Bayesian Network DBN action b conditional probability table x 2 cid5 1 c conditional probability table x 2 0 independent history given previous state The use DBN leads following factorization transition probabilities cid6 P cid5cid10x cid10x cid7 ncid14 i1 cid6 P cid5 x paa cid6 cid5 x cid7 cid7 Fig 2b shows conditional probability table CPT P x The tables combinations variable assignments parents x row Fig 2b Fig 2c 1 easily veriﬁed cid5 2 cid5 cid5 1paax 2 Fig 2c shows CPT x 2 0 cid5 cid5 2 deﬁnition sum 2 pax 11 42 Factored MDPIP As ﬁrst major contribution extend factored MDP representation 2 compactly represent MDPIPs This simply requires modifying DBN transition representation account uncertainty exact transition probabili ties Before formally transition function ﬁrst introduce possible extension SysAdmin factored MDP allow imprecise transition probabilities use running example factored MDPIP SysAdmin domain 5 In SysAdmin domain n computers c1 cn connected different directed graph topologies unidirectional ring b bidirectional ring c independent bidirectional rings pairs computers Fig 3 Let state variable xi denote ci running xi 1 xi 0 Let Connc j ci denote connection c j ci Formally CPTs domain following form rebootci 1 cid11 rebootci xi 1 pi1 x j jcid11ix j1Connc jci 1 cid11 rebootci xi 0 pi2 x j jcid11ix j1Connc jci 1 x j jcid11iConnc jci 1 1cid10x iii ii cid5 x P cid6 cid7 x j jcid11iConnc jci 1 12 constraints C probabilities variables C 085 pi2 cid3 pi1 cid3 095 We n 1 actions rebootc1 rebootcn notreboot indicates machine rebooted The intuition Eq 12 rebooted probability running time step 1 situation rebooted current state running situation ii running situation iii probability depends fraction computers incoming connections currently running The probability parameters pi1 pi2 constraint C deﬁne credal sets K cid10x The reward SysAdmin simply 1 computers running time step reward 0 cid19 n i1 xi An optimal policy problem reboot impact expected Rcid10x future discounted reward given network conﬁguration Like previous deﬁnition enumerated state MDPIP set legal transition distributions factored MDPIP deﬁned credal set K The challenge specify transition credal sets factored manner KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1503 Fig 3 Connection topologies SysAdmin example unidirectionalring b bidirectional ring c independent bidirectional rings pairs computers 5 Fig 4 Dynamic Credal Network action notreboot unidirectionalring topology SysAdmin domain 2 computers b Conditional prob cid5 1 constraints related probabilities c The Parameterized ADD representation ability table state variables x 1 x x1 x2 notreboot CPT notreboot A solid line indicates true 1 branch variable test dashed line indicates false 0 branch cid5 1 x 2 cid5 P x 1 cid5 1 compact For propose use dynamic credal networks DCNs special case credal networks 1115 appropriate language express factored transition credal sets Deﬁnition 41 Factored transition credal set A credal set containing conditional distributions values variable xi given values paaxi parents xi graph action referred factored transition credal set denoted Kaxipaaxi Deﬁnition 42 Dynamic credal network A Dynamic credal network DCN generalization DBN Different deﬁnition DBN DCN variable xi associated factored transition credal sets Kaxipaaxi value paaxi We assume DCN represents joint credal set 1511 variables consisting distributions cid5 paax satisfy factorization Eq 11 CPT distribution P x element transition credal cid5 set Kax cid5 paax associated DCN cid5 A DCN example shown Fig 4a For variable x cid5 DCN conditional probability table CPT imprecise probabilities If examine CPTs Fig 4b note entries speciﬁed probability parameters pi j cid5 cid5 variable x Furthermore note set linear j jth parameter CPT x constraints pi j shown boxes CPT collectively constraint set C We use cid10p denote vector containing parameter values free vary given credal sets satisfy probability constraints C DCN We note joint transition probability nonlinear probability parameters cid10p However explicitly introduce following restriction prevent exponents exceeding 1 cid5 Restriction 43 DCN parameter restriction factored MDPIP CPTs parameter pi j appear CPT x cid5 1 x 2 cid5 multiplied determine This restriction prevents multiplication pi j CPTs x joint transition distribution DCN This subset nonlinear expressions exponent pi j 0 1 referred multilinear expression To multilinearity transition probability Fig 4 observe cid5 P x 1 When combined set constraints C pi j eﬃcient implementations use practice solve resulting multilinear program Interestingly additional restrictions linear constraints C deﬁned pi j multilinear program Restriction 43 actually turns minor limitation practice demonstrate experimental domains Section 8 1x1 1 x2 1 notreboot p11 p21 1504 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 Fig 5 An example reward function Rx1 x2 x3 cid20 3 i1 xi represented ADD Even qualitatively represent conditional independence properties distribution DCNs certain independences represent Credal network structure independences hold speciﬁc contexts assignments values certain variables known contextspeciﬁc independence CSI 16 In order compactly represent CSI shared function structure CPTs MDPIP propose novel extension algebraic decision diagrams ADDs 17 called parameterized ADDs PADDs leaves parameterized expressions shown Fig 4c PADDs allow compactly represent CPTs factored MDPIPs enable eﬃcient computations factored MDPIP value iteration operations outline 5 Parameterized algebraic decision diagrams Algebraic decision diagrams ADDs 17 generalization ordered binary decision diagrams BDDs represent boolean functions 0 1n 0 1 18 A BDD data structure decision nodes node labeled boolean test variable successor nodes l low h high The arc node successor l h represents assignment 01 test variable BDDs DAGs variable tests path root leaf follow ﬁxed total variable ordering BDDs generate value boolean function follows given assignments boolean test variables BDD follow branches l h leaf boolean value returned function The difference ADD BDD terminal nodes ADD real values ADDs permit compact representation functions 0 1n R BDDs ADDs provide eﬃcient representation functions cid20 contextspeciﬁc independence 16 shared function structure For example reward function Rx1 x2 x3 3 i1 xi represented Fig 5 ADD exploits redundant structure subdiagrams DAG representation Operations ADDs performed eﬃciently exploiting DAG structure ﬁxed variable ordering Examples eﬃcient ADD operations unary operations min max return minimum maximum value leaves eliminates variable xi ADD binary operations given ADD marginalization variables addition subtraction cid14 multiplication division cid16 min max return ADD minmax values leaves We refer reader 17 details cid20 xi Parameterized ADDs PADDs extension ADDs allow compact representation functions 0 1n E E space expressions parameterized cid10p case restrict space multilinear expressions cid10p For example CPT Fig 6 represented PADD contains leaves consisting single parameters Fig 8d shows PADD leaf containing complex parameterized expression In following formally deﬁne PADDs basic operations needed construct eﬃcient solutions MDP IPs Because PADDs introduced solve MDPIPs following restrictive assumptions allow multilinear expressions leaves b deﬁne subset PADD operations inherited ADDs c operations closed yield resulting PADD multilinear leaves operations needed MDPIPs Finally contribute new unary operation MinParameterOut mincid10p speciﬁc PADDs 51 PADD Formal deﬁnition properties operations PADDs generalize constant realvalued leaves ADDs polynomials Poly expressed sumofproducts canonical form d0 cid3 cid14 di pi j j 13 di constants pi j parameters Formally deﬁne PADD following BNF grammar3 3 We adopt lowercase f refer mathematical function uppercase F refer function represented structurally PADD KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1505 cid5 cid5 2 action a1 b The Parameterized ADD representation P x Fig 6 Conditional probability table state variable x 2 1x1 x2 x3 x4 a1 F PolyifF var Fh Fl cid3 Poly d0 pi j cid14 di j This grammar notationally overloaded brieﬂy explain PADD node F terminal node expression type Poly decision node variable test F var x1 xn branches Fh Fl grammar nonterminal type F Fh taken F var 1 Fl taken F var 0 The value returned function f represented PADD F containing subset variables x1 xn variable assignment ρ 0 1n deﬁned recursively V alF ρ F Poly F cid11 Poly ρF var true ValFh ρ F cid11 Poly ρF var false ValFl ρ Poly This recursive deﬁnition ValF ρ reﬂects structural evaluation PADD F starting root node following branch decision node corresponding variable assignment ρ continuing leaf node reached returned V alF ρ As example PADD represented Fig 6 assigning ρ 1 0 1 0 variables x1 x2 x3 x4 yields ValF ρ p21 Like ADDs function f x1 xn ﬁxed variable ordering x1 xn reduced PADD deﬁned minimally sized ordered decision diagram representation function f Lemma 51 There exists unique reduced PADD F canonical PADD representation f satisfying given variable ordering ρ 0 1n f ρ ValF ρ The proof lemma BDDs provided 19 trivially generalized ADDs PADDs Since PADDs allow polynomial leaves change demonstrating lemma need ensure exists way identify leaf expressions identical easily sorting parameters multilinear term b factoring grouping terms ordered set parameters summing constants identical multilinear terms c sorting list terms according lowest variable index number parameters With unique leaf identiﬁcation method proof 19 generalizes PADDs shows unique canonical PADD representation function 0 1n polynomials form 13 In fact minimal reduced PADD exist function f represented PADD straightforward algorithm computing called ReducePADD present Section 521 Before present formal PADD algorithms ﬁrst discuss extensions unary binary operations ADDs PADDs Fortunately requires operations leaves ADDs modiﬁed accept produce resulting polynomials form 13 511 Binary operations PADDs The binary operations sum cid14 subtraction deﬁned ADDs 17 extended PADDs closed operations yield PADDs leaves form 13 However binary operation product 1506 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 Fig 7 An example application Restrict operation Marginalization operation PADD yield PADD leaves form 13 set parameters cid10p leaves operand disjoint Fortunately factored MDPIPs note place compute product DCN CPTs Restriction 43 usage parameters pi j CPTs note condition closed operations PADDs satisﬁed required factored MDPIP operations However PADD binary operations simple conditions closed We note PADDs closed cid16 binary division resulting leaves polynomial fraction expressed 13 Similarly binary min max operations deﬁned ADDs 17 generally computed closed form actual assignment parameters cid10p known Fortunately cid16 min max needed proposed solution factored MDPIPs 512 Unary operations PADDs The important classical unary operations ADDs restriction F xi marginalization extended PADDs follows cid20 xi easily Restriction variable xi true F xi 1 false F xi 0 calculated replacing decision nodes variable xi high low branch respectively This operation marginalization This operation affect leaves decision diagram extension ADDs PADDs straightforward cid20 The marginalization sum_out operation represented eliminates variable xi ADD It computed xi sum true false restricted functions F xi 1 F xi 0 Since closed PADDs marginalization closed PADDs An example shown Fig 7 The classical unary min max operations ADDs generally computed PADDs actual assignment parameters cid10p known However need particular PADD operation factored MDPIPs new unary operation PADDs called MinParameterOut case choices Nature Eq 9 Deﬁnition 52 MinParameterOut operation Represented mincid10pF operation takes input 1 PADD F 2 set C global constraints PADDs parameters returns ADD We note ADD special case PADD constant expressions leaves implies mincid10pF closed PADDs This unary operation calls nonlinear solver leaf expression e form 13 compute c mincid10pe wrt constraints C replaces leaf e constant c Because set variable assignments reach PADD leaf disjoint leaf minimized indepen dently This precisely operation need factored MDPIPs note Nature performs minimization independently state s 9 path PADD correspond different state assignment An example mincid10pF shown Fig 12 52 PADD algorithms Previously discussed PADD algorithms conceptually subsection discuss implement eﬃcient operations PADDs In following algorithms use hash tables ReduceCache NodeCache ApplyCache Min ParCache We use notation key value represent keyvalue pairs hash table The table NodeCache stores unique identiﬁcation node representing subdiagrams unique identiﬁers hash table ReduceCache stores reduced canonical nodes results previous Reduce operations table ApplyCache stores results previous Apply operations avoid redundant calculations hash table MinParCache stores results previous MinParameterOut operations KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1507 Algorithm 1 ReducePADDF input F root node id arbitrary ordered decision diagram output F r root node id reduced PADD begin terminal node return canonical terminal node F terminal node return canonical terminal node polynomial F use recursion reduce sub diagrams F F r ReduceCache Fh ReducePADDFh Fl ReducePADDFl canonical internal node id F r GetNodeF var Fh Fl insert F F r ReduceCache return F r end 1 2 3 4 5 6 7 8 9 10 11 12 13 Algorithm 2 GetNodecid3var Fh Flcid4 input cid3var Fh Flcid4 variable true false branches node ids internal node output F r canonical internal node id 1 2 3 4 5 6 7 8 9 begin redundant branches Fl Fh return Fl check node exists previously cid3var Fh Flcid4 id NodeCache id new unallocated id insert cid3var Fh Flcid4 id NodeCache return id 10 end 521 Reduce algorithm PADDs While know exists unique canonical form function expressible PADD Lemma 51 algo rithm ReducePADD actually allows eﬃcient construction unique canonical PADD representation arbitrary ordered decision diagram polynomial leaves type 13 Algorithm 1 recursively constructs reduced PADD In algorithm internal node repre sented cid3F var Fh Flcid4 F var variable Fh Fl true false branch node ids respectively Additionally input F refers arbitrary node returned value Fr refers canonical node id Reduced canonical nodes stored hash table ReduceCache helper function GetNode Algorithm 2 ensures dundant decision tests internal nodes removed The table NodeCache function GetNode stores unique identiﬁcation node An example application ReducePADD algorithm shown Fig 8 The hollow arrow points internal node F evaluated ReducePADD recursive calls ReducePADD lines 7 8 line 10 Fig 8a shows input diagram algorithm x3 evaluated ReducePADD creating canonical terminal nodes 03 5p12 0 Note evaluating node x3 left execution line 10 result insertion cid3x3 03 5p12 0cid4 NodeCache hash table Fig 8b shows resulting evaluation node x3 right returns previous canonical terminal nodes 03 5p12 0 And executing line 10 GetNode algorithm return id cid3x3 03 5p12 0cid4 previously inserted NodeCache Fig 8c shows evaluation x2 Note Fh Fl equal getNode called Fl returned consequence x2 disappears Finally Fig 8d shows canonical PADD representation input Note ReducePADD Fl returned canonical terminal node exists previously node 0 The running time space ReducePADD linear size input diagram use ReduceCache guarantees node visited unique reduced node generated canonical diagram node visited 522 Apply algorithm binary operations PADDs The notation use paper PADDs shown Fig 9 Any operation PADDs F 1 F 2 results new subdiagrams Fh Fl Note F ih new canonical PADD Fr eventually new root node F var F il represent subdiagrams r For binary operations use generic function ApplyF 1 F 2 op Algorithm 3 result computation table helper function ComputeResult Table 1 supports operations arbitrary PADD nodes polynomial leaves 1508 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 Fig 8 A stepbystep illustration application ReducePADD algorithm Algorithm 1 d input output PADDs respectively Fig 9 The notation Apply ChooseVarBranch algorithms Fig 10 An example PADDs multiplication Table 1 implemented method named ComputeResult simply case structure line Table 1 Notice lines 29 Table 1 deﬁne result PADD operations special cases avoid unnecessary computation Apply The Apply algorithm Algorithm 3 input operands represented canonical PADDs F 1 F 2 binary operator op cid14 output result function application represented canonical PADD F r Apply F 1 F 2 op ﬁrst checks result immediately computed calling method ComputeResult line 3 If result null checks result previously computed checking ApplyCache stores results previous Apply operations line 6 If cache hit Apply chooses earliest variable ordering branch calling auxiliary function ChooseVarBranch Algorithm 4 branches variable recursive Apply calls compute Fl compute Fh After results operations checked redundancy elimination GetNode function An example PADD multiplication Apply algorithm shown Fig 10 523 MinParameterOut algorithm PADDs The MinParameterOut algorithm Algorithm 5 input canonical PADD F set constraints C PADDs parameters output result calling nonlinear solver PADD leaf represented canonical ADD F r MinParameterOut ﬁrst checks F constant terminal node case necessary nonlinear solver leaf If terminal node constant need nonlinear solver passing leaf expression objective minimize subject C line 7 If F terminal node Algorithm 5 recursively traverses PADD Similar ReducePADD internal node represented cid3F var Fh Flcid4 previously computed canonical nodes stored hash table MinParCache The helper function GetNode Algorithm 2 ensures redundant decision tests internal nodes removed With speciﬁcation MinParameterOut formally described PADD algorithms need factored MDPIP solution We omit restriction marginalization algorithms PADDs identical operations ADDs operations dont modify leaves place PADDs ADDs differ KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1509 Algorithm 3 ApplyF 1 F 2 op input F 1 root node id operand 1 F 2 root node id operand 2 op binary operator op cid14 output F r root node id resulting reduced PADD begin check result immediately computed ComputeResultF 1 F 2 op F r cid11 null return F r check previously computed operation cid3F 1 F 2 opcid4 F r ApplyCache choose variable branch var ChooseVarBranchF 1 F 2 set nodes recursion F 1 nonterminal var F var 1 F v1 l F v1 h F 1l F 1h F v1 lh F 1 F v2 l F v2 h F 2l F 2h F 2 nonterminal var F var 2 F v2 lh F 2 l F v2 l h F v2 use recursion compute true false branches resulting PADD Fl ApplyF v1 op Fh ApplyF v1 h op F r GetNodevar Fh Fl save result reuse future insert cid3F 1 F 2 opcid4 F r ApplyCache return F r end 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 Algorithm 4 ChooseVarBranchF 1 F 2 input F 1 root node id operand 1 F 2 root node id operand 2 output var selected variable branch begin select variable branch based order criterion F 1 nonterminal node F 2 nonterminal node comes F var 2 F var 1 var F var 1 var F var 2 var F var 1 var F var 2 return var end 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 6 Factored MDPIP value iteration In previous sections showed compact representation factored MDPIPs based dynamic credal net works DCNs parameterized ADDs PADDs respective algorithms needed manipulate DCNs PADDs In section present ﬁrst exact value iteration solution exploits representations This solution extension SPUDD 3 algorithm First mathematical description proposed solution proceed formally specify algorithm computes 61 SPUDDIP description We extend SPUDD 3 algorithm exploiting DBN ADD structure solution factored MDPs novel algorithm SPUDDIP exploiting DCN PADD structure solution factored MDPIPs We begin expressing 1510 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 Table 1 Input case result method ComputeResult binary operations cid14 PADDs Case number 1 2 3 4 5 6 7 8 9 F 2 Poly2 Case operation F 1 op F 2 F 1 Poly1 F 1 F 2 F 2 0 F 1 F 2 F 1 0 F 1 cid14 F 2 F 2 0 F 1 F 2 F 2 1 F 1 F 2 F 1 1 F 1 F 2 F 2 0 F 1 F 2 F 1 0 Return Poly1 op Poly2 F 1 F 2 F 1 F 1 F 2 0 0 null Algorithm 5 MinParameterOutF C input F root node id PADD C set constraints output F r root node id ADD begin terminal node solver return value F terminal node node canonical terminal node polynomial F node constant return node c CallNonLinearSolvernodeC return canonical terminal node constant c use recursion compute sub diagrams F F r ReduceCacheMinPar Fh MinParameterOutFh Fl MinParameterOutFl canonical internal node id F r GetNodeF var Fh Fl insert F F r ReduceCacheMinPar return F r end 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 MDPIP value iteration 10 following factored form transition representation 11 operations decision diagrams4 D D cid10x max V t A R D D cid10x γ min cid10p cid3 ncid21 P D D cid10xcid5 i1 cid6 cid6 cid7 cid7 cid5 x paa cid5 x V t1 D D cid6 cid7 cid5 cid10x 14 cid5 paax Because transition CPTs MDPIP DCN contain parameters cid10p CPTs represented decision diagram cid5 On hand reward R D D cid10x represented ADD format PADDs P D D x contains constants purpose operations recall ADDs special cases PADDs Although appear D D cid10x PADD note parameters cid10p minimizedout wrt constraints cid10p form V t cid2 MinParameterOut operation PADDs performs mincid10p minimization parameters calling nonlinear solver leaf returns ADD This crucial D D cid10x maxa A performed ADDs recall max closed operation PADDs Thus resulting V t computed maxa A constant leaves expressed ADD special case PADDs cid2 operation 14 remember mincid10p To explain eﬃcient evaluation 14 exploit variable elimination algorithm 20 cid5 cid5 cid11 1 push 1 dependent x cid10xcid5 For example x cid20 marginalization states cid5 1 inwards obtain sum x D D cid10x max V t A R D D cid10x γ min cid10p cid3 ncid21 cid6 cid5 x paa cid7 cid6 cid5 x P D D cid7cid3 cid5 icid111 x i1icid111 cid5 x 1 cid6 cid5 x 1 paa cid6 cid7 cid7 cid5 x 1 V t1 D D cid7 cid6 cid5 cid10x P D D 15 We graphically example Fig 11 Here ADD representation ﬁrst value function V 0 cid5 R D D Fig 11a multiply P D D x 1 cid5 paax 1 Fig 11b yielding result Fig 11c sum D D 4 We use D D functions represented ADDs PADDs ﬁrst special case second KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1511 Fig 11 We V 0 cid5 representation P x 1 PADD A D D x1 x2 notreboot CPT Rx1 x2 unidirectionalring topology SysAdmin domain 2 computers represented ADD b The PADD x cid5 1 notreboot resulting PADD d The result summing x notreboot c The multiplication V 0 CPT A D D cid5 1 cid5 1 x cid5 cid5 paax 2 1 obtain ﬁnal result Fig 11d Then continue x x cid5 cid5 cid5 compute cid2 After cid2 contain anymore variables x summing x 2 repeating x variables xi cid5 cid5 2 multiplying result P D D x 2 Representing contents cid2 f cid10x cid10p obtain cid25 D D cid10x max V t A R D D cid10x γ min cid10p f cid10x cid10p cid26 16 Note mincid10p f cid10x cid10p leads separate nonlinear expression minimization cid10x subject set C linear constraints cid10p given DCN speciﬁcation follows deﬁnition MDPIP Bellman equation state gets minimizer PADD leaf corresponds set states exactly minimization objective This optimization problem represented simple multilinear program cid5 Restriction 43 guarantees pi j appears DCN CPT x prevents multiplication pi j preventing exponents exceeding 1 This restriction important guarantee existence exact solutions existence eﬃcient implementations use practice solve multilinear programs We note restriction factored MDPIP models To demonstrate mincid10p f cid10x cid10p performed PADDs refer Fig 12 Here leaf expression f cid10x cid10p Fig 12a given PADD corresponds function Nature minimize state We cru cially note PADD aggregates states minimization objective saving timeconsuming calls multilinear solver We observe time savings experiments Now need multilinear solver leaf passing leaf expression objective minimize subject constraints C DCN specify legal cid10p minimization replace leaf constant optimal objective value returned multilinear solver Fig 12b We mincid10p operation PADDs simpliﬁed special case ADDs leaf nodes constants To complete step factored MDPIP value iteration ADD resulting mincid10p operation multiply scalar γ add reward R D D cid10x ﬁnally perform sequence binary ADD max operations compute maxa yielding ADD V t D D cid10x completing step value iteration 14 D D cid10x ADD V t1 62 SPUDDIP algorithm Factored MDPIP value iteration formally speciﬁed following procedures Solve Algorithm 6 constructs series tstagetogo value functions V t D D represented ADDs First create PADD representation DCN CPTs MDPIP initialize ﬁrst value function 0 line 3 The loop repeated maximum number iterations Bellman error BE termination condition BE tol met 1512 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 Fig 12 The MinParameterOut operation example The PADD minimization multilinear program ﬁrst leaf solution leaf constant value c1 b The resulting ADD minimization leaves Fig 13 The value function V t error merged averaged resulting ADD simpliﬁed D D represented ADD b result ApproxADD applied V t D D approximation error 1 note leaves We note setting tolerance tol according 7 guarantees cid4optimality MDPIPs termination conditions MDPs directly generalize MDPIPs discounted case γ 1 At iteration Regress algorithm called line 13 V t D D action Af V tcid10x V t1cid10x computed tested termination We observe Algorithm 6 parameters ter BE maxcid10x δ APRICODD Objective Vmax play role approximation explain section particular use δ 0 obtain exact solution SPUDDIP D D updated max Q t D D Q t D D regresses V t1 Regress Algorithm 7 computes Q t D D action provides values Q t D D obtained executing acting obtain V t1 D D During regression prime variables cid5 V function convertToPrimes converts xi x D D state CPTs cid5 action multiplied summed lines 46 We assume synchronic arcs variables x cid5 j cid11 j DCN If synchronic arcs present algorithm simply modiﬁed multiply relevant x CPTs After MinParameterOut function performed calls multilinear solver ﬁnd minimizing cid10p leaf PADD wrt linear constraints C DCN line 11 resulting ADD We note leaf constant multilinear solver avoided altogether observation prove important later introduce objective pruning Finally future value discounted reward ADD added complete regression Objective error approximate value iteration discussed later 7 Factored MDPIP approximate value iteration The previous SPUDDIP exact value iteration solution factored MDPIPs yields improvement ﬂat value iteration demonstrate experiments But number state variables problem grows larger impossible obtain exact solution time space limitations Approximate value iteration AVI way trade time space error approximating value func tion iteration In section propose bounded AVI extensions SPUDDIP APRICODDIP ObjectiveIP algorithms Each method uses different way approximate value methods incur maximum δ Vmax error iteration Vmax computed Solve represents maximum possible value step value iteration 0 δ cid3 1 By making approximation error sensitive Vmax prevent overaggressive value approximation initial stages AVI values relatively small suggested 4 Even value ap KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1513 Algorithm 6 Solve MDPIP tol maxIter δ APRICODD Objective input MDPIP given cid3S A R K γ cid4 tol tolerance guarantees cid4optimality maxIter maximum number iterations variables approximate value iteration δ fraction maximum possible value 0 δ cid2 1 APRICODD APRICODD true execute APRICODDIP Objective Objective true execute ObjectiveIP output V t DD tstatetogo value function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 1 2 3 4 5 6 7 8 9 10 11 12 13 14 DD termination condition met begin ADD 0 cid5 pax MDPIP cid5 Create PADD P D D x V 0 Vmax maximum possible value iteration Vmax maxRDD t 0 construct tstagetogo value functions V t maxIter t t 1 V t update V t foreach A DD DD max Q t DD DDRegressV t1 Q t DD Q t DDmaxV t V t DD δ Vmax Objective DD compute Bellman Error BE check termination DD V t cid14 V t1 DD Diff DD BE maxmaxDiff DD minDiff DD BE tol break approximate value iteration APRICODDIP APRICODD pruning ApproxADD V t DD δ Vmax V t DD Vmax maxRDD γ Vmax return V t DD end Algorithm 7 RegressV DD error Objective input V DD value function action error maximum error Objective Objective true execute ObjectiveIP output Q DD value function obtained executing acting obtain V DD begin cid5 Q DD convertToPrimesV DD convert variables xi x CPTs multiplied summed cid5 Q DD x cid5 Q DD Q DD P D D x cid20 Q DD cid5 pax Q DD x cid5 approximate value iteration ObjectiveIP Objective pruning Q DD approxPADDLeaves Q DD error nonlinear solver PADD leaf returns ADD Q DD MinParameterOut Q DDC Q DD RDD γ Q DD return Q DD end proximation iteration satisfying termination condition BE tol tol yields strict guarantees overall approximation error given 7 discussed previously SPUDDIP 71 APRICODDIP algorithm The APRICODD algorithm 4 provides eﬃcient way approximating ADD value representation factored MDP reducing size reducing computation time iteration This approach immediately generalizes MDPIPs value function V t D D ADD To execute APRICODDIP AVI MDPIPs simply Solve Algorithm 6 APRICODD true set δ 0 δ cid3 1 fraction maximum possible value Vmax approximate calling algorithm ApproxADD line 22 Algorithm 6 1514 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 Algorithm 8 ApproxADDvaluei D D error input valuei D D ADD error maximum error output new ADD begin collect leaves ADD leavesoldcollectLeavesADD valuei group leaves merged maximum error leavesold leavesnew mergeLeaves leavesold error return simpliﬁed ADD return createNewDD valuei D D leavesold leavesnew D D end 1 2 3 4 5 6 7 8 ApproxADD Algorithm 8 inputs 1 value function represented ADD 2 approximation error merge leaves The output new ADD merged leaves The algorithm ﬁrst collects leaves ADD determines merged form new values approximating error The old values replaced new values creating new minimally reduced ADD represents approximated value function An illustrative example shown Fig 13 collectLeavesADD compiles leaves ADD puts set leavesold In example Fig 13 set old leaves 9 0 10 1 mergeLeaves groups leaves merged error computes average group creating new set leaves leavesnew In example Fig 13 groups merged error 1 9 10 0 1 new leaves 95 05 createNewDD creates simpliﬁed ADD replacing old leaves new ones The result operation example shown Fig 13b 72 ObjectiveIP algorithm APRICODD effective extension SPUDD factored MDPs MDPIPs reduces size value function ADDs largely dictate time complexity SPUDD algorithm However solving factored MDPIPs time dictated size value function ADD number calls multilinear optimizer cid2 SPUDDIP started attack source time complexity aggregating states compute mincid10p cid2 Our goal ObjectiveIP pruning algorithm closely target source time objective mincid10p complexity AVI version SPUDDIP approximating objectives attempt avoid calling solver altogether To execute ObjectiveIP MDPIPs simply Solve Algorithm 6 APRICODD false Objective true set δ 0 δ cid3 1 fraction maximum possible value Vmax Noting PADD leaf Regress function multilinear objective simplify calling ApproxPADDLeaves line 9 Algorithm 7 prior carrying multilinear optimization leaves PADD line 11 Algorithm 7 ApproxPADDLeaves Algorithm 9 called PADD Regress Objective true It takes input PADD maximum error output new PADD approximated leaves upper lower bounds parameters The main loop algorithm attempts approximate leaf PADD lines 317 To approximate multilinear term Algorithm 9 ﬁrst computes average maximum minimum values line 8 requires knowing absolute upper pU j lower bounds p L j pi j easily precomputed entire min pi j subject linear constraints C max pi j p L MDPIP calling nonlinear solver compute pU j j CPTs After Algorithm 9 computes error incurred maximum minimum values line 10 If actual accumulated error leaf curError termErrori maximum error error term removed line 13 replaced average line 14 In cases complexity leaf expression reduced actually reduced constant Note leaves approximated independently leaf corresponds different state set states state time Furthermore guarantee objective pruning leaves PADD incurs error multilinear optimization performed Theorem ApproxPADDLeavesError Bound Given MDPIP precomputed constants p L mum approximation error ApproxPADDLeaves Algorithm 9 reduces leaf d0 expression approximation error objective minimization mincid10p leaf bounded error j pU j pi j maxi cid20 terms j pi j simpler i1 cid19 di Proof We begin showing approximation error induced removing single term objective bounded termErrori To ﬁrst ﬁnd upper lower bounds term di j pi j based legal values j Thus possible legal values cid10p term cid10p We know maximal minimal possible value pi j pU bounded interval Li U Li U deﬁned follows j p L cid19 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1515 Algorithm 9 ApproxPADDLeavesDD error 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 input DD parameterized ADD error maximum error output DD simpliﬁed parameterized ADD begin cid19 approximate leaf independently cid20 foreach leaf d0 terms i1 1 curError 0 terms leaf prune possible curError error cid2 terms j pi j DD di cid19 cid19 j pU j compute average max min values term newValue di j p L j 2 compute error max min values term termErrori di j pU j p L 2 j error prune term leaf curError termErrori error j pi j leaf j cid19 cid19 cid19 remove term di d0 d0 newValue curError curError termErrori 1 return DD end cid27 Li di 0 di di 0 di cid19 cid19 j p L j j pU j cid27 U di 0 di di 0 di cid19 cid19 j pU j j p L j 2 Let g value term cid28g Li U Li U cid28g U cid28g max Li U U Li cid20 cid19 2 Now let OBJ1 d0 di 2 terms i1 mal objective value cid10p cid10p1 Let OBJ2 d0 cid28g replacing term 1 L1U 1 We want prove L1U 1 2 2 maxgg cid28g occurs g Li g U So max termErrori maxLi computed Algorithm 9 j pi j original nonapproximated objective expression minimize v 1 opti j pi j approximated objective expression minimize terms i2 cid20 cid19 di v 2 optimal objective cid10p cid10p2 v 1 v 2 L1U 1 cid5 1 First prove second inequality Using cid10p2 OBJ1 j p1 j cid10p2 v 2 d0 cid28g eval function d0 evald1 cid19 2 approximated objective expression obtain v evaluate term assigned values Because v 1 optimal v 1 cid3 v cid9 cid8 2 cid5 1 v 1 v 2 cid3 eval d1 p1 j cid10p2 cid28g 17 cid14 j L1U 1 Additionally possible legal values cid10p cid10p2 evald1 j p1 j cid10p2 cid28g L1U 1 The proof ﬁrst inequality follows reasoning time substituting cid10p1 OBJ2 nonapproximated objective expression Thus obtain cid5 v 2 From equation 17 obtain v1 v2 L1U 1 j p1 j cid10p1 Because v 2 optimal v 2 cid3 v d0 cid28g v 1 d0 evald1 j p1 j cid10p2 cid28g L1U 1 evald1 cid5 2 cid19 2 2 2 2 cid19 cid19 cid8 v 2 v 1 cid3 cid28g eval d1 cid9 p1 j cid10p1 cid14 j cid19 evald1 j p1 j cid10p1 cid28g L1U 1 2 From equation 18 Additionally possible legal values cid10p cid10p1 L1U 1 18 obtain v1 v2 L1U 1 2 2 This bounds objective approximation error term approximation simple induction additively bound accumulated error multiple approximations calculated curError Algorithm 9 cid2 8 Experimental results Before delve experimental results involving SPUDDIP APRICODDIP ObjectiveIP algorithms contributed previous sections begin describing factored MDPIP domains experiments 1516 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 81 Domains We perform experiments factored MDPIP domains Factory 4 SysAdmin 5 Traﬃc new domain In following review Factory introduce new Traﬃc domain SysAdmin introduced Section 4 811 Factory domain The Factory domain 4 based manufacturing problem connected ﬁnished parts produced The parts shaped polished painted connected bolting welding gluing In particular Factory main agents task connect objects A B The agent choose following actions shapex handPaintx polishx drillx weldx y dipx paint x dipping boltx y connect objects x y bolting gluex y connect objects x y gluing sprayPaintx sprayPaintx yields lower quality painting handPaintx The main variables domain connected connectedWell represent objects A B simply connected gluing nected welding The reason objects connected connected agent shapes apainted bpainted apaintedWell bpaintedWell variables represent painted state object respectively Painted object remains painted shaped polished drilled ashaped bshaped represent object A shaped B shaped respectively Shaped remains shaped drilled asmooth bsmooth object smoothed agent execute action polish succeeds Smoothed object remains smoothed shaped drilled adrilled bdrilled object drilled action drill apply succeeds There variables things available environment agent spraygun glue bolts drill clamps Additionally variable skilledlab represents existence skilled labor The quality required ﬁnished product represented variable typeneeded highquality low quality The process reward depend directly quality required For example highquality required handpainted drilled bolted objects reward spraypainted glued objects obtain little reward Additional variables included problem generate different instances To obtain factored MDPIP introduce uncertainty bolt action variable connected follows The success probability bolt action objects connected bolts A drilled B drilled p1 In case objects drilled bolts success probability p2 These probabilities constrained 02 p2 cid3 p1 cid3 1 05 cid3 p2 cid3 1 Note p1 equal higher probability p2 process associated p1 likely succeed implied constraint p2 cid3 p1 812 A new domain Traﬃc We introduce Traﬃc factored MDPIP domain motivated real traﬃc intersection control problem modeled cellular transition model dynamics 21 While meant accurate largescale traﬃc model long stretches road approximately model local traﬃc propagation busy intersections speeds necessarily limited queuing traﬃc turn delays A graphical representation examples state variables given Fig 14 We encode traﬃc state cid10x x1 xn cid10x O U n indicating traﬃc cell xi 1 cid3 cid3 n occupied O unoccupied U Our basic traﬃc model intermediate road cells car forward cell long unoccupied stops current cell waits For intersection road cell x j leading intersection deﬁne state variable t j turn noturn indicating car xi intend turn oncoming traﬃc The state variable t j drawn randomly probability pt car turn new car arrives When determining update x j note straight turn left green cross opposing lane right turn depends opposing traﬃc light state opposing traﬃc cell states xo opposing rightturning cars safely turn allowed conditioning We refer boundary traﬃc cell xk feeder road cell new cars introduced points We assume cell occupied new cars arrive time step probability pa Finally state variables cid10c encoding current state light cycle The action set simply remain state advance sequence A advance nochange In Fig 14 cid10c c1 c2 c3 c4 interpret binary ci indicating intended light green However ci need binary additional state period green lights advancing cycle We need commit particular state sequence simply rely modelspeciﬁc function nextstatecid10c generate state current lights advance With highlevel description proceed deﬁne DCN reward speciﬁc Traﬃc instance conﬁgurations article KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1517 Fig 14 Diagram showing 4way singlelane intersection cells dotted boxes state variables state description Note model road cells exit intersection assume cars freely exit boundaries model passed intersection Traﬃc DCN transition model Based description transition model provided compact factored format dynamic credal network DCN 1115 subdivided different functional subcomponents follows Light cycle transition Here simply model effect nochange advance action light state cid7 cid6 cid5cid10c cid10c P 10 nochange cid10c 10 advance cid10c 00 cid5 cid10c cid5 nextstatecid10c Lane turning indicator Here assume probability car head queue making right turn pt car waiting turn decision change cid6 t cid5 j P turnt j x j cid7 10 x j O t j turn 00 x j O t j noturn pt x j U It diﬃcult traﬃc models obtain accurate estimate pt hours day DCN allow cid3 1 deﬁned speciﬁc turn probability ﬂuctuate time model pmin problem instances cid3 pt cid3 pmax 0 cid3 pmin cid3 pmax t t t t Intermediate road cell The occupancy car intermediate road cell xi depends occupying car forward cell xi1 car previous cell xi1 forward place 1518 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 cid6 cid5 x P O xi1 xi xi1 cid7 10 xi O xi1 O 10 xi U xi1 O 00 xi Feeder road cell A feeder road cell simply serves input traﬃc network cars arriving unoccupied feeder cell probability pa cid6 cid5 x k P O xk cid12 cid7 10 xk O xk1 O pa It diﬃcult traﬃc models obtain accurate estimate arrival probabilities pa hours day cid3 1 DCN allow arrival probability ﬂuctuate time model pmin deﬁned speciﬁc problem instances cid3 pa cid3 pmax 0 cid3 pmin cid3 pmax Intersection road cell The intersection road cells complex cells model traﬃc network traﬃc behavior depends light state occupancy cells green access intersection state turning traﬃc Here attempt implement basic model traﬃc behavior taking account contingencies cid6 cid5 x j P cid7 O x j t j xo cid10c 00 x j U x j1 U 10 x j U x j1 O 00 x j O t j noturn 00 x j O t j turn xo U 00 x j O t j turn xo O greencid10c o 10 x j O t j turn xo O greencid10c o noturn 00 x j O t j turn xo O greencid10c o turn Here assume userdeﬁned helper functions greencid10c j extract state cid10c indicating cid5 intersection cell j green light We assume greencid10c o holds x x j making j simplifying assumption turns red Traﬃc reward model Because goal reduce traﬃc congestion intersection objective minimize count occupied road cells intersection Thus appropriate reward maximize count unoccupied cells5 5 We use I indicator function taking value 1 argument true 0 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1519 Fig 15 Time performance comparison Traﬃc SysAdmin Factory problems SPUDDIP Flat Value Iteration The includes number variables problem corresponding number states 2variables Rcid10x ncid3 i1 Ixi U Here 1 reward cell unoccupied In article solve instances Traﬃc domain opposing lanes In particular Traﬃc problem instances 1 furthermore constrain turn instances set turn probability minimum pmin probabilities p1 p2 different lanes highly correlated constraint p1 p2 cid3 01 Additionally 04 probabilities p3 p4 car arriving feeder cells lane use probability bounds pmin pmax 06 constrained p3 p4 cid3 01 0 maximum pmax t t 82 Evaluation In section empirically evaluate algorithms Flat Value Iteration 10 contributions previous section solving factored MDPIPs SPUDDIP offers exact solution ii APRICODDIP iii ObjectiveIP offer bounded approximate solutions As additional point comparison note recent years seen emergence fast approximate factored MDP solvers based Approximate Linear Programming ALP 5 Recently techniques extended factored MDPIPs 9 Thus compare approximate solutions APRICODDIP ObjectiveIP based approximate value iteration Approximate Multilinear Programming AMP algorithm 9 AMP performs linearvalue function approximation ﬁxed set basis functions compact constraint encoding multilinear optimization problems exploits structure DCN For algorithms set maxIter 50 SysAdmin maxIter 75 domains γ 09 In subsections present main results 821 Flat value iteration vs SPUDDIP In Fig 15 compare running time exact solution methods SPUDDIP Flat Value Iteration cid10x6 Solutions completing ﬁve hours marked Did Not Finish DNF We note SPUDDIP compute V outperform Flat Value Iteration SysAdmin domains exact value function little structure ADD However Traﬃc Factory highly structured value functions orders magnitude time improvement demonstrated SPUDDIP largely ability PADDs aggregate common nonlinear objectives saving substantial number calls nonlinear solver time 822 APRICODDIP vs ObjectiveIP In order scalability approximate solutions Fig 16 compare running time APRICODDIP ObjectiveIP vs number state variables δ 01 Factory Traﬃc conﬁgurations SysAdmin 6 We note comparison need slightly extend Flat Value Iteration algorithm 10 allow multilinear expressions transition probability table 1520 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 Fig 16 Time performance APRICODDIP ObjectiveIP Traﬃc SysAdmin Factory problems δ 01 We note ObjectiveIP runs faster APRICODDIP domains running ﬁxed bound maximum error iteration δ 01 In order evaluate policy returned AVI solutions compute ﬁxed value δ δ maximum error iteration wrt V max True Approximation Error TAE given cid4 cid4V cid4 cid4 cid10x V approxcid10x max cid10x 19 V approxcid10x value returned APRICODDIP ObjectiveIP V IP cid10x optimal value computed SPUDD In following plots ran Solve range δ In Figs 17 18 present detailed comparison time size number nodes ADD iteration number nonlinear solver calls required APRICODDIP ObjectiveIP plotted vs TAE traﬃc10 respectively We note little relationship space required ADD value representation number nodes running times algorithms space actually increases slightly ObjectiveIP running time decreases Fig 18 But striking plots running time algorithm directly correlated number nonlinear solver calls algorithm taking 100 ms cases reﬂecting intuitions time complexity solving MDPIPs governed computational overhead nonlinear optimization KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1521 Fig 17 Time nonlinear solver calls ADD size APRICODDIP pruning traﬃc problem 10 variables Results plotted δ 00 0025 005 0075 01 02 03 04 05 06 07 08 09 10 Fig 18 Time nonlinear solver calls ADD size ObjectiveIP pruning traﬃc problem 10 variables Results plotted δ 00 0025 005 0075 01 02 03 04 05 06 07 08 09 10 Fig 19 shows advantage ObjectiveIP pruning uses upper lower values approximate leaves PADDs For problems number nodes reduced constant grows True Approximation Error increases number calls multilinear solver decreases These ﬁgures cases ObjectiveIP approach PADD reduction occurs great success original PADD sizes exact cases large reduced orders magnitude exchange reasonable approximation error In Figs 20 21 22 23 24 comparison True Approximation Error TAE vs running times problems different sizes problem varying δ The results echo conclusion ObjectiveIP consistently takes time APRICODDIP achieve approximation error order magnitude time APRICODDIP This time reduction explained decreased number calls multilinear solver 823 Approximate value iteration vs approximate multilinear programming In Figs 20 21 22 23 24 compare approximate solution methods APRICODDIP ObjectiveIP implementation approximate multilinear programming AMP 9 MDPIPs We simple basis functions variable problem description pairwise basis functions pair variables common child variable DCN When ﬁnish limit hours AMP takes seconds produce approximate solution problem Factory domain return solution Comparing algorithms terms true approximation error observe SysAdmin problem Figs 22 23 24 AMP pair basis functions outperforms APRICODDIP obtains solution 23 larger error ObjectiveIP signiﬁcantly time b Traﬃc problem Fig 21 AMP simple basis solution obtains solution 23 error 1522 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 Fig 19 Number nonlinear solver calls number nodes reduced constant vs True Approximation Error ObjectiveIP pruning different problems Results plotted δ 00 0025 005 0075 01 02 03 04 05 06 07 08 09 10 Fig 20 True Approximation Error vs time required APRICODDIP ObjectiveIP MPA simple basis functions MPA pairwise ﬁnish hour time limit MPA simple basis functions ﬁnish problems Factory problems KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1523 Fig 21 True Approximation Error vs time required APRICODDIP ObjectiveIP MPA simple basis pairwise basis functions Traﬃc problem Fig 22 True Approximation Error vs time required APRICODDIP ObjectiveIP MPA simple basis pairwise basis functions SysAdmin problem unidirectionalring topology 1524 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 Fig 23 True Approximation Error vs time required APRICODDIP ObjectiveIP MPA simple basis pairwise basis functions SysAdmin problem bidirectionalring topology Fig 24 True Approximation Error vs time required APRICODDIP ObjectiveIP MPA simple basis pairwise basis functions SysAdmin problem independent bidirectional topology KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1525 ObjectiveIP signiﬁcantly time c case Factory problem Fig 20 AMP solve instance ObjectiveIP solve rest time limit lower error These results lead conclude ObjectiveIP consistently gives error 23 lower AMP runs fast AMP solution cases running slower 824 Results summary Over problems given unpredictable performance AMP error guarantees ﬁnish time limit consistently worse performance APRICODDIP compared ObjectiveIP ObjectiveIP stands reliable option offers guaranteed error bounds empirically offers consistently lower error rates lowest algorithm overall reasonable running times fastest 9 Related work The Boundedparameter Markov Decision Process BMDP 22 special case MDPIP probabilities rewards speciﬁed constant intervals Exploiting speciﬁc structure available BMDP given intervals algorithm 22 directly derive solution requiring expensive optimization techniques Recent solutions BMDPs include extensions realtime dynamic programming RTDP 23 LAO 2425 search best policy worst model The Markov Decision Process Setvalued Transitions MDPSTs 26 subclass MDPIPs probability distributions given ﬁnite sets states Since BMDP MDPST special cases MDPIPs represent ﬂat MDPIPs Then algorithms deﬁned paper clearly apply BMDPs MDPSTs solutions generalize factored MDPIPs examined paper allow multilinear probability representation resulting use DCN Furthermore MDPIPs allow general linear constraints probabilities prohibited interval bounded probability settings like BMDPs This use general linear constraints particularly useful know probabilities relative constraints probabilities Traﬃc problem unknown highly correlated Previous work ﬂat MDPIPs 6727 focused credal sets represented polytopes proposed algorithms based dynamic programming solved small problems It important notice factored MDPIP model expressive simple ﬂat MDPIPs referred papers saw Section 4 joint DCN transition probabilities factored MDPIPs nonlinear ﬂat MDPIPs transition probability state given previous state action trivially linear single parameter pi As discussed Section 8 interesting note allow interval bounds parameters CPTs DCN factored MDPIP result expressive model ﬂat MDPIP BMDP transition expression state given previous state action multilinear expression cid10p Consequently deﬁne Flat Value Iteration comparative analysis previous section note needed slightly extend previous work allow multilinear expressions transition probability tables required match expressivity factored MDPIPs A ﬁnal piece work related MDPIPs twoplayer zerosum alternating Markov Game 28 aka Stochastic Game 29 This subset ﬂat MDPIPs intermediate state variables introduced represent opponent actions parameters specify distribution opponent actions allowed vary interval 0 1 However computationally wasteful use ﬂat factored MDPIP algorithm solve Stochastic Game minimization ﬁnite set opponent actions likely computationally cheaper nonlinear optimization probability parameters required MDPIP solution Hence computationally advantageous use specialized algorithms solution ﬁnite action Stochastic Games exploit speciﬁc structure attempt use generalpurpose MDPIP algorithms presented Finally probability trees represent convex sets probabilities associated intervals obtain posterior intervals probability 30 Probability trees compactly represent contextspeciﬁc independence CSI saw Section 5 parameterized ADDs DAGs exploit CSI shared function structure Additionally PADDs represent general probability expressions multilinear case factored MDPIPs probability intervals 10 Concluding remarks Motivated realworld need solve MDPs uncertainty transition model number novel contributions literature article In Section 4 introduced factored MDPIP model based Dynamic Credal Networks DCNs In Section 5 contributed novel parameterized ADD PADD data structure containing leaves parameterized expressions showed eﬃciently obtain minimal canonical representation PADD showed eﬃciently perform variety unary binary operations PADDs In Section 6 contributed exact factored MDPIP solution algorithm SPUDDIP showed eﬃciently use PADD steps factored MDPIP value iteration algorithm The resulting SPUDDIP algorithm yielded orders magnitude speedup existing value iteration techniques MDPIPs 1526 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 To enhance SPUDDIP algorithm Section 7 contributed novel approximate value iteration ex tensions APRICODDIP ObjectiveIP While APRICODDIP obvious extension based previous work speciﬁcally target main source time complexity solving MDPIPs calls nonlinear solver MDPIP value iteration Based observation developed alternate novel approximation method directly ap proximated objective multilinear solver calls proving theoretical correctness innovative bounded error approximation approach substantially reducing number nonlinear solver calls running time approx imate value iteration In Section 8 performed comparisons algorithms previously existing ﬂat value iteration algorithm stateoftheart approximate multilinear programming AMP solver MDPIPs Altogether novel contributions particularly culmination ObjectiveIP algorithm enable bounded approximate solution factored MDPIPs scale orders magnitude existing ﬂat value iteration approaches MDPIPs yield substantially lower errors existing approximate MDPIP solvers like approximate multilinear programming AMP priori error guarantees depend appropriate basis function generation algorithms For future work note PADDs represent tip iceberg use advanced decision diagram techniques solving factored MDPIPs Following success Aﬃne extension ADDs solving factored MDPs 31 additive multiplicative structure interesting extend technique PADDs exploit structure MDPIPs Such advances ideally reduce running time solutions factored MDPIP problems like Traﬃc contains signiﬁcant additive structure reward deﬁnition amenable exploitation factored MDPIP problem structure Finally note exploration objectives maximin optimality factored MDPIPs interesting Although maximin criteria works ﬁne domain imprecise parameters like SysAdmin domain experiments observe problem large imprecision terms loose constraints 01 cid2 pi j cid2 09 maximin criterion adversarial reﬂect worstcase extremely unlikely practice Hence future work examine methods handling transition uncertainty Bayesian approach 32 determine factored MDPIPs PADDs enhance solution approaches alternate criteria Acknowledgements This work performed ﬁrst author visiting NICTA NICTA funded Australian Government represented Department Broadband Communications Digital Economy Australian Research Council ICT Centre Excellence program This work supported Brazilian agencies FAPESP grant 2008039955 CAPES References 1 ML Puterman Markov Decision Processes Wiley Series Probability Mathematical Statistics John Wiley Sons New York 1994 2 C Boutilier S Hanks T Dean Decisiontheoretic planning Structural assumptions computational leverage JAIR 11 1999 194 3 J Hoey R StAubin A Hu C Boutilier SPUDD Stochastic planning decision diagrams Proceedings UAI Morgan Kaufmann 1999 pp 279 288 4 R StAubin J Hoey C Boutilier APRICODD Approximate policy construction decision diagrams Proceedings NIPS MIT Press 2000 pp 1089 1095 5 C Guestrin D Koller R Parr S Venkataraman Eﬃcient solution algorithms factored MDPs JAIR 19 2003 399468 6 JK Satia RE Lave Jr Markovian decision processes uncertain transition probabilities Oper Res 21 1970 728740 7 CC White III HK ElDeib Markov decision processes imprecise transition probabilities Oper Res 42 4 1994 739749 8 T Dean K Kanazawa A model reasoning persistence causation Comput Intell 5 3 1990 142150 9 KV Delgado LN Barros FG Cozman R Shirota Representing solving factored Markov decision processes imprecise probabilities Proceedings ISIPTA Durham United Kingdom 2009 10 DP Bertsekas JN Tsitsiklis An analysis stochastic shortest path problems Math Oper Res 16 3 1991 580595 11 FG Cozman Credal networks Artiﬁcial Intelligence 120 2000 199233 12 P Walley Statistical Reasoning Imprecise Probabilities Chapman Hall London 1991 13 A Nilim L El Ghaoui Robust control Markov decision processes uncertain transition matrices Oper Res 53 5 2005 780798 14 R Shirota FG Cozman FW Trevizan CP Campos LN Barros Multilinear integer programming Markov decision processes impre cise probabilities Proceedings ISIPTA Prague Czech Republic 2007 pp 395404 15 FG Cozman Graphical models imprecise probabilities Internat J Approx Reason 39 23 2005 167184 16 C Boutilier N Friedman M Goldszmidt D Koller Contextspeciﬁc independence Bayesian networks Proceedings UAI 1996 pp 115123 17 RI Bahar EA Frohm CM Gaona GD Hachtel E Macii A Pardo F Somenzi Algebraic decision diagrams applications Proceedings ICCAD IEEE Computer Society Press Los Alamitos CA USA 1993 pp 188191 18 RE Bryant Symbolic Boolean manipulation ordered binarydecision diagrams ACM Comput Surv 24 3 1992 293318 19 RE Bryant Graphbased algorithms Boolean function manipulation IEEE Trans Comput 35 8 1986 677691 20 NL Zhang D Poole A simple approach Bayesian network computations Proceedings Tenth Canadian Conference Artiﬁcial Intelligence 1994 pp 171178 21 CF Daganzo The cell transmission model dynamic representation highway traﬃc consistent hydrodynamic theory Transport Res B 28 4 1994 269287 22 R Givan S Leach T Dean Boundedparameter Markov decision processes Artiﬁcial Intelligence 122 2000 71109 39 23 O Buffet D Aberdeen Robust planning LRTDP Proceedings IJCAI 2005 pp 12141219 24 S Cui J Sun M Yin S Lu Solving uncertain Markov decision problems intervalbased method Proceedings ICNC 2 2006 pp 948957 KV Delgado et al Artiﬁcial Intelligence 175 2011 14981527 1527 25 M Yin J Wang W Gu Solving planning uncertainty quantitative qualitative approach Proceedings IFSA 2 2007 pp 612620 26 FW Trevizan FG Cozman LN Barros Planning risk knightian uncertainty Proceedings IJCAI 2007 pp 20232028 27 JA Bagnell AY Ng JG Schneider Solving uncertain Markov decision processes Tech rep Carnegie Mellon University 2001 28 ML Littman Markov games framework multiagent reinforcement learning Proceedings ICML Morgan Kaufmann 1994 pp 157163 29 LS Shapley Stochastic games Proc Natl Acad Sci USA 39 1953 327332 30 A Cano S Moral Using probability trees compute marginals imprecise probabilities Internat J Approx Reason 29 1 2002 146 31 S Sanner D McAllester Aﬃne algebraic decision diagrams AADDs application structured probabilistic inference Proceedings IJCAI 2005 pp 13841390 32 MO Duff Optimal learning Computational procedures Bayesadaptive Markov decision processes PhD thesis University Massachusetts Amherst January 2002