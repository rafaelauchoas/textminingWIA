Artiﬁcial Intelligence 173 2009 13101342 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Weighted A search unifying view application Rüdiger Ebendt Rolf Drechsler b German Aerospace Center Institute Transportation Systems 12489 Berlin Germany b Institute Computer Science University Bremen 28359 Bremen Germany r t c l e n f o b s t r c t Article history Received 17 December 2007 Received revised form 9 June 2009 Accepted 10 June 2009 Available online 16 June 2009 Keywords Planning Search Heuristic search A Weighted A BDD STRIPS 1 Introduction 2 cid4 approach known These methods guarantee bounded suboptimality N upper bound optimal solution length algorithm wellknown heuristic bestﬁrst search method Several performance The A Interesting examples accelerated extensions exact A approximate algorithms heuristic function inﬂated weight referred weighted A As technical contribution paper presents previous results related weighted authors like Pohl Pearl Kim Likhachev condensed A unifying form With uniﬁed view novel general bound suboptimality result derived In case avoiding reopening expanded states cid2 0 bound 1 cid2cid3 N Binary Decision Diagrams BDDs wellknown AI setbased exploration sparsememory symbolic manipulation state spaces The problem exact approximate BDD minimization introduced possible new challenge heuristic search Like classical AI domains problem motivated realworld applications search applied problems BDD minimization Several variants weighted A classical domains like blocksworld slidingtile puzzles For BDD minimization comparison evaluated methods includes previous heuristic simulation based methods Rudells hillclimbing based sifting algorithm Simulated Annealing Evolutionary Algorithms A discussion results obtained different problem domains gives experiences weighted A value AI practitioner 2009 Elsevier BV All rights reserved In realworld problems dominating effort search involves huge state spaces Therefore large number papers search published numerous authors The drawbacks ﬁxedorder methods like breadthﬁrst search depthﬁrst search avoided following bestﬁrst order The disadvantages blind methods overcome heuristic search methods guide search A prominent guided bestﬁrst search algorithm wellknown A examples special cases bestﬁrst search breadthﬁrst search Dijkstras singlesource shortest path algorithm 22 Bestﬁrst search explores search graph list Open containing open frontier nodes generated expanded A second list Closed stores closed inner expanded nodes A cost function maps node cost value A bestﬁrst search expands promising open node minimum cost Expanding node means generate child nodes They inserted Open preserving order based cost values nodes algorithm 40 Bestﬁrst search general framework algorithms 55 A Corresponding author Email addresses ruedigerebendtdlrde R Ebendt drechsleinformatikunibremende R Drechsler 00043702 matter 2009 Elsevier BV All rights reserved doi101016jartint200906004 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1311 A The expanded node inserted Closed At start Open contains initial node search stops goal node chosen expansion The different instances bestﬁrst search differ cost functions For A cost node n f n gn hn Hereby components information node n gn information cost path covered The heuristic function value hn estimate cost remaining path goal node The vertices search graph represent states problem state space slidingtile puzzle state represented ordered sequence tiles The edges search graph possible transitions states details Section 21 ﬁelds application including diverse areas robotics 6264 computational biology 51597888 AI gameplay 12 hardware veriﬁcation 75 logic synthesis 28 If certain require ments heuristic function guiding search met A ﬁnd minimum cost path goal state 40 Section 21 A drawback A worstcase run time memory required expo nential depth search This led extensions A memorybounded 1349 5977878990 mainly aim reduction run time allowing bounded suboptimality These socalled methods actually guarantee bounded suboptimality contrasts generalizations bestﬁrst search weighted A KBest First Method KBFM Felner et al 33 Generally weighting heuristic function applied methods differ way idea weighting authors refer WA First Pohl proposed constantly inﬂate heuristic function h certain factor 1 cid2 cid2 0 71 Since A second proposal author Dynamic original idea weighted A Weighting DWA 72 At beginning search method starts high weighting heuristic function help ﬁnd promising direction quickly dynamically weights heavily search goes deeper The help prevent premature termination More recently Pohls ﬁrst conceptually simpler natural idea constant overweighting renewed 5288 It embedded Anytime Weighting A 38 Anytime Repairing A variants A 6263 ARA AWA In contrast 70 Traveling Salesman Problem TSP tackled extension A cid2 called A This condition triggers choice node expansion generating search transferred bidirectional relaxes selection condition A child nodes Further idea relaxing unidirectional A case 531 In paper previous results different authors presented condensed unifying form This allows comparison respective methods formal grounds Finally novel general bound suboptimality derived remain methods bounded suboptimality Section 5 It shown discussed variants weighted A expanded states reopened A previous bound stated case constant overweighting 63 A second contribution paper experimental evaluation variants In Section 7 respective variants weighted A novel applied benchmark problems classical AI domains like blocks world logistics domains slidingtile puzzle problem domain wellstudied hardware community This problem exact approximate minimization Binary Decision Diagrams BDDs BDDs known AI hardware community setbased exploration sparsememory symbolic manipulation state spaces For domain comparison evaluated methods includes previous heuristic simulationbased methods Rudells hillclimbing based sifting algorithm 76 Evolutionary Algorithms EAs 23 Simulated Annealing SA 4 BDDs uniquely represent Boolean functions described Section 63 It shown NPcomplete decide number nodes BDD decreased variable reordering 5 Although solving NPcomplete problems long tradition AI community Traveling Salesman Problem TSP 70 n n 1 slidingtile puzzle 6074 number partitioning 56 rectangle bin packing 5758 minimum vertex cover 3761 planning problems 1154 BDDs community sparsememory exploration 4489 run symbolic versions established search methods like A 30394373 best authors knowledge far problem exact approximate BDD minimization addressed AI However problem strongly motivated realworld applications VLSI CAD Therefore authors like introduce problem AI possible new challenge A discussion experimental results obtained different problem domains addresses AI practitioner This paper structured follows A brief description A basic notations deﬁnitions given different ideas weighted A brieﬂy reviewed Related technical results different authors presented unifying form The conse Section 3 In Section 4 instructive example illustrates reopening expanded nodes weighted A quences reopening nodes discussed Section 5 In Section 6 problem exact approximate BDD minimization introduced possible new challenge weighted A For purpose ﬁrst formal deﬁnition BDDs brieﬂy reviewed Experimental results problem given Then previous work exact BDD minimization A given Section 7 Finally Section 8 work concluded 1 In addition 48 gives excellent discussion relationship unidirectional bidirectional search general 1312 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 2 Background 21 State space search A algorithm A search problem corresponding search task formulated state space graph Vertices represent states q edges represent allowed state transitions 55 Section 1 For remainder paper traditionally denote vertices identiﬁed states represent letters q q cid5 states favored letters n n usually logical nodes search graph cid5 An important method guide search state space heuristic search With state q quantity hq associated estimates cost cheapest path q goal state t target This allows searching direction goal states The A algorithm heuristic bestﬁrst search algorithm Section 1 Given certain requirements met minimum cost path initial state s start goal state t A It starts s bases choice state expand criteria sum edge costs path initial state state q path cost short denoted gq estimate hq They combined cost function f g h For q cost q sum current path cost estimate q The cost minimum cost f q gq hq The cost minimum cost path s q denoted g path q goal state denoted h q For A estimate hq lower bound cost optimal path q goal state hq cid2 h q 1 In case h called admissible A ﬁnds minimum cost path 40 A nodes tie breaking class search algorithms use heuristic 20 terminates known optimally eﬃcient terms number expanded called admissible algorithm theory guarantees A Like bestﬁrst search A maintains prioritized queue Open ordered respect ascending values f q Section 1 Initially queue contains s At step state q minimal f value expanded dequeued list called Closed During expansion successor states q generated inserted queue Open according f values For g hvalue successor states computed dynamically cid5 cid5 denote transition cost edge cost Then q For transition q q cid5 gq cq q transitions r r optimal cost denoted cid5 kq q cid5 g accumulates transition costs In state q gq computed sum cost cr r occurring current tentative path q If path q q associated cost gq let cq q cid5 cid5 cid5 cid5 If state minimum f value tiebreaking rules select states The common rule select state lowest hvalue Such states estimative search state continued faster termination expected This idea later methods described Sections 231 232 233 cid5 cid5 cid5 cid5 A successor state q case gq generated second time q cid5 updated If q predecessor state If cheaper path reopened Open Thus s q states second chance search minimum cost path new information available These updates gcomponent f costs newly cheaper path continuously compensate fact cid5 character hcomponent estimative The cheapest known path q updated respectively2 list Closed q The algorithm terminates state expand goal state t The estimate ht h t zero In case t reported path t minimal cost denoted C bestﬁrst searches like solution As stated Section 1 cost function separates A Dijkstras singlesource shortest path algorithm f g g deﬁned greedy bestﬁrst search f h h deﬁned breadthﬁrst search edge costs uniform f g optimal path denoted p denoted pq C cid5 cid5 22 Monotonicity Deﬁnition 1 Consider A k optimal paths states Heuristic function h said monotone equivalently consistent algorithm heuristic function h satisfying ht 0 goal states t cost hq cid2 kq q cid5 cid5 2 descendant q hq cid5 q 2 In implementation usually backpointer predecessor stored The complete path p reconstructed sequence predeces sors initial state R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1313 In 40 shown case monotone heuristic function h A ﬁnds optimal paths expanded nodes More precisely Theorem 1 Consider A cheapest path q gq g q pq p q algorithm monotone heuristic function h path cost function g Then state q expanded Cost updates needed ﬁrst expansion With state expanded exactly performance degradation reopening states described later Section 4 23 Weighted A search In literature term weighted A All approaches relax This derive faster algorithm provable upper bound suboptimality The ideas vary subsumes approximate variants A conditions A signiﬁcantly following methods distinguished 231 Constant inﬂation In 71 Pohls ﬁrst suggestion constant inﬂation heuristic function h ﬁxed factor 1 cid2 cid2 0 That cost function f q gq 1 cid2 hq instead original cost function f A This method denoted WA speaking weighted A method suggested Pohl historically ﬁrst weighted variant A sequel refer collection methods WA proposed When denotes particular relaxed quickly direct search promising direction It noteworthy WA Even h admissible hold inﬂated heuristic 55 The admissibility condition breaks ties favor A state lower hvalue establishing special tie breaking rule Given h admissible cid2admissible ﬁnds solution cost exceed optimal cost shown WA factor 1 cid2 In comparison dynamic variant DWA section precautions premature termination taken 232 Dynamic weighting Pohls second idea 72 relax ﬁxed weighting heuristic function h Algorithm DWA starts high weighting h beginning search This help ﬁnd promising direction quickly Then method dynamically weights heuristic heavily search goes deeper preventing premature termination For cid2 0 cost function DWA f DWq gq hq cid2 cid2 cid3 1 dq N hq dq denotes depth vertex representing state q search graph N denotes optimal solution length respectively Usually N known advance upper bound estimate instead For problems N actually known For example paths goal vertex graph equal length length N number edges path The knowledge N improvements It shown cid2admissibility WA h admissible Both methods analyzed Section 3 previous section holds DWA 233 Search effort estimates This section reviews important approach Pearl Kim 70 The ﬁrst signiﬁcant point extension set states crucial A This set larger set blurring focus relaxing selection condition A f value Open It extended larger set states f value 1 cid2 times set states minimal f value The second important proposal use heuristic estimate remaining search effort given snapshot search progress This additional heuristic selects state aforementioned extended set focus state expand Thereby provides additional guide search process In Pearl Kim 70 suggest extension A cid2 adds second queue Focal maintaining subset called A states Open This subset set states cost deviate minimal cost state Open factor greater 1 cid2 More precisely Focal cid4 q f q cid2 1 cid2 min rOpen cid5 f r 3 cid2 selects state q Focal minimal value h F q The The operation A cid2 identical A function h F second heuristic estimating computational effort required complete search In nature A 1314 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 h F differs signiﬁcantly h h estimates solution cost remaining path h F estimates remaining time needed ﬁnd solution The choice h F puts high degree freedom approach subject investigation Section 3 In 70 suggested use h F h integrate properties subgraph emanating given state q The motivation ﬁrst point minimizing hvalue states set Focal means preferring estimative states As concrete suggestion second point h F q N dq later experimental evaluation Section 7 Again dq denotes depth vertex representing state q search graph N upper bound optimal solution length To minimize N dq means prefer deeper states search graph This motivation subgraphs emanating tend cid2 cid2admissible comparatively small expected remaining run time If h admissible A upper bound 1 cid2 suboptimality WA DWA 3 Unifying view cid2 section In section approach Pearl Kim 70 reviewed method A subjected closer consideration Special attention drawn nondeterministic formulation Depending choice additional heuristic h F basically allows expansion state extended focus set Focal As shown allows viewing earlier methods special cases A cid2 cid2 Historically A published idea constant inﬂation WA This suggests Pearl Kim developed algorithm aiming generalization earlier approaches In far following unifying view prepared work Pearl Kim Nevertheless following relationship A DWA explicit ﬁrst time This enables transfer general results special cases turn allows comparison respective methods formal grounds As ﬁrst step result states condition guarantees conformity cost function strategy described Section 233 Dynamic Weighting DWA cid2 WA Theorem 2 Let consider state space subset Open cost function f let cid2 0 let Focal deﬁned Eq 3 For states q state space let f q 1 cid2 f q let f q cid2 f q Let cid5q cid2 f ˆq arg min qOpen cid5 f q Then ˆq Focal Proof See Appendix A cid2 In Section 233 stated choice heuristic function h F leaves considerable degree freedom method Next clarify relaxation methods derived simply respective choices h F In Theorem 2 characterizes DWA instantiations generic method given Section 233 In Pearl Kims proposal proves weighted variation A The result shows serves framework weighted A WA let cid2 0 parameter A Theorem 3 Let consider state space graph representation let g path cost function h heuristic function A respectively For states q state space let q gq 1 cid2 hq let dq denote depth vertex representing q let N denote upper bound optimal f solution length let f DW gq hq cid2 1 dq hq Further assume identical tiebreaking rules N algorithms Then cid2 WA variations A DWA operation Algorithm WA operation Algorithm DWA cid2 search estimate h F f identical A cid2 search estimate h F f DW identical A Proof See Appendix A cid2 In brief result states choice state expand performed DWA relaxation strategy A cid2 stated Eq 3 Notice despite fact DWA functions different A conforms formulated use cost cid2 different f g h provably act f g h A WA WA R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1315 This holds formulation instantiation A precisely function h F replaced respective alternative cost function cid2 guided second heuristic h F It cid2 transferred directly DWA The result Theorem 3 allows provable result A cid2 cid2admissible The property follows cid2 For instance known A methods special instances A cid2 It WA DWA known f q cid2 1 cid2 C cid2 algorithm 70 This results following corollary immediately There need speciﬁc proofs respect particular instantiation A holds state q time expansion operation A WA Corollary 1 Let g path cost function let h admissible heuristic function let f g h cost function respectively For A operating state space Further let cid2 0 parameter A A A cid2 DWA tentative f values states time expansion A f q cid2 1 cid2 C cid2 WA variations A DWA WA Corollary 1 states necessary condition expansion state The result contrasts corresponding condition holds states q time expansion 40 holding original A following Theorem 4 Using unifying view possible express condition cost function f g h considered algorithms different cost functions DWA cid2 This turn A allows comparison respective instantiations algorithm In A f q cid2 C WA As ﬁrst consequence potential problem visible methods possible states This effect expanded DWA f q cid2 1 cid2 C q satisfying condition C cases exceed savings provided weighted approaches cid2 A A cid2 compared terms signiﬁcance problem A A cid2 algorithm general form property particular second heuristic h F exploited Next Theorem 4 considers conditions states eligible state expansion It strengthens Corollary 1 providing formal argument favor WA DWA Now WA DWA WA cid2 general A Theorem 4 Let g path cost function let h admissible heuristic function let f g h cost function A operating state space Further let cid2 0 parameter A respectively For snapshot DWA progress A A ﬁrst state path closed appears Open Then consider optimal path s q variations A cid2 WA cid5 cid5 DWA WA A cid2 q A A f q cid2 C cid2 f q cid2 1 cid2 C A A A WA states q time expansion states q time expansion f q cid2 C states q time expansion holds f q C f q cid2 UB cid6 hq cid5 cid7 hq cid5 UB gq 1 cid2 hq That hq halfopen interval 0 hq 1 cid2 C A DWA states q time expansion f q cid2 C C cid5 upper bound UB ranges 1 cid2 C C including UB gq cid5 1 cid2 cid2cid8 cid5 1 dq N cid9 cid8 hq cid5 1 dq N cid3 hq 1 dq N hq holds f q C cid9 cid9 cid8 f q cid2 UB cid5 That hq halfopen interval 0 Ndq Ndq 1 cid2 C C hq cid5 upper bound UB ranges 1 cid2 C C including Proof See Appendix A cid2 This result indicates following Both WA DWA states q C expansion f value stays stated upper bound UB To approach value 1 cid2 C hvalue eligible state hq search graph eligible UB cid5 andor eligible state reside signiﬁcantly deeper level This contrasts situation A cid2 additional restriction holds eligibility expansion In BDD minimization Section 6 problem domains states equal similar hvalues andor depth weighted variants Thus eligible states expanded series consecutive expansions A terms hvalue andor depth chosen expansion rare Hence far q eligible state q f q cid2 C typical f q cid2 1 cid2 C cid5 Consequently expected total number states expanded run WA typically consecutive A expansions nodes similar depth number expected remain low situations cid2 h F h h F N dq runs problems A If targeted domain A DWA DWA WA 1316 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 Suboptimal path expanded state b Worstcase scenario cid3 n 2 cid4 deviations odd case Fig 1 Examples behavior reopening 4 Monotonicity reopening In 63 Likhachev et al provide thorough analysis Anytime Repairing variant A In course analysis raise following question provided weighted A guided monotone heuristic h states reopened And performance improved reopening previously opened states This question algorithms A A weighted variants A concrete suggestion Likhachev et al improve method reopening previously expanded states weighted A algorithm constant inﬂation integral approach ARA Further authors prove bound suboptimality weighted A constant inﬂation reopening It shown deviation computed solution optimum greater 1 cid2 In case WA DWA cid2 WA ARA Following idea Likhachev et al section Section 5 aims answer corresponding questions Next instructive example given shows reopened states exist choices 3 general weighted A DWA A A cid2 WA Example 1 In Fig 1a left datum annotated node gvalue right hvalue Edges depict state transitions cost transition annotated edge The heuristic function h monotone Eq 2 respected path state space graph cid2 h F h let cid2 1 First let A A cid5 2 In beginning A cid2 expands initial state s successor states q cid5 f q0 2 Since q0 lowest hvalue q0 All states cost minimal states Open f s f q cost state appears estimative state expected closest goal state Thus q0 cid5 2 The successor state q0 state q appears Focal expanded minimum Open stays f q 3 The inconsistency cost function WA pointed authors 55 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1317 f q 3 cid2 1 1 state terms run time The successor state q state left Focal q q 2 2 3 Moreover state lowest hvalue 0 chosen promising 2 2 3 As expanded reopening successor q At time expansion q best path q appear Focal f q explored Hence gq 3 2 g q gq updated value 2 cid5cid5 4 1 1 cid5cid5 cid5 cid5 Next easy derive line argument remaining choices A showing q reopened let upper bound optimal solution length let cid2 3 2 In case A DWA To case A WA N 3 let cid2 9 4 During experiments conducted A cid2 monotone heuristic 28 phenomenon fact cid2 lost observed causing high increases run time Section 7 In words relaxation A capability A cid2 instantiations following new result states upper bound deviation g g gain monotonicity h To analyze operation A expanded state Lemma 1 Let cid2 0 The paths expanded states A However deviation bounded cid2 algorithm guided monotone heuristic suboptimal q Closed gq g cid6 cid7 q hq g q cid2 cid2 For special instance Algorithm WA result tightened q Closed gq g cid5 q cid2 cid2 kq cid5 q q ﬁrst state Open optimal path s q cid5 q time expansion q Proof See Appendix A cid2 5 Preventing reopening states 4 5 In section simple modiﬁcation weighted A suggested Likhachev et al case constant inﬂation cid2 instantiations This yields ﬁnal methods experiments denoted preﬁx NR applied A Notice NonReopening variant NRA new method proposed implemented Likhachev et al 63 NRWA different context cid2 called NRWA cid2 instantiations NRA cid2 method ﬁnds better path closed state q better path Consider following change operation A NRDWA ignored gq updated Otherwise method NRA cid2 follows usual operation A cid2 As said previous section interested general bound suboptimality bound cid2 Although cid2admissibility guaranteed NRA cid2 cid2 modiﬁcation denoted NRA framework A general following result shown Theorem 5 Let N upper bound optimal solution length When driven monotone heuristic Algorithm NRA ﬁnds solution exceeding optimal cost factor greater 1 cid2cid3 N cid4 2 cid2 Proof See Appendix A cid2 Basically proof follows similar line argument proof cid2admissibility A cid2 70 modiﬁed behavior algorithm account following consequence In NRA cid2 gvalue states By Lemma 1 states expanded optimal path irrecoverably affected deviations optimum g cid2 reopeningimprovement best known path suboptimal Due modiﬁed behavior NRA place later This effect increases maximum deviation optimal path The extent deviation termined worstcase scenario Let N maximal length optimal path Since nodes increases involved deviation gvalue occur proof Lemma 1 deviation gvalue g cid3 N cid4 times In Fig 1b dashed transition late transitions state lead opened 2 suboptimal path different p State qlast state prematurely opened way affected deviation gvalue We qlast qcid3 N cid4 regardless N odd Fig 1b The proof induction 1 cid3 N 2 cid4 2 Notice result case cid2 0 states case operation NRA driven monotone heuristic This expected A expanded states Consequently described modiﬁcation behavior A cid20 A Moreover Theorem 1 A cid20 affect operation cid2 The fact bounded suboptimality present case constant inﬂation general A new theoretical result However general bound exponential depth search In practice cid2 coincides A ﬁnds optimal paths 1318 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 useful smaller values cid2 N case examples approximate BDD minimization Notice construction worstcase gives strong intuition rare event As far domain cid2 approximate BDD minimization concerned expectation strengthened performance NRA far worstcase Section 7 Reconsidering upper bounds stated Theorem 4 straightforward derive following corollary Corollary 2 Let g path cost function let h monotone heuristic function let f g h cost function A state space Further let N upper bound optimal solution length let cid2 0 parameter A cid2 NRWA NRA respectively Then NRDWA operating variations A NRA A NRWA cid2 f q cid2 1 cid2cid3 N NRDWA f q cid2 1 cid2 C cid4 C 2 states q time expansion states q time expansion The proof analogous Theorem 4 The differences proofs places proof Theorem 4 gvalue ﬁrst open state optimal path bounded respective g value cid2 valid conclusion anymore costs states Due modiﬁcation A optimal paths higher optimal costs provably bounded Lemma 1 proof Theorem 5 For details proof Theorem 4 cid2 revised version NRA The result states respective NRA cid2 versions expand states original approaches ob tained upper bounds f value states larger The reason derivation bounds account possible degradation gvalue nodes optimal path As follows discussion cid2 suﬃcient evidence rare event number application domains Despite worstcase NRA result appropriate domains increase run time caused larger number state expansions expected practice It assumed revised algorithms behave forecasted Theorem 4 This conﬁrmed later experiments BDD domain Section 7 6 Approximate BDD minimization problem domain weighted A Reduced ordered Binary Decision Diagrams BDDs introduced 9 There ﬁelds application BDDs AI including software model checking 29 sparsememory applications 4489 BDDbased planning 2317183445 symbolic BDDbased heuristic search 3973 BDDs enhance classical search methods AI A algorithm enhance model checking hardware 3043 Moreover Reffel Edelkamp BDDbased version A veriﬁcation 75 This work example research intersections AI VLSI CAD In VLSI CAD BDDs known hardware veriﬁcation logic synthesis BDD graphbased data structure representation Boolean functions Redundant nodes graph nodes needed represent Boolean function f eliminated BDDs allow unique canonical representation Boolean functions At time allow good tradeoff eﬃciency manipulation compactness representation Exact BDD minimization requires ﬁnd optimal variable ordering yields minimum BDD size minimum number nodes It known NPcomplete problem 5 Approaches exact minimization proposed hardware community The algorithm Friedman Supowit 36 works truth table representations exponential time complexity O n2 3n This later reduced O n 3n application 2phase bucketsort technique Sieling Wegener 82 Other approaches aimed improvement performance reducing worstcase complexity 24274246 The recent suggestion use A algorithm 28 Besides fact shed additional light problem strong reasons research realworld applications VLSI CAD BDDs directly mapped circuits Henceforth BDD size directly transferred resulting chip area signiﬁcant drawback start BDD size optimized use heuristics This particularly holds methods like wellknown sifting algorithm 252676 based hillclimbing framework far away optimum In experiments described paper percentage loss quality sifting 80 Section 73 In 84 instructive example given sifting yields BDD large twice size optimum Moreover BDD sizes result sifting compared known upper bounds optimal sizes obtained use simulationbased approaches like SA EAs 423 This revealed difference large orders magnitudes In past numerous research papers addressed BDDbased approaches automated design logic opti mization FPGAs 14163268 Pass Transistor Logic PTL multiplexorbased design styles 10356667 Of note academic research strongly supported release publicly available BDDbased design automation tools like logic optimization BDS 86 PTLoriented synthesizing tool PTLS 80 In paper problem domain approximate BDD minimization added range typical AI problem domains slidingtile puzzle planning problems like logistics blocksworld problems To paper selfcontained section provides necessary formal background Boolean functions BDDs R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1319 61 Boolean functions The following introduction notations Boolean functions paper Deﬁnition 2 Let B 0 1 Xn x1 xn x1 xn Boolean variables Let m n N A mapping f Bn Bm called Boolean function In case m 1 f called multioutput function To emphasis arity n f choose write f n instead f A multioutput function f Bn Bm interpreted family m singleoutput functions f n To achieve standard set variables Boolean function f n assumed Xn If stated Boolean functions assumed total completely speciﬁed exists deﬁned function value vector input variables The Boolean functions constantly mapping variable 1 0 denoted zero singleoutput function f 1cid2icid2m Bn Bm x1 x2 xn cid11 1 zero Bn Bm x1 x2 xn cid11 0 An interesting class Boolean functions partially symmetric functions Later Section 64 explained based approach exact BDD minimization exploits partial symmetry reduce run time A Deﬁnition 3 Let f Bn Bm multioutput function Two variables xi x j called symmetric iff f x1 xi x j xn f x1 xi1 x j xi1 x j1 xi x j1 xn Symmetry equivalence relation partitions set Xn disjoint classes S1 Sk called symmetry sets called partially symmetric iff They sets variables pairwise symmetric A function f symmetry set S S 1 If function f symmetry set S Xn called totally symmetric 62 Shannon decomposition The wellknown theorem 79 allows decomposing Boolean functions simpler subfunctions In following def f value deﬁned function derived f ﬁxing variable inition cofactor Boolean function f B Deﬁnition 4 Let f xi c Bn Bm For variables Xn deﬁned f Bn Bm Boolean function The cofactor f respect xi c c B function f xicx1 x2 xi1 xi xi1 xn f x1 x2 xi1 c xi1 xn Repeated cofactoring yields cofactors respect variable 1 cid2 k cid2 n set k variable indices i1 ik 1 n xi1 xik ck cofactor multiple variables This cofactor equivalent Xn c1 ck Bk function f xi1 c2xik c1xi2 f xi1 c1xi2 c2xi j1 c j1xi j1 c j1xik ck xi j c j 1 cid2 j cid2 k Let f Bn Bm Boolean function let xi Xn Then function f iff said depend essentially xi f xi0 cid13 f xi1 Theorem 6 Let f Bn Bm Boolean function Xn For xi Xn f xi f xi1 xi f xi0 63 BDDs 6 In following formal deﬁnition BDDs given We start purely syntactical deﬁnitions means Directed Acyclic Graphs DAGs First singlerooted Ordered Binary Decision Diagrams OBDDs deﬁned This deﬁnition extended multirooted graphs yielding Shared OBDDs SBDDs Next semantics SBDDs deﬁned clarifying Boolean functions represented SBDDs After reduction operations SBDDs introduced preserve semantics SBDD This leads ﬁnal deﬁnition reduced SBDDs called BDDs short 1320 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 631 Syntactical deﬁnition BDDs Fig 2 A shared OBDD SBDD Deﬁnition 5 An Ordered Binary Decision Diagram OBDD pair π G π denotes variable ordering OBDD G ﬁnite DAG G V E V denotes set vertices E denotes set edges DAG exactly root node denoted root following properties A node V nonterminal node terminal nodes 1 0 Each nonterminal node v labeled variable Xn denoted varv exactly child nodes V denoted thenv elsev On path root node terminal node variables encountered order More precisely variable ordering π OBDD bijection π 1 2 n Xn π denotes ith variable ordering The condition order states non terminal node v cid6 cid7 varv π 1 π 1 cid6 cid6 cid7cid7 var thenv iff thenv nonterminal node cid6 cid7 varv π 1 π 1 cid6 cid6 cid7cid7 var elsev iff elsev nonterminal node For convenience variable orderings given sequences variables write x3 x1 x2 express π 1x3 1 π 1x1 2 π 1x2 3 Deﬁnition 6 A Shared OBDD SBDD tuple π G O G rooted possibly multirooted DAG V E consists ﬁnite number graph components These components OBDDs respecting variable ordering π O V 1 0 ﬁnite set output nodes O o1 o2 om An SBDD following properties A node V nonterminal node terminal nodes 1 0 Every root node component OBDD graphs contained O necessarily vice versa Example 2 An example SBDD given Fig 2 Solid lines edges v thenv dashed lines indicate edge v elsev The nodes pointed f 1 f 2 f 3 output nodes Notice root node output node pointed f 2 f 3 output node root node node pointed f 1 Also note SBDDs multiple graphs share node property helps save nodes reduce size diagram The idea set O declare additional nonterminal nonroot nodes nodes represent ing Boolean functions This clariﬁed section semantics BDDs deﬁned Notice SBDDs OBDDs terminal nodes shared components R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1321 Fig 3 Two different SBDDs f x1 x2 x3 cid11 x1 x2 x1 x3 632 Semantical deﬁnition BDDs Fig 4 Deletion Rule SBDDreduction Deﬁnition 7 An SBDD G O Xn O o1 o2 om represents multioutput function f f deﬁned follows n 1cid2icid2m If v terminal node 1 f v v terminal node 0 f v zero If v nonterminal node varv xi f v function f v x1 xn xi f thenvx1 xn xi f elsevx1 xn For 1 cid2 cid2 m f function represented node oi The expression f thenv f elsev denotes function represented child nodes thenv elsev At node SBDD essentially Shannon decomposition Theorem 6 performed In SBDD recursively splits function simpler subfunctions Two different variable orderings yield different BDDs Fig 7 Even considered variable ordering ﬁxed exist possibilities representing given function Fig 3 different SBDDs respecting variable ordering x1 x2 x3 representing function f B3 B x1 x2 x3 cid11 x1 x2 x1 x3 Figs 4 5 illustrate reduction operations SBDDs transform SBDD irreducible form function represented SBDD preserved With Deletion Rule redundant nodes deleted Subsequent application Merging Rule identiﬁes isomorphic subgraphs This leads SBDD respecting given variable ordering unique graph isomorphism A reduced SBDD ﬁnal form binary decision diagrams called BDD Deﬁnition 8 An SBDD called reduced iff node reduction rules Deletion Merging Rule applies The following theorem 9 holds Theorem 7 BDDs canonical representation Boolean functions BDDrepresentation given Boolean function respect ﬁxed variable ordering unique isomorphism 1322 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 Fig 5 Merging Rule SBDDreduction 64 Finding best BDD variable ordering path cost minimization 641 Idea In paper approximate BDD minimization achieved weighted A This approach based previous work To 28 describes exact BDD minimization problem ﬁnding minimum cost path solved A paper selfcontained basic concept work brieﬂy reviewed section The problem exact BDD minimization problem ﬁnding optimal variable ordering leads minimum number BDD nodes In 28 problem ﬁnding optimal variable ordering expressed problem ﬁnding minimum cost path initial state goal state Xn state space 2 Xn Sets variables q Xn successively growing Xn q extended transition variable xi Xn q xi q xi The algorithm starts initial state progresses goal state Xn reached As described q Xn optimal Section 21 A sequence transitions Consequently exist permutation σ numbers 1 n σ 1 n 1 n bijection aforementioned minimal cost accumulated transition cost transitions Xn Xn minimal cost The optimal path p ﬁnds path p xσ 1 xσ 1 xσ 2 xσ 1 xσ 2 xσ 3 xσ n Xn Xn The sequence variables occurring path obviously deﬁnes variable ordering p The basic idea approach following ordering annotated minimum cost path intended Xn intended number nodes BDD ordering xσ 1 xσ 2 xσ n Xn optimal variable ordering yielding optimal This means f Given holds sequence variables p minimum BDD size To achieve appropriate cost function chosen A sequence variables occurring transitions nongoal state semantics preﬁx variable ordering That path length k deﬁnes positions ﬁrst k variables variable ordering The key idea 28 deﬁne cost function number nodes ﬁrst k levels BDD taken cost corresponding path length k In method perform variable transpositions local search approaches incrementally generates ordering adding variable 642 Example An example run A based approach 28 given Fig 6 The algorithm applied initial BDD Fig 7a represents function f B4 B x0 x1 y0 y1 cid11 x0 x1 y0 y1 First function partially symmetric symmetry sets Deﬁnition 3 The ﬁrst set x0 x1 second y0 y1 Because symmetry variables set structure representing BDD preserved positions variable ordering swapped change renaming respective node labels Second function fourinput instance ninput Achilles heel function n given 9 The BDD general function linear size ordering respects L Rpartition variables L R symmetry sets However interleaved ordering variables different sets neighbored BDD exponential size details 9 This demonstrates Achilles heel BDDs crucial dependency ordering All BDDs depicted Fig 7 BDDs actually built run The graphical outputs generated use GraphVizinterface CUDD 3183 Different previous illustrations distinct identiﬁer annotated node actual node label respective variable annotated BDD levels ordering restriction Deﬁnition 5 variable label nodes BDD level This enables references particular nodes BDD textual descriptions ﬁgures Notice BDDs Fig 7 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1323 Fig 6 A applied BDD fourinput Achilles heel function bad initial ordering dotted edges dashed solid ones These indicate use Complemented Edges CEs CEs important extension basic BDD concept described 18 A CE ordinary edge tagged extra attribute complement bit This bit set indicate connected subgraph interpreted complement formula represents CEs allow represent function complement node modifying edge pointing node instead As consequence constant node needed Usually node 1 kept allowing function zero represented CE 1 The initial BDD respects interleaved ordering x0 y0 x1 y1 suboptimal ordering In Fig 6 states sets variables constitute nodes search graph The gvalue hvalue annotated state Edges depict state transitions The transition costs edge costs annotated edges A detailed description heuristic function h follows later Section 643 The initial state set expanded successors x0 y0 x1 y1 The edges leading costs 1 successor root node established ﬁrst BDD level Since g hvalues identical ﬁrst open nodes secondorder tiebreaking rule case motivated eﬃciency aspects selects state y1 During steps ties value f g h resolved ﬁrstorder tiebreaking rule favor state lower hvalue possible The expansion state y1 generates successors y1 x1 y1 y0 y1 x0 The order elements set notation gives path taken state saves space illustration In formal sense paths ordered sequences states unordered sets particular distinct paths y1 y0 y0 y1 end state y1 y0 However small example state second cheaper path occur path state simply given order elements state sets The successor state y1 x1 gvalue This reﬂects total nodes ﬁrst levels BDD example function given variable y1 situated root variable x1 resides second level 7b Notice structure ﬁrst general k levels holds regardless variable ordering BDD second general kth 1324 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 Initial ordering b Intermediate ordering c Optimal ordering Fig 7 BDDs initial intermediate optimal ordering level This follows wellknown theorem Friedman Supowit details rigorous proof 36 This important path cost function g maps states costs currently best known path map state value welldeﬁned function Due partial symmetry example function BDDs ordering y1 x0 gvalue BDD depicted Fig 7b In step state y1 y0 expanded lowest hvalue set open states minimal f value Again reasons partial symmetry BDDs orderings y1 y0 x0 y1 y0 x1 identical gvalue hvalue From set open states minimal f value states y1 y0 x0 y1 y0 x1 lowest hvalue selected ﬁrstorder tiebreaking rule The secondorder tiebreaking rule selects state y1 y0 x1 expansion This results optimal ordering y1 y0 x1 x0 BDD nodes 7c Notice achieved state expansions number expansions linear number input variables n corresponds problem size For brevity details optimizations method described 28 omitted Eg algorithm able detect symmetry sets variables When operating according option switch USE_SYMMETRY ﬁrst variable symmetry set processed obtain simple instructive example optimization example run depicted Fig 6 The variables skipped clear resulting g hvalues ﬁrst variable g hvalues states y1 x1 y1 x0 Henceforth symmetry exploited number generated states stays linear problem size n Notice calculation g hvalues BDD subjected optimization For purpose BDD reordered respect state currently processed The basic buildingblock reordering swap adjacent BDD levels This graph operation needs touch vertices affected BDD levels Nevertheless operation timeconsuming BDD levels large Since operation needed expansion approach timebounded memorybounded This classical AI domains time needed expansion constant different application A practice approaches memorybounded Several optimizations 28 address eﬃciency dynamical reordering needed state expansion 643 Heuristic function Next heuristic function 28 brieﬂy reviewed It derived relaxation original model problem consider BDD representing f ordering ﬁrst q variables constitute q The original problem determine minimum number nodes remaining lower BDD f remains correctly represented equivalently cofactors f respect variables q remain correctly represented The relaxed problem determine number distinct cofactors This lower bound minimum number nodes represent To notice additional node needed distinct cofactor node root node subgraph representing cofactor This said nodes different root subgraphs representing cofactors share nodes Fig 7b BDD node labeled ce shared subgraphs rooted nodes labeled d1 d2 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1325 More precisely let f Bn Bm f f 1cid2icid2m Boolean multioutput function depends essentially input variables For 1 cid2 k cid2 n let i1 ik 1 n set k variable indices Consider state q 2 Xn k elements correspond aforementioned set k indices q xi1 xik Xn For q let n cid4 cid5 cof f q f ixi1 a1xik ak nonconstant 1 cid2 cid2 m a1 ak 0 1k 7 For state q cof f q counts number cofactors respect variables q Eg Fig 7b cofactors respect variables y1 x1 represented BDD nodes labeled cd d1 ce More formally set cof f q set distinct nonconstant singleoutput cofactors interpreted family nary singleoutput functions respect variables q The heuristic function h 2 Xn N approach f f hq max cid6cid10 cid10 cid10cof f q cid10 n q cid7 8 It straightforward hq lower bound minimum number BDD nodes levels q 1 n BDD represents f variables q situated ﬁrst q levels First distinct cofactors cof f q represented different nodes levels q 1 n BDD represent f Second level q 1 n node f assumed depend essentially input variables This yields second term n q Hence maximum lower bounds hq lower bound cid7 h cid6 y1 x1 Eg state Fig 7b resulting hvalue cid6cid10 cid10 cid6 cid10cof cid10 y1 x1 max max3 4 2 3 cid7cid10 cid10 n f y1 x1 cid10 cid7 cid10 It computed effectively graph traversal BDD counting number direct references upper nodes nodes lower BDD 24 Of note heuristic function convenient property monotonicity Deﬁnition 1 For details rigorous proof 28 7 Experimental results Branch Bound BB For comparison plain concepts use combination A To evaluate algorithms discussion respective methods applied problem domains The ﬁrst suite experiments tackles problem approximate BDD minimization deﬁned Section 64 For purpose based approach 28 combines respective methods implemented authors starting A BB A All algorithms use DialJohnson queues quickly determine respective minimum Open 2147 To testing environment algorithms integrated CUDD package 83 By guaranteed run environment The present expertise particular domain allowed inclusion domaindependent approaches In second suite weighted A applied STRIPS benchmark problems typical planning domains They obtained previous planning competitions AIPS2000 IPC3 IPC4 distributions problem solvers available public domainindependent planner HSP2 Bonet Geffner 67 All experimental results carried machine Xeon processor running 32 GHz 12 GB memory For BDD domain run time limit 3600 CPU seconds imposed Within given time limit total 28 benchmark functions LGSynth93 19 benchmark suite combinational sequential circuits minimized variants For purpose logiclevel description given Berkeley Logic Interchange Format BLIF ﬁle A build representing BDDs Since BDD domain timebounded classical AI domains Section 64 memory requirement evaluated methods exceeded 500 MB memory limit applied For planning domains performance A different weights compared means domainindependent planner HSP2 implementation nonreopening variant NRWA obtained appropriate modiﬁcations source code HSP2 For purpose STRIPS problems aforementioned machine 100 CPU seconds planning domains chosen succeeded solve optimally A GB memory The number problems varies starting 38 23 problems PSR Blocksworld domain respectively problems Satellite domain WA NRWA Additionally Section 73 hard instances BDD domain STRIPS domains problems solved A given time memory limit solved weighted A 1326 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 Fig 8 Trading run time solution quality cid2 cid2 nra In experiments run time solution length number generated expanded search graph nodes acquired respectively 71 Application approximate BDD minimization 711 Aim methodology cid2 70 Sec cid2 instantiates A Two previous methods implemented ﬁrst called cid2 h F q N dq chosen dq denotes depth tion 233 BDD context As focal heuristic state q search graph N upper bound optimal solution length Section 233 The second 72 Section 232 In following parameter cid2 weighting referred degree DWA relaxation Besides approaches WA Section 231 new nonreopening cid2 variants known methods implemented corresponding methods nra NRDWA The aim experiments analysis comparison spective different methods suitability let user trade solution quality run time The user controls degree relaxation resulting different run times ﬁnal BDD sizes cid2 nonreopening variant nonreopening variant NRWA nonreopening version DWA Figs 8 10 1315 depict mean values dimensions run time quality group constituted different degree relaxation In graphs degree annotated points applied value cid2 The progress gain run time loss quality increasing degree relaxation cid2 illustrated Figs 11 12 Here mean values gain loss group depicted 712 Comparison cid2 nra cid2 In ﬁrst series experiments A cid2 achieves reduction run time 207 compared A cid2 applied benchmark circuits test suite Fig 8 cid2 nra depicts points space spanned dimensions solution quality number BDD nodes total run time test suite CPU seconds Both methods signiﬁcant gain run time compared A degree relaxation 30 cid2 gain For nra 346 The results run time methods monotonic decreasing allowing rising degradation solution quality Instead cid2 tends jump spanned space applying small increases relaxation This limits usefulness cid2 desired run timequality tradeoffs In contrast plot resulting cid2 similar monotonic decreasing hyperbola range 0 30 experiments method nra On hand nra cid2 achieves signiﬁcant better cid2 However cid2 better predictable run times qualities cid2 range 005 035 yields worse results cid2 04 Lemma 1 formulates reason reduced quality nra cid2 path expanded state suboptimal improved later state reopened Ie nra cid2 cid2 cost deviations optimal path permanent corrected later However commentary Theorem 5 formulated expectation loss quality stay far stated bound This conﬁrmed experimental results cid2 number state expansions state reopenings To explain improved predictability new method nra cid2 operating acquired experiments The percentage expansions reopen state run different degrees relaxation depicted Fig 9 As seen mean percentages reopenings groups monotonic growth cid2 This explains better run times nra cid2 method decelerated reopening For methods total run time increases degree larger 30 Similar results observed cid2 application 70 Traveling Salesman Problem TSP test vehicle A number states expanded monotonic decreasing function The reason phenomenon lies modiﬁed condition selection promising state This directly inﬂuences necessary condition cid2 cid2 nra expanded state expansion While A guarantees state q f q C R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1327 Fig 9 Degree relaxation vs percentage reopenings cid2 cid2 NRWA Fig 10 Trading run time solution quality nra guarantees states satisfying f q 1 cid2 C excluded expansion Consequently possible states q satisfying condition 1 cid2 C algorithm Theorem 4 We experimentally veriﬁed number state expansions ﬁrst decreases degree cid2 Fig 8 relaxation raised later increases As resulting plot similar curve nra included space limitations expanded weighted A original A cid3 f q C The relaxation strong potential reduce run time This positive effect focused search For cid2 negative effects oppose positive effect The ﬁrst increase reopenings second potential state expansions general The unpredictability result varying extent inﬂuence particular relaxation cid2 total effects positive negative In contrast nra cid2 negative effect general potential increased number state expansions counteracts reduction run time caused relaxation Here positive effect ﬁrst predominates eventually absorbed diminishes cid2 A disadvantage nra Consequently behavior predictable cid2 potentially worse results 713 Comparison nra cid2 NRWA In second series experiments A cid2 compared NRWA nra contrast behavior nra expectations revised version WA stated Theorem 4 explained remarks Corollary 2 For NRWA ﬁrst increases slowly cid2 0 05 later ascends steeply increasing cid2 NRWA cid2 run time NRWA The results depicted Fig 10 In monotonic decreasing This conﬁrms result Theorem 4 behave according upper bounds degradation solution quality The experiments conﬁrm observed improved suitability NRWA run timequality tradeoff user Fig 11 illustrates gain run time grows monotonic When comparing run time NRWA degree relaxation curve space spanned percentage gain degree cid2 convex hyperbola At higher relaxation degree cid2 30 reduction run time 90 average Taking account NRWA cid2 particular NRWA convenient theoretical properties NRA superior guarantees tighter upper bound deviation solution optimum NRWA cid2 theoretical practical standpoint It noted limited practical NRA evidence domain BDD minimization As Fig 12 shows high speedups obtained A 1328 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 Fig 11 Degree relaxation vs gain run time NRWA Fig 12 Degree relaxation vs loss quality NRWA small degradation solution quality In fact average degradation considerably worstcase degradation guaranteed theory factor 1 cid2 Also notice ﬁrst smaller weights percentage degradation grows slowly weight Similar results reported Korf application weighted A instances 15puzzle 55 This consistent results Section 72 describes experiments typical planning domains The results achieved method better quality guaranteed bound On hand pleasant property practice However indicate stated bound 1 cid2 tightened Operating 40 relaxation average results 05 larger optimum BDD size When theoreti cally allowing solutions twice minimum size average degradation 43 We applied high relaxations Fig 12 shows average degradation stays 20 wide range high relaxation degrees ﬁrst reaches 205 cid2 200 For higher weights resulting plot forms convex hyperbola slope falls ascending degree relaxation 714 Comparison WA NRWA DWA NRDWA In series experiments solution quality run time algorithms WA com NRWA cid2 cid2 compared The Different observations shows signiﬁcant reductions run time compared WA pared Fig 13 In contrast strong improvement observed Algorithm nra revised version WA reason average reopenings signiﬁcant cause run time WA cid2 average number reopenings grow signiﬁcantly degree relaxation nra However picture change looking speciﬁc benchmarks When WA Algorithm NRWA examples circuit s2081 percentage reopenings reaches 335 relaxation cid2 20 For cm150a mux 527 state expansions reopenings relaxation cid2 10 Accordingly run times benchmark offers stable run times functions signiﬁcantly higher WA reopenings occur run algorithm However certain penalty quality WA NRWA increased robustness signiﬁcant difference quality solutions obtained WA relaxation degrees 50 relaxation cid2 10 solutions obtained NRWA average 82 larger This corresponds respective observation Section 712 Lemma 1 states solutions yielded WA expanded NRWA best known path suboptimal modiﬁed behavior NRWA Therefore NRWA instead NRWA R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1329 Fig 13 Trading run time solution quality WA NRWA Fig 14 Trading run time solution quality DWA NRDWA Fig 15 Trading run time solution quality NRWA NRDWA reopeningimprovement place later However result Likhachev et al NRWA yields result cost exceed optimum factor 1 cid2 63 For reason penalty improved robustness remains comparatively small Second observations comparing DWA NRDWA Fig 14 715 Comparison NRWA NRDWA Next fourth series experiments NRWA terms quality run time As time slightly better results seen Fig 15 NRDWA obtained There clear relationship percentage improvement solution degree relaxation However ascending degrees relaxation blowup average run time NRDWA increases Eg relaxation cid2 03 run time NRDWA average solution obtained NRDWA Further increase relaxation yields average 18 BDD nodes NRWA signiﬁcantly higher run times NRWA 154 higher NRWA compared NRDWA 1330 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 Table 1 Results NRWA cid11 time A evolutionary algorithm simulated annealing sifting cid11 opt 04 cid11 time cid11 size 30 cid11 time cid11 size genetic cid11 time cid11 size annealing cid11 time cid11 size sifting cid11 time cid11 size 550839 s 3388 29785 s 3406 3313 s 3715 805 s 3409 677 s 3411 035 s 3701 improvements quality 3 yields ascending blowups run time At relaxation cid2 20 run time NRDWA average average solution obtained NRDWA 16 smaller solution NRWA Summarized signiﬁcant penalty small improvements quality provided NRDWA 359 higher NRWA 716 Comparison NRWA classical simulationbased heuristic techniques A ﬁfth series experiments compares method NRWA classical simulationbased heuristic techniques like Evolutionary Algorithms EAs 23 Simulated Annealing SA 4 Rudells sifting 76 performs classical hill climbing approach All algorithms integrated CUDD package publicly available 83 The critical shows total run time computation minimum time A points results shown Table 1 Column opt shows total number BDD BDD size 28 benchmark circuits LGSynth93 test suite A nodes BDDs needed minimal representation 28 circuits The following ﬁve doublecolumns 04 30 cid11 size BDDs genetic annealing sifting total run time resulting time total number BDD nodes Column cid11 cid11 cid11 running degree relaxation cid2 04 cid2 30 respectively method NRWA genetic algorithm 23 simulated annealing approach 4 hillclimbing approach 76 relaxation degree 40 large reduction run time 459 observed comparing Using NRWA The actual average degradation quality degree relaxation 053 better average A quality EA SA For complex circuits solutions obtained EA SA sifting signiﬁcant degradation Eg comp solution shows 10 BDD nodes optimum size SA 20 EA sifting results 50 blow solution In contrast method NRWA advantage guaranteed upper bound deviation optimum This come free run time high compared simulationbased heuristic methods However theoretical nonapproximability result 81 course expected result If average quality low sifting acceptable smaller run times achieved higher degrees relaxation At degree cid2 30 benchmarks test suite minimized minutes A certain advantage sifting cost results guaranteed times optimum upper bound deviation sifting EA SA guarantee It expected bound albeit grossly exceeded EASA hard problem instances benchmarks solved A ﬁrst experiments showed evidence supports hypothesis Section 73 Within limited scope experiments simulationbased approaches performed raise question use weighted beneﬁcial domain BDD minimization On hand EAsSA work A hard examples different benchmark suites Moreover good simulationbased approaches depend domain knowledge holds particular ﬁt ness functions cross mutation operators EAs hand application domain In particular solutions sparse local search methods run problems Opposed exists domainindependent realization A Section 72 weighted A 72 Weighted A STRIPS planning This section describes application weighted A STRIPS benchmark problems typical planning domains Blocksworld Puzzle slidingtile puzzle known n n 1 puzzle Depots Logistics PSR Satellite Freecell Driverlog domain The additional experiments observations Section 71 wider context different domains characteristics 721 Background In past domainindependent heuristic problem solvers suggested including optimal planners STAN 65 BLACKBOX 50 HSP recently HSPrHSP2 Bonet Geffner 67 The recent versions able search backward HSPr HSP2 solve STRIPS planning problems use weighted A goal initial state known regression search 6985 This signiﬁcant improvement ﬁrst version WA R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1331 HSP way unnecessary recomputations heuristic avoided 6 The heuristic domainindependent admissible heuristic called maxpair denoted h2 Haslum Geffner 41 HSPr showed good performance biennial ICAPS planning competitions 6 The source code available public The latest version called HSP2 subsumes functionalities previous releases HSP HSPr obtained appropriate modiﬁcations HSP2 Throughout For experiments implementation NRWA experiments backward search maxpair heuristic AWA The application A STRIPS problems subject previous work Bonet Geffner 7 Hansen Zhou 38 The present experiments extend results aspects ﬁrst variation weight studied intensively In 7 weights 10 20 50 applied Throughout experiments 38 weight 100 applied The authors examine idea decreasing weight algorithm The reported total run times given completion iteration Anytime WA iterations While shedding light role weights anytime framework diﬃcult derive weight far analyzed approach particular domain Second NRWA good original WA framework Anytime algorithms Likhachev et al applied ARA algorithm special technique limit node reexpansions particular domain robot planning domain 6263 Hansen Zhou reimplemented ARA examined Likhachevs idea limit number reexpansions regard domain 38 Different ﬁrst suite experiments include remaining variants WA A cid2 depend application domain Dynamic Weighting works upper bound optimal solution length N For domains hard number BDD minimization Pohls original problem TSP harder The automated derivation bound arbitrary STRIPS domains diﬃcult Even given upper bound use tighter bound suﬃces change behavior 72 As discussed Section 3 Pearl Kims method A cid2 leaves high degree freedom It advantageous utilize freedom available domain knowledge On hand possible obtain domainindependent cid2 maxpair heuristic h2 resorting focal heuristic h F h2 However way variant A cid2 hardly hinders fair comparison truly domainindependent methods potential A DWA Due space restrictions include local search methods Instead like refer respective previous work experiments Bonet Geffner domainindependent hillclimbing approach 67 applied STRIPS problems similar planning domains 722 Results The results conducted experiments depicted Figs 16a20b Figs 16a20b Figs B3a B3b Appendix B respectively progression average run time loss quality degree relaxation cid2 benchmark problems respective domain Figs B1 B2a B2b Appendix B total number expanded nodes problems respective domain varies cid2 As results weighted A generally works majority examined domains For domains large gain run time observed weights smaller 120 Blocksworld domain weight small 108 yields reduction run time 80 quickly reaching 980 weight 120 Fig 16a Other domains require slightly larger weights achieve best possible run time reductions Logistics domain observed gain weight 120 40 percent But gain increased 90 weight 150 applied Fig 17 In Satellite domain maximum reduction run time 60 achieved weight 20 average loss quality 6 Figs 18a 18b The gain curves generally high steepness PSR domain curve ﬂatter Here higher reduction run time 80 ﬁrst observed weight 30 reduction increases 90 weights 30 Fig 19 The curves gain run time monotonically decreasing relatively smooth total range cid2 domains The presented theory gives reasons overall convenient behavior Theorem 4 Section 3 On hand theoretical reason case actually noteworthy exceptions encountered Experiment 1 Appendix B The Blocksworld domain shows relatively smooth degradation quality increasing weight Fig 16b For domains curves plateaux reached different ranges weights For domains plateau zero considered weights quality fully preserved This holds applying high weights Logistics PSR Figs 17 19 For domains loss quality zero close zero appropriate weight chosen At time weight yields high reduction run time 10X speedup With exception use high weights yield losses 6 12 average average run time increase exception Experiment 2 Appendix B As far performance resulting use high weights concerned actual run times determined interaction positive effect focused search negative effect reopenings Experiment 3 Appendix B In experiments weighted A reach ﬁxed point increases weight signiﬁcant impact behavior results run algorithm Instead portion search space visited solution regardless weight increases This consistent respective observation BDD minimization domain Figs 11 12 There simple reason large weights 1332 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 Gain Blocksworld domain b Loss Blocksworld domain Fig 16 Gain loss Blocksworld domain Fig 17 Gain loss Logistics domain 1 cid2 term 1 cid2 h dominates gvalue point effect decisions algorithm By weighted A gradually fades greedy bestﬁrst search Section 21 There examples WA WA work Experiment 4 Appendix B When comparing small average gains observed However looking speciﬁc problems method NRWA yield signiﬁcant gains run time Experiment 4 Appendix B conducted Freecell domain reduction number expanded generated nodes 15 loss quality Using weight 100 Puzzle domain NRWA problem prob03 Again penalty terms quality loss For problems observed reduction number generated yields higher expanded nodes smaller 110 However example NRWA Experiment 5 Appendix B For appropriate weights negative effect run time original weighted A vanishes completely expands 30 nodes generates 28 nodes WA R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1333 Gain Satellite domain b Loss Satellite domain Fig 18 Gain loss Satellite domain Fig 19 Gain loss PSR domain NRWA slightly higher loss quality WA This happen inappropriate weight chosen examples Blocksworld Depots Puzzle domain Figs 16b 20b B3b Otherwise quality good WA 73 Hard problem instances The experiments weighted A described previous sections included comparison results algorithm Therefore necessary restrict test suites cases performance original A Besides interesting hard instances problems solved solved A In series experiments applied A weight 120 hard instances considered STRIPS domains On hand applying weights larger 120 possibly yield solutions However obtained solution lengths guaranteed 20 away optimum anymore making diﬃcult interpret results In domains Blocksworld PSR given time memory limit solved weighted A 1334 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 Gain Depots domain b Loss Depots domain Fig 20 Gain loss Depots domain Table 2 Results WA problem BLOCK140 PSRP50_S107 cid2 02 applied hard instances solution length generated nodes expanded nodes 38 23 101281 31244 33416 20451 solutions hard instances In Table 2 results largest solved hard instances given solution lengths node counts identical WA NRWA For BDD domain solutions hard instances compared results sifting simulationbased approaches For weight 120 hard instances solved largest count term1 35 34 inputs respectively The results better sifting For weight 20 lution term1 90 BDD nodes obtained minutes The result sifting 163 BDD nodes 80 higher However results simulated annealing approach genetic algorithm better SA results 85 BDD nodes EA yields 75 BDD nodes seconds 74 Summary experimental results For domain BDD minimization methods nonreopening variant NRWA STRIPS problems planning domains included comparison WA focused domainindependent realizations approaches cid2 NRDWA cid2 nra In contrast erratic behavior cid2 shows predictable cid2 achieve desired run timequality tradeoff relaxation degrees 30 behavior A practitioner use nra When compared instantiation Pearl Kims A cid2 increased predictability better run times come cost reduction quality If solution quality matters original method Pearl Kim better choice nonreopening variant On hand method NRWA cid2 application new method nra considered superior NRA cid2 theoretical practical stand turning point run time relaxation degree For reason qualities NRWA point ﬁrst practitioner rely tighter bound NRWA better nra cid2 Second NRWA R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1335 observed number state expansions run time increased Theorem 4 sheds light reason better behavior However degrees freedom approach Kim Pearl allow better utilization experts domain knowledge The fact freedom beneﬁcial BDD minimization domain implemented particular focal heuristic imply case domains Also notice results Section 3 NRWA instance general framework provided A cid2 instead WA The advantages NRDWA debatable slightly better results come high penalty run time Concerning average run time experiments BDD minimization domain clear advantage cid2 Similar results suffer reopenings NRWA reduction number node generations expansions obtained planning domains For NRWA low percent average 30 speciﬁc problems In BDD domain corresponding observed maximum gain NRWA comparison WA higher 50 method WA NRWA There example use NRWA caused high increase number node generations expansions Depots domain weight 120 150 run time worse In BDD minimization planning domains weights small penalty terms quality WA Nevertheless given appropriate weight example observed NRWA signiﬁcant penalty run time quality reopening expanded nodes In BDD minimization domain NRWA compared local search techniques The practitioner processed choose expected quality similar hillclimbing approaches like sifting In case NRWA test suite minutes guaranteed bound deviation optimum factor If guaranteed higher quality needed targeted application run times weighted A order magnitude away sifting simulationbased methods Hence unpredictable outliers results frequently downgraded qualities particular yielded sifting tolerated application sifting probably way If addition higher run times accepted use EAs reduces expected frequency magnitude deviations optimum signiﬁcantly However disadvantage unpredictable quality results Moreover design good EA depends domain knowledge hand application domain particularly solutions sparse For remaining applications bounded suboptimality required aforementioned VLSI applications search offer interesting alternative Section 6 high run times accepted Here weighted A bonus implemented domainindependent approach Summarized weighted A works considered problems allowing reductions run time 98 zero small loss quality Exceptions problems Freecell domain deﬁnite winner The problem Driverlog domain With regard different variants weighted A local search approaches Depending different users preferences hold comparing weighted A method better suited Theorem 4 formulates advantage constant overweighting cid2 algorithm uses standard cost function f g h There empirical evidence obtained A cid2 framework experiments particular domain BDD minimization Nevertheless advantages A freedom generality remain Section 3 Some domains require higher weights Among considered domains domain smallest effec tive weights Blocksworld domain highest PSR domain PSR BDD minimization domain require higher weights remaining planning domains While diﬃcult general advice choice appropriate weights results suggest choose comparatively high weight ﬁrst trial It worth mentioning choice default weight 20 HSP planner Bonet Geffner follows strategy In experiments suﬃces achieve high reduction run time cases However applying higher weights loss quality 20 example Puzzle domain 70 penalty Therefore beneﬁcial repeatedly apply gradually decreased weights sum solution lengths falls threshold quality alternatively threshold relative improvement quality 8 Conclusion We presented unifying view previous approaches weighted A A particular concern paper effect reopening expanded states This led novel variations All considered approaches studied theoretical empirical perspective As technical contribution novel general bound suboptimality derived unifying view In experimental evaluation BDD minimization problems weighted A corresponding benchmark circuits STRIPS benchmark problems classical AI planning domains solved respective variants weighted A The experiments clearly demonstrate eﬃciency weighted A On hand actual performance depends problem domain problem instance In different impacts weight reopenings observed On hand aspects behavior similar considered domains With regard considered variants weighted A deﬁnite winner differed performance presenting tradeoff Besides essential tradeoff run time vs quality tradeoffs considered 1336 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 predictability behavior vs quality Weighted A turned method suits best depends preferences user compared local search approaches Again value AI practitioner We provided detailed discussion experiences weighted A Acknowledgements The authors like thank anonymous reviewers helpful comments earlier draft paper We like thank Shavila Devi Armando Franco Brandon Jue Jennifer Worley help English presentation Our thanks Laura Lo YunPang Wang coordination proofreading Finally thank Tony Cohn coordination reviewing process time valuable suggestions improve English presentation ﬁnal version Appendix A Proofs Proof Theorem 2 Let q0 arg minqOpen f q We cid5 cid5 ˆq q0 f ˆq cid2 f cid2 f cid2 f q0 1 cid2 f q0 1 cid2 min qOpen f q A1 A2 A3 A4 Eq A1 holds deﬁnition f deﬁnition f cid5 By Eq A4 ˆq Focal follows cid2 cid5 assumption Next Eq A2 holds deﬁnition ˆq Then Eq A3 holds Proof Theorem 3 First easily veriﬁed f q cid2 f DWq cid2 f q cid2 f q states q considered state space By Theorem 2 respective state expanded WA contained Focal Second A respective cost function respective tiebreaking rule A respectively cid2 cid2 chooses state q F Focal q F arg minqFocal h F q As h F assigned WA cid2 act exactly DWA DWA A Proof Theorem 4 The results cases A A cid2 wellknown 4070 They included compare cid5 new results Because q expanded q f q f q cid2 hq cid2 f cid5 q case A WA f DWq f q cid2 cid3 cid2 1 dq N hq cid2 f DWq cid5 A5 A6 case A DWA left equations A5 A6 respectively The upper bounds range stated intervals To derive stated upper bounds A WA suﬃces separate f q A DWA cid5 bounded h term hq optimal path considered gq q cid5 admissibility h cid5 g q cid5 ﬁnally f q cid5 cid2 C cid2 Proof Lemma 1 Consider optimal path p s q Let q appears Open4 Assume q cid13 q monotonicity h Eq 2 straightforward conclude result Theorem 1 gq g situation different relaxed selection condition q selected expansion In A cid5 implies f q cid2 f q cid5 ﬁrst state p s q cid5 q cid5 q However A cid2 Let f 0 minimal cost state Open With Eq 3 selection condition f q cid2 1 cid2 f 0 On cost cid5 Different situation A cid5 deﬁnition f 0 Thus f q cid2 1 cid2 f q hand f 0 cid2 f q q exceed q cid5 factor 1 cid2 worstcase 4 Notice straightforward prove operation algorithm state p open state The proof induction length p started s ﬁrst state occurring Open p R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1337 A7 A8 Consequently gq hq cid2 1 cid2 1 cid2 cid2 1 cid2 1 cid2 cid5 cid6 cid6 cid6 cid6 cid5 cid5 q cid7 hq cid7 cid5 cid5 hq cid7 cid5 q hq kq q cid7 q hq cid5 gq g g g cid5 p closed gq q cid5 kq A9 cid5 cid5 q equal q cid5 Eq A8 holds monotonicity h Eq 2 Eq A9 holds sum g ﬁrst open state optimal path p ancestors q ancestor q optimal path p Then Eq 4 follows separating gq g Eq A7 holds q q g q q g left equation cid5 Next let consider operation WA Since q expanded q cid5 f q cid2 f q cid5 consequently similar line argument cid5 gq 1 cid2 hq cid2 gq cid2 gq g g q cid2 kq cid5 cid5 1 cid2 hq 1 cid2 cid5 kq q q cid2 kq cid6 kq q cid2 kq cid5 cid5 cid7 cid5 q hq cid5 q 1 cid2 hq cid5 q Eq 5 follows cid2 Consequently gq cid2 g q 1 cid2 hq cid5 1 q1 Proof Theorem 5 Consider optimal path p s q1 Let q cid5 appears Open Assume q1 cid13 q cid2 q1 1 q1 selected expansion Due modiﬁed behavior NRA marked closed To start induction length p assume ﬁrst time situation occurs operation Let f 0 minimal cost state Open As long q cid5 1 ﬁrst state p s q cid5 1 resides Open f r cid2 1 cid2 f 0 cid2 1 cid2 f q cid5 1 open state r eligible expansion Moreover f q cid5 1 cid2 C concluded q follows Consequently f r cid2 1 cid2 C cid5 1 ﬁrst open state optimal path gq cid5 1 g q A10 cid5 1 As h admissible Eq A10 However deviation worse q cid2 ignores better paths closed states gq1 updated optimal path cost q NRA reach f cid5 1 eventually expanded steps operation As f q1 cid5 1 p q1 However Lemma 1 loss exactness bounded5 q1 cid2 cid2 cid7 q1 hq1 gq1 g cid6 A11 The equation holds similar argument f q cid5 1 In following refer Fig 1b notation illustration idea In induction length p cid4 similar argument applied repeatedly remaining pairs adjacent states qi claim cid5 qi p 1 cid2 cid2 cid3 N 2 gqi g qi cid2 cid2 C i1cid12 1 cid2k k0 A12 In case 1 claim equivalent Eq A11 Now assume claim proven For step 1 derive gq cid5 i1 gqi kqi q cid5 i1 i1cid12 cid2 g qi cid2 C 1 cid2k kqi q k0 cid2 g q cid5 i1 cid2 C i1cid12 1 cid2k k0 cid5 i1 A13 A14 5 The lemma applied operation A cid2 NRA cid2 identical ﬁrst state reopened g cid2 cid2 C 1338 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 Eq A13 holds induction hypothesis Eq A12 Eq A14 holds optimality p It f qi1 cid2 cid5 1 cid2 f q 1 But similar argument Lemma 1 cid5 i1 holds argument applied q cid5 i1 qi1 expanded q cid6 cid7 gqi1 hqi1 cid2 1 cid2 cid6 gq cid13 cid5 i1 hq cid7 cid5 i1 cid2 1 cid2 g q cid5 i1 cid2 C cid2 1 cid2 cid13 cid13 g q cid5 i1 kq i1cid12 1 cid2k hq cid14 cid5 i1 k0 cid5 i1 qi1 hqi1 cid2 C cid14 cid14 i1cid12 1 cid2k k0 cid2 1 cid2 g qi1 hqi1 cid2 C 1 cid2k i1cid12 k0 Eq A15 holds Eq A14 Eq A15 holds monotonicity h Eq 2 Eq A15 holds optimality path p By Eq A15 cid13 gqi1 cid2 1 cid2 g qi1 cid2 C consequently cid14 i1cid12 1 cid2k k0 cid2 hqi1 gqi1 g qi1 cid2 cid2 cid15 cid16 qi1 hqi1 g 1 cid2 cid2 C i1cid12 1 cid2k k0 cid2 cid15 cid16 qi1 hqi1 g cid2 C i1cid12 1 cid2k1 cid2 cid15 cid16 qi1 hqi1 g cid2 C k0 icid12 1 cid2k k1 cid2 cid2 C cid2 C icid12 1 cid2k k1 cid2 C icid12 1 cid2k k0 claim induction shown Eq A15 holds admissibility h In particular qlast qcid3 N 2 A15 cid4 gqlast g qlast cid2 cid2 C cid41cid12 cid3 N 2 1 cid2k k0 0 cid2 0 gqlast g qlast cid2 cid2 C cid41cid12 cid3 N 2 1 cid2k k0 cid2 C cid4 1 2 1 cid2cid3 N cid2 cid15 cid4 1 cid3 N 2 cid4 C 1 cid2 cid3 N 1 cid2 2 cid16 C C A16 Eq A16 holds wellknown sum formula geometric series applies case cid2 cid13 0 That optimal path constructed operation NRA qlast cid2 deviation optimum greater factor gqlast g C cid4 C 1 cid2 cid3 N 2 cid2 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1339 Fig B1 Total number expansions Blocksworld domain Appendix B Additional experiments Experiment 1 For Blocksworld domain weight 110 curve progression suggests average gain 90 measured value 60 Fig 16a This corresponds high numbers expanded nodes ﬁt general progression curve Fig B1 A similar observation Satellite domain IPC4 Fig 18a Here weight 150 yields higher average run time larger total number generated expanded nodes weight 120 Fig B2b expanded nodes Experiment 2 The exception general rule higher weights usually cause high degradations solution quality set instances EightPuzzle contained HSP2 distribution average loss quality went 70 applying weights larger 100 Fig B3b For random puzzle prob04 number generated expanded nodes doubles weight increased 30 60 numbers fall half original value weight 110 applied The harder instances prob02 prob03 similar blow weights 100 110 Experiment 3 A potential negative effect higher weights increase number reopenings incon sistency weighted heuristic increases We observed effect diminishes domains Blocksworld Depots Logistics domain weights increased Eg problems Depots domain openings weight w 120 w cid3 20 Logistics domain reopenings 110 cid2 w cid2 20 w cid3 30 Here number reopenings goes zero positive effects relaxation focused search helps good solutions quickly The beneﬁt relaxation dominating higher weights For sliding tile puzzle vice versa reduction run time resulting relaxation absorbed increase reopenings Nevertheless total number generated expanded nodes examined set EightPuzzles increased signiﬁcantly higher weights This weights aforementioned negative effect different distinct problems positive effects problems So experiment WA worked Experiment 4 The ﬁrst example poor performance WA Driverlog domain IPC3 problem size 2 named pﬁle1 completely insensitive changes weight Regardless applied weight number nodes created expanded yielding solution A The second example set problems able solve bigger size 2 Freecell domain AIPS2000 benchmark collection A problems machine 100 seconds Unfortunately WA nonreopening variant solve problems quickly weights 101 102 110 change number expanded generated For weight 120 number expanded generated nodes run time nodes compared A doubles higher weights 20 50 100 result dramatic increase generated created works best nodes Hence run time limit 100 seconds exceeded Hansen Zhou state weighted A closetooptimal solutions available 38 Freecell fact example domain sparse solution space probably reason observed behavior NRWA The authors report successful experiment applying AWA Freecell problem size 3 weight 20 The algorithm failed ﬁnd solution running memory higher weights 50 100 We applied WA problem IPC3 suite size 3 Our results consistent observations Hansen Zhou weight 20 solution seconds variants weighted A Moreover methods result solution length The nonreopening variant NRWA performs signiﬁcantly faster 2879 nodes expanded 15118 nodes generated instead 3387 nodes expanded 17757 generated WA Here reopenings avoided use nonreopening variant Both variants perform worse 1340 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 Node expansions Depots domain b Node expansions Satellite domain Fig B2 Total number expansions selected domains Gain Puzzle domain b Loss Puzzle domain Fig B3 Gain loss Puzzle domain R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 1341 weight 150 fail completely weights greater equal 30 tried 50 100 200 500 Experiment 5 The examples NRWA Depots domain IPC3 weight 120 dramatically weight 150 causes high increase number generated expanded nodes Fig B2a expanded nodes yields higher run time WA References 1 S Akers Functional testing binary decision diagrams Eighth Annual Conf FaultTolerant Computing 1978 pp 7582 2 P Bertoli A Cimatti M Roveri Heuristic search symbolic model checking eﬃcient conformant planning Proc Intl Joint Conf Artiﬁcial Intelligence 2001 pp 467472 3 P Bertoli A Cimatti M Roveri P Traverso Planning nondeterministic domains partial observability symbolic model checking Proc Intl Joint Conf Artiﬁcial Intelligence 2001 pp 473478 4 B Bollig M Löbbing I Wegener Simulated annealing improve variable orderings OBDDs Intl Workshop Logic Synth 1995 pp 5b51 510 5 B Bollig I Wegener Improving variable ordering OBDDs NPcomplete IEEE Trans Comp 45 9 1996 9931002 6 B Bonet H Geffner Heuristic search planner 20 AI Magazine 22 3 2001 7780 7 B Bonet H Geffner Planning heuristic search Artiﬁcial Intelligence 129 1 2001 533 8 K Brace R Rudell R Bryant Eﬃcient implementation BDD package Design Automation Conf 1990 pp 4045 9 RE Bryant Graphbased algorithms Boolean function manipulation IEEE Trans Comp 35 8 1986 677691 10 P Buch A Narayan A Newton A SangiovanniVincentelli Logic synthesis large pass transistor circuits Intl Conf CAD 1997 pp 663670 11 T Bylander Complexity results planning Proc Intl Joint Conference Artiﬁcial Intelligence 1991 pp 274279 12 T Cain Practical optimisation A 13 P Chakrabarti S Ghose A Acharya S Sarkar Heuristic search restricted memory Artiﬁcial Intelligence 47 1989 197221 14 S Chang M MarekSadowska T Hwang Technology mapping TLU FPGAs based decomposition binary decision diagrams IEEE Trans path generation AI Game Programming Wisdom Charles River Media 2002 pp 146152 CAD 15 10 1996 12261236 15 M ChrzanowskaJeske Z Wang Mapping symmetric partiallysymmetric functions CAtype FPGAs Proc Midwest Symp Circuits Systems 1995 pp 290293 16 M ChrzanowskaJeske Z Wang Y Xu A regular representation mapping ﬁnegrain locallyconnected FPGAs Proc Intl Symp Circuits Systems 1997 pp 27492752 17 A Cimatti E Giunchiglia F Giunchiglia P Traverso Planning model checking A decision procedure AR Proc European Conf Planning 1997 pp 130142 18 A Cimatti M Roveri P Traverso Automatic OBDDbased generation universal plans nondeterministic domains Proc National Conf Artiﬁcial Intelligence 2000 pp 875881 19 Collaborative Benchmarking Laboratory 1993 LGSynth Benchmarks North Carolina State University Department Computer Science 1993 20 R Dechter J Pearl Generalized bestﬁrst search strategies optimality A Journal Association Computing Machinery 32 3 1985 505536 21 RB Dial Algorithm 360 Shortest path forest topological ordering Commun ACM 12 11 1969 632633 22 EW Dijkstra A note problems connexion graphs Numerische Mathematik 1 1959 269271 23 R Drechsler B Becker N Göckel A genetic algorithm variable ordering OBDDs IEE Proc Comp Digital Techniques 143 6 1996 364368 24 R Drechsler N Drechsler W Günther Fast exact minimization BDDs IEEE Trans CAD 19 3 2000 384389 25 R Drechsler W Günther F Somenzi Using lower bounds dynamic BDD minimization IEEE Trans CAD 20 1 2001 5157 26 R Ebendt R Drechsler The effect lower bounds dynamic BDD reordering IEEE Trans CAD 25 5 2006 902909 27 R Ebendt W Günther R Drechsler An improved branch bound algorithm exact BDD minimization IEEE Trans CAD 22 12 2003 1657 1663 28 R Ebendt W Günther R Drechsler Combining ordered bestﬁrst search branch bound exact BDD minimization IEEE Trans CAD 24 10 2005 15151529 29 S Edelkamp T Mehler Byte code distance heuristics trail direction model checking Java programs Proc Workshop Model Checking Artiﬁcial Intelligence 2003 pp 6976 30 S Edelkamp F Reffel OBDDs heuristic search Advances Artiﬁcial Intelligence LNAI Springer Verlag 1998 pp 8192 31 J Ellson E Gansner G Low D Dobkin E Koutsoﬁos S North KP Vo G Woodhull Graphviz graph visualization software Website httpwwwgraphvizorg 20002008 32 S Ercolani GD Micheli Technology mapping electronically programmable gate arrays Proc 28th Design Automation Conf 1991 pp 234239 33 A Felner S Kraus R Korf KBFS Kbest search Annals Mathematics Artiﬁcial Intelligence 39 12 2003 1939 34 Z Feng E Hansen S Zilberstein Symbolic generalization online planning Proc Annual Conf Uncertainty Artiﬁcial Intelligence 2003 pp 209216 35 F Ferrandi A Macii E Macii M Poncino R Scarsi F Somenzi Symbolic algorithms layoutoriented synthesis pass transistor logic circuits Intl Conf CAD 1998 pp 235241 36 S Friedman K Supowit Finding optimal variable ordering binary decision diagrams IEEE Trans Comp 39 5 1990 710713 37 M Garey D Johnson Computers Intractability A Guide Theory NPCompleteness WH Freeman New York 1979 38 E Hansen R Zhou Anytime heuristic search Journal Artiﬁcial Intelligence Research 28 2007 267297 39 E Hansen R Zhou Z Feng Symbolic heuristic search decision diagrams Symp Abstraction Reformulation Approximation 2002 pp 8398 40 P Hart N Nilsson B Raphael A formal basis heuristic determination minimum cost paths IEEE Trans Syst Sci Cybern 2 1968 100107 41 P Haslum H Geffner Admissible heuristics optimal planning Proc Intl Conf AI Planning Systems 2000 pp 7082 42 N Ishiura H Sawada S Yajima Minimization binary decision diagrams based exchange variables Intl Conf CAD 1991 pp 472475 43 R Jensen R Bryant M Veloso SetA algorithm Proc National Conf Artiﬁcial Intelligence 2002 pp 668673 44 R Jensen E Hansen S Richards R Zhou Memoryeﬃcient symbolic heuristic search Proc Intl Conf Automated Planning Scheduling An eﬃcient BDDbased A 2006 pp 304313 45 R Jensen M Veloso ASET A multiagent planning language nondeterministic durative tasks BDDbased fault tolerant planning Proc Intl Conf Automated Planning Scheduling Workshop Multiagent Planning Scheduling 2005 pp 5865 1342 R Ebendt R Drechsler Artiﬁcial Intelligence 173 2009 13101342 46 SW Jeong TS Kim F Somenzi An eﬃcient method optimal BDD ordering computation Intl Conf VLSI CAD 1993 47 DB Johnson Eﬃcient algorithms shortest paths sparse networks J ACM 24 1 1977 113 48 H Kaindl G Kainz Bidirectional heuristic search reconsidered Journal Artiﬁcial Intelligence Research 7 1997 283317 49 H Kaindl A Khorsand Memorybounded bidirectional search Proc 12th National Conf Artiﬁcial Intelligence 1994 pp 13591364 50 H Kautz B Selman Unifying SATbased graphbased planning Proc Int Joint Conf Artiﬁcial Intelligence 1999 pp 318327 51 H Kobayashi H Imai Improvement A algorithm multiple sequence alignment Proc 9th Workshop Genome Informatics 1998 pp 120130 52 A Köll H Kaindl A new approach dynamic weighting Proc European Conf Artiﬁcial Intelligence 1992 pp 1617 53 A Köll H Kaindl Bidirectional bestﬁrst search bounded error Summary results Proc 13th International Joint Conf Artiﬁcial Intelligence 1993 pp 217223 54 RE Korf Planning search A quantitative approach Artiﬁcial Intelligence 33 1 1987 6568 55 RE Korf Linearspace bestﬁrst search Artiﬁcial Intelligence 62 1 1993 4178 56 RE Korf A complete anytime algorithm number partitioning Artiﬁcial Intelligence 106 2 1998 181203 57 RE Korf An improved algorithm optimal bin packing Proc Intl Joint Conf Artiﬁcial Intelligence 2003 pp 12521258 58 RE Korf Optimal rectangle packing New results Proc Intl Conf Automated Planning Scheduling 2004 pp 142149 59 RE Korf W Zhang Divideandconquer frontier search applied optimal sequence alignment Proc 17th National Conf Artiﬁcial Intelligence 2000 pp 910916 60 RE Korf W Zhang I Thayer H Hohwald Frontier search J ACM 52 5 2005 715748 61 K Kotecha N Gambhava A hybrid genetic algorithm minimum vertex cover problem Proc Indian Intl Conf Artiﬁcial Intelligence 2003 pp 904913 62 M Likhachev D Ferguson G Gordon A Stentz S Thrun Anytime search dynamic graphs Artiﬁcial Intelligence 172 14 2008 16131643 63 M Likhachev G Gordon S Thrun ARA Formal analysis Technical report Carnegie Mellon University 2003 64 M Likhachev GJ Gordon S Thrun ARA provable bounds suboptimality S Thrun L Saul B Schölkopf Eds Advances Anytime A Neural Information Processing Systems vol 16 MIT Press Cambridge MA 2004 65 D Long M Fox The eﬃcient implementation plangraph STAN J Artiﬁcial Intelligence Research 10 1999 85115 66 L Macchiarulo L Benini E Macii Ontheﬂy layout generation PTL macrocells Design Automation Test Europe 2001 pp 546551 67 A Mukherjee R Sudhakar M MarekSadowska S Long Wave steering YADDs A novel noniterative synthesis layout technique Design Automation Conf 1999 pp 466471 68 R Murgai Y Nishizaki N Shenoy R Brayton A SangiovanniVincentelli Logic synthesis programmable gate arrays Proc 27th Design Automation Conf 1991 pp 620625 69 N Nilsson Principles Artiﬁcial Intelligence Tioga Publishing Company Palo Alto CA 1980 70 J Pearl J Kim Studies semiadmissible heuristics IEEE Trans Pattern Analysis Machine Intelligence PAMI4 4 1982 392399 71 I Pohl Heuristic search viewed path ﬁnding graph Artiﬁcial Intelligence 1 3 1970 193204 72 I Pohl The avoidance relative catastrophe heuristic competence genuine dynamic weighting computational issues heuristic problem solving Proc 3rd Int Joint Conf Artiﬁcial Intelligence 1973 pp 1217 73 K Qian A Nymeier Heuristic search algorithms based symbolic data structures Proc Australian Conf Artiﬁcial Intelligence 2003 pp 966979 74 D Ratner M Warmuth Finding shortest solution n nextension 15puzzle intractable J Symbolic Computation 10 2 1990 111137 75 F Reffel S Edelkamp Error detection directed symbolic model checking World Congress Formal Methods 1999 pp 195211 76 R Rudell Dynamic variable ordering ordered binary decision diagrams Intl Conf CAD 1993 pp 4247 77 S Russell Eﬃcient memorybounded search methods Proc 10th European Conf Artiﬁcial Intelligence vol 16 1992 pp 701710 78 S Schroedl An improved search algorithm optimal multiplesequence alignment Journal Artiﬁcial Intelligence Research 23 2005 587623 79 C Shannon A symbolic analysis relay switching circuits Trans AIEE 57 1938 713723 80 R Shelar S Sapatnekar Pass Transistor Logic Synthesizer Version 10 PTLS University Michigan 2002 81 D Sieling Nonapproximability OBDD minimization Information Computation 172 2 2002 103138 82 D Sieling I Wegener Reduction BDDs linear time Information Processing Letters 48 3 1993 139144 83 F Somenzi CU decision diagram package release 241 University Colorado Boulder available httpvlsicoloradoedufabioCUDD 2004 84 I Wegener Worst case examples operations OBDDs Information Processing Letters 74 2000 9196 85 D Weld An introduction commitment planning AI Magazine 15 4 1994 2761 86 C Yang M Ciesielski BDS A BDDbased logic optimization IEEE Trans CAD 21 7 2002 866876 87 R Zhou E Hansen Memorybounded A 88 R Zhou E Hansen Multiple sequence alignment anytime A graph search 15th Int Florida Artiﬁcial Intelligence Research Soc Conf 2002 pp 203209 Proc 18th National Conf Artiﬁcial Intelligence Student Abstract 2002 pp 975976 89 R Zhou E Hansen Sparsememory graph search Proc 18th Joint Conf Artiﬁcial Intelligence 2003 pp 12591266 90 R Zhou E Hansen Sweep A Spaceeﬃcient heuristic search partially ordered graphs Proc 15th IEEE Int Conf Tools Artiﬁcial Intelligence 2003 pp 427434