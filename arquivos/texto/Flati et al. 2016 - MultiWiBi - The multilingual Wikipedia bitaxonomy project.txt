Artiﬁcial Intelligence 241 2016 66102 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint MultiWiBi The multilingual Wikipedia bitaxonomy project Tiziano Flati Daniele Vannella Tommaso Pasini Roberto Navigli Dipartimento di Informatica Sapienza Università di Roma Italy r t c l e n f o b s t r c t Article history Received 14 May 2015 Received revised form 10 August 2016 Accepted 15 August 2016 Available online 8 September 2016 Keywords Taxonomy extraction Taxonomy induction Machine learning Natural language processing Collaborative resources Wikipedia 1 Introduction We present MultiWiBi approach automatic creation integrated taxonomies Wikipedia pages categories written different languages In order create taxonomies arbitrary language ﬁrst build English project taxonomies languages automatically help languagespeciﬁc resources tools The process crucially leverages novel algorithm exploits information available taxonomies reinforce creation taxonomy Our experiments taxonomical information MultiWiBi characterized higher quality coverage stateoftheart resources like DBpedia YAGO MENTA WikiNet LHD WikiTaxonomy languages MultiWiBi available online http wibitaxonomyorg multiwibi 2016 Elsevier BV All rights reserved Over recent decades knowledge increasingly fundamental lubricant society The Web today far largest repository knowledge history gradually creeps aspects everyday lives ability manipulate control knowledge concerns great mass general users researchers 13 big industry players 45 called process deliver information eﬃcient accurate manner With exception rare cases WordNet 6 knowledge manually encoded building big repositories knowledge requiring human intervention extended development times entails unfortunately longer feasible Such approaches simply cope high volume information heterogeneity need knowledge available languages possible Nevertheless having large repositories knowledge embedded intelligent systems positively impact Natural Language Processing NLP tasks question answering 710 machine reading 11 entity linking 1213 information extraction 1415 automatic reasoning 1618 For example traditional opendomain Question Answering systems able answer questions Which architect designed Shard London Bridge Even case answer effect provided text Renzo Piano designed skyscrapers Shard London Bridge additional information usually needed semantic type level 19 Renzo Piano architect Shard London Bridge skyscraper As demonstration concept Word Sense Disambiguation 2021 receive signiﬁcant boost Consider instance sentence The woman lit match combining information match lighter contest contribution taxonomy ii fact lighters usually lit contribution disambiguation possible achieve higher disambiguation performance Because usefulness taxonomies researchers industrial stakeholders seeking decades design Corresponding author Email addresses ﬂatidiuniroma1it T Flati vannelladiuniroma1it D Vannella pasinidiuniroma1it T Pasini naviglidiuniroma1it R Navigli httpdxdoiorg101016jartint201608004 00043702 2016 Elsevier BV All rights reserved T Flati et al Artiﬁcial Intelligence 241 2016 66102 67 novel mechanisms capable automatically extracting valuable information broad accurate time This goal pursued different ways In early days approaches remain alive conviction desire extract knowledge linguistic textual repositories methods based distributional word cooccurrence statistical analysis linguistic patterns relied free text Given limited size source textual corpora systems relied proved accurate failed serve true general domain data providers As time went collaborative efforts started sprout spontaneously aim developing true encyclopedic stores users actively contribute enhancing resource additional information Wikipedia started 2001 biggest movements currently active knowledge available 294 languages time writing A real added value brought Wikipedia possibility enrich text hyperlinks feature combined availability tabular information makes possible extract semistructured information large scale 2223 Over time systems targeted different types relation general opendomain TextRunner 24 ReVerb 25 approaches syntacticsemantic interface like 26 DefIE 14 speciﬁc bound particular domain Semantic relations encode large number linguistic aspects spanning general relatedness case links Wikipedia pages speciﬁc types hypernymy holonymy meronymy 27 It increasingly clear hypernymy relations represented important types boost current artiﬁcial intelligent systems Starting eighties branch research focused type semantic relation pioneering work Hearst 28 laying foundation forthcoming literature Hearsts patterns designed applicable free text exploit speciﬁc feature collaborative machinereadable repositories come One ﬁrst attempts extract isa information Wikipedia dates WikiTaxonomy 29 transformed noisy network Wikipedia categories structured taxonomy concepts Subsequently example WikiTaxonomy inspired line research including YAGO 30 WikiNet 31 MENTA 32 recently LHD 33 Many abovementioned taxonomies focused English easily scale dozens languages dependency English corpora tools Nonetheless multilinguality issue addressed existing taxonomies number ways DBpedia based manual mappings Wikipedia infoboxes languages concepts small upper ontology MENTA combines taxonomical information WordNet information coming elements Wikipedia infoboxes categories LHD relies simple general linking approach based stringmatching rules However type knowledge extracted approaches partial isa information provided Wikipedia pages Wikipedia categories incomplete lacking coverage heterogeneous drawn shared standard repository In contrast paper present approach automatic creation integrated bitaxonomy Wikipedia pages categories multiple languages called MultiWiBi addresses abovementioned issues 1 First focus Wikipedia pages categories taxonomizes sides showing mutually beneﬁcial inducing widecoverage ﬁnegrained integrated taxonomy In particular hypernyms returned coherent manner Wikipedia page category Wikipedia page category hypernym The rationale decision Wikipedia designed separate interconnected structures mind nature sides Wikipedia different pages encode concepts named entities categories group pages coherent sets For reasons unnatural merge types item 2 Second method able taxonomize Wikipedias language way fully independent additional resources At core approach fact lies idea English version Wikipedia linguistically exploited pivot project taxonomic information language offered Wikipedia order produce bitaxonomy arbitrary languages English chosen pivoting language quality Wikipedia languages comparable English version Section 12 ii language provable highestperformance syntactic parser leading best hypernym lemmas iii English language features far greatest number pages Wikipedia1 Nonetheless method potentially pivot language English chose English pivoting language language highest data presumably highest quality 3 Third prove approach overcomes language barrier extracting hypernyms projectable concepts concepts English counterpart represent culturespeciﬁc bits knowledge 2 Background contributions In section introduce background explain key idea Wikipedia bitaxonomy clarify contribu tions We summarize assumptions work relies introduce notation 1 Note Swedish second popular language Wikipedia 2885256 pages half English knowledge 68 T Flati et al Artiﬁcial Intelligence 241 2016 66102 21 Background This work stems insight biggest collaborative encyclopedia Wikipedia auto matically deriving hypernymy isa information entities concepts described To exploit dual nature Wikipedia pages categories provided The following paragraphs explain differences pages categories present core terminology Wikipedia pages A Wikipedia page provides encyclopedic description single entity concept example page Albert Einstein reports relevant known facts physicist page Person describes concept person The text semistructured information available XMLlike language information divided sections paragraphs Whenever possible pages contain dates tables biographies citations media ﬁles images What makes Wikipedia interesting fact pages interlinked words page associated pages Wikipedia The resulting hypertext viewed semantic network Wikipedia pages This network dense heterogeneous links unlabeled implicitly encode isa relations types semantic relations bornin locatedin common case general relatedness For example Wikipedia page Enrico Fermi contains link Physicist link brings reader type Enrico Fermi Nobel Prize Physics strongly related physicist represent isa relation Besides regular pages Wikipedia provides socalled redirections Redirections special pages act HTML redirections Wikipedia pages For example redirections Wikipedia page Singing include Singer Vocalist redirections Wikipedia page Headphones include Stereo headphones Head phones Headphone As clear foregoing examples redirections include misspellings ﬁnal Wikipedia page concepts related ﬁnal page necessarily convey meaning Wikipedia categories Wikipedia categories instead separate entities group pages broader classes instance Theoretical physicists category Albert Einstein Person categorized Concepts ethics Notably sides intertwined pages usually associated multiple categories category acts bucket similar pages pagecategory associations crosslinks However note Wikipedia categories represent proper categorization page example Albert Einstein associated Theoretical physicists 1879 births characterize physicist particular manner apart having born 1879 Institute Advanced Study faculty related Albert Einstein physicist person Wikipedia categories seen mixedlabel graph category nodes connected isa relatedness relationships explicit distinction Crosslinks One core elements work represented crosslinks These links special relations nect pages categories vice versa Thanks particular type link fact hypernymy information extracted automatically page Wikipedia transferred category vice versa For example knowing pages linked category American singers assigned page Singer hypernym impor tant hint increasing strength isa association categories American singers Singers Wikipedia pages usually connected Wikipedia categories hold fact categories pages associated pages need categorised example Wikipedia page MacQuarrie cat egories associated Wikipedia category Transport disasters Yemen pages associated In English happens 16 136 time page category sides respectively English Wikipedia Sense inventories A sense inventory represents predeﬁned set concepts Two major schools thought emerge literature ﬁrst option adopt work use Wikipedia pages redirections categories form sense inventory Speciﬁcally work hypernyms pages drawn set pages redirections hypernyms categories drawn set categories The second option draw sources external Wikipedia WordNet DBpedia ontology case alternative approaches MENTA YAGO DBpedia Section 9 For example YAGO returns person1 n Wikipedia category People Barcelona DBpedia returns httpdbpediaorgontologySettlement Wikipedia page Barcelona2 Our idea Despite inherent asymmetry pages categories hunch sides Wikipedia fruitfully exploited mutually synergistically extract information generalization pages categories In fact byproduct acquire hypernymy information page infers generalizations Wikipedia categories vice versa As sides connected output 2 We use sense notation 20 w p ith sense w speech p T Flati et al Artiﬁcial Intelligence 241 2016 66102 69 Fig 1 Example input output MultiWiBi seen pair taxonomies taxonomy Wikipedia pages taxonomy Wikipedia categories taxonomy linked crosslinks We pair taxonomies bitaxonomy More formally bitaxonomy pair B T P T C taxonomies T P taxonomy Wikipedia pages T C taxonomy Wikipedia categories T P T C deﬁned set hypernymy edges cid3 T C algorithm page category Wikipedia T P p p cid3 P C set Wikipedia pages categories These edges represent c c hypernymy information algorithm instance taxonomy Wikipedia pages contains edge Albert Einstein Physicist means automatically inferred Albert Einstein physicist In follows presence edge p p cid3 isap h h hypernym lemma generalizes p cid3 P p isa p cid3 C c isa c cid3 p cid3 p p cid3 c c Fig 1 provides visual excerpt real input output The page category sides depicted lines crosslinks drawn dashed lines For instance consider Wikipedia page Donald Duck Wikipedia page graph points pages Mickey Mouse Cartoon Thanks application MultiWiBi Cartoon promoted hypernym Donald Duck result ﬁrst edge discarded On hand Wikipedia category Disney comics character super categories Disney characters Disney comics ﬁnally associated hypernym category Disney characters discarding super category The multilingual case Key approach idea ﬁrst acquiring bitaxonomy English projecting information available English language English seen pivot language allows infer facts known English languages Note mean possible English information transferred languages For majority languages fact English Wikipedia contains concepts Wikipedias languages taken individually On hand note English 70 T Flati et al Artiﬁcial Intelligence 241 2016 66102 Wikipedia far union information languages individually Wikipedia edition contains unique information represents cultural concepts food dances people native given country available English Italian page Paccheri wellknown type pasta produced Italy Savarin famous French sweet With MultiWiBi able acquire taxonomical information Data paper All data paper examples experimental setup based En glish Wikipedia 2012 details Section 5 This ensure level playing ﬁeld alternative approaches general draw version Wikipedia dating year Sections 9 10 22 Contributions Our major contributions following We provide novel algorithm inducing taxonomy Wikipedia pages Wikipedia categories Starting raw dump English Wikipedia performed steps The ﬁrst step produces ﬁrst taxonomy page Wikipedia second step starting noisy category graph iteratively isolates hypernyms Wikipedia categories discriminating isa relations general relations thanks crosslinks step reﬁnes bitaxonomy improving overall coverage solving structural ﬂaws page category graphs We output bitaxonomy taxonomies aligned meaning concepts entities page tax onomy linked categories category taxonomy vice versa In contrast alternative approaches output hypernyms drawn different sense inventories taxonomical information output homoge neous Thanks advanced exploitation Wikipedia interlanguage links link surface forms provide proba bilistic mechanism obtaining translations English hypernym lemmas multiple languages This crucial step order generalize MultiWiBi languages English We provide method bound particular language fact MultiWiBi extracts bitaxonomy arbitrary Wikipedia languages independently additional resources Notably succeeds covering concepts English counterpart marked contrast alternatives instead provide limited coverage We developed novel approach translating lemmas Wikipedia language language encyclopedia This statistical method able provide lemma given language distribution translated lemmas target language drawing information extracted Wikipedia As result work release numerous gold standard datasets pages categories different languages benchmark experimentation comparison purposes total 3850 1000 1000 256 155 436 232 140 500 131 annotated items This work extension conference paper Two Is Bigger Better Than One The Wikipedia Bitaxonomy Project 34 The main novelty journal article new method automatic extension multilingual case In striking contrast English case fact procedure rely existing resource tool external Wikipedia making MultiWiBi virtually independent replicable new version Wikipedia language We performed range additional experiments demonstrate accuracy approach comparison resources 23 Paper organization The paper organized follows Sections 38 present construction multilingual bitaxonomy Section 9 presents related work introduces main competitors compare comparative evaluation reported Section 10 The extension multilingual case explained Section 11 corresponding multilingual evaluation presented Section 12 Section 13 ﬁnally draws conclusions 3 A Wikipedia bitaxonomy English In order induce English Wikipedia bitaxonomy taxonomy pages categories proceed 3 phases 1 Creation initial page taxonomy ﬁrst create taxonomy Wikipedia pages parsing textual deﬁ nitions page extracting hypernym lemmas ii disambiguating hypernym lemma according Wikipedia sense inventory 2 Creation bitaxonomy leverage hypernyms page taxonomy links corre sponding categories induce taxonomy Wikipedia categories iterative way At iteration links page taxonomy identify category hypernyms conversely new category hypernyms identify page hypernyms T Flati et al Artiﬁcial Intelligence 241 2016 66102 71 Fig 2 The dependency tree Wikipedia deﬁnition Noam Chomsky 3 Reﬁnement bitaxonomy ﬁnally employ structural heuristics overcome inherent problems affecting certain classes category page hypernyms The output threephase approach bitaxonomy millions pages hundreds thousands categories English Wikipedia 4 Phase 1 inducing page taxonomy The goal ﬁrst phase induce taxonomy Wikipedia pages Let P set Wikipedia pages let T P P E directed graph page taxonomy nodes pages edge set E initially E For p P aim identify suitable generalization ph P create edge p ph add E For instance given page Apple represents fruit meaning apple want determine hypernym Fruit add hypernym edge connecting pages E E Apple Fruit To proceed steps syntactic step extracts pages textual deﬁnition lemma best represents hypernym page ii semantic step identiﬁes suitable sense lemma extracted syntactic step according Wikipedia sense inventory 41 Syntactic step hypernym extraction Given pages textual deﬁnition aim syntactic step identify lemma best generalises pages concept To page p P extract zero hypernym lemmas textual deﬁnition p output potentially ambiguous hypernyms page The ﬁrst assumption follows Wikipedia guidelines3 validated literature 3536 ﬁrst sentence Wikipedia page p provides textual deﬁnition concept represented p The second assumption build idea lexical taxonomy obtained extracting hypernyms textual deﬁnitions This idea dates early 1970s 37 developments 1980s 3839 1990s 40 later 4143 To extract hypernym lemmas draw notion copula relation complement copular verb copular verb itself4 Therefore apply Stanford parser 44 deﬁnition page order extract dependency relations sentence For example given deﬁnition page Noam Chomsky Avram Noam Chomsky American linguist philosopher cognitive scientist logician historian political critic activist Stanford parser outputs set dependencies shown Fig 2 The noun involved copula relation linguist taken pages hypernym lemma Finally capture multiple hypernyms iteratively follow conj_and conj_or relations starting initially extracted hypernym For example consider deﬁnition Noam Chomsky given Initially linguist hypernym selected thanks copula relation following conjunction relations philosopher scientist logician extracted hypernyms To understand relevance step consider MultiWiBi succeeded extracting hypernym lemma 12 English Wikipedia pages We acknowledge sophisticated approaches like 35 45 applied especially consider lightweight solution instead leverages syntactic parser extract hypernym lemmas Obtaining high coverage critical case practice hypernym extraction approach able cover signiﬁcantly pages Handling special cases Words kind type selected hypernym lemmas However desirable lemmas represent class objects Consider instance deﬁnition page Tressette Tressette Tresette Italys major national tricktaking card games Scopa Briscola copula relation extracted hypernym lemma extracted Despite correct general sense rejected favour game Thus cope problem use specially designed class nouns5 To avoid discarding valuable hypernyms handle cases class term followed preposition type Note identiﬁed class terms 3 See http en wikipedia org wiki Wikipedia Writing _better _articles 4 Cf http nlp stanford edu software dependencies _manual pdf 5 species genus list term form type collection group set branch order class family series style variety kind pair 72 T Flati et al Artiﬁcial Intelligence 241 2016 66102 Frequency 96706 54970 53128 18315 Class term species genus Level Level 0 Level 1 Level 2 Level 3 lemmas 3978522 305598 4561 28 Percentage 92767 7125 0106 0001 Frequency 4 frequent class terms English glosses b Distribution hypernym lemma nesting level Fig 3 Statistics nested hypernym lemmas Fig 4 Coverage Wikipedia pages hypernym lemma extraction step independently underlying data distribution dataoriented languagespeciﬁc Hence occurs replace class term x noun n involved dependency relation prep_of x n In previous example involved dependency relation prep_of games lemma replaced concrete informative hypernym lemma game Furthermore cope problem nested special nouns gloss set recursively applying procedure explained For example given page Harmonic mean deﬁnition In mathematics harmonic mean kinds average able extract lemma average hypernym The frequent nested noun species shown Table 3a followed genus Out total number hypernym lemmas extracted 92 nesting level 0 remaining 7 lemmas nested level 1 negligible percentage nesting level 2 3 seen Table 3b Filling gaps syntactic parser sister approach By analyzing coverage lemmas extracted thanks syntactic parser 400286 English pages 10 total hypernym lemma extracted We considered sample 100 pages syntactic parser extract hypernym Out corresponding 100 textual deﬁnitions 4 deﬁnitions contained hypernym lemma copula relation representing cases syntactic parser failed parse correctly 8 unrecognized disambiguation pages able remove total list pages 18 contained hypernym lemma expressed relations copula deﬁnition Arthur Walworth noted biographer Woodrow Wilson word biographer involved prep_as dependency relation copula relation 70 illformed deﬁnitions clearly deﬁne concept represented Wikipedia page brieﬂy history role world leave generalization implicit The class illformed deﬁnitions include example Audi deﬁned AUDI Aktiengesellschaft subsidiaries design engineer manufacture distribute auto mobiles motorcycles Audi Ducati Lamborghini brands6 In order cover pages affected problems applied algorithm able assign hypernym lemma inducing information pages Given page p algorithm considers socalled sister pages p pages share p category syntactic parser able provide hypernym lemma The algorithm builds distri bution hypernym lemmas selects overlaps lemmas ps Wikipedia categories For page instance selected hypernym lemma manufacturer overlaps Audi categories Motor vehicle manufacturers Germany Car manufacturers Germany Thanks sister ap proach able recover hypernym lemma 70 pages covered syntactic parsing approach To visually grasp impact application approaches report Fig 4 coverage Wikipedia pages The bar represents number pages hypernym lemma extracted thanks syntactic parsing dark colour sister approaches light colour seen 3712201 pages covered overall approximately 97 total number Wikipedia pages The second bar represents instead overall number 6 Note deﬁnition page improved 2014 Audi AG German automobile manufacturer designs engineers produces markets distributes luxury automobiles meaning syntaxbased approach effective T Flati et al Artiﬁcial Intelligence 241 2016 66102 73 hypernym lemmas extracted approaches recall hypernym extraction procedure potentially extracts multiple hypernyms single deﬁnition total number hypernym lemmas extracted higher total number Wikipedia pages vertical red line ﬁgure fact 3712201 Wikipedia pages covered 4288709 hypernym lemmas extracted total 42 Semantic step hypernym disambiguation Since aim connect pairs pages hypernym relations second step consists disambiguating obtained hypernym lemmas page p suitable senses For instance given fruit hypernym Apple like link Apple page Fruit opposed Fruit band Fruit album As explained Section 21 going previous work 3646 inventory given lemma consider set pages redirections main title lemma sense speciﬁcation parentheses It important frequent concepts Singer Philosopher Volleyball player lack pages Wikipedia Even hand Wikipedians continually mitigating issue time Philosopher Wikipedia page 2014 hand kind problem likely persist future Singer exist independent page In order disambiguate hypernym lemmas extracted previous step apply battery hypernym linkers output suitable sense given lemma combined procedures limit sense drifts application linkers 421 Hypernym linkers To disambiguate hypernym lemmas exploit structural features Wikipedia pipeline hypernym linkers L Li applied cascade order We start set pagehypernym pairs H p h obtained syntactic step The successful application linker pair p h H yields page ph suitable sense h resulting setting isap h ph At step ith linker Li L applied H hypernyms linker disambiguate removed H This prevents lowerprecision linkers overriding decisions taken accurate ones cf Section 53 Hypernym linkers applied order presented details Section 53 In follows denote p h ph fact deﬁnition Wikipedia page p contains occurrence h linked page ph Note constrain ph necessarily sense h let represent arbitrary Wikipedia page instance allow hypernym lemma person linked Wikipedia page Individual sense person Wikipedia Category linker Given set W P Wikipedia pages category common p select majority sense h hyperlinked deﬁnitions pages W isap h arg max cid2 ph pcid3W 1p cid3 h ph cid3 h ph characteristic function equals 1 h linked ph page p 1p 0 For example linker sets isaEggplant plant Plant pages associated Tropical fruit category Eggplant contain deﬁnitions term plant linked Plant page cid3 h ph hypernym h manually linked ph p Wikipedians Crowdsourced linker If p assign isap h ph For example capital linked Brussels page deﬁnition Capital city set isaBrussels capital Capital city Distributional linker This linker provides distributional approach hypernym disambiguation We represent textual deﬁnition page p distributional vector cid10v p components English lemmas Wikipedia consider nouns adjectives adverbs verbs The value component occurrence count corresponding content word deﬁnition p We perform compounding discard lemmas length equal 1 discard verb contained Wikipedia deﬁnitions The goal approach ﬁnd best link hypernym h p pages h linked set deﬁnitions Wikipedia Formally ph h linked ph deﬁnition deﬁne set pages P ph deﬁnitions contain link ph cid3 P ph explained create P ph p aggregate vector cid10v ph pcid3 cid10v pcid3 For discriminating vectors remove target lemma cid10v ph Finally determine similarity p ph calculating dot product vectors simp ph cid10v p cid10v ph If simp ph 0 ph perform following association cid3 h ph We build distributional vector cid10v pcid3 p cid3 P p cid3 isap h arg max ph simp ph 74 T Flati et al Artiﬁcial Intelligence 241 2016 66102 Fig 5 Absolute number distribution hypernyms disambiguated hypernym linkers For example consider Wikipedia page Aristotle hypernym lemma teacher Among Wikipedia textual deﬁnitions occurs teacher linked senses Teacher Piano teacher The vectors starting page Aristotle senses shown cid10v Aristotle student1 philosopher1 polymath1 cid10v Teacher student30 philosopher14 polymath1 cid10v Piano teacher pianist1 virtuoso1 composer1 The similarities vector starting page vectors senses similarit yAristotle Teacher 1 30 1 14 1 1 450 similarit yAristotle Piano teacher 0 In ﬁrst case vectors share lemmas student philosopher similarity greater zero second case vectors word common Hence Teacher sense teacher maximises similarity Aristotle linker sets isaAristotle teacher Teacher Monosemous linker If h monosemous Wikipedia single sense ph lemma link sense setting isap h ph For example syntactic step extracted hypernym lemma businessperson deﬁnition Merchant unambiguous link Businessperson m ph m multiword expression containing lemma h words set isap h ph Multiword linker If p For example set isaArea 51 base Military base multiword expression military base linked Military base deﬁnition Area 51 Sister linker Finally given set W P Wikipedia pages category common p share hypernym lemma select frequent hypernym For example determine isaGuitarist person Person thanks fact seven pages Composer Disc Jockey Person common hypernym share category Occupations music starting page Guitarist Fig 5a plots coverage Wikipedia pages hypernym linkers applied presented order Two lines shown blue line plots number pages hypernym green line shows number total hypernyms certain phase Again MultiWiBi extracts hypernym lemma given page total number hypernyms higher total number Wikipedia pages Fig 5b shows absolute number hypernym links corresponding relative ratios The ﬁrst heuristics provide thirds total hypernyms contained Wikipedia page taxonomy increasingly disambiguate hypernym lemmas 4046411 total hypernyms 3529647 Wikipedia pages covering 92 total Wikipedia pages In order limit potential noise introduced linkers application linker apply special modules aim preserve quality linking pipeline detect possible shifts meaning T Flati et al Artiﬁcial Intelligence 241 2016 66102 75 Input Strings s1 s2 Output true s1 s2 semantic shift false 1 s1 normalizes1 2 s2 normalizes2 3 h1 get_heads1 4 h2 get_heads2 5 r shift_testh1 h2 6 r undef return r 7 t1 get_last_tokens1 8 t2 get_last_tokens2 9 r shift_testt1 t2 10 r undef return r 11 return false The Semantic Shift Recognizer SSR Algorithm Freq 47299 13321 4871 3671 3388 3360 s1 footballer painter singer fencer boxer athlete s2 Association football Painting Singing Fencing Boxing Athletics sport b Excerpt frequent semantic shifts recognized SSR module Fig 6 The SSR algorithm excerpt frequent shifts returned algorithm b 422 Preserving meaning hypernym lemmas hypernym senses As result application entire linking pipeline obtain large number disambiguated hypernym lemmas However nonnegligible number disambiguated hypernyms suffer problem semantic shift This phenomenon occurs pages hypernym lemma linked page closely related sense hypernym hand Consider example textual deﬁnition Heinrich von Tenner Austrian fencerFencing hypernym term fencer linked page Fencing This inappropriate se instead reﬂects common phenomenon consists annotating text domain word sense Fencing considered topic domain usually associated fencer sense it7 Furthermore phenomenon involves different kinds linguistic aspects gender differentiation actressactor distinction activity associated role singingsinger paintingpainter In addition important point links Wikipedia pages redirections As redirections include mispellings ﬁnal Wikipedia page concepts related ﬁnal page necessarily convey meaning Note redirections text associated hard deﬁne solid linguistic rules measure relationship redirection target page Lemma preserver LP As ﬁrst simple attempt cope semantic shift phenomenon apply procedure called Lemma preserver Whenever linkers presented Section 421 outputs Wikipedia page p disambiguation hypernym lemma l routine tries preserve meaning l looking possible redirections p More speciﬁcally detects cases hypernym lemma l disambiguation p match In cases new candidate searched redirections p A redirection p p selected new l match ignoring case linguist Linguist l contained title disambiguation l title p lemma wrestler title Professional wrestler For example Category linker disambiguated p hypernym lemma linguist Wikipedia page Noam Chomsky Linguistics Of course explained closely related page considered valid disambiguation hypernym lemma extracted As result LP procedure instead Linguistics replaced Linguist redirection This frequent important action consider 17 links output ﬁrst category linker replaced lemma preserver cid3 cid3 cid3 Semantic shift recognizer SSR A second general linguisticallybound strategy represented module called Semantic Shift Recognizer SSR basis English handcrafted rules automatically discriminates isa relations semantic shifts We mechanism SSR module pseudocode reported Fig 6a To recognize semantic shift concepts represented strings s1 s2 ﬁrst normalize lines 12 words parentheses removed Person sport cut Person ii s1 s2 lowercased iii acronyms normalized s1 ep s2 extended play normalized ep iv separators normalized space business_man businessman normalized business man The core SSR module consists isolating heads strings lines 34 subsequently applying following string matching rule function shift_ test line 5 algorithm Fig 6a shift test extract stems r1 r2 heads remaining suﬃxes x1 x2 h1 r1x1 h2 r2x2 If r1 r2 coincide suspend judgement returning undef If coincide x1 x2 differ return 7 In fact edges bear important semantics principle left taxonomy opaque RELATEDTO label As decided discard order provide cleaner coherent taxonomy Wikipedia page 76 T Flati et al Artiﬁcial Intelligence 241 2016 66102 true false For example s1 singer s2 singing considered shift strings share stem sing different suﬃxes ering instead s1 plant s2 plant considered shift stems suﬃxes coincide The test designed return true cases likely semantic shifts Therefore case previous test detect semantic shift variable r line 6 undeﬁned shift test repeated respective tokens s1 s2 lines 78 If semantic shift detected SSR assumes shift occurs For instance pair s1 human s2 person detected shift Fig 6b reports frequent semantic shifts detected Semantic Shift Recognizer module seen consist topic drifts 5 Page taxonomy evaluation For ease reading experiments results step step Thus soon taxonomy creation process described provide evaluation output In section introduce measures datasets evaluate techniques All experiments based 2012 edition Wikipedia 4 different languages8 This forced choice nearly available taxonomic resources refer version Wikipedia dates 20129 51 Evaluation measures Unfortunately measuring quality taxonomy trivial task Currently agreement perform 43 On hand performing complete validation edges contained taxonomy unattainable hand smaller sample edges validated clear measures use correct fair evaluation For reasons deﬁned measures values 0 1 try characterise different dimensions quality precision recall coverage Note measures evaluate page taxonomy category taxonomy Section 83 We macro precision average ratio correct items total number items returned This measure designed count average correctness information provided single node covered taxonomy For example nodes taxonomy ﬁrst correct edge second 19 edges wrong estimate precision 50 Note taxonomy contains correct edge precision 1 means measure truly grasp overall quality taxonomy Given wide range possible answers considered correct standard recall resources calculated We deﬁned variant recall R ratio items outputs correct answer In order calculate precision recall resource manually marked hypernym returned correct Another useful measure acts upper bound precision recall coverage deﬁned fraction items answer returned independently correctness rationale measure rough idea information provided taxonomy considering number items covered 52 Page dataset To evaluate quality page taxonomy randomly sampled 1000 Wikipedia pages For page provided list suitable hypernym lemmas page mainly selected deﬁnition ii lemma correct hypernym pages 53 Hypernym linker order The optimal order application linkers presented Section 421 It established selecting combination possible permutations maximized macro precision tuning set 100 randomly sampled Wikipedia pages disjoint page dataset The Sister Linker instead employed exploits hypernym links previous linkers 54 Results Results lemma sense level reported Fig 7a The ﬁrst lines performance considering quality extraction ambiguous hypernyms As seen lemma level conﬁguration exploits 8 The exact timestamps different languages 20121001 English 20121007 French 20121012 Italian 20120927 Spanish 9 All MENTA instead extracts data Wikipedia 2010 See Table 1 details T Flati et al Artiﬁcial Intelligence 241 2016 66102 77 Fig 7 Page taxonomy performance sister pages combination simple syntactic extraction phase produces modest increment coverage recall little detriment precision The ﬁnal conﬁguration shown bold syntactic sisters The following lines table results disambiguation step vanilla ii LP module application linkers LP iii SSR module applied application linkers ﬁnally iv modules applied LP SSR As seen applying LP module alter coverage module ﬁlter linkers answer In contrast precision recall boosted modestly When SSR module applied instead coverage decreases 9420 precision recall receive important increase Finally modules applied peak reached precision recall coverage somewhat vanilla setting restrictive LP SSR individually In bold highlighted ﬁnal chosen conﬁguration combination linkers LP SSR procedures Fig 7b shows performance terms precision recall coverage hypernym linkers applied Precision generally high positive spike application ﬁrst linker decreases slowly subsequent linkers chained measuring 90 Recall coverage consistently increase linkers considered performing par precision 6 Phase 2 inducing bitaxonomy The Wikipedia page taxonomy built Section 4 serve stable pivotal input second phase aim build bitaxonomy taxonomy pages aligned taxonomy categories Our key idea generalization information available partial taxonomies mutually beneﬁcial We implement idea exploiting taxonomy add new hypernymy relations vice versa iterative way ﬁxed point reached The ﬁnal output phase hand page taxonomy augmented additional hypernymy relations hand category taxonomy built starting noisy category graph Section 2 61 The bitaxonomy algorithm We bitaxonomy algorithm To help reader explanation support presentation reference Fig 8 shows steps algorithm divided We identiﬁed steps step represented number enclosed square named follows Item switch step 1 Taxonomy climbing step 2 Candidate discovery step 3 Sanity check step 4 Before going details single step let explain data structures initialised 62 Initialization Our initial bitaxonomy B T P T C pair consisting page taxonomy T P P E obtained Section 4 category taxonomy T C C 1super C contains Wikipedia categories 1super e u v u 1 C G Wikipedia category graph simpler words initialization category EC G deg taxonomy considers nodes outdegree equal 1 super category noisy category graph adds edges set ET C The algorithm started category taxonomy partial page taxonomy input line 1 In algorithm denote T taxonomy reﬁned T taxonomy algorithm draws cid3 update T Initially T T C T cid3 T P line 1 78 T Flati et al Artiﬁcial Intelligence 241 2016 66102 Fig 8 Example application MultiWiBi iterative algorithm category Wikipedia Categor y S Categor yi denote starting candidate categories respectively 63 The steps We core algorithm Fig 9 approach iteratively populates reﬁnes edge sets ET C ET P Item switch step 1 In ﬁrst step start considering uncovered node t T Depending current iteration t page category line 5 We apply operator σ switch operator takes input Wikipedia item page category returns set Wikipedia counterpart elements items belong Wikipedia connected means crosslink Section 2 In words σ expresses mutual membership relation existing pages categories More formally given c C σ c set pages categorized c given p P σ p set categories associated page p Wikipedia In step algorithm starts t uses σ t switch taxonomy line 7 Fig 8 1 Example Consider uncovered Wikipedia category t Olympics line 5 By applying switch operator Olympics reach following set pages σ Olympics Paralympic Games Olympic Games Olympic Cup σ Olympics 26 cid3 σ t goal step harvest hy Taxonomy climbing step 2 Given dual Wikipedia items σ t t pernyms dual nodes σ t switched starting taxonomy To build set reaching hypernyms distance equal hypernymy dis Hσ t climbing taxonomy T σ t line 8 The maximum climbing distance changes iterations tance parameter δ starting item t constrain algorithm favour closer hypernyms ﬁrst iterations allow reach hypernyms proceeds line 21 Fig 8 2 cid3 1 t cid3 cid3 Example contd Out total 26 pages contained σ Olympics 23 pages come hypernym discovered construction page taxonomy line 8 example Paralympic Games Multisport event All hypernyms distance 1 added Hσ Olympics set pages project category taxonomy example Multisport event contained set Candidate discovery step 3 The goal step identify set candidate hypernyms starting node t To cid3 end having Hσ t input step apply switch operator t h Hσ t lines 910 count number times reach node T line 11 As Wikipedia items taxonomy usually associated multiple items taxonomy items counted multiple times generate distribution The result step distribution candidate nodes notably belong taxonomy given input algorithm cf Fig 8 3 This core bitaxonomy algorithm hypernymy knowledge transferred taxonomy Example contd For hypernym page Hσ t apply switch operator obtain candidate categories sum 1 As result obtain following distribution Multisport events4 Awards1 Swimsuits1 meaning end counting category Multisport events times hypernymy paths page taxonomy led Multisport event turn connected category categories Awards Swimsuits T Flati et al Artiﬁcial Intelligence 241 2016 66102 79 cid3 T P ξ 1000 λ 1 δ 1 λmax 6 δmax 3 Algorithm 1 The bitaxonomy algorithm Input T P T C 1 T T C T 2 repeat 3 4 5 6 7 si zeT ET convergence f alse t V T st cid2 th T t th ET reset candidate_count cid6 σ t H get_hypernymscid6 δ T t H th σ t cid3 h cid3 h candidate_countth cid3 8 9 end end end 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 end swap T T 30 31 convergence 32 return T T cid3 cid3 λ 1 δ δ 1 end th sortcandidate_count sanit y_checkt th T ET ET t th break end T T C ET sizeT ξ λ λ 1 λ λmax end δ δmax convergence true end cid12 step 1 cid12 step 2 cid12 step 3 cid12 step 4 cid12 Parameter update stop condition Fig 9 The bitaxonomy algorithm Sanity check step 4 The input step sides bitaxonomy starting node t T candidate hypernym th T belonging taxonomy The goal step select possible best hypernym candidate list previous step Such promotion performed candidate hypernym th passes sanity check guarantees compatibility starting node t Given different nature sides Wikipedia devised specialised conditions step depends current taxonomy updated As regards page taxonomy given page p T P candidate hypernym page ph T P sanity check ascertains ph sense hypernym lemmas extracted p Section 41 As category taxonomy given category c T C candidate hypernym category ch T C sanity check ascertains c ch connected path length λ Section 64 If holds select direct supercategory c lying shortest path c ch The rationale asymmetry lies fact category Wikipedia backed underlying noisy graph connectivity techniques generalised easily page This fourth step considers items contained distribution step 3 decreasing order promotes node h highest count passes sanity check line 15 new edge e t t h ﬁnally added t taxonomy line 16 Note soon candidate node passes sanity check new edge added taxonomy remaining candidates discarded line 17 The sanity check aim discriminating hypernym candidates contained set Hσ t checking safe add edge starting node candidate Example contd We proceed decreasing order vote ascertain sanity check categories holds As Multisport events highest count connected starting category Olympics path Wikipedia category network fact direct supercategory ﬁnally add hypernym edge Olympics Multisport events T C line 16 exit step 4 line 17 64 Parameter update stop condition At end iteration role played taxonomies swapped partial taxonomy new input new iteration line 30 The steps repeated stop condition satisﬁed line 27 The 80 T Flati et al Artiﬁcial Intelligence 241 2016 66102 algorithm governed parameters maximum path length parameter λ maximum hypernymy distance parameter δ The controls maximum length path category sanity check regulates maximum hypernymy distance taxonomy climbing step step 2 We voluntarily let δ smaller values λ assign overgeneralised hypernyms At end given iteration ξ edges added λ incremented When maximum value λmax reached λ reset 1 order closer categories henceforth preferred δ increased As safety stop condition constrain hypernymy distance parameter δ maximum value δmax Indeed starting page category climbing taxonomy maximum value risk reaching taxonomy assigning hypernyms general Entity Being likely contribute generating errors In case hypernymy distance parameter δ reaches maximum value allowed algorithm stopped taxonomies returned Note parameters modiﬁed temporary convergence parameters reached fact algorithm assigns small number edges particular iteration fact means path length parameter high let algorithm generalize suﬃciently Hence need increase path parameter spin algorithm additional iteration Note λ depends ξ possible know priori number iterations algorithm perform 65 Parameter tuning The optimal values parameters bitaxonomy algorithm λmax δmax ξ chosen according development sets containing 100 pages 100 categories disjoint datasets sections 52 83 We let λmax δmax range 1 10 ξ 10 100 1000 10000 7 Phase 3 bitaxonomy reﬁnement Despite successful application bitaxonomy algorithm taxonomies suffer structural shortcomings focus As regards page taxonomy algorithm crucially leverages important features discover right hypernym promote ﬁrst Wikipedia page needs categories associated second needs provide hypernym lemma This means small class Wikipedia pages algorithm applied fact left This class mainly contains redirections promoted hypernym construction categories deﬁnitions associated cf Section 21 For reason introduced ﬁnal reﬁnement page taxonomy addresses problem ﬁnding proper generalization set redirections As regards categories problem similar Since bitaxonomy algorithm crucially exploits switch operator harvest pages associated certain category fails pages categorised To end designed adhoc procedure overcomes structural shortcoming 71 Page taxonomy reﬁnement At core reﬁnement page taxonomy simple ideas applied cascade order use trivial taxonomical property node taxonomy hypernyms reconcile hierarchy common ancestor For example ideal taxonomy hypernyms Elvis Presley Singer Actor Person Artist lowest common ancestor The ideas called IYA I You Are ILY I Like You exploit principle The IYA Fig 10a exploits ancestors hyponyms given redirection For example order discover hypernym redirection Singer ﬁrst consider pages Gianni Morandi PSY consider turn alternative hypernyms Actor Record producer respectively We climb taxonomy common ancestor encountered Person ﬁnally promoted hypernym initial redirection Singer Ancestors met frequently preferred The ILY Fig 10b contrarily IYA leverages ancestors pages outgoing link redirection considered choosing voted ancestor For example order ﬁnd hypernym redirection Sea star consider pages pointing redirection Sepia bandensis Sea urchin Similarly previous procedure ILY determines common ancestor Organism sets isaSea star Organism Note procedures differ set starting Wikipedia pages considered In ﬁrst case preference given pages redirection direct hypernym second case instead condition relaxed pages contain outgoing link redirection considered In order evaluate edges extracted thanks phase validated 100 randomly sampled relations obtaining 93 accuracy 72 Category taxonomy reﬁnement The reﬁnement category taxonomy aims address structural weakness represented fact given Wikipedia category crosslinks missing limited number For reason diﬃcult provide hypernyms type category basis crosslinks suﬃcient infer hypernymy T Flati et al Artiﬁcial Intelligence 241 2016 66102 81 Fig 10 Patterns coverage reﬁnement page taxonomy Edges bold represent inferred hypernymy relations Fig 11 Pattern category taxonomy reﬁnement information required For example note English categories associated 5 pages represent 40 total number categories Wikipedia cid3 st c c We designed simple enrichment heuristic applied iteratively convergence adds hypernyms cid3 ET C Fig 11 Note categories c hypernym phase 2 cid2c heuristic leverage crosslinks information learned application algorithm Given uncovered category c consider direct Wikipedia supercategories let vote direct hypernym categories Then proceed decreasing order vote select highestranking category c cid3 connected c T C We ﬁnally pick direct supercategory c cid3cid3 ET C In case ties categories contributed score c add edge c c favoured For example shown Fig 11 given category Canals country supercategories Canals Waterways country Water transport country let vote according hypernym categories T C For example Waterways accumulates score 23 bitaxonomy algorithm 20 pages contributed insertion edge Canals Waterways 3 pages contributed insertion edge Waterways country Waterways Given Waterways voted hypernym algorithm chooses Canals hypernym category contributes score Waterways adds edge Canals country Canals T C c lies path c c cid3cid3 cid3cid3 cid3 As previously pages evaluated procedure manner randomly sampling 100 edges validating hand This resulted 81 accuracy demonstrating approach consistently increases category coverage keeping quality extracted relations high 82 T Flati et al Artiﬁcial Intelligence 241 2016 66102 Fig 12 Category taxonomy evaluation 8 English bitaxonomy evaluation 81 Page taxonomy improvement After application ﬁrst phase Wikipedia page taxonomy 359925 items 3889572 uncovered hypernyms associated cf Section 421 After phases 2 3 59303 total edges added page taxonomy covering 58113 nodes 15 total uncovered pages ﬁrst phase 82 Category taxonomy statistics We applied phases 2 3 output phase 1 evaluated Section 5 In Fig 12a increase category coverage iteration phase 3 The ﬁnal outcome category taxonomy includes 603590 hypernymy links categories covering 95 635972 categories 2012 English Wikipedia dump The graph shows steepest slope ﬁrst iterations phase 2 converges 400k categories iteration 30 signiﬁcant boost 213k hypernymy edges result reﬁnement phase 3 83 Category taxonomy quality To estimate quality category taxonomy randomly sampled 1000 categories manually associated supercategories deemed appropriate hypernyms We calculated precision recall way pages Section 51 Fig 12b shows performance trend algorithm iteratively covers categories Phase 2 particularly robust iterations leads increased recall retaining high precision As regards phase 3 reﬁnement leads slight precision decrease improving recall considerably Overall ﬁnal taxonomy T C achieves 9167 precision 9020 recall 9840 coverage dataset 84 Quality upper taxonomies To assess quality toplevel edges page category taxonomy extracted manually validated topmost 100 edges The evaluation resulted 76 accuracy page 65 category This excellent result consider edges come upper level taxonomy deﬁnition contains general concepts deﬁned Wikipedia Note manual validation upper taxonomy feasible involves small number edges easily relatively short time 9 Related work Although extraction taxonomies machinereadable dictionaries studied early 1970s 37 pioneering work large amounts data appeared early 1990s 2840 More recently approaches based handcrafted patterns pattern matching techniques developed provide supertype extracted terms 3547494143 inter alia However methods link terms existing taxonomies T Flati et al Artiﬁcial Intelligence 241 2016 66102 83 explicitly link adding new leaves existing taxonomy instead acquiring widecoverage taxonomies scratch 5051 The recent upsurge collaborative knowledge curation enabled approaches largescale taxonomy acquisition 23 Most approaches initially focused Wikipedia category network entangled set generalizationcontainment relations Wikipedia categories extract hypernymy taxonomy subset network The ﬁrst approach kind WikiTaxonomy 2952 based simple effective lightweight heuristics talling 100k isa relations Another approach type YAGO 3053 yields taxonomical backbone linking Wikipedia leaf categories ﬁrst frequent sense category heads WordNet Interest taxonomizing Wikipedia pages instead developed DBpedia 54 pioneered current stream work aimed extracting semistructured information Wikipedia templates infoboxes In DBpedia entities mapped coarsegrained ontology collaboratively maintained contains 270 classes corresponding popular named entity types Freebase 55 later development merger resources MusicBrainz ChefMoz While based infoboxes set million topics loosely organized relies collaborative editing mixture strict informal relations The Linked Hypernym Dataset LHD 33 recent effort tries taxonomize Wikipedia encyclopedia associating Wikipedia pages DBpedia entity DBpedia ontology concept type The types hypernyms mined pages free text handcrafted lexicosyntactic patterns Furthermore LHD released versions LHD 10 provides hypernyms DBpedia entities concepts drawn DBpedia ontology version 39 LHD 20 contains concepts drawn smaller DBpedia ontology To knowledge LHD approach addition providing hypernyms Wikipedia pages attaches corresponding ambiguous hypernym lemmas A notable efforts reconcile sides Wikipedia pages categories forward recently WikiNet 3156 project heuristically exploits different aspects Wikipedia obtain concept network deriving isa relations types relations A second project MENTA 32 creates largest multilingual lexical knowledge bases interconnecting 13M pages 271 languages Hypernym extraction supervised decisions basis labelled training examples requires reconciliation step owing heterogeneous nature hypernyms A totally different approach proposed 57 exploits hierarchical layouts Wikipedia pages extract hypernymhyponym candidates An SVM classiﬁer trained order recognize candidate real hyponym subheading Earl Grey tea hyponym page Black tea The approach complementary focuses hierarchical structure Wikipedia However based handwritten languagespeciﬁc patterns recognize hyponym candidates We plan investigate future generalize approach multiple languages exploit pipeline Finally work differs substantially respects ﬁrst marked contrast resources similarly WikiNet WikiTaxonomy resource selfcontained depend resources WordNet second similarly MENTA differently address taxonomization task sides pages categories providing algorithm mutually iteratively transfers knowledge bitaxonomy provide wide coverage bitaxonomy closer structure granularity manual WordNetlike taxonomy contrast example DBpedias ﬂat typeoriented hierarchy Another related task sense alignment The goal task link concept appearing distinct sources Pilehvar et al 58 propose uniﬁed approach uses novel similarity measure compare deﬁnitions lexical resources Nieman Gurevych 59 instead construct multilingual lexical resource Wiktionary disam biguating semantic relations translations This new resource measure monolingual crosslingual verb similarity The task tackled Gurevych et al 60 perform alignment means supervised classiﬁer Meyer et al 61 instead built new multilingual resource based Wiktionary demonstrated cope monolingual multilingual sense alignment tasks verbs However related task sense alignment different task taxonomy building In fact task establishing hor izontal links entries resources contain information aligning WordNets synset athleten 1 Wikipedia page Jock athlete 59 extracting taxonomy Wikipedia instead means establishing vertical links page category suitable generalization exact resource In contrast sense align ment algorithms alignment bitaxonomies returned algorithm byproduct result aim research In addition approaches crossresource sense alignment generally rely rich contextbased features textual deﬁnitions associated resource entries easily obtainable case categories deﬁnitions The section presents evidence assertions comparing statistics structure taxonomies presenting experiments assess quality resources 10 Comparative evaluation In section measures described Section 5 provide thorough comparison Multi WiBis English bitaxonomy major alternatives literature Section 101 presents discusses dimensions characterizing different resources In Section 102 report different measures concerning taxonom ical structure In Section 103 selection construction datasets Section 104 84 T Flati et al Artiﬁcial Intelligence 241 2016 66102 Table 1 Features main taxonomic resources WN stands WordNet P Wikipedia pages R Wikipedia redirections C Wikipedia categories D DBpedia ontology H Human effort WKT Wiktionary Categories Languages Resource Pages MultiWiBi WikiNet DBpedia LHD WikiTaxonomy YAGO YAGO3 MENTA Timestamp ddmmyy 011012 040112 010612 1012 011012 011212 0414 100410 Page hyp sense inventory P R P C D D C WN C WN P C WN Category hyp sense inventory C P C C WN P C WN Type additional sources H Syntax H Syntax D H PoS tagger D H Syntax H Syntax WN H Syntax WN H Syntax WN WKT 271 1 EN 125 3 EN DE NL 1 EN 1 EN 10 271 report discuss results obtained Note YAGO3 doesnt provide taxonomic information Wikipedia categories evaluation YAGO 101 Features taxonomic resources In order examine differences MultiWiBi resources analyzed work ﬁrst present features Table 1 For resource report data timestamp accurate date Wikipedia dumps data derived ii resource provides hypernyms Wikipedia pages iii resource provides hypernyms Wikipedia categories iv inventory hypernyms drawn v type dependencies language tools resources ﬁnally vi degree multilingualism measured number languages covered resource time writing Timestamp First seen Table 1 second column resources MENTA YAGO3 isochronous apart small differences reference month come 2012 This makes comparison easier Wikipedia sides covered hypernym inventories For years resources covering sides approaches mainly divided groups provide hypernyms pages provide hypernyms categories Within classiﬁcation discriminate basis inventories hypernyms drawn DBpedia LHD consistent return hypernyms drawn DBpedia upper ontology ii WikiTaxonomy consistent returning Wikipedia categories In contrast resources systems presented Table 1 try cover sides Wikipedia WikiNet MENTA YAGO MultiWiBi fact resources provide hypernyms pages categories As regards hypernym inventory differ substantially On hand WikiNet mixes sides Wikipedia MENTA returns hypernyms Wikipedia pages Wikipedia categories WordNet synsets amassed On hand instead YAGO outputs WordNet synsets hypernyms Wikipedia categories YAGO3 outputs WordNet synsets Wikipedia categories Wikipedia pages MultiWiBi distinct contrast returning separate aligned taxonomies disjoint hypernym sets associates hypernyms coherent consistent manner result Wikipedia pages pages categories categories hypernyms Dependency additional sources Another feature separates systems different classes need sort human intervention additional resource sensetagged corpora The second column Table 1 shows resource type dependency The degree resource tied human effort turn linked ease converting resource language course human effort required better As regards human intervention MultiWiBi depends list stopwords introduced syntactic step need additional human effort LHD WikiNet WikiTaxonomy instead rely heavily lexicosyntactic patterns X Y X VBN IN Y LHD learns patterns 600 manually annotated training examples language WikiNet WikiTaxonomy instead patterns deﬁned hand making patternbased models laborious generalize languages YAGO YAGO3 involve human effort categorytoWordNet mappings corrected hand making diﬃcult generalize languages automatically Finally case MENTA WikipediatoWordNet mappings established supervised linker trained 200 manually labelled training ex amples ii CategoryWordNet subclass relationship learnt thanks supervised learning model trained 1539 labelled training mappings This languages As regards dependency external tools note MultiWiBi needs syntactic parser extracting hypernym lemmas English extracting heads strings passed SSR module LHD requires PoStagger order train transducer learns lexicalsyntactic patterns WikiNet WikiTaxonomy YAGO YAGO3 MENTA need syntactic parser extract heads categories Needless dependency tools languagespeciﬁc limits applicability languages having tools Even MultiWiBi relies syntax English case Section 11 introduce new mechanism extracting hypernym lemmas languages requires raw Wikipedia dump desired language T Flati et al Artiﬁcial Intelligence 241 2016 66102 85 Table 2 Structural analysis taxonomies literature Feature nodes coverage edges avg height Feature nodes coverage edges avg height Resources MultiWiBi 3600781 9245 4100634 589 WikiNet 2949685 7551 14280200 171 DBpedia 1906274 4918 2112468 411 423 MENTA 2936667 6616 8054 2958235 176 490 LHD 10 3038604 6714 3013824 102 225 LHD 20 2960780 6594 2960508 1 295 YAGO3 3628053 7286 20469826 101591 WordNet 82115 84427 807 Page taxonomies Resources MultiWiBi 605887 9491 603557 1669 WikiNet 487469 6339 834837 311 WikiTax 389027 5597 568987 346 YAGO 385657 5210 378942 1 675 b Category taxonomies MENTA 559530 5618 555155 133 373 WordNet 82115 84427 807 As regards instead dependency external resources distinguish types dependency approaches use external resource hypernym inventory This case DBpedia LHD YAGO YAGO3 DBpedia LHD use DBpedia Ontology hypernym inventory letter D Table 1 YAGO links Wikipedia categories WordNet synsets YAGO3 draws hypernyms Wikipedia pages sets Wikipedia categories Word Net synsets These systems exploit external resource In contrast MENTA makes heavy use external resources different purposes countability information category heads based WordNet Wiktionary isa classiﬁer takes input hypernymy information contained WordNet In marked contrast WikiNet WikiTaxonomy MultiWiBi rely additional information selfcontained taxonomies exploit data coming solely Wikipedia Degree multilingualism Finally dimension considered tightly intertwined dependency external resources multilingualism ﬁrst note resources multilingual thanks interlanguage links connect different editions Wikipedia Section 11 details By merely analysing resources publicly released instead note resources rely English Wikipedia WikiNet WikiTaxonomy YAGO The possibility extension languages resources questionable owing dependency language tools LHD applied 3 languages separate data repositories released independently The YAGO3 page taxonomy released 10 different languages category taxonomy instead available DBpedia released 125 languages managed 18 isolated chapters MultiWiBi MENTA resources applicable Wikipedia language making truly languageindepedent approaches relies WordNet Wiktionary labelled training examples 102 Structural analysis taxonomic resources In addition aspects considered previous section present comparative evaluation concerning structure taxonomies As mentioned Section 51 easy ﬁnd valid measures capable evaluating taxonomy comprehensive manner Before reporting precision recall coverage wish present discuss structural measures considered resources page category Wikipedia Tables 2a 2b respectively We account indicators number nodes edges contained taxonomies coverage Wikipedia pages categories average height new measure called granularity 1021 Structural features taxonomies Pagebased resources Table 2a reports statistics concerning Wikipedia pages In order reference point report measures WordNet note WordNet contains far fewer nominal concepts number nodes edges informative The ﬁrst measure consider important number nodes ﬁrst row coverage calculated number pages respect Wikipedia hypernym returned regardless correctness second row Since MENTA builds Wikipedia dump dating 2010 parentheses report coverage respect page inventory time As seen MultiWiBi best resource terms coverage 9245 nodes covered hypernym Since WordNet contain Wikipedia pages coverage calculated shown table The dimension considered number edges row expresses quantity hypernymy informa tion contained resource As seen MultiWiBi provides largest number edges surpassed WikiNet The high number edges contained WikiNet correlate quality study Sections 1022 104 86 T Flati et al Artiﬁcial Intelligence 241 2016 66102 Fig 13 Hypernym granularity resources The important feature probably average height taxonomy row measured average length hypernymy paths linking leaves root This feature gives idea generalization power taxonomy longer path ﬁnegrained generalization For DBpedia LHD 10 LHD 20 YAGO YAGO3 MENTA rely external taxonomies parentheses report average height adjusted including external taxonomy The ﬁrst use DBpedia Ontology returning hypernyms Wikipedia pages resources instead use WordNet Wikipedia categories sense inventory The average height augmented resources obviously greater nonetheless average height 589 MultiWiBi surpasses approaches making resource structurally closest WordNet height 807 Categorybased resources In general scenario categories different illustrated page based resources As regards categories Table 2b MultiWiBi resource best coverage YAGO resource lowest coverage fact attention paid leaf categories MultiWiBi exhibits maximum average height ﬁve times greater resource We note average height category taxonomy T C greater page taxonomy T P fact category taxon omy distinguishes subtle classes Albums artists vs Albums recording location instead merged concept Album page taxonomy 1022 Taxonomy granularity A second important aspect analyzed granularity taxonomy determined drawing source bidimensional plane number distinct hypernyms nonleaf nodes x axis total number hypernyms edges y axis Figs 13a 13b position pagebased category based resources respectively Two baselines use opposite strategies displayed ﬁgure essential determining differences different systems positions twodimensional plane ﬁrst represents baseline assigns hypernym Wikipedia items achieving minimum granularity second represents assigns different ﬁctitious hypernym Wikipedia item achieving maximum granularity As seen MultiWiBi page taxonomy MENTA resource best granularity attain high coverage provides larger variety classes generalizations pages categories Speciﬁcally MultiWiBi provides hypernyms 4M hypernym pages chosen range 104k distinct hypernyms exhibit considerably smaller range distinct hypernyms DBpedia design WikiNet 11k distinct page hypernyms The large variety classes provided MENTA providing 100k Wikipedia categories page hypernyms categories deaths births represent 3 distinct hypernyms Finally YAGO3 exhibits highest number distinct hypernyms 380k As regards categories number distinct hypernyms MultiWiBi WikiTaxonomy approximately 130k total number hypernyms returned WikiTaxonomy 580k taxonomies refers half categories covered MultiWiBi row coverage Table 2a As regards WikiNet large number variety category hypernyms instead counterbalanced low precision recall experimental results Section 104 103 Experimental setup We compared MultiWiBi Wikipedia taxonomies major knowledge resources literature providing hypernym links DBpedia WikiNet MENTA WikiTaxonomy YAGO YAGO3 Section 9 As datasets T Flati et al Artiﬁcial Intelligence 241 2016 66102 87 Table 3 Taxonomy comparison lemma level Lemma Lemma LHD P 9483 9278 R 9020 8100 C 9850 8730 items 1000 denotes statistically signiﬁcant difference χ 2 test p 001 MultiWiBi LHD Dataset Pages Table 4 Page category taxonomy evaluation System MultiWiBi WikiNet DBpedia MENTA YAGO3 LHD 10 LHD 20 P 9076 5686 7787 8152 8644 7620 9157 Categories MultiWiBi WikiNet WikiTax YAGO MENTA MENTA ent 9065 6405 8968 9358 8711 8518 items 767 631 R 8748 7132 5411 7249 8357 5385 6375 8906 4992 5515 5309 8463 7195 C 9478 8201 5827 8892 8357 7066 6962 9826 7116 5943 5674 9715 8447 denotes statistically signiﬁcant difference χ 2 test p 001 MultiWiBi daggered resource gold standards 1000 randomlysampled pages Section 5 categories Section 83 In order ensure fair playground evaluation decided reannotate item datasets considering inclusion competitors hypernyms item Moreover given heterogeneity release date resources detected pages categories exist resources removed ensure potential coverage dataset resources As explained Section 101 fact MENTA resource based dump dating 2010 bit far However hand acknowledge performance relatively higher 2012 dump potentially counterbalanced higher ambiguity hand software generating MENTA different Wikipedia dump available10 WikiTaxonomy originally based 2009 dump instead reimplemented order align dump MultiWiBi The column Table 4 reports size levelled datasets item deletion11 104 Results Lemma taxonomy Thanks procedure Section 41 exploits dependencies extracted Stanford parser lemma taxonomy achieves good scores measures As seen Table 3 fact MultiWiBi scores 90 precision recall coverage overtaking LHD loses 10 points recall coverage despite having good precision Not conﬁrm assumption Wikipedia taxonomy extracted page deﬁnitions shows pages encyclopedia formed deﬁnition Wikipedia pages We ﬁrst report results knowledge resources provide page hypernyms compare WikiNet DBpedia MENTA YAGO3 LHD We results page hypernym dataset Table 4 As seen systems WikiNet exhibit good precision WikiNet LHD 20 stick opposite poles precisionrecall trend achieves high recall 71 cost lower precision 57 high number hypernyms provided incorrect characterised high precision low recall LHD 20 instead highest precision shows modest coverage recall inspection answers returned revealed 32 11 hypernyms http dbpedia org ontology Agent http dbpedia org ontology Place respectively despite correct general In case DBpedia considering types edge provided hypernym relation modest precision 7787 similar LHD 10 low coverage 5593 shown dependency availability infoboxes Wikipedia pages Here report individual performances types edges contained DBpedia coverage change signiﬁcantly changing source information 10 Personal communication authors 11 We wish clear datasets presented Section 52 Section 83 different regards size item deletion 88 T Flati et al Artiﬁcial Intelligence 241 2016 66102 Table 5 Excerpt answers given different systems category dataset Category Resources MultiWiBi WikiNet WikiTax Nigerian culture Racism Russia Orellana Province Salvadoran cuisine Turkish artists People Campania Culture nationality Racism country Provinces Ecuador Latin American cuisine Artists nationality People region Italy Cultures Africa Blackonblack racism Province capitals Ecuador Latin American culture People region Italy African culture nationality Provinces Ecuador Cuisine nationality Artists nationality People region Italy YAGO politician1 n artist1 n person1 n MENTA entity1 n entity1 n entity1 n entity1 n person1 n person1 n ranging 1030 5593 MENTA YAGO3 resources closest remark hypernyms output resources heterogeneous MENTA fact 48 hypernyms represented WordNet synset 37 Wikipedia categories 15 Wikipedia pages YAGO3 exhibits similar behaviour giving output hypernym categories WordNet synsets YAGO3 OWL classes yagoGeoEntity owlThing In contrast resources MultiWiBi outputs hypernyms coherent manner linking pages hypernym pages time achieving highest performance 9076 precision 8748 recall 9478 coverage Wikipedia categories We compared MultiWiBi knowledge resources deal categories WikiNet WikiTaxonomy YAGO MENTA We results category dataset Table 4 MultiWiBi best resource achieving second highest precision 9065 highest recall 8906 coverage 9826 WikiNet characterised lowest precision recall The lowest coverage 56 59 attained WikiTaxonomy YAGO case likely inadequacy lexicalsyntactic patterns succeed capturing category vari ants case fact leaf categories considered MENTA closest resource obtaining comparable overall performance Notably MENTA outputs ﬁrst WordNet sense entity 13 given answers despite correct counted precision recall uninformative Since baseline outputs entity maximise measures calculated formance MENTA discarding entity answer Table 4 shows MENTA recall drops 7195 Note Entity returned MultiWiBi hypernym dataset item To investigate phenomenon identiﬁed general Wikipedia pages Entity Being categories Objects Concepts Humans Culture calculated number times given output hypernyms taxonomies In marked contrast MENTA provides general hypernym 130408 nodes taxonomy MultiWiBi outputs general hypernyms 1808 005 total pages 38 0006 total categories ent Table 5 shows way example different answers given systems items category dataset As seen MENTAs answers general speciﬁc returned systems Further analysis presented shows speciﬁcity hypernyms returned systems considerably lower MultiWiBi 105 Taxonomy speciﬁcity To insight results performed additional analysis means quality measure We estimated level specialization hypernyms different resources datasets The idea hypernym valid time speciﬁc possible Singer preferred Person apply We calculated measure called speciﬁcity computes percentage times outputs speciﬁc answer To manually ranked answers systems 767 items page dataset described Section 103 Each hypernym returned evaluated according degree speciﬁcity comparatively associating valid answer score 0 score S x 1 In case answer missing wrong score S x set 0 For example given page Alan Edmonds assigned score 5 MENTAs hypernym 1930s births 1 MultiWiBis hypernym Reporter speciﬁc However certain systems return categories hypernyms likely speciﬁc MultiWiBi This case YAGO3 example assigned categories hypernym WordNet synsets page Since S allowed return hypernym item considered speciﬁc answer When comparing systems S1 S2 item x S1 speciﬁc S2 score S1 x score S2 x We calculate types conﬁguration depending score S1 x equal greater score S2 x denote conﬁgurations S1 S2 S1 S2 S1 S2 respectively More formally S1 cid14 S2 D score S1 x cid14 score S2 x D cid14 item page category dataset D Table 6 shows results resources page category taxonomies MultiWiBi consistently provides considerably speciﬁc T Flati et al Artiﬁcial Intelligence 241 2016 66102 89 Table 6 Speciﬁcity comparison MultiW Bi cid14 S D scoreMultiW Bi x cid14 score S x D cid14 MultiWiBi X Dataset Pages System X WikiNet DBpedia MENTA LHD 10 LHD 20 YAGO3 MultiWiBi X 2151 2999 2047 4668 2568 000 MultiWiBi X 7536 5919 5424 4641 6441 500 Categories WikiNet WikiTax YAGO MENTA 4200 4231 951 1062 4532 4025 8605 7861 313 1082 2529 691 991 9500 1268 1743 444 1078 hypernyms resource middle column quantitatively corroborating qualitative insight based example inspection To investigate results systems heterogeneous hypernyms considered items dataset given output Wikipedia category recalculated speciﬁcity systems MENTA YAGO3 WikiNet LHD 1012 Results MENTA better performance speciﬁc MultiWiBi 44 times WikiNet improves scores remains speciﬁc MultiWiBi 52 times The happens LHD 10 speciﬁc MultiWiBi 14 times YAGO3 instead remains speciﬁc MultiWiBi 90 time This item dataset speciﬁc answer YAGO3 time category Overall experiment demonstrates MultiWiBi speciﬁc systems categories ﬁnergrained pages 11 Projecting bitaxonomy We method obtaining bitaxonomy language English The general idea combining bitaxonomy obtained English exact methodology outlined Section 3 order obtain bitaxonomy second arbitrary language To crucially leverage important element characterizing Wikipedia interlanguage links By linking concepts Wikipedia language equivalent concepts language present interlanguage links play key role allow MultiWiBi approaches taxonomic information available languages We inform reader advance MultiWiBi goes direct integration interlanguage links means innovative approach able cover Wikipedia items English counterpart Interlanguage links projection rule Interlanguage links links page Wikipedia language equiv alent page language For example Irish Wikipedia page Ireland titled Éire English Wikipedia page Ireland link Irish vice versa13 Thanks interlanguage links possible align pages contained English Wikipedia pages language preserving original meaning target language Notably interlanguage links present categories Wikipedias different languages This kind link paves way simple effective mechanism enables project hypernymy informa tion coming language language We mechanism projection rule exploit rule project bitaxonomies languages Simply means interlanguage links rule checks given Wikipedia item source language page category hypernym exist target language More formally projection rule deﬁned follows X E isa Y E X E X F Y E Y F X F isa Y F X E Y E T E X F Y F T F Projection rule According rule given English language E arbitrary language F cid18 E know English page X E taxonomy T E hypernym X E isa Y E ii English page equivalent page X F language F X E X F iii English hypernym equivalent language F Y E Y F safely infer valid hypernym foreign page X F isa Y F This idea depicted Fig 14 example We English page Subapical consonant Consonant hypernym furthermore know corresponding Italian equivalents Consonante subapicale Consonante respectively given facts derive fact isa relation holds corresponding Italian Wikipedia pages Consonante subapicale isa Consonante14 We draw projection rule basically occasions projecting English bitaxonomy 12 LHD 20 DBpedia categories hypernym pages recalculate results 13 http en wikipedia org wiki Help Interlanguage _links 14 The projection rule despite correct principle hold practice It happen fact interlanguage links preserve meaning languages align exactly concept speciﬁc types snow represented 90 T Flati et al Artiﬁcial Intelligence 241 2016 66102 Fig 14 Example application projection rule The dashed edge Italian Wikipedia right represents new isa information inferred English counterpart left Fig 15 Relationship English Wikipedia versions languages Section 112 ii building multilingual gold standard enable fair comparison languages Section 12 A limitation interlanguage links As seen Fig 15 English Wikipedia overlaps Wikipedias languages certain extent For example 65 Italian pages equivalent English With regard English Wikipedias languages contain additional concepts typical particular culture exist language Italian page Castagnole dolce typical Italian sweet despite culturespeciﬁc represent cultures concept French page Teatro del Giglio famous Italian theatre exist English written From set pages WEE pages pages Without English Equivalent Therefore procedure relies interlanguage links producing multilingual taxonomy major drawback application limited pages equivalent English Going interlanguage links We present innovative approach overcome limitation provide hypernyms pages corresponding page English Wikipedia Our method general applied version language Wikipedia having input respective XML Wikipedia dump algorithmic procedures presented bound language whatsoever However convenience present discuss evaluate bitaxonomies languages French FR Italian IT Spanish ES details Section 12 In order obtain bitaxonomy language English forward mechanism compensates lack syntactic parser language syntactic step cf Section 41 proceed steps 1 Construction Translation Table TT provide mechanism build translation table large number lemmas contained Wikipedia 2 Extraction multilingual hypernym lemmas exploit translation table built previous step associate Wikipedia page language hypernym lemma 3 Application WiBi apply exactly procedure hypernym lemma disambiguation bitaxonomy algorithm bitaxonomy reﬁnement presented English case cf Sections 47 Wikipedias translated general snow ﬁnegrained distinction Thus order evaluate general Wikipedia quality preserved languages means projection rule randomly sampled 500 pages English Wikipedia presented interlanguage link Italian evaluated correctness links We 2 cases 0004 total equivalence aligned concepts hold Note wrong cases include alignments completely incorrect example English page Mythological hybrid linked Italian page Cecaelia particular mythological hybrid T Flati et al Artiﬁcial Intelligence 241 2016 66102 91 Table 7 Excerpt EnglishItalian translation table numbers indicate translation conﬁdence English lemma plane car key Translations piano_cartesiano020 piano015 pialla004 aeroplano003 aereo0023 piano_astrale002 automobile033 autovettura011 automobili005 auto002 autovetture001 vettura001 chiave037 chiavi003 chiave_crittograﬁca0001 chiave_segreta00005 Fig 16 Paths connecting surface anchor pianta Italian surface anchor plant English 111 Construction translation tables In phase starting English Wikipedia build Translation Table TT arbitrary Wikipedia language A translation table seen sort bilingual dictionary words source language translated words target language In contrast standard bilingual dictionaries translation tables contain explicit probabilities associated translations given lemma An excerpt Italian translation table obtained result step shown Table 7 Here ambiguous English lemma plane translated Italian piano cartesiano x y plane probability 020 piano metaphoric sense plane probability 015 pialla carpenters plane probability 004 aeroplano airplane probability 003 cid3 cid3 cid3 cid3 p language L In order build Translation Table TT given language consider linked tokens Wikipedia More formally TT language L contains translation information English lemma l Wikipedia contains linked occurrence l page p ii p equivalent page p linked foreign term l For instance Italian Translation Table contains translations lemma plant cf Fig 16 contain translations lemma saucepan linked page Saucepan redirection Italian equivalent The input procedure word lE source language E output probability distribution P lE words target language F We set problem ﬁnding suitable translations given word exploiting hand interlanguage links provided Wikipedia hand association Wikipedia pages associated textual anchors occurring Wikipedia Fig 16 shows means example The data left ﬁgure belong English Wikipedia data right belong Italian Wikipedia Edges surface form page represent fact linked numbers report times link occurs Wikipedia The English lemma plant left example linked 10634 times Wikipedia page Plant 30 times Factory The pages linked anchor represent meanings given surface form different contexts A similar conﬁguration seen right ﬁgure Italian surface forms linked corresponding meanings Note general anchor link different meanings plant pointing Plant Factory given page linked anchors Italian page Fabbrica pointed fabbrica stabilimento Finally interlanguage links shown undirected edges linking sides ﬁgure example English page Plant aligned Italian Plantae Factory Fabbrica Our hunch network exploited derive translation probabilities Starting given English lemma fact possible reach translations language following paths join sides For example order infer pianta valid translation plant suﬃcient follow graph pattern plant Plant Plantae pianta Each path exactly edges represent respectively association source anchor meanings linked ii interlanguage link source target meanings iii association target meaning target anchor By calculating paths pair anchors source target anchors obtain possible 92 T Flati et al Artiﬁcial Intelligence 241 2016 66102 Table 8 Top 10 languages term extracted lemmas Language DE FR IT ES JA NL RU PL PT SV extracted lemmas 414810 381845 307293 265629 246455 223528 206213 195017 188094 165207 Average number translations 236 199 208 215 164 150 321 291 181 159 translations Note general single path anchors instance ambiguous anchors share senses languages necessary account paths link source anchor language anchor language We ready formally deﬁne probabilities provided translation table Given lemma lE source language E deﬁne probability lemma l F target language F translation lE P l F lE 1 Z cid2 p E O lE p F O l F P p E lE P p F p E P l F p F P p E lE clE p E O lE clE p cid3 E cid3 p cid3 E cid4 P p F p E P l F p F cid3 1 exists interlanguage link p E p F 0 cl F p F Ip F cl p F cid3 F l cid3 F 1 2 3 4 Z normalization constant O l X denotes set pages linked l X language X Ip X denotes set surface forms pointing p X language X cl X p X count times l X points p X language X Equation 1 probability paths going lE ending l F Each terms sum represents probability single path terms probability having lE linking p E ﬁrst term P p E lE Equation 2 ii probability having p E aligned p F second term P p F p E Equation 3 iii probability having p F linked lemma l F language term P l F p F Equation 4 For example given term lE plant probability P p E Plant lE plant 99 probability P p E Factory lE plant 001 probability P p E Plant person lE plant 00023 Equation 1 case lE plant l F pianta probability English surface form plant translates Italian pianta P piantaI T plant E N 1 Z cid2 p E O plant E N p F O piantaI T P p E plant E N P p I p E P piantaI T p I The set O plant E N includes example Plant Factory Flowering plant The path nonzero factors plant Plant Plantae pianta Since P Plant plant 99 P PlantaePlant 1 P pianta Plantae 38 overall product P pianta plant 1 99 1 38 37 In conclusion result systematic application technique obtain TT Wikipedia lan guage Each TT associate hypernym lemmas Wikipedia pages particular target language explained subsection 10015 1111 TT statistics We report statistics TT tables obtained Since method applicable language report statistics languages evaluation available As seen Table 8 German language highest number extracted lemmas average 236 translations given lemma We calculated score distribution languages evaluated paper Italian French Spanish We grouped scores buckets 001 01 02 09 1 plotted distribution obtained Fig 17 On average 2955 translations score 09 1 interval 4339 translations score 001 interval scores 0109 equally divided remaining translations T Flati et al Artiﬁcial Intelligence 241 2016 66102 93 112 Extraction multilingual hypernym lemmas Fig 17 Score distribution Italian French Spanish translations We exploit Translation Tables conjunction interlanguage links provide hypernym lemmas page arbitrary Wikipedia language The assignment hypernym lemmas based strategies exploit different sources information interlanguage links Wikipedia languages ii TT local context given page textual deﬁnition categories iii context provided sisters given page basically distribution hypernym lemmas sister pages iv global features Wikipedia hypernym lemmas discovered point Wikipedia pages These strategies applied order presentation cascade order Exploiting interlanguage links PROJECTED strategy The ﬁrst heuristic exploits interlanguage links means application projection rule The hypernym lemma assigned page target language title lemma projected hypernym page Thanks heuristic example Spanish Wikipedia page Madrid assigned hypernym lemma ciudad English Wikipedia page Madrid aligned Spanish Madrid City hypernym The turn aligned Ciudad title lemma Ciudad ciudad assigned Spanish starting page However note heuristic cover concepts encoded English Wikipedia covered instead subsequent strategies Exploiting translation tables local context TT strategy This strategy draws TT presented Section 111 represents ﬁrst effort automatically translate hypernym lemma associated English page equiv alent given language At step local features exploited pages textual deﬁnition titles categories Starting English hypernym lemma lE heuristic considers decreasing order probability translations lE checks contained deﬁnition p F category titles p F For instance hypernym lemma Italian page Karl Popper ﬁlosofo English Karl Popper philosopher hypernym lemma heuristic considers translations including ﬁlosofo ﬁlosoﬁa ﬁlosoﬁ ﬁlosofa Given Italian deﬁnition Karl Popper Popper è anche considerato ﬁlosofo politico di statura considerevole difensore della democrazia e del liberalismo contains translation ﬁlosofo promoted hypernym lemma page Exploiting context provided sister pages SISTER strategy In order cover pages language equivalent English designed heuristic draws sister pages given page ex ploits distribution hypernym lemmas discovered sister pages The strategy considers decreasing importance distribution hypernym lemmas p F s sisters assigns p F frequent hypernym lemma contained deﬁnition p F categories p F For example heuristic Wikipedia French page Yahoo Messenger assigned hypernym lemma logiciel contained following categories Logiciel propriétaire Logiciel messagerie instantanée Logiciel pour Mac OS Logiciel pour Unix This strategy provides added values ﬁrst exploits sister pages pages equivalent English covered For example strategy succeeds identifying actrice hypernym lemma French page Stéphanie Reynaud page available French The added value exploits features mere textual deﬁnition page able extract suitable hypernyms pages deﬁnition contain hypernym lemma contains lemma speciﬁc expected deﬁnition page Platinum Tower El Platinum Tower es una lujosa ediﬁcación 94 T Flati et al Artiﬁcial Intelligence 241 2016 66102 lemma contained ediﬁcación speciﬁc expected rascacielos instead thanks SISTER strategy Exploiting global features FIDF strategy There nonnegligible fraction Wikipedia WEE pages early stage development suffer lack content For example 30 Italian WEE pages lack Wikipedia category 25 deﬁnition Note ﬁrst strategy applied class pages English equivalent The TT SISTER strategies instead applicable effective translation provided TT contained textual deﬁnition target page p F applicable pages categories related hypernym lemma discovered bring sister pages valid hypernym lemma For example SISTER strategy useful Spanish page Hemisferio norte Northern Hemisphere English category Geografía Geography English To overcome limitation introduce measure called fidf resolves problem considering global infor mation This heuristic takes account possible content available given page considering pages textual deﬁnition present ii categories present iii words title appearing paren theses word ﬁume title Ticino ﬁume Given context possible ngrams collected n 5 ngram maximises following formula promoted hypernym lemma scorew f w idf w 1 f w frequency ngram w hypernym lemma obtained application previous strategies Wikipedia idf w inverse deﬁnition frequency logarithm inverse ratio Wikipedia deﬁnitions containing w The prefers ngrams common hypernym lemmas Wikipedia lemma taxonomy built far favours speciﬁc ngrams Italian brano musicale idf 2761 4298 For instance consider Italian page Cercami Renato Zero famous song vs brano idf Italian singer textual deﬁnition Cercami è famoso brano di Renato Zero secondo singolo estratto dallalbum Amore dopo amore del 1998 The ngrams extracted page include Renato Zero Cercami brano famoso brano secondo Among assigned hypernyms Italian taxonomy brano 98 times fbrano 98 singolo f singolo 85 secondo f secondo 16 zero f zero 7 The corresponding idf 1 4298 brano 1 660 zero brano ngram ﬁnally preferred score 98 1 9501 singolo 4298 0023 candidate promoted hypernym lemma Cercami Renato Zero Finally pages having equivalent English heuristics succeeded assigning hypernym lemma backoff MFT Most Frequent Translation l F lE For instance lemma assigned Spanish page Frederick Lugard explorador translation highest probability English hypernym lemma explorer 15667 secondo 1 1 1 As result application strategies nonEnglish Wikipedia able associate hypernym lemma totality foreign pages 113 Application WiBi multilingual setting Now hypernym lemmas extracted page speciﬁc nonEnglish language aim disambiguate hypernym lemmas build page taxonomy sense level Notably situation English case right application semantic step Section 42 We reapply hypernym linkers English page taxonomy cf Section 421 exception distributional linker assumes availability PoStagger target language Thus English case cf Section 6 starting resulting page taxonomy build bitaxonomy nonEnglish language taxonomy page taxonomy category Wikipedia applying iterative algorithm presented Section 61 In order assess impact interlanguage links ﬁnal category taxonomy perform kinds experiment yielding different category taxonomies ﬁrst experiment initialize category taxonomy exactly manner explained Section 62 plain category taxonomy second experiment ﬁrst apply projection rule hypernymy edges contained English category taxonomy perform initialization performed obtain plain category taxonomy projected category taxonomy Finally exactly Section 7 apply reﬁnement step nonEnglish bitaxonomy obtained result application bitaxonomy algorithm 114 Statistics multilingual setting We present main statistics multilingual bitaxonomies obtained languages lemma sense level page taxonomies types category taxonomies considered T Flati et al Artiﬁcial Intelligence 241 2016 66102 95 Fig 18 Multilingual lemma taxonomy coverage different strategies Fig 19 Distribution multilingual disambiguated hypernyms Hypernym lemmas Fig 18 shows coverage heuristics considered language French Italian Spanish As seen coverage increases consistently heuristics applied approximately coverage lemma level achieved language The trend similar languages attribute phenomenon similar distribution hypernym lemmas editions Wikipedia Hypernym links Fig 19 shows distribution hypernym lemmas disambiguated linkers In contrast case English pies include hand hypernym pages coming application projection rule hand display information distributional linker Apart projected edges distribution hypernyms linker varies depending language considered This hold projected isa information seen overlap English languages change signiﬁcantly expect information transferred languages As regards linkers isa edges returned category linker represent substantial fraction total In terms number links impact monosemous linker comparable distributional linker English case multiword linker proves marginally contributing Overall extracted 1246524 isa relations French 825465 Italian 895301 Spanish providing hypernym pages respectively 1116330 pages 1221845 91 742796 pages 926129 80 809410 pages 908820 89 Bitaxonomies In Fig 20 coverage trend categories applying iterative algorithm plain blue lower line projected green upper line category taxonomy Note similarly case English coverage progressively increases iteration 30 ﬁnally reaches plateau Thanks application category reﬁnement step gap respect total greatly reduced reaching approximately coverage Wikipedia categories As seen ﬁgure xlabel START projected category taxonomies categories covered languages Interestingly bitaxonomy algorithm category reﬁnement step applied lines reconcile approximately point meaning starting projected category taxonomy necessarily result signiﬁcantly greater coverage However Section 124 projected taxonomy leads generally better performance overall Analysis page taxonomies languages After running MultiWiBi nonEnglish edition Wikipedia obtain augmented bitaxonomy overlaps concepts contained English Wikipedia certain extent differs signiﬁcantly We distinguished types taxonomised pages 96 T Flati et al Artiﬁcial Intelligence 241 2016 66102 Fig 20 Multilingual category taxonomy coverage iterations For interpretation colours ﬁgure reader referred web version article Pages hypernyms aligned Pages corresponding page English hypernyms coincide English hypernym aligned languages For example Italian page Sciroppo dacero aligned English Maple syrup Italian page Sciroppo hypernym aligned turn English Syrup Pages hypernyms semantically aligned Pages corresponding page English concept expressed hypernyms differs respect represented equivalent concept English This hap pens hypernym English redirection possible project different speciﬁcity An example ﬁrst case French page Arnolfo di Cambio hypernym Sculpteur French hypernym Sculptor English aligned languages redirections hypernyms returned languages expressing exactly concept considered different surface level equivalence established Wikipedia far For second case French page Richard II dAngleterre Monarque hypernym King England English note King England equivalent French Monarque aligns Monarch English WEE pages hypernym Pages corresponding page English hypernyms This class extreme importance hypernyms belonging class unique sense information derived English means simple projection rule The pages included class usually discussion Section 11 culturespeciﬁc ﬁnd Italian Wikipedia page San Gimignano vino famous Italian wine English counterpart taxonomised Vino Wine Other Finally fraction pages taxonomised example Italian E penso te album English counterpart MultiWiBi succeed taxonomising hypernym lemma extraction step managed associate lemma album In Fig 21 plot distribution types page different languages roughly 60 taxonomised pages lexicalized English orange blue slices set distinguish pages hyper nyms aligned English orange sector ii pages hypernyms semantically aligned blue sector As regards WEE pages instead MultiWiBi managed disambiguate hypernym lemmas 401k 213k 274k pages French Italian Spanish represent 86 66 80 respectively total number WEE pages languages This highly signiﬁcant piece information quantiﬁes potentially culturespeciﬁc knowledge MultiWiBi able extract Just reader clearer grasp groundbreaking effect achieved covering type concept Table 9 report sample list WEE pages French Italian Spanish MultiWiBi suitable hypernyms Even contained nonEnglish Wikipedias characteristic lexicalized English represent additional concepts MultiWiBi succeeded taxonomizing 12 Multilingual evaluation We present experimental setup multilingual experiments report results multilingual bitaxonomies evaluated measures described Section 5 We creation gold standards Section 121 present discuss results lemma level Section 122 sense level Sections 123 124 page category sides respectively T Flati et al Artiﬁcial Intelligence 241 2016 66102 97 Fig 21 Characterization pages hypernyms languages Table 9 Example culturespeciﬁc concepts French Page Langhe Chardonnay Diplomate pâtisserie Savarin Le Brebiou Fromages en Provinois Chécy fromage Hypernym Vin Pâtisserie Pâtisserie Fromage Fromage Fromage français Italian Page Trenette al pesto Lasagne gastronomia Maltagliati Piemonte Brachetto Nebbione Zagarolo vino Hypernym Pasta Pasta Pasta Vino Vino Vino Spanish Page Crema catalana Baldomero Fernández Moreno Luis García Montero El Rey canción Cantares canción J M Serrat Mediterráneo canción Hypernym Postre Poeta Poeta Canción Canción Canción 121 Experimental setup In order guarantee comparability results languages decided start datasets presented Section 5 For language created dataset types page Projected pages dataset obtained automatically projecting English dataset manually ﬁxing projection errors Since pages aligned language editions Wikipedia projection coverage obtained After projection obtained 256 pages French 218 Italian 205 Spanish WEE pages second dataset obtained sampling certain number Wikipedia pages English equivalent This number chosen order preserve balance concepts expressed languages set P E P F concepts existing language set P F P E From datasets called D W E E dataset WEE pages language F F For building datasets lemma level lack interlanguage links lemmas manually provided hypernym lemmas page dataset exactly English At sense level instead decided double size page dataset English equivalent Italian Italian chosen problematic language languages considered having illformed deﬁnitions lack explicit hypernym Thus Italian dataset sense level numbered 436 items pages English equivalent 232 WEE pages We computed interannotator agreement Cohens kappa coeﬃcient Spanish French datasets scoring 0825 0811 respectively 122 Results multilingual hypernym lemmas In section provide experimental results quality taxonomies lemma level In particular compare quality automatic translation procedure described Section 112 toolbased syntactic lemma extraction similarly English setting Section 41 ii analyse discuss results considering pages English equivalents Projected pages WEE pages respectively As seen Table 10 MultiWiBi achieves good results As regards projected datasets consistently 99 pages lemma means nearly pages target languages covered lemma level Also quality high Italian precision recall 70 languages high 80 85 Lower performances Italian pages categories associated illformed textual deﬁnitions lacking explicit hypernym lemma Flavio Crespi Wikipedia categories deﬁned means textual deﬁnition Pratica larrampicata falesia e ha gareggiato nelle competizioni di diﬃcoltà hypernym lemma arrampicatore totally implicit This means strate 98 T Flati et al Artiﬁcial Intelligence 241 2016 66102 Table 10 Multilingual lemma taxonomy quality Language FR Setting Projected pages WEE pages IT Projected pages WEE pages ES Projected pages WEE pages Approach MultiWiBi Syntactic Syntactic sisters MultiWiBi Syntactic Syntactic sisters MultiWiBi Syntactic Syntactic sisters MultiWiBi Syntactic Syntactic sisters MultiWiBi Syntactic Syntactic sisters MultiWiBi Syntactic Syntactic sisters P 8176 8241 7869 7667 9068 8690 7646 5877 8395 7000 6757 7455 7337 7022 R 8242 6953 7500 7419 6903 8129 7798 5776 8439 6537 6878 6667 5285 6260 C 9961 8438 9531 9677 7613 9355 9908 9828 9951 9024 9854 8943 7073 8780 items 256 155 218 116 205 123 gies presented Section 112 managed translate possible extract meaningful hypernym lemmas considered pages As regards WEE datasets witness general decrease performance Italian achieves performances 60 French Spanish achieve precision 75 recall 66 74 Now English version languagespeciﬁc syntactic parser extract hypernym lemmas Wikipedia pages language To test lemma taxonomy actually beneﬁts syntactic parser speciﬁc version Wikipedia syntactically extracted terms involved dependency relation corresponding English copula Since names dependency relations change languages label mappings provided manually French instance identiﬁed ast relation Malt syntactic parser15 Spanish att relation output FreeLing syntactic parser16 As English possible employed list class hypernym lemmas cf Section 41 manually translated English variety translated variedad Spanish variété French exploited relations corresponding English conj_ conj_or relations coord French Spanish Unfortunately possible ﬁnd syntactic parser Italian Rows Syntactic Syntactic sisters Table 10 report performances vanilla sister syntactic settings cf Section 41 Fig 7a Similarly English case including context coming sister pages greatly boosts coverage languages improving recall time slight detriment precision Except French WEE pages syntactic parser improve MultiWiBi performance scenarios MultiWiBi yields comparable better results syntactic parser quality measures In conclusion automatic inference hypernym lemmas English taxonomy provides better hypernym translations overall monolingual approach signiﬁcant increase precision recall compared setting syntactic parser target language exploited This phenomenon likely factors hand heuristics project taxonomical information exploit context available syntactic parsers monolingual level hand syntactic parsers mature English Stanford counterpart need extensive training data input Translation table evaluation In order assess quality translation table decided compare Moses statistical machine translation tool trained Europarl parallel corpus17 English Italian We built new version Italian lemma taxonomy Mosess translation table candidate hypernym lemma repository evaluated considering hypernyms assigned heuristics exploit translation table The taxonomy built TT achieves 7123 precision 2798 recall coverage 3853 TT obtained Moses sults performances somewhat lower 6136 precision 2523 recall 4037 coverage While acknowledge Moses trained larger parallel corpora issues domain speciﬁcity law institutional topics lack coverage areas knowledge need dealt Instead approach depend availability parallel corpora generally missing Wikipedia language pair performs equally domains 15 http wwwmaltparserorg 16 http nlp lsi upc edu freeling 17 http wwwstatmt org europarl v7 iten tgz T Flati et al Artiﬁcial Intelligence 241 2016 66102 99 Table 11 Multilingual page taxonomy evaluation Language FR IT ES Resource MultiWiBi MENTA DBpedia YAGO3 MultiWiBi MENTA DBpedia YAGO3 MultiWiBi MENTA DBpedia YAGO3 P 8451 8137 9408 9400 8006 7973 9847 9238 8698 8102 7677 8586 R 8086 4883 2852 8086 7936 5321 5917 8349 8195 4293 3707 7854 C 9414 5977 2969 8086 9633 6674 6009 8349 9366 5268 4829 7854 items 256 436 205 denotes statistically signiﬁcant difference χ 2 test p 001 MultiWiBi daggered resource Language FR Table 12 Multilingual WEE page taxonomy evaluation Setting MultiWiBi MENTA DBpedia YAGO3 7639 8571 10000 8933 P IT ES MultiWiBi MENTA DBpedia YAGO3 MultiWiBi MENTA DBpedia YAGO3 5988 8791 9908 9840 6947 7619 6613 9133 R 7097 3484 1677 5871 4440 3448 4526 2241 5366 2602 3333 3577 C 9290 4065 1677 5871 7414 3922 4569 2241 7724 3415 5041 3577 items 155 232 123 denotes statistically signiﬁcant difference χ 2 test p 001 MultiWiBi daggered resource 123 Results multilingual page taxonomies We evaluation hypernym lemmas evaluation associated pages Results multi lingual page taxonomies presented Table 11 languages compared alternative approaches DBpedia YAGO3 MENTA LHD excluded comparison available languages WikiNet excluded average coverage normal datasets D W E E datasets 4951 546 respectively F As seen performances high languages projected datasets considered certain extent comparable results obtained English For languages observe 85 precision 80 recall 93 coverage This result expected considering datasets projected version English equivalents Nevertheless needs borne mind application hypernym linkers hypernyms MultiWiBi English language differ considerably Section 114 causing relatively small differences evaluation results YAGO3 performs precision high coverage lower MultiWiBi Furthermore YAGO3s high recall fact generic hypernym yagoGeoEntity owlThing given output page evaluated correct independently generality Section 104 assessment YAGO3s degree speciﬁcity Other systems instead seriously affected low coverage achieving precision comparable higher MultiWiBi exhibit recall 60 We results D W E E datasets Table 12 We observe possible obtain performance comparable English First point results vary depending target language example French exhibits good results achieving 76 precision 71 recall Italian Spanish lower coverage French lower performance general Spanish despite affected low recall stands high 6947 precision F These results promising MultiWiBi ﬁrst resource providing information concepts English equivalent As seen table fact alternative approaches suffer critical coverage problems Even YAGO3 performed pages English equivalent lower recall coverage MultiWiBi In addition approaches answers correct general 100 T Flati et al Artiﬁcial Intelligence 241 2016 66102 Table 13 Multilingual category taxonomy evaluation Resource MultiWiBi plain MultiWiBi projected MENTA Language FR IT MultiWiBi plain MultiWiBi projected MENTA P 7807 8071 8261 8970 8354 7713 R 7417 8071 5500 8900 8354 2540 C 9500 10000 6571 9920 10000 3280 items 140 500 ES MultiWiBi plain MultiWiBi projected MENTA 8475 8443 8046 denotes statistically signiﬁcant difference χ 2 test p 001 MultiWiBi daggered resource 8197 8443 5420 9672 10000 6641 131 DBpedia returning http dbpedia org ontology Monument instead Église édiﬁce uninformative MENTA returning 1970 births instead Écrivain français MultiWiBi represents ﬁrst approach manages extract languagespeciﬁc information automatically Wikipedia performances dependent quality individual Wikipedias 124 Results multilingual category taxonomies In Table 13 report performance evaluating plain projected MultiWiBi category taxonomy gold standard Table 13 The alternative resource compared MENTA proved closest terms performance English experimental setup Note YAGO YAGO3 WikiTaxonomy compared multilingual version resources exists Section 101 We projecting category taxonomy English greatly beneﬁts category taxonomies languages First means automatic projection achieved coverage category dataset Second precision Italian Spanish measures exhibit remarkable increase ranging 127 583 percentage points 13 Conclusions In paper presented MultiWiBi new approach constructing bitaxonomies Wikipedia arbitrary languages bitaxonomy taxonomies establish isa relations Wikipedia pages categories respectively For language approach mainly divided phases The ﬁrst phase aims building taxonomy page Wikipedia second phase triggers iterative algorithm incrementally populates taxonomy category Wikipedia exploiting interlanguage links existing sides phase aimed solving problems affecting structure Wikipedia categories output polished category taxonomy Our contribution threefold First taxonomies bitaxonomy aligned pages aligned categories bitaxonomies aligned languages concepts English aligned corresponding concepts languages Second marked contrast approaches work crucially pivots English edition Wikipedia inducing bitaxonomies languages relying external resource like WordNet manual upper ontologies parallel corpus tool Third experiments bitaxonomies characterized higher accuracy speciﬁcity alternatives making MultiWiBi best set taxonomies literature time writing We integrated MultiWiBi BabelNet18 thanks fullﬂedged taxonomy lexicographic ency clopedic knowledge available In order maintain high precision integrated edges MultiWiBi taxonomies different languages agree We plan exploit MultiWiBi applications multilingual distributional semantics 6263 question answering Acknowledgements The authors gratefully acknowledge support ERC Starting Grant MultiJEDI No 259234 We thank Luca Telesca implementation WikiTaxonomy Jim McManus comments manuscript 18 http babelnet org References T Flati et al Artiﬁcial Intelligence 241 2016 66102 101 1 T Mitchell Reading Web breakthrough goal AI AI Mag 2005 15171519 2 S Mirkin I Dagan E Shnarch Evaluating inferential utility lexicalsemantic resources Proceedings 12th Conference European Chapter Association Computational Linguistics EACL 09 Athens Greece 2009 pp 558566 3 H Poon J Christensen P Domingos O Etzioni R Hoffmann C Kiddon T Lin X Ling Mausam A Ritter S Schoenmackers S Soderland D Weld F Wu C Zhang Machine reading University Washington Proceedings 1st International Workshop Formalisms Methodology Learning Reading Conjunction NAACLHLT 2010 Los Angeles California USA 2010 pp 8795 4 A Singhal Introducing knowledge graph things strings Tech rep Oﬃcial Blog Google 2012 Retrieved May 18 2012 5 DA Ferrucci Introduction This Watson IBM J Res Dev 56 3 2012 1 6 C Fellbaum Ed WordNet An Electronic Database MIT Press Cambridge MA 1998 7 P Mcnamee R Snow P Schone Learning named entity hyponyms question answering Proceedings Third International Joint Conference Natural Language Processing 2008 pp 799804 8 D Moldovan A Novischi Lexical chains question answering Proceedings 19th International Conference Computational Linguistics COLING 02 Taipei Taiwan 24 August1 September 2002 2002 pp 17 9 H Cui MY Kan TS Chua Soft pattern matching models deﬁnitional question answering ACM Trans Inf Syst 25 2 2007 130 10 D Ferrucci E Brown J ChuCarroll J Fan D Gondek AA Kalyanpur A Lally JW Murdock E Nyberg J Prager et al Building Watson overview deepqa project AI Mag 31 3 2010 5979 11 O Etzioni M Banko MJ Cafarella Machine reading Proc AAAI 2006 pp 15171519 12 T Lin O Etzioni et al Entity linking web scale Proceedings Joint Workshop Automatic Knowledge Base Construction WebScale Knowledge Extraction AKBCWEKEX 12 Association Computational Linguistics 2012 pp 8488 13 A Moro A Raganato R Navigli Entity linking meets word sense disambiguation uniﬁed approach Trans Assoc Comput Linguist 2 2014 231244 14 C Delli Bovi L Telesca R Navigli Largescale information extraction textual deﬁnitions deep syntactic semantic analysis Trans Assoc Comput Linguist 3 2015 529543 15 A Moro H Li S Krause F Xu R Navigli H Uszkoreit Semantic rule ﬁltering webscale relation extraction The Semantic Web ISWC 2013 Proceedings 12th International Semantic Web Conference Sydney NSW Australia October 2125 2013 Part I 2013 pp 347362 16 M Pennacchiotti P Pantel Ontologizing semantic relations Proceedings 21st International Conference Computational Linguistics 44th Annual Meeting Association Computational Linguistics COLING 06 Sydney Australia 1721 July 2006 2006 pp 793800 17 S Soderland B Mandhani Moving textual relations ontologized relations AAAI Spring Symposium Machine Reading AAAI 2007 pp 8590 18 G Sutcliffe M Suda A Teyssandier N Dellis G Melo Progress effective automated reasoning world knowledge FLAIRS Conference 19 M Pasca S Harabagiu The informative role Wordnet opendomain question answering Proceedings NAACL01 Workshop WordNet 2010 pp 110115 Other Lexical Resources 2001 pp 138143 20 R Navigli Word Sense Disambiguation survey ACM Comput Surv 41 2 2009 169 21 R Navigli A quick tour Word Sense Disambiguation induction related approaches M Bieliková G Friedrich G Gottlob S Katzenbeisser G Turán Eds SOFSEM 2012 Theory Practice Computer Science Lecture Notes Computer Science vol 7147 Springer Heidelberg 2012 pp 115129 22 O Medelyan D Milne C Legg IH Witten Mining meaning Wikipedia Int J HumComput Stud 67 9 2009 716754 23 EH Hovy R Navigli SP Ponzetto Collaboratively built semistructured content Artiﬁcial Intelligence story far Artif Intell 194 2013 227 24 M Banko MJ Cafarella S Soderland M Broadhead O Etzioni Open information extraction Web Proceedings 20th International Joint Conference Artiﬁcial Intelligence IJCAI 07 Hyderabad India 612 January 2007 2007 pp 26702676 25 A Fader S Soderland O Etzioni Identifying relations open information extraction Proceedings Conference Empirical Methods Natural Language Processing EMNLP 11 Edinburgh UK 2011 pp 15351545 26 A Moro R Navigli Integrating syntactic semantic analysis open Information extraction paradigm Proceedings 22nd International Joint Conference Artiﬁcial Intelligence IJCAI 13 Beijing China 2013 pp 21482154 27 A GómezPérez D ManzanoMacho et al A survey ontology learning methods techniques OntoWeb Deliverable D 1 5 2003 28 MA Hearst Automatic acquisition hyponyms large text corpora Proceedings 25th International Conference Computational Linguistics COLING 92 Nantes France 1992 pp 539545 29 SP Ponzetto M Strube Deriving large scale taxonomy Wikipedia Proceedings 22nd Conference Advancement Artiﬁcial Intelligence AAAI 07 Vancouver BC Canada 2226 July 2007 2007 pp 14401445 30 J Hoffart FM Suchanek K Berberich G Weikum YAGO2 spatially temporally enhanced knowledge base Wikipedia Artif Intell 194 31 V Nastase M Strube Transforming Wikipedia large scale multilingual concept network Artif Intell 194 2013 6285 32 G Melo G Weikum MENTA inducing multilingual taxonomies Wikipedia Proceedings 19th ACM International Conference Information Knowledge Management CIKM 10 New York NY USA 2010 pp 10991108 33 T Kliegr V Zeman M Dojchinovski Linked hypernyms datasetgeneration framework use cases 3rd Workshop Linked Data Linguistics Multilingual Knowledge Resources Natural Language Processing 2014 p 82 34 T Flati D Vannella T Pasini R Navigli Two bigger better Wikipedia bitaxonomy project Proceedings 52nd Annual Meeting Association Computational Linguistics ACL 2014 Association Computational Linguistics Baltimore Maryland 2014 pp 945955 35 R Navigli P Velardi Learning wordclass lattices deﬁnition hypernym extraction Proceedings 48th Annual Meeting Association Computational Linguistics ACL 2010 Association Computational Linguistics Uppsala Sweden 2010 pp 13181327 36 R Navigli SP Ponzetto BabelNet automatic construction evaluation application widecoverage multilingual semantic network Artif Intell 193 2012 217250 37 N Calzolari L Pecchia A Zampolli Working Italian machine dictionary semantic approach Proceedings 5th Conference Computational Linguistics COLING 73 Pisa Italy 1973 pp 4970 38 RA Amsler A taxonomy English nouns verbs Proceedings 19th Annual Meeting Association Computational Linguistics 39 N Calzolari Towards organization lexical deﬁnitions database structure Proceedings 9th Conference Computational Linguistics ACL 81 Stanford California USA 1981 pp 133138 COLING 82 Prague Czechoslovakia 1982 pp 6164 40 N Ide J Véronis Extracting knowledge bases machinereadable dictionaries wasted time Proceedings Workshop Knowledge Bases Knowledge Structures KBKS 93 Tokyo Japan 1993 pp 257266 41 Z Kozareva EH Hovy A semisupervised method learn construct taxonomies Web Proceedings Conference Empirical Methods Natural Language Processing EMNLP 10 Seattle WA USA 2010 pp 11101118 2013 2861 102 T Flati et al Artiﬁcial Intelligence 241 2016 66102 42 R Navigli P Velardi S Faralli A graphbased algorithm inducing lexical taxonomies scratch Proceedings 22nd International Joint Conference Artiﬁcial Intelligence Barcelona Spain 2011 pp 18721877 43 P Velardi S Faralli R Navigli OntoLearn reloaded graphbased algorithm taxonomy induction Comput Linguist 39 3 2013 665707 44 D Klein CD Manning Fast exact inference factored model natural language parsing Advances Neural Information Processing Systems vol 15 NIPS Vancouver British Columbia Canada 2003 pp 310 45 H Saggion Identifying deﬁnitions text collections question answering Proceedings 4th International Conference Language Resources Evaluation LREC 04 Lisbon Portugal 2628 May 2004 European Language Resources Association 2004 pp 19271930 46 M RuizCasado E Alfonseca P Castells Automatic assignment Wikipedia encyclopedic entries WordNet synsets Advances Web Intelligence Lecture Notes Computer Science vol 3528 Springer Verlag 2005 pp 380386 47 O Etzioni M Cafarella D Downey S Kok A Popescu T Shaked S Soderland DS Weld A Yates Webscale information extraction KnowItAll Proceedings 13th International Conference World Wide Web WWW 04 2004 pp 100110 48 O Etzioni M Cafarella D Downey AM Popescu T Shaked S Soderland DS Weld A Yates Unsupervised namedentity extraction web experimental study Artif Intell 165 1 2005 91134 49 S Blohm Using web reduce data sparseness patternbased information extraction Proceedings 11th European Conference Principles Practice Knowledge Discovery Databases PKDD Springer Warsaw Poland 2007 pp 1829 50 P Pantel D Ravichandran Automatically labeling semantic classes Proceedings Human Language Technology Conference North American Chapter Association Computational Linguistics NAACL HLT 13 Boston Massachusetts 27 May 2004 2004 pp 321328 51 R Snow D Jurafsky A Ng Semantic taxonomy induction heterogeneous evidence Proceedings 21st International Conference Computational Linguistics 44th Annual Meeting Association Computational Linguistics COLINGACL 06 2006 pp 801808 52 SP Ponzetto M Strube Taxonomy induction based collaboratively built knowledge repository Artif Intell 175 910 2011 17371756 53 FM Suchanek G Kasneci G Weikum YAGO large ontology Wikipedia WordNet J Web Semant 6 3 2008 203217 54 S Auer C Bizer G Kobilarov J Lehmann R Cyganiak Z Ive DBpedia nucleus web open data Proceedings 6th International Semantic Web Conference Joint 2nd Asian Semantic Web Conference ISWCASWC 2007 Busan Korea 2007 pp 722735 55 K Bollacker C Evans P Paritosh T Sturge J Taylor Freebase collaboratively created graph database structuring human knowledge Proceed ings International Conference Management Data SIGMOD 08 New York NY USA 2008 pp 12471250 56 V Nastase M Strube B Boerschinger C Zirn A Elghafari WikiNet large scale multilingual concept network Proceedings Seventh International Conference Language Resources Evaluation LREC10 Valletta Malta 2010 pp 10151022 57 A Sumida N Yoshinaga K Torisawa Boosting precision recall hyponymy relation acquisition hierarchical layouts Wikipedia LREC European Language Resources Association 2008 pp 24622469 58 MT Pilehvar R Navigli A robust approach aligning heterogeneous lexical resources Proceedings 52nd Annual Meeting Association Computational Linguistics Volume 1 Long Papers Association Computational Linguistics Baltimore Maryland 2014 pp 468478 59 E Niemann I Gurevych The peoples web meets linguistic knowledge automatic sense alignment Wikipedia Wordnet Proceedings Ninth International Conference Computational Semantics IWCS 11 Association Computational Linguistics Stroudsburg PA USA 2011 pp 205214 60 I Gurevych J EckleKohler S Hartmann M Matuschek CM Meyer C Wirth UBY largescale uniﬁed lexicalsemantic resource based LMF Proceedings 13th Conference European Chapter Association Computational Linguistics EACL 12 Stroudsburg PA USA 2012 pp 580590 61 MM Christian G Iryna To exhibit loiter multilingual sensedisambiguated wiktionary measuring verb similarity Proceedings 24th International Conference Computational Linguistics COLING 2012 vol 4 2012 pp 17631780 62 J CamachoCollados MT Pilehvar R Navigli Nasari novel approach semanticallyaware representation items Proceedings 2015 Conference North American Chapter Association Computational Linguistics Human Language Technologies Association Computa tional Linguistics Denver Colorado 2015 pp 567577 63 J CamachoCollados MT Pilehvar R Navigli Nasari integrating explicit knowledge corpus statistics multilingual representation concepts entities Artif Intell 240 2016 3664