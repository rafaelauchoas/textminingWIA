Artiﬁcial Intelligence 196 2013 2652 Contents lists available SciVerse ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Physical search problems probabilistic knowledge Noam Hazon a1 Yonatan Aumann b Sarit Kraus b David Sarne b Robotics Institute Carnegie Mellon University Pittsburgh PA USA b Department Computer Science BarIlan University Ramat Gan Israel r t c l e n f o b s t r c t Article history Received 31 August 2011 Received revised form 30 September 2012 Accepted 24 December 2012 Available online 3 January 2013 Keywords Graph search Economic search This paper considers problem agent team agents searching resource tangible good physical environment resource good possibly obtained locations The cost acquiring resource good given location uncertain priori agents observe true cost physically arriving location Sample applications include agents exploration patrol missions agent seeking ﬁnd best location deploy sensing equipment path The uniqueness settings cost observing new location determined distance current impacting consideration optimal search order Although model captures real world scenarios investigated far We analyze variants problem differing objective minimizing total expected cost maximizing success probability given initial budget minimizing budget necessary obtain given success probability For variant ﬁrst introduce analyze problem single agent providing polynomial solution problem proving NPcomplete We introduce fully polynomial time approximation scheme algorithm minimum budget variant In multiagent case analyze models managing resources shared private budget models We present polynomial algorithms work ﬁxed number agents shared private budget model For noncommunicating agents private budget model present polynomial algorithm suitable number agents We analyze difference homogeneous heterogeneous agents respect allotted resources respect capabilities Finally deﬁne problem environment selfinterested agents We ﬁnd Nash equilibrium polynomial time prove bound performance algorithms respect social welfare tight 2013 Elsevier BV All rights reserved 1 Introduction Frequently order successfully complete task agent need explore search environment choose different available options For example agent seeking purchase product Internet needs query electronic merchants order learn posted prices robot searching resource tangible good needs travel possible locations resource available learn conﬁguration available This paper extends earlier conference papers Aumann et al 2008 6 Hazon et al 2009 31 Corresponding author Email addresses noamhcscmuedu N Hazon aumanncsbiuacil Y Aumann saritcsbiuacil S Kraus sarnedcsbiuacil D Sarne 1 This work author BarIlan University 00043702 matter 2013 Elsevier BV All rights reserved httpdxdoiorg101016jartint201212003 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 27 diﬃculty obtaining In environments beneﬁt associated opportunity revealed observing The knowledge available agent prior observing opportunity probability associated possible value prospect While virtual environments exploration considered costless physical environments traveling observing typically entails cost Furthermore traveling new location increase decrease distance locations cost associated exploring unexplored locations changes For example consider Rover robot goal mining certain mineral Potential mining locations identiﬁed based satellite imaging location associated uncertainty diﬃculty mining In order assess battery power required mining speciﬁc location robot needs physically visit The robots battery mining mineral traveling potential location Consequently agents strategy environment associated search costs maximize overall beneﬁt resulting search process deﬁned value option eventually minus costs accumulated process merely ﬁnding best valued option In physical environments common use team agents single agent Extending single agent solution multiagent strategy require subdividing search space different agents However agents means communication wish distant assis tance For example Rover suﬃcient battery power mining given location useful travel site order determine exact mining cost robots necessary battery power In case scheduling robots travel times key carefully planned If agents fully cooperative selﬁsh behavior considered Each agents try minimize traveling costs achieving groups goal Finally agents different types different amounts resources For example Rover robots entering mission differing initial battery charges They differ capabilities like team Rovers speciﬁcally designed mining missions require battery power mining task This paper aims taking ﬁrst steps understanding characteristics physical search environments single multi agent cases developing eﬃcient exploration strategies like Our main focus case opportunities aligned path case perimeter patrol 601923 We note single multiagent coverage algorithms convert complex environment simple long path 522532 Furthermore problem general metric spaces NPcomplete tree graphs For exposition purposes remainder paper use classical procurement application goal search purchasing product value observed opportunity represents price Of course example general setting exploration physical environment discussion results paper relevant setting provided exploration fulﬁlling task consume type resource We consider variants problem differing objective The ﬁrst MinExpectedCost problem agent aims minimize expected total cost completing task The second MaxProbability considers agent given budget task exceed aims maximize probability complete task reach opportunity budget large successfully buy product In variant MinBudget agent required guarantee predeﬁned probability completing task aims minimize overall budget required achieve said success probability We consider multiagent extensions variants While ﬁrst variant ﬁts product procurement applications variants ﬁt applications robots engaged remote exploration operating limited battery power budget 11 Summary results We ﬁrst consider single agent case We prove general metric spaces problem variants NPhard Thus mentioned focus setting locations located path For setting provide poly nomial algorithms MinExpectedCost problem We problems MinBudget MaxProbability NPcomplete path Thus consider restrictions provide approximation scheme We problems polynomial number possible prices constant Even restriction problems NPcomplete tree graph For MinBudget problem provide FPTAS fullypolynomial timeapproximationscheme provides 1 cid2 approximation cid2 0 time O polyncid21 n size input For multiagent case ﬁrst analyze shared budget model resources costs shared agents We number agents ﬁxed singleagent algorithms extend kagents time bounds growing exponentially k Therefore computation agents strategies performed number agents relatively moderate common scenario physical environments agents cooperate exploration search If number agents input multiagent versions MinBudget MaxProbability NPcomplete path single price We investigate model private budgets agent initial budget We assume number possible prices bounded In case separately consider setting agents communicate setting For noncommunicating agents polynomial algorithm MaxProbability 28 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 Table 1 Summary results n input size m number points store locations d number different possible prices wp phone version MinExpectedCost ability purchase phone Section 13 d d 1 k number agents na problem deﬁned case need solution f polynomial function deﬁned Lemma 22 General metric spaces Trees Path Single price d prices General case 1 cid2 approximation k agents General case 1 kcid2 approximation Nocommunication k ﬁxed k parameter Withcommunication k ﬁxed k parameter Single agent MinExpectedCost NPhard na O d3m4 O d2m2 wp O d3m4 O d2m2 wp na MaxProbability NPcomplete NPcomplete O m O m2d em NPcomplete 2d 2d b Multiagent shared budget path MinExpectedCost O d2k12k m k 4k O d22k m k 2k wp MaxProbability 2kd 2kd O m2kd em NPcomplete na c Multiagent private budget path MinBudget NPcomplete NPcomplete O m O m2d em NPcomplete O ncid26 2d 2d MinBudget 2kd 2kd O m2kd em NPcomplete O ncid26k MaxProbability MinBudgetidentical MinBudgetdistinct O m3k2 O m3k2 O m3k2n O m3k2n cid2 cid2 m2kd f em 2d cid3 2kd k d k cid3 P O m2kd em NPcomplete 2d 2kd problem suitable number agents For MinBudget problem noncommunicating agents present polynomial algorithm case agents allotted identical resources problem NP hard general case number agents ﬁxed Next consider agents communicate assistance As noted case scheduling different agents moves carefully planned We present polynomial algorithms MaxProbability problem MinBudget problem work constant number agents nonpolynomial number agents constant We selfinterested agents setting agents seek obtain item tries minimize use private budget traveling We deﬁne games sequential game MinExpectedCostGame simultaneous game MinBudgetGame We number possible prices bounded number agents ﬁxed strategy maximizes social welfare polynomial time We MinBudgetGame strategy Nash equilibrium case MinExpectedCostGame We present polynomial algorithm guarantees ﬁnding strategy Nash equilibrium Furthermore upper bound algorithms performance prove tight Finally extend results case heterogeneous agents different capabilities discuss assumptions paper Table 1 presents summary results Empty entries represent open problems 12 Related work Models single agent search process prior probabilistic knowledge attracted attention searchers areas mainly economics operational research prompting reviews years 4042 These search models developed point total contribution referred search theory Probably famous problem ﬁeld secretary problem remarkably long list articles dedicated variations 22 extensive bibliography2 Nevertheless economicbased search mod els extensions years multiagent environments 35463648 assume cost associated observing given opportunity stationary change search process While permissive assumption facilitates analysis search models frequently capture real situation physical world illustrated Fig 1 Therefore paper assume cost associated observing given opportunity change search process The use changing search costs suggests optimal search strategy structure different traditional economic search models merely deciding terminate search agent needs integrate exploration sequence considerations decision process 2 While secretary problem classical optimalstopping online problem involve search costs goal maximize probability ﬁnding best candidate minimizing expected overall cost case N Hazon et al Artiﬁcial Intelligence 196 2013 2652 29 Fig 1 An example cost associated observing given opportunity change search process When agent located u3 cost observing prices u2 u5 5 9 respectively When agent moves u4 cost observing prices u2 u5 10 5 respectively Search changing search costs previously considered science domain contexts prizecollecting traveling salesman problems 9 orienteering problem 55 graph searching problem 39 In PrizeCollecting Traveling Salesman Problems PCTSP given graph nonnegative prize values associ ated node salesman needs pick subset nodes visit order minimize total distance traveled maximizing total prize collected Since tradeoff cost tour prize spans variants developed All variants PCTSP NPhard generalizations famous Traveling Salesman Problem TSP One variant PCTSP kTSP node prize goal minimize total distance traveled visiting k nodes Over years constantfactor approximations developed kTSP 52816829 The Orienteering Problem OP wellstudied variant PCTSP goal maximize total prize collected keeping distance traveled cer tain threshold Several stochastic variants OP considered Campbell et al 17 investigated Orienteering Problem Stochastic Travel Service times OPSTS Another stochastic variant OP Orienteering Problem Stochastic Proﬁts OPSP 34 These variants TSP OP related fundamentally differ model traveling budget prizes models distinct different currencies Thus travel budget affect prize collected node In work contrast traveling buying use resource battery power This fundamental difference best exempliﬁed considering situation path On path solving TSP PCTSP OP OPSP trivial problems consider remain NP totally trivial As methods developed solving PCTSP OP variants focus general metric spaces relevant problem focuses path metric In Graph Searching Problem GSP agent seeks single item resides node graph distri bution deﬁned probabilities ﬁnding item node graph The goal minimize expected cost MinExpectedCost problem The GSP shown strictly related classic wellstudied problem Minimum Latency Problem MLP 47 called traveling repairman problem 1 schoolbus driver problem 59 delivery man problem 2343 In problem agent supposed visit nodes graph way minimizes sum latencies nodes latency node distance traveled agent visiting node The minimum latency problem shown NPcomplete metric space induced tree 51 solved linear time underlying graph path 127 In operations research commu nity exact exponential time algorithms MLP 6123501441 Researchers evaluated heuristic approaches 5856 In science community large branch research dealing approximate solutions MLP For general metrics Blum et al 15 gave ﬁrst constant factor approximation This improved Goemans Kleinberg 30 later Chaudhuri et al 18 Koutsoupias et al 39 provided stant factor approximation unweighted case shortest path metric unweighted graph Arora Karakostas 4 gave quasipolynomial O n O log n time approximation scheme weighted trees points Rd The MLP generalized multiagent settings k repairmen Fakcharoenphol et al 2021 Koutsoupias et al 39 later Ausiello et al 7 showed extend results obtained MLP GSP For example cases approximation developed MLP applied GSP Extensions GSP scenarios item mobile character 2638 The GSP models fundamentally differ model GSP single item located graph needs single binary probability node In model item simultaneously available nodes different prices node distribution multiple prices economic search theory Additionally model traveling purchasing consume resource element lacking GSP model This paper tries bridge gap classical economic search theory mainly suitable virtual nondimensional worlds changing search cost constraint imposed operating physical multiagent environ ments From broad perspective search problems lay ﬁeld planning uncertainty Some important relevant models ﬁeld Markov Decision Process MDP 1245 Decentralized Markov Decision Process DEC 30 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 MDP 13 Stochastic Games 49 In models Stochastic Games general MDP restricted goal maximize expected cumulative reward ﬁnite inﬁnite number steps This objective MinExpectedCost problem use MDP formulation solve MinExpectedCost problem path Section 212 The problems consider concerned expected rewards MDP formulations variants inapplicable There ﬁelds AI general consider problems closely related problems One ﬁeld work path planning uncertain knowledge environment In settings agent reveals traversability edges reaching The Focused Dynamic A algorithm 53 popular heuristic search method repeatedly determines shortest path agents current position goal able replan quickly knowledge terrain changes Consequent alternatives D lite 37 DSA 54 able handle case goal changes time addition traversability edges Unlike model line work uncertainties values costs possible goal locations need considered Therefore D lite DSA algorithms solve problem D D Another related line work scheduling particular scheduling uncertainty considers similar types objectives 101124 Much research carried ﬁeld 33 survey considering problem optimal allocation resources activities time parameters uncertain Our problems seen scheduling problem assign agents visit different stores time However scheduling domain chosen plan affect way uncertain parameters processing time job length determined In case cost visiting store processing time probability buying probability distribution job length depends selected plan Moreover scheduling uncertainty problem formulations underlying deterministic problem NPhard research focus developing heuristics cope probabilistic version problem In case underlying deterministic problem prices known MinBudget MaxProbability deﬁned MinExpectedCost trivial solution In addition concentrate analyzing cases exact polynomial solution proven approximation guarantees distance optimal solution 13 Terminology deﬁnitions We provided set m points S u1 um represent locations item available stores distance function dis S S R determines travel costs locations3 We provided agents initial locations assumed WLOG loss generality stores products price store With single agent initial k location k agents provided vector initial locations u s In addition provided cost probability function pic stating probability cost obtaining item store c Let D set distinct prices nonzero probability d D We assume actual price store revealed agent reaches store Given inputs goal roughly obtain product minimal total cost including travel costs purchase price Since dealing probabilities rough goal interpreted different concrete formulations u 1 s 1 MinExpectedCost minimize expected cost obtaining product 2 MinBudget given success probability psucc minimize budget necessary guarantee obtaining product probability psucc 3 MaxProbability given total budget B maximize probability obtaining product In problems optimization problem entails determining strategy order visit different stores terminate search In MinBudget MaxProbability search terminated product available price greater remaining budget agent located store product purchased In MinExpectedCost budget allocated advance agent decide buy product store currently located different store In case agent return speciﬁc store paying return costs This model includes returning costs basic MinExpectedCost model consider In addition following standard assumption economic search literature consider model returning costs In physical environment justiﬁed product purchased phone following ﬁrst physical visit store We analyze variants problem refer MinExpectedCost MinExpectedCostphone problems respectively Technically easier work failure probability instead success probability In order compute failure probability need multiply failure probabilities node visited For success probability needs use addition multiplication Therefore instead maximizing psucc phrase objective minimizing failure probability 3 We metric space N Hazon et al Artiﬁcial Intelligence 196 2013 2652 31 2 Single agent We start analyzing single agent case general distance functions stores located general metric space Unfortunately settings mentioned problems NPhard MinBudget MaxProbability remain hard metric space tree Thus focus case stores located single path We like emphasize general metric spaces stores path traced However agent freely store store directly associated travel cost When stores located path mean agents movement restricted agent located store directly adjacent neighbors current location We denote problems MinBudget path MaxProbability path MinExpectedCost path respectively In case assume WLOG points line away distance function dis Rather distance ui u j simply ui u j Furthermore WLOG assume stores ordered lefttoright u1 u2 um For exposition purposes analysis paper includes sketch proofs hardness The detailed proofs given Appendices A B 21 MinimizeExpectedCost We prove MinExpectedCost variant hard general metric spaces To prove ﬁrst convert problem maximum expected cost M The problem decide decision version In MinExpectedCostDecide given set points S distance function dis S S R agents initial location priceprobability function p policy obtain product expected cost M 211 Hardness general metric spaces Theorem 1 For general metric spaces MinExpectedCostDecide NPhard The reduction Hamiltonian path build instance way agent needs visit stores obtain product target expected cost We note proof number possible prices d depend input Thus general metric spaces MinExpectedCostDecide hard d bounded Furthermore assume agent purchase product phone leaving store MinExpectedCostDecide hard proof essentially identical remove returning cost 2n M Before continuing analysis point cost arriving location ﬁxed vir tual environment ecommerce cost visiting store depend visited store MinExpectedCost solved polynomial time The optimal search strategy case proved Weitzman 57 based setting reservation value threshold store according distribution characterizing value cost revealing value The searcher continue search long best value obtained far lowest reservation value associated stores explored Formally reservation value R store associated ﬁxed cost F ci distribution pic extracted following equation F ci cid4 cR R cpic 1 Intuitively R value searcher precisely indifferent expected marginal beneﬁt revealing actual value store righthand exactly equals cost lefthand The use variable exploration costs physical constraints need factored dramatically increases complexity determining agents optimal strategies precluding simple solutions 212 Solution path When stores located path MinExpectedCost MinExpectedCostphone problems modeled ﬁnitehorizon Markov Decision Process MDP follows For exposition purposes start MinExpectedCostphone Note path point time pointsstores visited agent constitute contiguous interval visited interval Clearly algorithm need decisions store locations Furthermore decisions limited times agent stores edges visited interval At location agent possible actions right extending visitedinterval store right left extending visitedinterval store left stop stopping search buying product phone best price far Also note agent visited interval ucid3 ur exactly covered interval matter future decision costs incurred Accordingly states MDP quadruplets cid3 r e c cid3 cid2 s cid2 r e cid3 r c D representing situation agents visited stores ucid3 ur currently location ue best price encountered far c The terminal states Buyc states 32 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 cid6 transition state cid3 r 1 r 1 c form 1 m e c terminal cost c For states possible actions right provided r m left provided 1 cid3 stop The cost right state cid3 r e c ur1 ue cost left ue ucid31 The cost stop 0 Given state cid3 r e c right cid6 c With remaining probability transition cid6 c probability pr1c state cid3 r 1 r 1 c Transition states zero probability Transitions left action analogous Given state cid3 r e c action stop probability 1 transition state Buyc This fully deﬁnes MDP The optimal strategy ﬁnitehorizon MDPs determined dynamic programming 45 Ch 4 In case number entries dynamic programming table m m 2 d upper bound number possible states takes O d steps compute entry Therefore complexity solving MinExpectedCostphone O d2m2 steps O dm2 space For MinExpectedCost phone need larger MDP basic structure similar First note interval ucid3 ur visited item purchased future purchase interval purchase agent coming outside interval interval moving directly store purchasing In addition unique store uxr searcher coming right ur purchasing ucid3 ur purchases uxr similarly unique store uxcid3 purchases coming left ucid3 The reason cost purchasing store sum price distance So ﬁxed additional distance change minimum Thus price uxr lowest coming ur minimum coming urcid6 right ur Therefore states MDP MinExpectedCost septuplets cid3 r e ccid3 xcid3 cr xr representing situation agent visited stores ucid3 ur currently location ue e cid3 r best price encountered far coming left respectively right ccid3cr store uxcid3 uxr The terminal states Buyc e x terminal cost c ue ux states form 1 m e ccid3 xcid3 cr xr terminal cost ccid3 uxcid3 e m The actions MDP MinExpectedCostphone transition probabilities different Given state cid3 r e ccid3 xcid3 cr xr right probability pr1c With remaining probability transition state cid3 r 1 r 1 ccid3 xcid3 cr xr Transition states zero probability Transitions left action analogous Given state cid3 r e ccid3 xcid3 cr xr action stop probability 1 transition state Buyccid3 e xcid3 e cid3 Buycr e xr e r This fully deﬁnes MDP Using analysis complexity solving MinExpectedCost O d3m4 steps O d2m4 space cid6 transition state cid3 r 1 r 1 ccid3 xcid3 c u1 e 1 cr um uxr cid6 cr ur1 uxr cid6 r 1 c 22 MinBudget MaxProbability 221 NP completeness Unlike MinExpectedCost problem problems NPcomplete path To prove convert problems decision versions In MinBudgetDecide problem given set points minimum success S distance function dis S S R probability psucc maximum budget B We decide success probability psucc obtained budget B The exact formulation constitutes decision version MaxProbability problem agents initial location priceprobability function p Theorem 2 The MinBudgetDecide problem NPcomplete path The reduction 01 Knapsack We build instance agent needs forth line zigzag movement Before direction switch agent needs decide weather moving close store collect probabilities budget head direction Each decision corresponds decision spend space insert item knapsack save item Thus need consider restricted instances consider approximations We 222 Restricted case Bounded number prices We consider restricted case number possible prices d bounded For brevity focus MinBudget path problem The algorithm similar analysis work MaxProbability path problem Consider ﬁrst case possible price c0 At store product available price probability pi pic0 available price In setting problem solved O m steps This based following lemma stating case direction change necessary Lemma 3 Consider price c0 suppose optimal strategy starting point area covered remaining budget c0 interval ucid3 ur Then WLOG assume optimal strategy cid3 ur cid3 ucid3 cid3 ucid3 cid3 ur Proof Any route yield higher cost cover interval cid2 Using observation immediately obtain O m3 algorithm single price case interval ucid3 ur consider possible options compute total cost resulting probability Choose option N Hazon et al Artiﬁcial Intelligence 196 2013 2652 33 Algorithm 1 OptimalPolicyForSinglePriceSuccess probability psucc single price c0 1 ur leftmost point right st 1 2 cid3 s ur 3 B RL min 4 cid3 cid2 0 r cid2 s 5 6 is1 pi cid2 psucc cid5 r cid5 r B 2ur ucid3 B B RL min B B RL min r r 1 cid3 cid2 0 1 7 8 9 10 11 ucid3 rightmost point left st 1 12 r s ul 13 B LR min 14 r cid3 m cid3 cid3 s 15 16 cid3 cid3 1 icid3 1 pi psucc cid5 B 2us ucid3 ur B B LR min B B LR min cid3 cid3 1 r cid3 m 1 cid5 r 17 18 19 20 21 return minB RL r r 1 min B LR min c0 icid3 1 pi psucc s icid3 1 pi cid2 psucc requires lowest budget success probability psucc With little care complexity reduced O m First note single price c0 add c0 budget end assume product provided stores free provided available Now consider strategy ﬁrst moving right switching left In case need consider minimal intervals provide desired success probability compute necessary budget This performed incrementally total O m operations minimal intervals point added deleted given time Similarly strategy ﬁrst moving left switching right The details provided Algorithm 1 Next consider case different available prices number d ﬁxed We provide polynomial algorithm case exponential d First note MinBudget problem seek minimize initial budget B necessary guarantee success probability psucc given initial budget Once budget allocated requirement minimize actual expenditure Thus store product available price greater remaining budget purchased immediately search If product price current available budget product purchased store circumstances Denote D c1 c2 cd c1 c2 cd For ci interval I ucid3 ur points covered remaining budget ci By deﬁnition I I i1 Thus consider incremental area covered remaining budget ci cid4i I I i1 cid41 I1 Each cid4i union interval left interval right possibly The lemma multiprice analogue Lemma 3 states possible optimal strategies cover cid4i Lemma 4 Consider optimal strategy incremental areas cid4i 1 d deﬁned strategy For ci D let ucid3i leftmost point cid4i uri rightmost point Suppose optimal strategy covering cid4i starts point usi Then cid3 uri Furthermore starting point WLOG assume optimal strategy usi covering cid4i1 ending point covering cid4i cid3 ucid3i usi cid3 ucid3i cid3 uri Proof The areas cid4i fully determine success probability strategy Any strategy ones speciﬁed lemma require travel budget enlarging cid4i cid2 Thus optimal strategy fully determined leftmost rightmost points cid4i choice ending points covering area We consider possible cases choose lowest budget provides necessary success probability There m2d 2d 2d ways choosing external points cid4i s total 2d options consider covering For option computing budget probability takes O m steps Thus total time O m2d em 2d 2d Similar algorithms applied MaxProbability path problem In obtain 2d cid2 em Theorem 5 MinBudget path MaxProbability path solved O m steps single price O m2d em prices 2d 2d d In summary effect bounding number prices surprising Indeed showed Lemma 4 number prices determines incremental intervals covering agent Each price induces interval 34 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 optimal ways cover interval Therefore number prices ﬁxed increase number stores enumerate check possible ways cover intervals optimally Unfortunately moving path MinBudgetDecide turns hard bounded number possible prices tree Theorem 6 The MinBudgetDecide problem NPcomplete tree bounded number prices The reduction 01 Knapsack In proof build star tree agent located root stores We use possible prices 0 inf difference stores distance root corresponds knapsack items size probability purchasing product corresponds knapsack item value 223 MinBudget approximation Next provide FPTAS fullypolynomialtimeapproximationscheme MinBudget path problem The idea force agent quantum steps ﬁxed size δ In case tour taken agent divided segments size δ Furthermore agents decision points restricted ends segments case way agent suﬃcient budget purchase product store case stops We movement agent δresolution tour Note larger δ decision points complexity problem decreases Given 0 cid2 1 proper choice δ guarantee 1 cid2 approximation optimum maintaining complexity O n poly1cid2 n size input Our algorithm based computing essentially initial possible budget B maximal achievable success probability pick minimum budget probability psucc Note interval cid3 r covered purchasing product information matters future decision remaining budget ii current location The exact fruitless way interval covered point immaterial This memoryless nature calls dynamic programming approach We provide dynamic programming algorithm compute optimal δresolution tour WLOG assume 0 initial location origin For integral let w iδ The points w resolution points decision points algorithm Set L R w L rightmost w left stores w R leftmost w right fail act cid3 r L cid2 cid3 cid2 0 cid2 r cid2 R e cid3 r stores We deﬁne tables end points budget B failcid3 r e B minimal failure probability achievable purchasing stores outside wcid3 wr assuming remaining budget B starting location Similarly actcid3 r e B best act perform situation left right stop Given initial budget B best achievable success probability 1 fail0 0 0 B ﬁrst act0 0 0 B It remains compute tables The computation tables performed outside induction number remaining points For cid3 L r R stores search failL R e B 1 e B Assume values known remaining points compute 1 remaining points Consider costcid3 r e B 1 remaining points Then failure probability obtainable decision right wr1 F R 1 failcid3 r 1 r 1 B δ cid6 cid6 cid7 pr1c cid7 pcid31c cid4 ccid3Bδ cid4 ccid3Bδ Similarly failure probability obtainable decision left wcid31 F L 1 failcid3 1 r cid3 1 B δ maxδ furthest point reachable budget Bδ Thus choose act providing failure probability determining actcid3 r e B failcid3 r e B In practice compute table Bs integral multiples δ This add δ optimum Also place bound Bδ maxδ w R Bδ max maximal B consider table In case start ﬁlling table w L Bδ max Next choose δ prove approximation ratio Set λ cid29 Let α minus us1 us1 minimum budget necessary away starting point β m2um u1 maxc pic 0 upper bound total usable budget We start setting δ λ2α double δ λ2β performing computation values δ For value δ ﬁll tables scratch values Bs 2λ2δ We prove choices δ obtain 1 cid2 integral multiples δ Bδ approximation max Consider success probability psucc suppose optimally success probability obtained budget Bopt tour T opt By tour mean list actions right left stop decision point opt follows For cid4 0 T opt moves case store locations We convert T opt δresolution tour T δ opt moves way w i1 Similarly cid2 0 T opt moves ﬁrst time ﬁrst time right w T δ left w T δ opt moves way w i1 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 35 Note T δ opt makes t turns t direction changes Then total additional travel cost tour T δ opt requires additional travel costs overshoots goes way resolution point T opt This happen step ii T opt makes direction change Type happen costs δ Type ii happen resolution point costs 2δ Suppose T δ opt opt budget Bopt 2t 1δ T opt 2t 1δ Furthermore use T opt budget B opt T δ store available budget T δ opt δresolution tour budget Bopt 2t 1δ succeeds probability cid4 psucc Hence dynamic algorithm ﬁnds optimal cid2 Bopt 2t 2δ obtaining success probability Note δresolution tour ﬁnd tour budget Bδ include additional δ integral multiples δ tables opt available T opt Thus T δ opt Since T δ opt tturns T opt tturns targets t distinct resolution segments For ith turn T opt necessarily means T opt moves point 1 segments away distance 1δ Thus B opt travel cost T opt have4 Bopt cid4 tcid4 i1 1δ t 1t δ cid4 t2 4 δ 2 On hand consider options δ multiples 2 ˆδ 2 ˆδ cid4 Bopt cid4 λ2 2 λ ˆδ Combining 2 3 t cid2 2λ1 Thus approximation ratio cid2 1 2t 1 ˆδ λ2 ˆδ2 ˆδ opt Bopt B cid2 Bopt 2t 1 ˆδ Bopt cid3 8λ 4λ2 cid2 1 cid2 cid2 1 cid2 2 3 4 5 Also combining 3 5 ˆδ opt B cid2 Bopt1 cid2 cid2 2λ 2 ˆδ B ˆδ max Hence tables resolution ˆδ consider budget B ˆδ opt It remains analyze complexity algorithm For given δ Bδ maxδ 2λ2 budgets consider number resolution points entries table Thus size table cid2 8λ6 O cid26 The computation entry takes O 1 steps discussion We consider δ powers 2 β cid2 2n n size input Thus total computation time O ncid26 We obtain Theorem 7 For cid2 0 theMinBudget path problem approximated 1 cid2 factor O ncid26 steps 3 Multiagent shared budget Since single agent case hard general metric spaces multiagent case focus solely situations stores single path We assume k agents operating underlying physical setting single agent case set stores S price probability function store We assume goal individualized agents seek obtain item having multiple goods beneﬁcial Furthermore agents fully collaborative care agent obtain item We begin analyzing shared budget multiagent model resources costs shared agents In theory agents parallel minimizing time objective assume WLOG given time agent moves When agent reaches store ﬁnds price location optimal strategy tell purchase product agent Therefore kSharedMinExpectedCost problem agents try minimize expected total cost includes travel costs agents plus ﬁnal purchase price prices agents sampled In kSharedMinBudget kSharedMaxProbability initial budget use agents success probabil ity agents purchase location Since agents use budget model inter alia traveling costs assume agents communicate coordinate moves In kSharedMinBudget kSharedMaxProbability agents need announce agents reach speciﬁc store In kSharedMinExpectedCost agents need communicate price ﬁnd location reached 4 Assuming t 1 If t 0 1 additional cost small 3 36 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 In general algorithms singleagent case path extended multiagent case additional complexity coordinating agents The proofs relegated Appendix B similar single agent case We obtain Theorem 8 With k agents kSharedMinExpectedCostphone solved O d22k m solved O d2k12k m k 4k k 2k kSharedMinExpectedCost Theorem 9 With k agents kSharedMinBudget kSharedMaxProbability d possible prices solved O m2kd em 2kd 2kd Theorem 10 With k agents cid2 0 kSharedMinBudget approximated factor 1 kcid2 O ncid26k steps arbitrary number prices While complexity multiagent case grows exponentially number agents physical environ ments agents cooperate exploration search number agents relatively moderate In cases computation agents strategies eﬃciently facilitated principles algorithmic approach presented paper If number agents ﬁxed input complexity variants grows exponentially Most striking kSharedMinBudget kSharedMaxProbability NPcomplete path single price This contrast single agent case single price case solved O n steps To prove formulate problems decision version kSharedMinBudgetDecide given set points S minimum success probability psucc path initial locations agents u maximum budget B decide success probability psucc achieved maximum budget B priceprobability function p u 1 s k s Theorem 11 kSharedMinBudgetDecide NPcomplete path single price The reduction 01 Knapsack We build instance number agents corresponds number possible knapsack items Each agent visit store set distances stores shared budget As probabilities stores correspond knapsack items values distances correspond knapsack items sizes The problem decide agents given initial budget corresponds decision items insert knapsack given size 4 Multiagent private budget We investigate model ofprivate budgets agent j initial budget B j unlike previous shared budget model If objective minimize total expected cost private budgets model equal shared budget model agents cooperative Therefore case concrete problem formulations 1 kPrivateMaxProbability given initial budgets B j agent j maximize probability obtaining item 2 kPrivateMinBudget given target success probability psucc minimize agents initial budgets necessary guarantee acquisition item probability psucc Since corresponding singleagent problems hard path assume number possible prices d bounded In kPrivateMinBudget problem important distinguish different agent models Identical budgets initial budgets agents The problem minimize initial budget denote problem kPrivateMinBudgetidentical Distinct agents initial budgets different In case problem minimize average initial budget denote problem kPrivateMinBudgetdistinct 41 Noncommunicating agents We ﬁrst consider case agents communicate In case agents assist Hence solution strategy comprised set ordered lists agent determining sequence stores agent visit The success probability strategy probability agents succeed task Technically case easier calculate complementary failure probability probability agents succeed tasks For example suppose stores agents located illustrated Fig 2 consider depicted strategy This strategy fails agents stores visit cost item higher N Hazon et al Artiﬁcial Intelligence 196 2013 2652 37 Fig 2 A possible input suggested strategy The numbers edges represent traveling costs The table store ui represents cost probability function pi c The strategy agent illustrated arrows remaining budget This happen probability 1 2 19 20 We begin considering kPrivateMaxProbability problem We prove 5 1 4 4 1 1 2 20 Hence success probability strategy Theorem 12 In communication case number possible costs constant kPrivateMaxProbability solved polynomial time number agents The proof based following deﬁnitions lemmata The key idea cases stores visited agent optimal strategy However cases store visited agent We identify cases ﬁxed number We able provide dynamic programming algorithm ﬁnd optimal strategy Note multiple strategies result success probability In case strategies equivalent In particular optimal strategy Deﬁnition 13 Let S strategy Agents said separated S store reached reached Lemma 14 If agents separated optimal strategy optimal strategy agents pass initial location Proof WLOG assume right Consider optimal strategy S Let r rightmost store reached l leftmost store reached Assume contradiction agents passes initial location S Thus store initial locations reached agents WLOG assume reaches store higher budget remaining budget reaching denote r rightmost store Consider following modiﬁed strategy goes according S till stage reach r goes way straight r Otherwise stops If reach l reaching r reaching r goes way straight l Otherwise stops reaching r Agents separated strategy success probability S contradiction cid2 If reach r instead reaching r goes according S till stage reach r Based lemma agents separated optimal policy movement speciﬁc structure Lemma 15 Suppose agents separated optimal strategy Let S optimal strategy Suppose S agent passes initial location agent agent stay initial location Then optimal strategy following holds moves direction opposite ﬁnal movements direction Furthermore ﬁnal movements direction right left passes leftmost rightmost store reached Either Proof WLOG assume right Let l r interval stores covered Since passes initial location l located left u s r located right u First assume reaches store outside interval l r If consider following cases If remaining budget store high remaining budget rightmost store remaining budget higher theorem holds Otherwise let r s 38 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 Fig 3 The cases pair agents separated remaining budget If r left initial location proof Lemma 14 agents separated If r right initial location equals r need reach r store s r budget Thus optimal strategy moves u left passes rightmost store reached If r right left r Since budget location l moves need r r Thus optimal strategy moves right passes leftmost store reached Thus assume reaches store outside interval l r WLOG assume ﬁnal movements direction left suppose reaches store outside interval l r left l If budget l higher remaining budget higher u agents separated If budget l higher remaining budget reach stores left l Now suppose moves right opposite direction ﬁnal movement passes u changes direction The reason change directions reach store left initial location higher budget store reach store reach In cases reach store l u budget location S optimal modify S letting cid2 s s s Using lemmata observe agents constant number possible cases agents separated optimal strategies Fig 3 illustrates core cases symmetrical Here agents 1 3 nonseparated agents Note agent like agent 2 optimal strategy Therefore use dynamic programming approach ﬁnd optimal strategy agents separated check nonseparated strategies individually N Hazon et al Artiﬁcial Intelligence 196 2013 2652 39 Recall problem objective maximize success probability given initial budgets Technically easy work failure probability instead success probability Deﬁnition 16 failui j minimal failure probability reachable stores interval u1 ui agents 1 j allowed actui j optimal strategy achieving failui j conditions5 Note ui u failui j deﬁned Given actui j failui j easily computed O m steps For technical reasons add agent 0 budget zero set initial location leftmost store u u1 failui 0 1 agent doesnt affect failure probability policy We ready prove Theorem 12 showing polynomial time algorithm kPrivateMaxProbability 0 s j s j s Proof Theorem 12 We use dynamic programming calculate failum k actum k For failui 1 actui 1 single agent case employ polynomial algorithm obtained Theorem 5 j l cid2 u Let u l s Given agent j ﬁrst consider case ui u In case optimal strategy j moves left leftmost store visited j optimal strategy given interval agent l j l equal 0 Each agent t l t j optimal strategy Otherwise l u agents t j separated according Lemma 15 agent t pass rightmost store u j possible The argument shows agent t t cid2 l reach u l j j l1 l known movement agent j u actu l steps j s Therefore actui j composed takes O m Thus computing u j l j l j l l s u Let u cid2 u Next consider case ui u In case optimal strategy j directions leftmost store visited j optimal strategy interval agent l First note agent t t cid2 l j separated optimal policy j Otherwise l u s according Lemma 14 t pass initial location j according Lemma 15 j reach store outside occur Since j passes initial locations agent t l t j moves interval u goes opposite direction ﬁnal movement direction j according Lemma 15 illustrated Fig 3 Since direction according lemma moves optimal policy Therefore compute actui j check following options choose best 1 j actui j actui j 1 2 Each agent t l t j Thus actui j composed actu j l1 l optimal movement agent j s j s j interval u j l ui The previous options assume j agent separated Otherwise t 3 One agent t l t j moves Let u l l cid2 u agent l u s t agents j t interval u ui l leftmost store visited agent t j optimal strategy t t l1 l optimal movement l actui j composed actu There m possible options u Therefore agent j store ui actui j O m2k steps actum k O m3k2 time steps O mk space cid2 In option check k agents m possible options u t l j l We use algorithm kPrivateMaxProbability problem obtain polynomial time algorithm kPrivateMinBudgetidentical problem Theorem 17 In communication setting number costs constant kPrivateMinBudgetidentical solved polynomial time number agents Proof By Theorem 12 given budget B calculate maximum achievable success probability Thus run binary search possible values B ﬁnd minimal guarantees success probability psucc 5 There strategy failure probability actui j 40 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 Fig 4 A possible input suggested moves The numbers edges represent traveling costs The table store ui represents cost probability function pi c The moves illustrated arrows The maximum required budget 2 u1 um max D input Thus binary search require polynomial number steps cid2 Surprisingly results kPrivateMinBudgetdistinct different We note kPrivateMinBudgetdistinct prob lem objective minimize average budget minimizing total budget Therefore number agents ﬁxed use polynomial time algorithm proof Theorem 9 ex cept visited intervals agents disjoint If number agents parameter hardness kPrivateMinBudgetdistinct follows kSharedMinBudget problem We obtain Theorem 18 If number agents ﬁxed kPrivateMinBudgetdistinct communication solved O m2kd em 2d 2kd If number agents parameter kPrivateMinBudgetdistinct communication NPcomplete single possible cost 42 Communicating agents Once communication added agents assistance relative scheduling agents moves considered In case solution ordered list moves pair stating agent destination The success probability solution calculated according order moves For example suppose stores agents located illustrated Fig 4 Consider following solution agent 2 ﬁrst goes u4 agent 1 goes u2 Agent 2 succeed u4 probability 08 With probability 02 succeed agent 1 probability 02 succeed u2 Hence success probability 08 02 02 084 If switch order moves probability 09 succeed u2 ﬁrst agent 2 called assistance cost required 100 If agent 2 u4 Hence solution success probability 09 01 08 098 When number agents ﬁxed kPrivateMaxProbability kPrivateMinBudgetidentical kPrivateMin Budgetdistinct known solvable polynomial time However physical environments agents cooperate exploration search number agents relatively small In case problems solved polynomial time We Theorem 19 In setting communicating agents number agents number different costs ﬁxed kPrivateMaxProbability kPrivateMinBudgetidentical kPrivateMinBudgetdistinct solved polynomial time For brevity focus kPrivateMaxProbability problem The algorithm similar analysis work problems First note MaxProbability kPrivateMaxProbability need maximize probability obtaining item given initial budgets B requirement minimize actual resources consumed contrast kSharedMaxProbability Thus store agents obtain item cost greater remaining budget search Furthermore cost agents available budget agent suﬃcient budget travel current location obtain item agent called search Otherwise item obtained store circumstances Thus basic strategy structure determines agent goes remains Unless search terminated decision agent affected knowledge gained Using similar argument proof Theorem 9 following result For brevity denote d instead d 1 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 41 Fig 5 A possible input suggested strategy The numbers edges represent traveling costs The table store ui represents cost probability function pi c The moves agent illustrated arrows Proposition 20 For k agents needs consider O m2kd em 2d 2kd number options set moves agents j I 1 Each cid4 j union interval left u j ucid3 ur points Proof Let c1 c2 cd set costs For agent j ci interval I j j I i1 Thus consider covered agents remaining budget ci Furthermore j I j agent incremental area covered remaining budget ci ci1 cid4 j I i1 cid4 j j possibly s 1 Since communication agent continue reach store chance obtaining item order reveal cost use agents Thus optimal strategy deﬁne interval j j greater 0 By Lemma 31 Appendix B I d moves agent fully determined leftmost rightmost stores cid4 j ending points covering area Therefore j m2d 2d external stores cid4 j options set moves O 2kd em 2d choice 2d possible choices d options consider covering Thus total number ucid3 ur points covered remaining budget 2kd polynomial m cid2 interval right u s total 2 cid2 em 2d I j j s It remains consider scheduling moves order Theoretically n moves n different possible orderings We given set moves need consider polynomial number possible orderings Consider given set moves M determining sets cid4 j M said preﬁx M agent moves M Note agent M fully determines order preﬁx preﬁx We inductively deﬁne notion cid6 cid6 suﬃx M M M moves agent A subset M moves agent M A subset M cascading order cid6 cid6 1 The trivial order moves single agent cascading 2 Let M set moves let ci0 highest cost product agent pay An order S M cascading M S decomposed form M Mpre Mmid Mpost S Spre Smid Spost Mpre preﬁx M consisting moves agents budget ci0 Spre cascading order Mpre There exists agent j cid6 budget ci0 Mmid consists moves j cid6 cid6 cid4 j i0 Smid possible order moves Mpost remaining moves M Spost cascading order To visualize deﬁnition consider example Fig 5 Given depicted set moves highest cost agent pay 60 agent 2 u4 Therefore possible cascading order S decompose M Mpre agent 3 goes u7 Mmid agent 2 goes u4 Mpost agent 1 goes u1 u3 Since group contains decompose M moves single agent S cascading order M Another possible cascading order S Mpre agent 1 goes u1 u3 agent 3 goes u7 Mmid agent 2 goes u4 Mpost S cascading cid6 agent 1 goes ﬁrst agent 3 goes second We S post trivial S der M S prove induction cascading orders optimal cid6 post S cid6 mid S cid6 S cid6 mid cid6 pre cid6 pre S cid6 cid6 Lemma 21 For set moves M exists cascading order optimal success probability 42 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 cid6 Proof The proof induction number agents number moves M If agent moving M order cascading Otherwise consider order S M let Ai0 set agents budget ci0 Let j let t0 time completes covering Mpre includes cid4 j i0 moves taken agents Ai0 prior t0 Mmid includes moves j Mpost rest moves M We decrease success probability ﬁrst making moves Mpre Mmid ﬁnally Mpost By inductive hypothesis Spre Smid Spost optimal Mpre Mmid Mpost respectively result follows ﬁrst agent Ai0 cover cid4 j i0 cid6 cid6 cid6 Before t0 agents Ai0 higher budget agent Ai0 Thus t0 agents Ai0 Ai0 Thus let agents Ai0 moves ﬁrst success probability decrease We allow moves Mpre performed ﬁrst Also t0 agents Ai0 needs assistance resource bracket Thus allow moves independently decreasing success probability In par ticular allow j member Ai0 moves Thus ﬁrst having moves Mpre Mmid decrease success probability The moves Mpost remaining moves cid2 complete covering cid4 j i0 cid6 cid6 Finally number cascading orders polynomial Lemma 22 For ﬁxed k d set moves M polynomial number cascading orders M polynomial n Since cid3 cid2 k result follows Clearly cid3 Proof Let f n k d cid3 number cascading orders k agents n moves d costs cid3 agents Ai0 We prove f n k 0 cid3 cid3 induction f useless Then deﬁnition cascading orders f n k d cid3 cid2 cid3nkcid3 f n k cid3 d 1 k cid3 f n k d cid3 1 nk choice Mpre By inductive hypothesis f n k cid3 d 1 k cid3 f n k d cid3 1 polynomials n Thus f n k d cid3 cid2 Together Proposition 20 total number options consider polynomial proving kPrivate MaxProbability Theorem 19 The proof problems similar 5 Selfinterested agents In section consider strategic behavior occur agents selfinterested We assume k agents operate underlying physical setting previous multiagent case private budgets stores single path number possible prices d bounded ﬁxed number agents However selfinterested agents setting agents seek obtain item want spend individual budgets travel costs assume purchase price equally shared agents In case deﬁne games simultaneous game MinBudgetGame sequential game MinExpectedCostGame 51 MinBudgetGame In MinBudgetGame given target success probability psucc agents objective minimize initial budget necessary guarantee item acquired probability psucc To avoid case agent set initial budget zero set utility guaranteeing success probability psucc low worthwhile attain We assume game simultaneous game agents choose initial budgets After phase agents calculate collaborative strategy maximize success probability given chosen budgets follow The decision point game agent needs choose budget Since number agents number different costs ﬁxed optimal solution kPrivateMinBudgetdistinct polynomial time agents communicate Theorem 19 Let Balg initial budget assigned agent algorithm Theorem 19 This solution ofkPrivateMinBudget distinct optimal directly translated strategy denote Optsoc agent individually choose initial budget B alg Obviously Optsoc maximizes social welfare computed polynomial time Furthermore Optsoc Nash equilibrium 44 p 14 Clearly agent incentive deviate choose budget larger Balg success probability psucc guaranteed assuming agents deviate On hand algorithm Theorem 19 optimal incentive agent deviate choose budget smaller B alg psucc achieved recall utility guaranteeing success probability low We obtain Balg N Hazon et al Artiﬁcial Intelligence 196 2013 2652 43 Theorem 23 In MinBudgetGame strategy maximizes social welfare Optsoc polynomial time Nash equilibrium 52 MinExpectedCost game In MinExpectedCostGame agents objective minimize total expected cost As previous game avoid case agent want set utility obtaining item low worth traveling store purchase product The MinExpectedCostGame sequential game rules follows At time step agents allowed store decide Then decision phase agent allowed buy product optout If agent decides buy product purchased game agents decide optout No matter agents decide buy product minimal price purchased If agent decides buy product agent decides optout game buying product Otherwise decision phase ends game proceeds allowing agent according ﬁxed predeﬁned cyclic order The predeﬁned order movement phases welldeﬁne game essential meaning agents option turns actually order movements occur In order ﬁnd strategy maximize social welfare Optsoc need run algorithm The run polynomial time However unlike MinBudgetGame solution orem 8 In setting directly translated strategy First need translate movements At stage algorithm kSharedMinExpectedCost decides speciﬁc agent instance agent strategy MinExpectedCostGame deﬁnes agent turn agent ment phase agents decision phase We need handle case agent according strategy For purpose determine case agents deviates determined policy movement phase agents purchase product decision phase follows If possible product available agents located agents optout decision phase The translation algorithms decision buy straightforward strategy deﬁnes corresponding decision phase agents decide buy agent buy optout We need handle case agent deviates decision phase game case In conclusion Optsoc strategy MinExpectedCostGame maximizes social welfare polynomial time algorithm Theorem 8 However Optsoc Nash equilibrium shown Example 24 For ease notation describing Optsoc strategy omit movement decision phases agents Example 24 Suppose stores agents located illustrated Fig 6 The traveling costs u2 u3 u4 u5 high reasonable moves according illustrated arrows Optsoc example agent 1 u2 If price 6 product purchased Otherwise agent 3 u6 price 6 product purchased Otherwise agent 2 u4 product purchased minimal sampled price 12 27 The expected cost strategy 14375 Nash equilibrium Clearly product purchased moves agents 1 3 minimal sampled price 27 At stage agent 2 deviates decides product purchased private cost agent 2 9 purchase price equally shared agents If agent 2 proceeds according Optsoc expected cost 4 05 4 05 9 105 9 Therefore agent 2 incentive deviate Optsoc If switch movement order agents 2 3 expected cost higher 15125 strategy Nash equilibrium Clearly agent 1 deviate turn agents optout Agent 2 deviate turn private cost 10 follow strategy expected cost 4 05 4 05 05 2 05 9 875 10 assuming agents deviate Agent 3 deviate turn private cost 10 follow strategy expected cost 4 05 2 05 9 95 10 Example 24 demonstrates Optsoc Nash equilibrium We polynomial algorithm returns strategy Nash equilibrium Furthermore upper bound algorithms performance prove tight Theorem 25 There polynomial algorithm ﬁnding Nash equilibrium MinExpectedCostGame Proof The algorithm works follows It divides buying costs k solves ﬁnitehorizon MDP proof Theorem 8 The solution translated strategy MinExpectedCostGame way translated optimal solution kSharedMinExpectedCost Optsoc We denote strategy OptNash Since preprocess takes O d operations algorithm ﬁnding OptNash polynomial 44 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 Fig 6 A possible input suggested moves The numbers edges represent traveling costs The table store ui represents cost probability function pi c The reasonable moves illustrated arrows Any strategy S consists traveling costs buying costs denoted ti bi respectively We write associated probabilities We write ti j pb bi pt expected cost S ES traveling cost ti credited movement agent j ti ipb ipt cid8 cid8 We analyze steps OptNash First note product available agent incentive deviate agents optout game We assume product available The step OptNash decision step product purchased By deﬁnition incentive purchase product step In decision phase strategy OptNash purchase product However agent j deviates movement phase product purchased decision phase follows Therefore need consider movement phases Now consider agent j movement phase r suppose j needs r If j deviates expected cost ck best price available divided number agents Since OptNash optimal respect modiﬁed buying costs 6 7 ck cid4 cid4 cid2 cid3 pt ti cid4 cid2 cid3 pb bik icid2r icid2r In addition cid4 cid2 pt cid3 cid4 ti cid4 cid2 cid3 pt ti icid2r icid2rti j Combining 6 7 cid4 cid4 cid2 cid3 pt ti cid2 cid3 pb bik ck cid4 icid2rti j icid2r right term expected cost agent j follows OptNash Therefore agent j incentive deviate The analysis shows j incentive deviate need r cid2 OptNash Nash equilibrium maximize social welfare Furthermore Nash equilibrium yield larger social welfare For example recall settings Example 24 In settings OptNash policy agent 1 u2 If price 6 product purchased Otherwise agent 3 u6 buy product minimal price 6 27 This Nash equilibrium expected cost 1525 However showed better Nash equilibrium expected cost 15125 We prove upper bound performance OptNash expected cost OptNash k times worse expected cost Optsoc Theorem 26 EOptNash cid2 k EOptsoc k EOptsoc Proof Suppose EOptNash cid4 cid2 cid3 cid4 cid2 Therefore cid9cid4 cid3 EOptNash pt ti pb bi k cid2 pt j t j cid4 cid2 cid3 pb j b j cid10 cid3 k EOptsoc j j Then cid4 cid2 pt tik cid4 cid2 cid3 pb bik cid3 cid4 cid2 cid4 cid2 cid3 cid3 pb j b j pt j t j j j N Hazon et al Artiﬁcial Intelligence 196 2013 2652 45 Since ti tik b j b jk cid4 cid2 cid4 cid2 cid3 pb bik cid3 cid4 cid2 pt j t j cid4 cid2 cid3 pt ti cid3 pb j b jk j j The left right terms expected costs OptNash Optsoc respectively buying costs divided k Therefore OptNash optimal settings Contradiction cid2 As lower bound consider following example 1 Example 27 For cid2 0 suppose price u2 u k probability 1 price leftmost s store u1 0 probability 1 The traveling cost u2 u1 1 cid2 In stores price high traveling costs store u2 high instance 2k Optsoc example agent 1 left buy product u1 The cost strategy 1 cid2 Nash equilibrium Clearly agent 1 prefer buy product initial location u2 cost 1 instead 1 cid2 Optsoc The total cost strategy k Nash equilibrium Therefore algorithm ﬁnds strategy S Nash equilibrium ES Ω k 1cid2 bound Theorem 26 tight EOptsoc 6 Heterogeneous agents The analysis far assumes agents type identical capabilities Speciﬁcally cost obtaining item given store assumed agents However agents different types different capabilities For example agents equipped drilling arm allows consume battery power mining In section consider situations heterogeneous agents results extended settings While agents different capabilities cases reasonable assume agent capable location capable locations capable Hence following deﬁnition Deﬁnition 28 We agents inconsistent exist budgets B B location budget B cid6 agents j j cid6 locations cid6 cid11 Pr j obtain item Pr cid6 j cid12 obtain item location cid6 budget B cid6 cid11 Pr j obtain item Pr cid6 j cid12 obtain item We results Section 41 extended heterogeneous agents Theorem 29 In private budget communication setting number different costs agent constant kPrivateMaxProbability kPrivateMinBudgetidentical solved polynomial time number heterogeneous agents provided agents consistent The algorithm essentially dynamic programming algorithm described Section 41 The consistency assump tion necessary Lemmata 14 15 remain true In case away consistency assumption Clearly need assume reaching site agents assess cost obtaining item agents Otherwise communication meaningless We obtain Theorem 30 In setting communicating agents constant number agents constant number different costs agent kSharedMinExpectedCost kSharedMinExpectedCostphone kSharedMaxProbability kSharedMinBudget kPrivateMaxProbability kPrivateMinBudgetidentical kPrivateMinBudgetdistinct solved polynomial time inconsistent heterogeneous agents The algorithms proofs remain essentially case homogeneous agents 46 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 7 Discussion In paper mainly analyzed case stores located path closed nonclosed We fair applicability proposed model reallife applications The importantappropriate application discussed paper robot patrolling 601923 The reason common patrolling scheme patrolling surroundings area robots movement task deﬁnition restricted path shortcuts However additional important families applications model mapped exploration path Typical applications kind include Finding place camping path consider expedition group campers follows trail travel river When deciding set night camp group consider different locations trailriver associated uncertainty related beneﬁt spending night Positioning scouts consider bordercontrol squad needs position scouting based information illegal inﬁltrators arrive hours Many possible locations border segment potentially squad offering different visibility level accessibility different point inﬁltrators arrive priori unknown visibility conditions terrain conditions human factors Deciding restaurant consider group wants dine numerous restaurants Balboa Blvd Newport Beach Assume true utility dining restaurants observed getting observing menu crowd getting impression general atmosphere Deciding place bets consider visitor arriving Las Vegas Blvd interested gambling casinos Similar restaurants example gambler able learn utility gambling expected payoff likely similar places gambling experience terms atmosphere crowd excitement given casino visiting Buying souvenirs consider tourist visiting pier Key West Florida Walking pier tourist ﬁnd souvenir stores selling practically items different prices In case tourist consider tradeoff potential saving cost alternative cost time going forth visiting different stores Finding best place install spying device place communication line assume possible locations line applicable installing equipment characterized different chance discovered different chance success All applications characterized physical search line potential locations explored distribution potential gainsutilities location Indeed numerous physical environments represented planar graph Theorems 1 6 physical search problems hard planar graphs trees single agent ﬁnding heuristic practical nonetheless It ﬁrst steps building heuristic utilize results For example try avoid repeated coverage possible restrict number cases coverage necessary showed Theorem 12 Another idea convert complex graph structure path site path represents region stronglyconnected nodes original graph Many graphs represent real physical environments consist regions strongly connected nodes edges connect regions example cities roads inside connected highways A heuristic algorithm graphs use algorithm construct strategy sites path use additional heuristic visiting sites inside region We considered case mining costs roundedestimated constant number possible options We believe assumption appropriate given input problems includes prior probabilistic knowledge Usually data comes sort estimation reasonable assume number options ﬁxed If possible values accurate estimation hard achieve Nevertheless number costs constant rounded ﬁxed number costs yields PTAS polynomialtime approximation scheme problems We assume agents seek item As soon item needed results hold seemingly problems NPcomplete 8 Conclusions future work This paper considers single multiagent physical search problems prior probabilistic knowledge This integration changing search cost economic search models important improves realism applicability mod eled problem At time dramatically increases complexity determining agents optimal strategies precluding simple solutions easily computable reservation values example Pandoras problem 57 brieﬂy discussed Section 211 Indeed showed problems hard metric space tree We focused path case presenting polynomial algorithms variants MinExpectedCost N Hazon et al Artiﬁcial Intelligence 196 2013 2652 47 problem proving hardness MaxProbability MinBudget problems We provided FPTAS MinBudget case showed problems polynomial number possible prices bounded For multiagent case analyzed shared private budget models In case shared budget showed singleagent algorithms extend kagents time bounds growing exponentially k We proved case private budget model agents communicate In case private budget communicating agents presented polynomial algorithm suitable number agents We extended analysis heterogeneous agents Finally considered selfinterested agents setting showing ﬁnd Nash equilibrium MinBudgetGame MinExpectedCostGame polynomial time In cases showed upper bound ratio solution optimal maximizes social welfare proved tight For future work interesting open problems With single agent complexity MinExpectedCost problem tree explored This case interesting shown MinExpectedCost In shared budget model complexity easy speciﬁc tree star graph d bounded kSharedMinExpectedCost problem k input open In private budget model complexity problems nonconstant number communicating agents open In addition interesting extensions consider We showed results extended heterogeneous agents different buying capabilities The step analyze results heterogeneous agents different traveling capabilities Another direction add time constraint possibly result completely different optimal strategies Currently assume communication agent free reliable possible extension integrate communication costs model handle consequences nonreliable communication The MinBudgetGame extended instead deﬁning utility achieving psucc step function high achieving psucc low deﬁned linear function psucc Finally metric spaces line remain open challenge As discussed Section 7 techniques results given paper facilitate development approximations andor heuristics general metric space Appendix A Proofs Section 2 Theorem 1 For general metric spaces MinExpectedCostDecide NPhard cid8 n j1 2 Proof The proof reduction Hamiltonian path deﬁned follows Given graph G V E V v 1 vn decide simple path v i1 v i2 v G covering nodes V The reduction follows Given graph G V E V v 1 vn set S set stores S u1 designated start location u1 correspond v 1 vn The distances deﬁned follows For j 1 n disus ui 2n disui u j length shortest path v v j G Set nn n 1 2n For pi0 05 piM 05 psn 1 M 2n j j 1 2 Suppose Hamiltonian path H v i1 v i2 v G Then following policy achieves expected cost exactly M Starting ui1 continue traversing according Hamiltonian path If point ui way price 0 purchase stop Otherwise continue node path If points path price M return purchase price n The expected cost policy follows The price initial step ui1 ﬁxed 2n For j probability obtain price 0 ui j n case 2 purchase price n plus n 1 wasted steps Hamiltonian path cost 2n returning The total expected cost exactly M j The cost reaching ui j ui1 j 1 The probability u j price 0 2 Conversely suppose Hamiltonian path G Clearly price large optimal strategy check nodesstores u1 purchasing Since Hamiltonian path G explo ration strictly expensive Hamiltonian path Thus expected cost strictly M cid2 Theorem 2 The MinBudgetDecide problem NPcomplete path Proof Given optimal policy easy compute total cost success probability O n steps MinBudgetDecide NP The proof NPhardness reduction 01 Knapsack problem deﬁned fol lows Given knapsack capacity C 0 N items item value v Z determine selection items δi 1 selected 0 ﬁts knapsack i1 δi si cid2 C total value size si Z cid8 cid8 N N i1 δi v V Given instance 01 Knapsack build instance MinBudgetDecide problem follows We assume WLOG points line Our line consists 2N 2 stores N stores correspond knapsack items denoted uk1 ukN The N 2 stores denoted u g0 u g1 u gN1 u g0 agents initial location Let T 2 i1 si maxV N maxi v For odd u gi right u g0 u gi2 right u gi For cid12 0 u gi left u g0 u gi2 left u gi We set u0 u1 u0 u2 T 0 cid8 N 48 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 Fig 7 Reduction 01 Knapsack MinBudgetDecide problem proof Theorem 2 N 3 cid8 u gi2 uki We set B T u gi T If N odd ukN right left u gi rightmost leftmost point As uki points uki located u gi u gi2 odd u gi2 u gi For cases u gi si See Fig 7 illustration N1 j1 j 2C 1 set X T i1 j1 s j At store u gN1 product maxV available price On store u gi available price 1 probability 1 2 product available price B X probability available At store uki v available price Finally set product available price B X si probability 1 2 psucc 1 2 maxVN1 2 j1 j 2 V cid8 cid8 N cid8 cid8 i1i T δi 2si N 1 T T Suppose selection items ﬁt knapsack total value V consider following policy right u g0 u g1 Then 1 2 N δi 0 item selected change direction u gi1 Otherwise continue current direction uki change direction u gi1 This N1 i1 2C B 1 agent budget policys total travel cost reach u gi uki δi 1 When agent reaches u gi N 1 spent traveling cost exactly maxV purchase product store When T reaches u gN1 end tour agents total traveling cost B 1 probability i1 1 2 j1δ j s j si cid2 v purchase product store In total success probability X si agent probability 1 2 1 2 N i1 2 maxV purchase product When reaches uki spent exactly T i1 j1δ j s j cid2 X agent probability 1 2 V psucc required v δi cid4 1 2 maxVN1 2 maxVN1 j1 j 2 j1 j 2 cid8 cid8 cid8 cid8 cid5 Suppose policy plc total travel cost equal B success probability V Since maxV N maxi v plc reach psucc Hence plcs failure probability 1 psucc 2 N 1 stores u gi budget Hence plc right u g0 u g1 u gi u gi1 Therefore plc goes zigzag movement repeatedly plc select uki reach budget Thus plc reach uki right corresponding store u gi We use γi 1 indicate event plc selects reach uki right u gi γi 0 denote complementary event plcs total traveling cost equal B 1 able purchase product store V cid2 u gN1 T 1 2 i1 v γi Setting δi γi gives selection items ﬁt knapsack cid2 j1 γ j s j cid2 C Also psucc 1 2 j1 γ j s j cid2 T V cid2 N i1 2 N1 j1 j 2 cid5 N i1 2 N1 j1 j 2C Thus maxVN1 2 maxVN1 2 v γi V cid4 maxVN1 v γi 2 cid8 cid8 cid8 cid8 cid8 cid5 N N N Theorem 6 The MinBudgetDecide problem NPcomplete tree bounded number prices Proof Membership NP immediate proof Theorem 2 The proof NPhardness reduction 01 Knapsack problem Given instance 01 Knapsack build instance MinBudgetDecide problem follows We N 2 stores N stores corresponds knapsack items denoted uk1 ukN The 2 stores u0 ue u0 agents initial location The stores placed star tree internal node u0 N 1 leaves The distance uki deﬁned according item size disu0 uki si2 disu0 ue C At store uki v available price At store u0 product product available price 0 probability 1 2 maxV maxV N maxi v available store ue product available price 0 probability 1 2 available price Finally set psucc 1 2 V B 2 C maxV 2 N cid8 Suppose selection items ﬁt knapsack total value V consider following policy 1 2 N δi 1 item selected u0 uki u0 Finally u0 i1δi si C cid2 2 C B If product available store price 0 Thus ue This policys travel cost success probability policy 1 2 v δi cid4 1 2 Suppose policy plc total travel cost equal B success probability V Since maxV N maxi v plc reach psucc Hence plcs failure probability 1 psucc 2 store ue plc select uki reach disu0 ue C B 2 C plc reach uki reaching ue We use γi 1 indicate event plc selects reach uki γi 0 denote complementary j1 γ j s j cid2 C Also psucc event plcs traveling cost going ue equal C able reach ue V psucc required maxV 2 maxV 2 maxV N i1 2 cid8 cid5 N N Hazon et al Artiﬁcial Intelligence 196 2013 2652 49 N i1 2 v γi 2 V cid2 cid5 N i1 2 v γi V cid4 cid8 N i1 v γi Setting δi γi gives selection maxV 2 maxV 1 2 items ﬁt knapsack cid2 V cid2 1 2 cid5 Appendix B Proofs Section 3 Theorem 8 With k agents kSharedMinExpectedCostphone solved O d22k m solved O d2k12k m k 4k k 2k kSharedMinExpectedCost Proof We start kSharedMinExpectedCostphone Since stores path point time pointsstores visited agents constitute set k disjoint contiguous intervals visited intervals Clearly algorithm need decisions store locations Furthermore decisions limited times agents stores edges visited interval At location agent possible actions right extending visitedinterval store right left extending visitedinterval store left stop stopping search buying product best price far Also note agent visited interval ucid3i uri exactly covered interval matter future decision costs incurred Accordingly states MDP quadruplets L R E c L cid31 cid32 cid3k R r1 r2 rk E e1 e2 ek c D For agent cid3i cid2 si cid2 ri ei cid3i ri Every state represents situation agent visited stores ucid3i uri currently location uei best price encountered far c Since intervals disjoint ri cid3i1 cid6 c The terminal states Buyc states stores visited The terminal cost c For states 2k 1 possible actions agent right provided ri cid3i1 ri m agent left provided ri1 cid3i 1 cid3i stop The cost agent right uri1 uei cost agent left uei ucid3i1 The cost stop 0 Given vector V let V j vector value j index Given state L R E c agent right probability pri1c cid6 transition state cid6 c With remaining probability transition state L R iri 1 E iri L R iri 1 E iri 1 c 1 c Transition states zero probability Transitions agent left actions analogous action stop probability 1 transition state Buyc This fully deﬁnes MDP The optimal strategy ﬁnitehorizon MDPs determined dynamic programming 45 Ch 4 In case complexity brought O d22k m k 2k space We kSharedMinExpectedCost Like single agent case interval ucid3i uri visited agent item purchased future purchase interval purchase agent coming outside interval interval moving directly store purchasing Note interval ucid3i uri visited agent purchaser immediate neighbors agents 1 1 In addition unique store u purchaser coming right uri purchasing ucid3i uri purchases u purchases coming left ucid3i Therefore states MDP kSharedMinExpectedCost septuplets L R E Ccid3 Xcid3 Cr Xr L cid31 cid32 cid3k R r1 r2 rk E e1 e2 ek Ccid3 ccid31 ccid32 ccid3k Xcid3 xcid31 xcid32 xcid3k Cr cr1 cr2 crk Xr xr1 xr2 xrk Every state represents situation agent visited stores ucid3i uri currently location uei ei cid3i ri best price encountered far ucid3i uri coming left respectively right ccid3i cri store uxcid3i ux k 2k steps O d2k m Given state L R E Ccid3 Xcid3 Cr Xr let BuyAti minimum cost purchasing visited interval agent BuyAti mincei uei ux cri uei1 uri cli uei1 uli The terminal states Buyi terminal cost BuyAti states stores visited terminal cost minik BuyAti The actions MDP kSharedMinExpectedCostphone transition probabilities different Given cid6 transition state L R iri state L R E Ccid3 Xcid3 Cr Xr agent right probability pri1c 1 E iri 1 Ccid3 Xcid3 C With remaining probability transition state L R iri 1 E iri 1 Ccid3 Xcid3 Cr Xr Transition states zero probability Transitions agent left action analogous Given state L R E Ccid3 Xcid3 Cr Xr action stop probability 1 transition state Buyi arg minik BuyAti This fully deﬁnes MDP Using analysis complexity solving kSharedMinExpectedCost O d2k12k m cid6 cri ur1i ux cid6 X iri 1 c similarly unique store u k 4k steps O d2k2k m k 4k space cid2 ri rc x cid3 x r x r ei ri Theorem 9 With k agents kSharedMinBudget kSharedMaxProbability d possible prices solved O m2kd em 2kd 2kd Proof For brevity focus kSharedMaxProbability problem The algorithm similar analysis work kSharedMinBudget problem Let c1 c2 cd set costs For agent j ci interval j j i1 I j Thus consider agent incremental area covered remaining budget ci ci1 cid4 j i1 j ucid3 ur points covered remaining budget ci Furthermore j I I I I j 50 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 Fig 8 Reduction 01 Knapsack problem MultiMinBudgetDecide problem proof Theorem 11 N 3 j I 1 Each cid4 j cid4 j possibly 1 The lemma multiagent MaxProbability analogue Lemma 4 states possible optimal strategies cover cid4 j union interval left u interval right u j s j s Lemma 31 Consider optimal solution incremental areas agent j cid4 j For 1 d let u cid4 j j u si ri Furthermore starting point covering cid4 j leftmost store cid4 j starts location u cid3 u cid3 u u j cid3i j ri j si j j cid3i i1 ending point covering cid4 j Then WLOG assume optimal strategy j u 1 d deﬁned solution rightmost store Suppose optimal strategy covering j si cid3 u j ri cid3 u j cid3i Proof Any strategy ones speciﬁed lemma reach stores covered optimal solution available budget cid2 choice ending points covering area For agents j1 m k 2d 2d cid2 em By previous lemma moves agent fully determined leftmost rightmost stores cid4 j j2 intervals covered I 2kd 2d possible choices s total 2d options consider covering For option 2kd 2kd polynomial j1 points disjoint I d external stores cid4 j computing budget probability takes O m steps Thus total time O m2kd em m cid2 Therefore j j2 d Theorem 10 With k agents For cid2 0 kSharedMinBudget approximated factor 1 kcid2 O ncid26k steps arbitrary number prices Proof For k agents extend dynamic programming algorithm calculates fail act tables way extended single agent algorithm proof Theorem 8 We save k disjoint intervals tables size O cid26k The rest approximation algorithm remains essentially We consider δ powers 2 β cid2 2n n size input Thus total computation time O ncid26k Since approximation ratio interval guaranteed 1 cid2 total ratio 1 kcid2 cid2 Theorem 11 kSharedMinBudgetDecide NPcomplete path single price Proof An optimal policy deﬁnes time step agent direction Since 2m time steps easy compute success probability total cost O m steps problem NP The NPhard reduction 01 Knapsack problem We assume WLOG points line We use N agents line consists 2N stores N stores i1N i1 s correspond knapsack items denoted uk1 ukN The N points starting point agents u We set left point u s right uki Set u right point ukN For 1 cid2 cid2 N 1 set uki right u B 1 See Fig 8 illustration The price nodes c0 1 pki 1 1 2 For agent possible node pki denote γi 1 agent moves pki 0 Therefore N i1 δi v V iff selection v Finally set B C 1 psucc 1 2 i1 δi si cid2 C total value cid5 selection items ﬁt si uki s u uki i1 s V u 1 s s cid8 cid8 cid8 N N i1 γi si cid2 B total probability 1 N i1 γi2 v psucc 1 2 V cid2 agents References 1 F Afrati S Cosmadakis C Papadimitriou G Papageorgiou N Papakonstantinou The complexity traveling repairman problem Theoretical Informatics Applications 20 1986 7987 2 N Agmon S Kraus GA Kaminka Multirobot perimeter patrol adversarial settings Proceedings 2008 IEEE International Conference Robotics Automation ICRA2008 2008 pp 23392345 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 51 3 N Agmon D Urieli P Stone Multiagent patrol generalized complex environmental conditions Proceedings TwentyFifth AAAI Conference Artiﬁcial Intelligence AAAI2011 2011 pp 10901095 4 S Arora G Karakostas Approximation schemes minimum latency problems Proceedings ThirtyFirst Annual ACM Symposium Theory Computing STOC1999 1999 pp 688693 5 S Arora G Karakostas A 2 cid2 approximation algorithm kMST problem Proceedings Eleventh Annual ACMSIAM Symposium Discrete Algorithms SODA2000 2000 pp 754759 6 Y Aumann N Hazon S Kraus D Sarne Physical search problems applying economic search models Proceedings TwentyThird AAAI Conference Artiﬁcial Intelligence AAAI2008 2008 pp 916 7 G Ausiello S Leonardi A MarchettiSpaccamela On salesmen repairmen spiders traveling agents Algorithms Complexity Springer BerlinHeidelberg 2000 pp 116 8 B Awerbuch Y Azar A Blum S Vempala Improved approximation guarantees minimum weight ktrees prizecollecting salesmen SIAM Journal Computing 28 1 1999 254262 9 E Balas The prize collecting traveling salesman problem Networks 19 1989 621636 10 JC Beck N Wilson Job shop scheduling probabilistic durations Proceedings Sixteenth European Conference Artiﬁcial Intelligence ECAI2004 2004 pp 652656 11 JC Beck N Wilson Proactive algorithms job shop scheduling probabilistic durations IEEE Transactions Robotics 28 1 2007 183232 12 R Bellman A Markovian decision process Indiana University Mathematics Journal 6 4 1957 679684 13 D Bernstein D Givan N Immerman S Zilberstein The complexity decentralized control Markov decision processes Mathematics Operations Research 27 4 2002 819840 14 L Bianco A Mingozzi S Ricciardelli The traveling salesman problem cumulative costs Networks 23 2 1993 8191 15 A Blum P Chalasani D Coppersmith B Pulleyblank P Raghavan M Sudan The minimum latency problem Proceedings TwentySixth Annual ACM Symposium Theory Computing STOC1994 1994 pp 163171 16 A Blum R Ravi S Vempala A constantfactor approximation algorithm kMST problem Journal Computer System Sciences 58 1 1999 101108 17 AM Campbell M Gendreau BW Thomas The orienteering problem stochastic travel service times Annals Operations Research 186 1 2011 6181 18 K Chaudhuri B Godfrey S Rao K Talwar Paths trees minimum latency tour Proceedings 44th Annual IEEE Symposium Foundations Computer Science FOCS2003 2003 pp 3645 19 Y Elmaliach A Shiloni GA Kaminka A realistic model frequencybased multirobot fence patrolling Proceedings 7th International Joint Conference Autonomous Agents Multiagent Systems AAMAS2008 2008 pp 6370 20 J Fakcharoenphol C Harrelson S Rao The ktraveling repairman problem Proceedings Fourteenth Annual ACMSIAM Symposium Discrete Algorithms SODA2003 2003 pp 655664 21 J Fakcharoenphol C Harrelson S Rao The ktraveling repairmen problem ACM Transactions Algorithms 3 4 2007 40 22 TS Ferguson Who solved secretary problem Statistical Science 4 3 1989 282289 23 M Fischetti G Laporte S Martello The delivery man problem cumulative matroids Operations Research 41 1993 10551064 24 N Fu P Varakantham HC Lau Towards ﬁnding robust execution strategies RCPSPmax durational uncertainty Proceedings Twen tieth International Conference Automated Planning Scheduling ICAPS2010 2010 pp 7380 25 Y Gabriely E Rimon Spanningtree based coverage continuous areas mobile robot Annals Mathematics Artiﬁcial Intelligence 31 2001 7798 26 S Gal Search Games Academic Press 1980 27 A García P Jodrá J Tejel A note traveling repairman problem Networks 40 2002 2731 28 N Garg A 3approximation minimum tree spanning k vertices Proceedings 37th Annual IEEE Symposium Foundations Computer Science FOCS1996 1996 pp 302309 29 N Garg Saving epsilon 2approximation kMST problem graphs Proceedings ThirtySeventh Annual ACM Symposium Theory Computing STOC2005 2005 pp 396402 30 M Goemans J Kleinberg An improved approximation ratio minimum latency problem Proceedings Seventh Annual ACMSIAM Symposium Discrete Algorithms SODA1996 1996 pp 152158 31 N Hazon Y Aumann S Kraus Collaborative multi agent physical search probabilistic knowledge Proceedings Twentyﬁrst International Joint Conference Artiﬁcial Intelligence IJCAI2009 2009 pp 164167 32 N Hazon GA Kaminka Redundancy eﬃciency robustness multirobot coverage Proceedings 2005 IEEE International Conference Robotics Automation ICRA2005 2005 pp 735741 33 W Herroelen R Leus Project scheduling uncertainty Survey research potentials European Journal Operational Research 165 2 2005 289306 34 T Ilhan SMR Iravani MS Daskin The orienteering problem stochastic proﬁts IIE Transactions 40 4 2008 406421 35 J Kephart A Greenwald Shopbot economics Autonomous Agents MultiAgent Systems 5 3 2002 255287 36 J Kephart J Hanson A Greenwald Dynamic pricing software agents Computer Networks 32 6 2000 731752 37 S Koenig M Likhachev Fast replanning navigation unknown terrain IEEE Transactions Robotics 21 3 2005 354363 38 BO Koopman Search Screening General Principles Historical Applications Pergamon Press 1980 39 E Koutsoupias CH Papadimitriou M Yannakakis Searching ﬁxed graph Proceedings 23rd International Colloquium Automata Lan guages Programming ICALP1996 1996 pp 280289 40 S Lippman J McCall The economics job search A survey Economic Inquiry 14 1976 155189 41 A Lucena Timedependent traveling salesman problem deliveryman case Networks 20 6 1990 753763 42 J McMillan M Rothschild Search R Aumann S Amsterdam Eds Handbook Game Theory Economic Applications Elsevier 1994 pp 905 927 Chapter 27 43 E Minieka The delivery man problem tree network Annals Operations Research 18 14 1989 261266 44 MJ Osborne A Rubinstein A Course Game Theory The MIT Press 1994 45 ML Puterman Markov Decision Processes Discrete Stochastic Dynamic Programming WileyInterscience 1994 46 I Rochlin D Sarne M Laifenfeld Coordinated exploration shared goal costly environments Proceedings 20th European Conference Artiﬁcial Intelligence ECAI2012 2012 pp 690695 47 S Sahni T Gonzales Pcomplete problems approximate solutions Proceedings 15th Annual Symposium Switching Automata Theory SWAT1974 1974 pp 2832 48 D Sarne S Kraus Managing parallel inquiries agents twosided search Artiﬁcial Intelligence 172 45 2008 541569 49 LS Shapley Stochastic games Proceedings National Academy Sciences USA 39 10 1953 10951100 50 D SimchiLevi O Berman Minimizing total ﬂow time n jobs network IIE Transactions 23 3 1991 236244 52 N Hazon et al Artiﬁcial Intelligence 196 2013 2652 51 R Sitters The minimum latency problem NPhard weighted trees Proceedings 9th Conference Integer Programming Combina torial Optimization IPCO2002 2002 pp 230239 52 SV Spires SY Goldsmith Exhaustive geographic search mobile robots spaceﬁlling curves First International Workshop Collective Robotics 1998 pp 112 53 A Stentz The focussed D algorithm realtime replanning Proceedings 14th International Joint Conference Artiﬁcial Intelligence IJCAI1995 1995 pp 16521659 54 X Sun W Yeoh S Koenig Dynamic fringesaving A Systems AAMAS2009 2009 pp 891898 Proceedings 8th International Joint Conference Autonomous Agents Multiagent 55 T Tsiligirides Heuristic methods applied orienteering Journal Operational Research Society 35 9 1984 797809 56 IR Webb Depthﬁrst solutions deliveryman problem treelike networks evaluation permutation model Transportation Sci ence 30 2 1996 134147 57 Martin L Weitzman Optimal search best alternative Econometrica 47 3 May 1979 641654 58 RJV Wiel NV Sahinidis Heuristic bounds test problem generation time dependent traveling salesman problem Transportation Sci ence 29 2 1995 167183 59 T Will Extremal results algorithms degree sequences graphs PhD thesis University Illinois UrbanaChampaign 1993 60 K Williams J Burdick Multirobot boundary coverage plan revision Proceedings 2006 IEEE International Conference Robotics Automation ICRA2006 2006 pp 17161723 61 C Yang A dynamic programming algorithm travelling repairman problem AsiaPaciﬁc Journal Operations Research 6 10 1989 192206