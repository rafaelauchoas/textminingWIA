Artiﬁcial Intelligence 173 2009 11541193 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint From textual description accident causes Daniel Kayser Farid Nouioua 1 Laboratoire dInformatique ParisNord UMR 7030 du CNRS Institut Galilée Université Paris 13 99 avenue JeanBaptiste Clément F 93430 Villetaneuse France r t c l e n f o b s t r c t Article history Received 29 September 2008 Received revised form 7 April 2009 Accepted 23 April 2009 Available online 6 May 2009 Keywords Natural language understanding Causal reasoning Norms Inferencebased semantics Seminormal defaults Every human reading short report concerning road accident gets idea causes The work reported attempts enable determine causes event textual description It relies heavily notion norm reasons The notion cause debated remains poorly understood postulate people tend cause abnormal event like accident fact speciﬁc norm violated Natural Language Processing given prominent place deduction concerns Semantics truthbased inference However normbased inference powerful technique conclusions human readers derive text The paper describes complete chain treatments text determination cause The focus set called linguistic semanticopragmatic reasoning The extracts socalled semantic literals result parse reduces description accident small number kernel literals suﬃcient determine cause Both use nonmonotonic reasoning viz LPARSE SMODELS Several issues concerning representation modalities time discussed illustrated examples taken corpus reports obtained insurance company 2009 Elsevier BV All rights reserved 1 Motivation 11 Basic postulates The work described grounded postulates perceived cause event norm event perceived normal violation norm event considered abnormal semantics natural language NL based notion truth norms Corresponding author Email addresses DanielKayserlipnunivparis13fr D Kayser FaridNouioualipnunivparis13fr Faridnouiouaunivcezannefr F Nouioua 1 Now Laboratoire des Sciences lInformation et des Systèmes UMR 6168 du CNRS Université Paul Cézanne AixMarseille 3 Avenue Escadrille NormandieNiemen 13397 Marseille Cedex 20 France 00043702 matter 2009 Elsevier BV All rights reserved doi101016jartint200904002 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1155 The notion norm plays central role paper descriptive prescriptive meaning2 In descriptive sense norms explains difference perceived normal In prescriptive sense norms build corpus basis agent considered legally entitled perform action In Artiﬁcial Intelligence meanings given rise separate ﬁelds study On hand nonmonotonic logics developed order derive conclusions considered normal absence speciﬁc circumstance invalidating derivation On hand deontic logics purpose formalizing reasoning agents respecting normative prescriptions 81748 In paper norms generally taken descriptive sense clearly normal follow rules acceptation norms includes special case prescriptive sense deal duties normative Our ﬁrst postulate concerns old controversial issue sensible A causes B Deter mining essence notion cause agenda Artiﬁcial Intelligence However commonsense reasoning makes intensive use causation diagnosing planning predicting AI 3355 completely ignore debate concerning notion What AI needs concern meta physics cause people reason causally And observation reveals use word cause mean different things word polysemic vast majority cases causal abnormal event fact agent violated norm We report paper psychological experiment showing violations selectively chosen causes event Consider second postulate dealing sentence The car braked suddenly A truthbased approach 132735 derive conclusions C logically follow existence time t car c following propositions true t c brakes suddenly ii c located writer Clearly propositions valid logical sense come mind human reader iii t writer driving iv driving direction c v vehicle c himher vi act quickly order prevent accident Subsequent information force reader retract conclusions Nonetheless likely present mind person shares culture necessity consider separately propositions C derived means truthpreserving operations ones said pertain semantics according prevailing theories propositions derived means norms generally said result pragmatics Knowing norms domain absolutely necessary understand texts domain But exists exhaustive list norms ruling given domain rules regulations visible iceberg know implicit domain An indirect consequence study point examining people ascribe causation events happening domain powerful means reveal implicit norms 12 Speciﬁcation goal In order validate postulates need focus domain number norms remains reasonable abnormal events frequent events reported natural language easy ask people cause events reported We selected domain road accidents following reasons A large number short texts exists describing accidents insurance company receives daily number forms ﬁlled drivers describing happened Most people culture know car crashes sensible answers having read text asked caused accident Each report describes facts clearly implies number facts logically entailed We postulates work check reasoning based norms captures kind reasoning reader An accident anomaly text generally goes anomaly allegedly explains happened We test anomaly taken cause accident conﬁrm inﬁrm ﬁrst postulate The number norms involved large small They clearly limited listed Highway Code The corpus perform study studied different points views See example 601934 The work presents produces automatically 3D scene accident textual description3 2 Von Wright 62 Chap 1 discusses greater details meanings word norm 3 Another study 63 concerns British records road accidents authors use description logic order check consistency natural language report coded data components record 1156 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 However drawback corpus worth mention Most reports sent driver insurance company obvious reasons biased order lessen authors responsibility rhetorical aspect plea interferes basic descriptive report truthful The fact texts necessarily reﬂect happened se problem norms domain better revealed true descriptions mean biased ones The unwanted consequence choice corpus requires effort identify time ignore added pure argumentative reasons A study currently progress examines speciﬁcally argumentative strategies authors highlight minimize aspects accident order convey best possible impression behavior 9 As dimension reports affect results present work We obtained courtesy MAIF insurance company number reports written French Some unclear accompanying drawings understandable We discarded kept selfcontained basis understood happened build hypothesis justify cause accident Our ﬁrst intention write program ﬁnds causes human readers This objective presupposes human readers agree causes But recent experiment conducted colleagues Laboratoire Travail et Cognition Université ToulouseLeMirail reports appeared having clear cause shows subjects wider diversity opinion expected Therefore start want obtain actually obtain good correspondence intuition cause result program This proves reasonable model causal reasoning Moreover subjects experiment answer differing expectation higher importance norms use notion norm ascribe cause shows captured fair extent general features human causal reasoning 13 Methodology The strategy development simpler started language proceeded different steps architecture natural order morphosyntax semantics pragmatics However require solving hard linguistic problems knowing crucial task It turns linguistic complexity scope modals precise interpretation grammatical tenses relevant argumentative report ﬁrst I thought I realized dropped core search causes accident We adopted reverse strategy started corpus 73 texts later called training sample basis identiﬁed semantic literals set concepts relevant causal reasoning This set satisfy main conditions To accessible texts represent pieces information evoked explicitly texts To suﬃciently ﬁnegrained discriminate texts sharing similar features cause accident according human readers different The method identify set ensures respect conditions took turn different sentences texts training sample extracted manually concepts refer following intuitive principles ﬁrst ignore passages written purely argumentative reasons description damage help determine cause accident The second principle stay level granularity close text choose concepts direct translation words linguistic expressions possible altering causal ascription merge single concept linguistic terms differ connotative power We deﬁned way 50 semantic literals necessary suﬃcient carry endeavor successful end Moreover soon identiﬁed limited subset semantic literals called kernel terms possible causes expressed Section 611 After having chosen set semantic literals training texts step strategy develop semanticopragmatic reasoning4 texts assumption succeed extracting semantic literals texts The linguistic reasoning later developed analogously going text required result semantic literals input necessary result input consists set called linguistic literals syntactic relations words text assumed parser While developing semanticopragmatic linguistic reasoning continued collect reports keeping aside validation purposes As appears clearly results Section 8 selection semantic literals 4 The semanticopragmatic reasoning infers cause accident described text semantic literals D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1157 kernel fairly good allows analyze correctly new reports differ considerably training sample Finally parsers available work satisfaction developed parser added set posttreatment heuristics adapt output required input linguistic reasoning The semanticopragmatic linguistic reasoning represent main parts importance given implements hypotheses norms causes In contrast parsing task importance respect objectives work developed ensure complete chain treatment late stage project reports available That consider validation process 14 Plan paper The plan paper follows Section 2 introduces notion causation seen AI point view Section 3 gives overview general architecture All modules importance study focuses semanticopragmatic processing corresponds causal reasoning The morpholexical syntactic treatments needed build complete chain text cause treated cursorily admittedly contain ad hoc features contain original points brieﬂy presented Section 4 presents representation language paper different layers represen tations needed progressively elaborate cause textual input The general idea use ﬁrstorder reiﬁed language simulates secondorder features like quantifying properties kind modal reasoning The formulas language represent norms nonmonotonic rules Section 5 describes linguistic reasoner process takes place parser completed work uses commonsense knowledge correct mistakes parser solves anaphora infers semantic propositions assigns proposition temporal state Section 6 presents semanticopragmatic reasoner process starts semantic literals obtained linguistic reasoner uses common knowledge infer implicit information situation described text This reasoning process stops soon cause accident determined expressed violation norm In Section 7 discuss implementation issues We ﬁrst brief overview answer set programming paradigm Then explain use translate default inference rules extended logic programs Section 8 devoted validation It subsections One assess agreement causes considered intuitively cause accident selected text corpus Unsurprisingly agreement good 73 training texts remarkable 87 texts kept validation Moreover order test robustness main modules considered inputs actual input ideal input crafted manually order contrast results operated noisy data received upstream modules performances clean data A second confront results answers provided subjects psychological experiment 10 texts Appendix A selected representativeness We present conclusions 2 Causation AI As noted introduction causation extremely controversial notion AI need contro versy But user notion notice usual cases humans causes event isare abnormal factors enable event place Here word factor taken absolutely neutral cause physical mental event nonevent fact expected event occur general speciﬁc principle law comes mind asked caused happen A revealing example taken inﬂuential books causation 45 goes follows explosion happens lit cigarette cause explosion If event takes place home answer gas leaking occurs oil reﬁnery sensible answer smoking places forbidden In ﬁrst case smoking abnormal presence ﬂammable material opposite true second case The extremely rich literature causation dates antiquity nowadays deeply inﬂuenced controversies bygone ages Anyway little help want hints discover cause abnormal event described text There studies aim ﬁnd explicit causal links texts French 21 discuss difference meaning diverse means language uses express causal links 52 extract automatically causal knowledge NL texts 12 But tell answer whyquestions 40 author explicit causal links text 1158 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 A large number psychological experiments conducted examine subjects attribute causal power circumstances accept causal transitivity causation relates explanation parameters affect judgments causal responsibility 3129 Most time interested knowing cause x long x happen want prevent happening want This reason theories concerning nature causation usable ones everyday life ones based intervention Admittedly interventionist conception ﬁt common causal assertions moon causes tide consider sentences evoke metaphorical situation intervention remove moon observe longer tide But current uses notion cause easy bring light actions justify resorting notion Many technical approaches causal reasoning explicit appeal idea propagation 15 determination exogenous variables 33 ways idea acting tracing effect action brought reasoning Even philosophers opposed interventionist conception causality 37 contrast allegedly objective notion cause ﬂexible notion causal responsibility Therefore appropriate AI tools reason causes closely related representation actions inﬂuential AI works causation incorporate theories action For instance Drew McDermotts 47 predicates pcause ecause deﬁned framework socalled chronicles dense sets states ordered tree like time structure node tree represents choice action representation framework 5 seen elaboration early work The nonmonotonic causal logic discussed 251 represents causality introducing new causal operator deﬁne causal rules The resulting causal theories represent properties actions like concurrently executed actions nondeterministic actions actions conditional effects Another formalization causal dependencies actions direct indirect effects proposed 24 In work conditional logic conditional implication interpreted causal implication In case notion action goes notion conditions enabling action succeed wellknown qualiﬁcation problem cf 23 propagation effects ramiﬁcation issues cf 61 Pearls 55 fundamental work causality assigns central role operator order explicit dif ference follows observed correlation intervention 30 introduces notion actual cause cause explains effectively given event speciﬁc scenario This idea matches concern primary anomaly Sections 43 65 developed different context orig inated meet needs control theory equations describing physical given problem determine variables act obtain desired behaviors avoid undesired ones Halpern Pearl use structural equations capture dependencies socalled endogenous variables ones act endogenous variables exogenous variables external The interventionist aspect theory clear fact cause event modiﬁcation result intervention value endogenous variables exogenous ones In context model physical want matter fact texts physical world represented according scientiﬁc physics The choice scientiﬁc physics computationally expensive include large number parameters representationally inadequate value number parameters present derivable text worse texts written experts mechanics drivers likely share misconceptions force energy common population 32 What makes sense translatable terms scientiﬁc physics Finally cause perceived readers generally amenable contrary control theory change value parameter Dubois Prade 18 tackle problem similar interested perceived causality suppose domain represented set structural equations They use instead Kraus Lehmann Magidors relation nonmonotonic deductibility 3839 Despite fact relation developed consideration temporal evolution use express beliefs agents concerning normal course events agent believes context C B follows normally A accepts deductibility relation C A B If context observes B time t takes B persistent observes event A occurs time t B true time t 1 A cause B5 Our approach differs theirs aspects express norm ﬁnd necessary explicit temporal direction given situation normal expectations concerning future normal postdictions confused 38 nonmonotonic scheme acknowledge explicitly possibility having extensions However multiplicity extensions corresponds real phenomenon natural languages texts truly 5 A comparison approaches causal ascription precisely domain road accidents 4 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1159 ambiguous Even phenomenon seldom present corpus prefer use tools able account choice representation language Section 4 3 Architecture NaturalLanguage understanding 31 General AI researchers sought build systems understand NL After ﬁrst limited spectacular attempts answer questions asked NL narrow domain 26 solve problems expressed NL 7 turned diﬃcult problems adopted stratiﬁed architecture morpholexical issues solved ﬁrst comes parser result parser interpreted semantically order build representation literal meaning ﬁnally pragmatic step ﬁnds meaning makes sense interaction speakerwriter hearerreader Each step carried care resources possible order feed step reliable data However despite remarkable increase capabilities computers architecture limited suc cess reasons goal separate step deﬁned theoretical level faced concrete texts unclear correct solution agreement annotators reached artiﬁcial conventions The second reason requirement optimality step misguided fect sense texts spelling syntactic andor semantic mistakes long information sources compensate corrupted items It language comprehension result equilibrium number linguistic extralinguistic constraints result oneway deductive process starting textual input yielding end product nature The reason stratiﬁed architecture widely alternatives diﬃcult construct architecture based blackboards semanticallydriven parses multiagent systems forth tried lack principled rules generally worked restricted environments The architecture developed present study original looks like stratiﬁed ones suffers adhoc features Its original features nonetheless follows basic mechanism inference stage works hypothesis input imperfect results imperfect logic underpinning inferences nonmonotonic separation semantics pragmatics goaloriented architecture designed order converge small variety possibilities Each stage seen reduction fewer dictionary entries morphological forms concepts words far potential causes accident combinations relevant concepts This architecture obviously inadequate handle arbitrary texts arbitrary purposes believe learn factoring makes taskoriented systems work satisfactorily conceiving general language toolbox More speciﬁcally architecture described Fig 1 Before examining turn components idea corpus operate 32 The corpus As said earlier started 73 reports training sample kept aside reports collected af terwards All reports ﬁltered criterion discarded consider selfcontained We ended 160 reports selected diversity sample 10 reports psychological experiment This sample provided Appendix A corpus available web page httpwwwlipnunivparis13frkaysercorpus160pdf The spelling mistakes blatant stylistic inadequa cies corrected names people locations erased rest including lexical oddities discrepancies academic French kept The following ﬁgures idea nature corpus 160 reports contain 380 sentences altogether 58 reports 36 sentence report 10 sentences The length report goes 7 184 words The length sentence goes 2 48 words The overall size sample 6790 words 1242 distinct forms occur forms stem 868 distinct dictionary entries maximum number forms dictionary entry 14 reached auxiliaries être avoir 33 Morpholexical level In sense skipped diﬃcult issues level provided list forms appearing corpus form annotated syntactic classes takes 1160 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 Fig 1 Overall architecture corpus We identiﬁed 10 main syntactic classes adverbials A subordinations B coordinations C determiners D nouns N pronouns O prepositions P qualiﬁers Q relatives R verbs V subclasses gender number D N O Q tense person V For example avancée VsFS avant NMS avant QNS avant P avancée noun French corpus verb V avancer forward tense past participle s feminine F singular S On contrary avant possible syntactic classes present corpus noun N lavant du véhicule vehicle case masculine singular MS qualiﬁer Q la porte avant le phare avant door light case singular masculine feminine N neutral preposition P avant le choc shock The diﬃculties solved elision E polylexical units units extending words The entry elided form provided form polylexical unit selected key unit ﬁrst L S word depending likely autonomously We key list words unit For instance aux Eàles afin LdeP conséquent SparA means respectively aux elided form sequence à les aﬁn ﬁrst word polylexical unit aﬁn preposition P conséquent word polylexical unit par consequent consequently adverbial A 34 Syntactical level The multiplicity syntactic classes ambiguity polylexical units sequence built isolated words lead short sentences hundreds thousands distinct decompositions Only couple worth considering parse We adopted solution similar old systèmesQ 14 instead D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1161 ﬁrst building possibilities eliminating impossible considered directed acyclic graph choice corresponds node having successors different alternatives successor Once graph built small number rules applied order prune paths contain sequence categories French completely implausible car crash reports This technique reduces number paths considered dozen The step group sequences categories build noun phrases verb phrases prepositional phrases It easy replace graph sequences macrounit Then sequence macrounits examined order ﬁnd ones follow regular patterns French sentences Again paths survive remaining Each path analyzed syntactic relations elements explicit Example Je circulais sur la voie droite lit I drove lane right subject circulais je6 compl_v sur circulais voie compl_n voie droite qualif_v circulais imparfait subject drove I verbal complement drove lane noun complement lane right verb qualiﬁcation drove imperfect The results obtained technique contain mistakes The reasons focused com mon constructions neglecting correct ordinary turns nonetheless present corpus ii writers ignore rules academic language assume rightly reader ﬁnd correct meaning incorrect sentence Rather writing complex rules prefer yield erroneous predicates rely subsequent stages things right 35 Discussion We actually use morpholexical syntactic analyzers available shelf Several preliminary experiments dissuaded One best morpholexical analyzers French Treetagger7 yields generally good results sentences makes number blunders easily avoided soon domain known For example takes chaussée causeway past participle verb chausser shoe disturbed expressions like véhicule A véhicule B extremely frequent corpus randomly assigns categories A B We tried write ad hoc rules correct blunders practical work managing thousand forms remains easy handle vocabulary bigger order magnitude adaptation Treetagger similar program better choice Similarly tried use commercially available free parsers French The resulting trees unus able Our ﬁrst write grammar encompasses exactly possible speciﬁcity corpus complete analysis sentence We written set 400 contextfree rules But extremely ad hoc improvements number parses sentence low average climb nearly 1000 worst cases When realized subsequent steps need complete structure sentence easily available relationships erroneous relations harmful thought opted solution described 4 Representation The different steps treatment designed order converge identiﬁcation cause accident We ﬁrst identiﬁed predicates kernel suﬃcient identify according intuition cause accident reported corpus Section 611 As transforming result parse set propositions predicates kernel single step implemented sequence trans lations Each step sequence consists inferring conclusions new predicates presumably closer kernel premises expressed old predicates closer natural language We treatments represented Fig 1 inference engine working different layer representation However layers share general format 41 Reiﬁcation The different layers ﬁrstorder languages They differ set predicate symbols result parse uses grammatical predicates subject qualiﬁcation semanticopragmatic reasoner uses predicates samelane 6 In order distinguish occurrences word arguments syntactic relations ranks words instead words words readability 7 Treetagger available web address httpwwwimsunistuttgartdeprojektecorplexTreeTagger 1162 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 follows kernel contains predicates hascontrol isstopped They differ arguments result parse words later treatments concepts temporal states However order homogenize possible treatments follow general principles The ﬁrst principle widespread AI reiﬁcation It prevents resorting higherorder logics sense allows representation cope modalities introducing modal logics As matter fact writing holds follows veh_A veh_B instead follows veh_A veh_B makes possible stay ﬁrst order logic factoring property common positional predicates A terminological diﬃculty arises follows normally predicate symbol technically constant In rest paper reserve term predicate predicates reiﬁed logic holds predicate use property denote predicate ordinary logic follows property properties encompass heterogeneous concepts like actions effects We immediately meet problem holds like predicate given ﬁxed arity statements represented involve variable number arguments We circumvent adopting following convention holds ternary predicate arguments property sense agent temporal marker Whenever property involves arguments binary function combine creates new property property extra arguments For instance express vehicle A follows vehicle B time 3 write holds combinefollows veh_B veh_A 3 exists complex property follow veh_B agent veh_ A satisﬁes time 3 Should arity basic property greater application combine iterated times necessary This convention analogous treatment adopted Montague grammars 51 statements type t obtained application elements type te elements universe type e agents elements type te intransitive verbs built elements type tee transitive verbs combined argument type e similarly combine creates unary property binary argument Another drawback reiﬁed languages boolean operator properties axiomatized instead given free standard languages However turns need explicit operators properties negation Therefore introduce function axiom 1 P holds notP A T holds P A T 42 Modalities One beneﬁts reiﬁcation fact reiﬁed logic predicates play role modalities ordinary logic use need introducing new symbols Duties play important role application perceived abnormal traced agent comply hisher duties To way corresponds interventionist conception causality interested causes event e insofar ﬁnd held responsible necessarily legal sense following agent endowed free time past possibility action according hisher decision normal course events followed includes event e 36 So fact agent duty doingnot action opposite good candidate cause anomaly We write duty P A T denote fact time T agent A duty making P true P simple complex property notP combinePA But circumstances agents duties able comply instance agent duty stopping reason lost control hisher vehicle In case cause accident reason loss control fact agent stop To express kind situation introduce modality is_able_to P A T denote fact time T agent A possibility making P true P simple complex property D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1163 The modalities look like necessity possibility sense respectively But acces sibility relation regard Therefore usual duality obvious having duty stop different having capacity Another modality availability action presented time Section 64 43 Anomalies Our goal identify cause accident cause understood written report truthful Our postulate says accident perceived abnormal cause anomaly We need language predicate denoting abnormalities The previous section alludes fact kinds anomalies exist anomaly derived explained earlier anomaly agent stop stop abnormal behavior anomaly gets explanation text agent lost control icy patch anomaly derived anomaly primary implied text allows attribute earlier event Therefore language contains distinct predicates Derived_anomaly P A T Primary_anomaly P A T denote abnormal property P happened agent A time T anomaly respec tively derived primary 44 Nonmonotonicity According views understanding natural language amounts reasoning linguistic extralinguistic premises The notion norm plays central role goes idea exception norm describes happens generally The logics incorporating notion exception nonmonotonic In practice need nonmonotonic logics cope situations information changes account cause accident For example read driver vehicle B lost control hit car causal reasoning ﬁnd loss control primary anomaly cause accident Now sentence reads Vehicle B lost control icy patch causal reasoning conclude loss control represents derived anomaly primary anomaly presence icy patch road AI developed large number nonmonotonic schemes multiextensional We require multi extensional logics reasons adequacy cases sentence yield readings reasoning capability yield sets conclusions But selected texts corpus clarity expect unique extension As matter fact getting extensions served signal bugs Should nonetheless case arise rerun search anomalies extension possibly ﬁnd different causes accident depending reading The reasons linguistically consistent readings eliminated heterogeneous polysemy words grammatical constructions resolved knowledge domain The pragmatics writing insurance company plays role interpretations I1 I2 linguistically possible I1 increase responsibility writer I2 neutral favorable extremely likely I1 meaning intended writer All reasons default conclusions acceptable point defeated siderations taken account words default priority defaults Technically amounts selecting logic semimonotonic 11 We chosen Reiters seminormal defaults 5657 nonmonotonic nonsemimonotonic logic en dowed multiextensionality easily translatable Answer Set Programs Section 7 Seminormal default theories extensions unlikely cases 20 We adopt convention ﬁnd readable Reiters original notation8 Normal defaults written A B instead AB B Seminormal defaults written A B C instead ABC B 8 According Reiters convention default containing free variables stands set defaults variables replaced elements Herbrands base Moreover free variables regular ﬁrstorder formulas considered implicitly universally quantiﬁed 1164 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 For implementation reasons limit forms inference rules Let A1 An B C1 Ck ﬁrst order literals An inference rule forms iiii A1 An B A1 An B A1 An B C1 Ck ii iii usual material implication B inferred extension A1 An belong extension ii normal default B inferred extension A1 An belong extension long consistent iii seminormal default B inferred extension A1 An belong extension long consistent Ci 1k belongs extension 45 Representing time The reports continuously evolving world Should represent time means continuous functions This closer physical reality allow use scientiﬁc deﬁnitions speed acceleration But explained Section 2 makes sense writers reports translatable terms scientiﬁc physics A second diﬃculty concerns time represented There actually times linear sequence actual events described report possible evolutions agents mind different moments I thought going turn left time writing I realize things happened way spot I believed happened differently It turns second time writers justify behavior showing achieve desirable goals avoid undesirable ones We forget reports mainly descriptive goal reduce responsibility writer accident By limiting representation actual events miss substance On hand creating sequence states future protagonists likely envisioned like McDermotts chronicles 47 increase necessity case number issues solve This reason postulated following hypothesis Hypothesis The detection anomalies requires representation statesofaffairs presented having oc curred potential counterfactual states play role determine expectations protagonists reasons acting acting need represented states se existence implicitly assumed modalities hold states belonging actual unfolding event Corollary The temporal states represented natural numbers This hypothesis given satisfactory results keeping number states small 7 texts analyzed 46 Representing causation We studies 421625 special connector reﬂecting causal implications Instead appear later predicate pot_cause Act Eff represents common belief effect Eff result action Act reading text reporting Eff people naturally mind possibility Act This predicate bijective actions come mind given effect reciprocally action evoke possible outcomes By action mean decision agent having free performing performing Act fact notAct decision acting As view causal reasoning focused intervention prefer ascribe cause abnormal event accident decision known provoke observed effect If decision taken abnormal setting agent duty capacity complying duty decided comply assume primary anomaly Only preference satisﬁed unable ﬁnd intervention action failure act explains accident look external causes As readers willing accept exogenous circumstances causes situations accept nonagentive causes This reason property Disruptive_factor combined arguments icy patch account cases better explained intervention agent D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1165 5 The linguistic reasoner 51 Posttreatments The result provided syntactic analyzer completely suitable fed reasoning process The ﬁrst step consists means posttreatments process rough product analyzer The posttreatments based simple principles advantage speciﬁcity domain Let discuss brieﬂy 511 Correction erroneous subjectverb relations As mentioned Section 34 parser makes number mistakes left uncorrected These mistakes concern mainly predicates expressing subjectverb relations 8 relations produced analyzer erroneous We want ﬁrst detect erroneous relations correct determining correct subject verb We purpose simple heuristic based compatibility semantic features associated subset nouns verbs belonging lexicon This information speciﬁc domain coded boolean matrix Whenever relation subjectV N detected erroneous determination correct subject N based simple strategy gives acceptable results texts Section 8 results We start searching correct subject N text situated verb V search fails look N verb V During ﬁrst search V V present participle followed relative qui likely correct subject far verb look ﬁrst compatible noun pronoun V In cases frequent ones start looking noun N known subject verb semantically compatible V ensures kind syntactic parallelism substitute subjectV N subjectV N Only subject exists limit ﬁrst compatible noun pronoun In cases solution searching V look ﬁrst compatible noun V Example Consider following sentence taken Report B2A corpus Report B2A Le motocycliste qui circulait sur la ﬁle droite dune double voie à sens unique perdu le contrôle son véhicule et dérapé sur une ﬂaque dhuile The motorcyclist drove righthand ﬁle doublelane oneway road lost control vehicle skidded pool oil The subjectverb relations provided parser subject circulait motocycliste subject perdu voie subject dérapé contrôle subjectdrove motorcyclist subjectlost road subjectskidded control The ﬁrst correct road subject lost control subject skidded The mistakes detected noun road nominal feature Lane compatible verbal feature AgentiveVerb associated verb lose Analogously feature VehicleState characterizes noun control incompatible feature MoveVerb associated verb skid Once detected mistakes corrected ﬁrst relation look ﬁrst subject situated verb lose compatible As result ﬁnd noun motorcyclist9 We apply strategy second relation ﬁnd subject feature Person compatible feature MoveVerb 512 Supporting verbs The corpus contains number sentences main verb play usual role verb predicate subject merely introduces alters meaning verb Such verbs called 28 supporting verbs10 For example sentence il est venu heurter mon véhicule lit came hit vehicle 9 The compatibility relation takes account frequent metonymic use names vehicles drivers vice versa 10 Actually use supporting verbs general sense deﬁned 28 works linguistic literature But general idea analogous kept term 1166 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 uses venir come supporting verb heurter hit In example support suppressed altering meaning sentence matter fact draw roughly conclusions sentence il heurté mon véhicule hit vehicle In case cases treating supporting verb boils replacing occurrences literals output analyzer supported verb Here parser provides relation subject venir ilsubject come simply replace subject heurter il subject hit However treat supporting verbs cases require treatments For instance sentence il oublié freiner forgot brake verb oublier forget mainly present argumentative reasons bad guy forgot act necessary treated supporting verb requiring addition literal qualif_v freiner neg verb quali ﬁcation brake neg express subjectverb relation brake taken negatively We listed verbs corpus play role support speciﬁed implemented corresponding treatments 513 Anaphora resolution The resolution anaphora renowned diﬃcult problem NL Processing Our goal propose origi nal approach solve general We simply heuristic adapts wellknown semantic consistency criterion 50 speciﬁc domain We present sketch algorithm details 53 We interested determination references insofar referents active agents accident described vehicles persons Accordingly set possible referents contains following agent names author writer report veh_ A veh_B vehicle_name1 person_name1 11 texts anonymized identify people involved accident replaced generic names For text determine list expressions nouns pronouns possessive adjectives potential designators agent We associate referent property called nature initially default value vehicle better speciﬁed execution algorithm taking values like car motorbike bicycle truck We notice nature vehicle compatible terms terms incompatible In cases reference obvious Words like je mon ma I clearly refer writer cor respond reference author similarly symbols like A B individualize vehicles indicate agents veh_ A veh_B After having resolved trivial cases remaining referents considered according order text To unsolved referent anaphora resolution algorithm decides attribute reference resolved referent create new reference Moreover resolution referent information propagated help systematically solve referents reference propaga tion reﬁne nature reference nature propagation 53 The idea propagation words X Y connected speciﬁc syntactic relations constrained refer reference12 Hence words X resolved anaphor algorithm propagates reference Y The holds nature nature words X speciﬁc nature Y nature X propagated Y words having reference Y For example expres sion ma moto motorcycle reference ma author trivial resolution nature default vehicle nature moto Motorcycle nature propagates nature author takes value Motorcycle The decision create new reference taken cases ﬁrst case arises particular linguistic contexts reinforce likelihood new reference For example referent noun introduced indeﬁnite article followed relative like qui que subject present participle ﬁrst referent introduced text belongs set nouns like voisin neighbor adversaire opponent likely noun creates new reference The second case antecedent nature compatible current referent In contrast set compatible antecedents contains element algorithm chooses nearest reference giving priority reference author stage unlikely referent indicating writer resolved 11 If given text referent simultaneously designated different expressions use order provided section select referred But order critical choice matter 12 If relation compl_n X Y reference Y R reference X R For example le véhicule nom_de_personne Mr Soandsos vehicle reference vehicle Mr Soandso Similarly relation qualif_poss X Y Y possessive reference R reference X R For instance ma moto motorcycle ma trivial reference author propagation assigns reference author moto This rule exceptions neighbor neighbor Author reference Clearly heuristics work speciﬁc context like D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1167 Table 1 Application anaphora resolution algorithm Report B2A Word Reference Nature Motorcycle Type New Comments The noun motocycliste motorcyclist ﬁrst referent introduced text New1 New1 New1 Author Author Moto1 Motorbike1 Il Moto2 Motorbike2 Mon My Véhicule Vehicle Moto3 Motorbike3 Voiture Car Motorcycle Old Motorcycle Old Only antecedent new1 Its nature Motorcycle compatible nature referent Vehicle receives speciﬁc value Motorcycle Only antecedent new1 It shares nature Motorcycle referent Car Car Trivial Introduced beginning algorithm Propagation Propagation means relation qualif_n véhicule mon qualify_poss vehicle New1 Motorcycle Old Two antecedents new1 author By giving priority author choose new1 Author Car Old Two antecedents new1 author The nature Motorcycle new1 incompatible nature Car referent We choose reference author mon véhicule vehicle receive nature Car propagation Example continued Report B2A corpus reads Report B2A Le motocycliste qui circulait sur la ﬁle droite dune double voie à sens unique perdu le contrôle sa moto1 et dérapé sur une ﬂaque dhuile Il été éjecté Sa moto2 est venue heurter mon véhicule roulant à son niveau sur la voie gauche La moto3 heurté lavant buté sur le côté droit la voiture lit The motorcyclist drove right ﬁle doublelane oneway road lost control motorbike skidded pool oil He thrown His motorbike came bump vehicle rolling level left lane The motorbike bumped banged right vehicle The ﬁrst step anaphora resolution algorithm solves trivial references performs ﬁrst propagation associates reference author referents mon véhicule vehicle Table 1 shows algorithm computes references corresponding remaining unsolved referents13 52 Steps linguistic reasoning The syntactic relations extracted text parser adapted posttreatment lexical information provided lexicon explicit textual knowledge available reasoning This knowledge provides set premises socalled linguistic reasoning This reasoning aims constructing expressing explicit content text terms logical language described Section 4 The literals result linguistic reasoning format holds P A T called semantic literals Following goaloriented strategy determined limited list 52 semantic literals Appendix B estimate suﬃcient express relevant information stages causal reasoning The role linguistic reasoning hand reduce variety linguistic expressions present texts limited set semantic concepts hand ﬁnd temporal order events expressed concepts Let notice limitation domain use goaloriented development methodology allow study limited set linguistic phenomena simplify treatment For example choose safely easily appropriate senses words general polysemic consider words synonyms absolutely true general The convergence process semantic literals performed gradually linguistic reasoning main steps Each uses inference rules different nature Fig 2 Let explain principles guiding step 53 Intermediate semantic literals The ﬁrst step linguistic reasoning consists inferring set intermediate semantic literals subset linguistic literals based relations subjectverb verbobject verbcomplement The general form intermedi 13 The new references designated New1 New2 At end algorithm symbols replaced names agents designate referents predetermined list names earlier section The column Reference type indicates way reference calculated trivial obtained propagation mechanism old antecedent compatible new 1168 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 Fig 2 Architecture linguistic reasoning process ate semantic predicate holds_I P_Prop P_Ag temp_refW The _I holds_I stands intermediary distinguishes literals ﬁnal product linguistic rea soner P_Prop P_Ag stand respectively potential property potential agent Intermediary predicates express ﬁrst supposition conﬁrmed disconﬁrmed later property agent genuine semantic literal The parameter temp_refW means temporal reference temporal parameter semantic literal provisionally related word W text This ﬁrst step approaches form semantic predicates remaining level manipulates exclusively words language concepts real world This step motivated mainly methodological reason replaces subset syntactic relations abstract predicates appropriate premises inference The intermediate semantic literals inferred means ﬁve inference rules 26 given Rule 2 normal default adapted intransitive verbs It infers intermediate literals holds_I V N temp_refV relation subject V N Negative propositions treated rule 3 inhibits default 2 Anal ogously rules 4 5 deal transitive verbs lead literals form holds_I combineV O N temp_refV relations subject V N object V O Finally rule 6 capture relation verb subject prepositional phrase 2 subject V N holds_I V N temp_refV 3 subject V N qualif_v V neg holds_I V N temp_refV 4 subject V N object V O holds_I combineV O N temp_refV qualif_vV neg 5 subject V N object V O qualif_v V neg holds_I combineV O N temp_refV 6 subject V N compl_v Z V C holds_I combinecombineZ V C N temp_refZ D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1169 Example Report B2B14 Je circulais1 sur1 la voie1 de1 droite Dans le virage la moto dérapé sur2 des graviers Je suis tombé de2 lengin qui ﬁni sa course sur3 la voie2 de3 gauche Le véhicule1 A circulant2 sur4 cette voie3 na pu stopper et percuté mon véhicule2 I drove1 on1 right lane1 In curve motorbike skidded on2 bits gravel I fell machine ended way on3 left lane2 Vehicle1 A driving2 on4 lane3 stop hit vehicle2 The set linguistic literals extracted text posttreated following subjectcirculer1 author subjectdéraper author subjecttomber author subjectfinir author subjectcirculer2 veh_A subjectstopper veh_A subjectpercuter veh_A objectfinir course objectpercuter author compl_vsur1 circuler1 voie1 compl_vdans déraper virage compl_vsur2 déraper gravier compl_vde2 tomber author compl_vsur3 finir voie2 compl_vsur4 circuler2 voie3 compl_nde1 voie1 droite compl_nde3 voie2 gauche qualif_nvéhicule1 A qualif_posscourse sa qualif_possvéhicule2 author qualif_vcirculer1 imparfait qualif_vdéraper passe_compose qualif_vtomber passe_compose qualif_vfinir passe_compose qualif_vcirculant2 participe_present qualif_vstopper passe_compose qualif_vpercuter passe_compose subjectdrive1 author subjectskid author subjectfall author subjectend author subjectdrive2 veh_A subjectstop veh_A subjecthit veh_A objectend way objecthit author compl_von1 drive1 lane1 compl_vin skid curve compl_von2 skid gravel compl_vfrom fall author compl_von3 end lane2 compl_von4 drive2 lane3 compl_n lane1 right compl_n lane2 left qualif_nvehicle1 A qualif_possway qualif_possvehicle2 author qualif_vdrive1 imperfect qualif_vskid present_perfect qualif_vfall present_perfect qualif_vend present_perfect qualif_vdrive2 present_participle qualif_vstop present perfect qualif_vhit present_perfect The application rules 2 3 yields following intermediate semantic literals holds_Icirculer1 author temp_refcirculer1 holds_Idéraper author temp_refdéraper holds_Itomber author temp_reftomber holds_Ifinir author temp_reffinir holds_Icirculer2 veh_A temp_refcirculer2 holds_Ipercuter veh_A temp_refpercuter holds_Istopper veh_A temp_refstopper holds_Idrive1 author temp_refdrive1 holds_Iskid author temp_refskid holds_Ifall author temp_reffall holds_Iend author temp_refend holds_Idrive2 veh_A temp_refdrive2 holds_Ihit veh_A temp_refhit holds_Istop veh_A temp_refstop Rules 4 5 infer holds_Icombinefinir course author temp_reffinir holds_Icombineend way author temp_refend holds_Icombinepercuter author veh_A temp_refpercuter holds_Icombinehit author veh_A temp_refhit Finally obtain rule 6 literals holds_Icombinecombinesur1 circuler1 voie1 author temp_refsur1 holds_Icombinecombineon1 drive1 lane1 author temp_refon1 holds_Icombinecombinedans déraper virage author temp_refdans holds_Icombinecombinein skid curve author temp_refin holds_Icombinecombinesur2 déraper gravier author temp_refsur2 holds_Icombinecombineon2 skid gravel author temp_refon2 14 Reports B2A B written protagonists accident happened aﬃliated insurance company 1170 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 holds_Icombinecombinede2 tomber author author temp_refde2 holds_Icombinecombinefrom fall author author temp_reffrom holds_Icombinecombinesur3 finir voie2 author temp_refsur3 holds_Icombinecombineon3 end lane2 author temp_refon3 holds_Icombinecombinesur4 circuler2 voie3 veh_A temp_refsur4 holds_Icombinecombineon4 drive2 lane3 veh_A temp_refon4 54 Atemporal semantic literals This second step deals semantic content aims producing version semantic literals close ﬁnal version differs temporal parameters remain unsolved stage That reason literals resulting step called atemporal This step effectively performs convergence limited set concepts necessary start semantico pragmatic reasoning The inference rules active step 300 rules capture relevant concept different linguistic contexts lead detect presence They associate inferred concept appro priate temporal reference remains expressed means word text In order factor common classes words avoid completely ad hoc stage lexical information categorize words semantic classes types This enables group rules completely instantiated arguments premises merely words leads better level abstraction Although rules remain dependent particular domain small subset rules high level generality easily transported domains rules 710 These rules capture cases direct passage verb transitive intransitive linguistic arguments linguistic level property parameters conceptual level We introduced literal type V direct_trans verb V characteristic holds The binary predicate sem_rep P Q semantic representative holds Q semantic constant concept associated word P 7 type A vehicle type P direct_trans intransitive P sem_rep P Q holds_I P A T holds Q A T 8 type A vehicle type P direct_trans intransitive P sem_rep P Q holds_I P A T holds Q A T 9 type A vehicle type B object type P direct_trans transitive P sem_rep P Q holds_I combineP B A T holds combineQ B A T qualif_v P passive 10 type A vehicle type B object type P direct_trans transitive P sem_rep P Q holds_I combineP B A T holds combineQ B A T qualif_v P passive Example continued The verbs circuler drive déraper skid tomber fall stopper stop percuter hit present text B2B belong class verbs directly translatable semantic predicates All verbs transitive We following literals typecirculer direct_trans typedéraper direct_trans typetomber direct_trans typestopper direct_trans typepercuter direct_trans transitivepercuter intransitivecirculer intransitivedéraper intransitivetomber intransitivestopper typedrive direct_trans typeskid direct_trans typefall direct_trans typestop direct_trans typehit direct_trans transitivehit intransitive drive intransitive skid intransitive fall intransitive stop We following predicates concerning semantic classes verbs sem_repcirculer is_moving sem_repdéraper is_slipping sem_reptomber is_falling sem_repdrive is_moving sem_repskid is_slipping sem_repfall is_falling D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1171 sem_repstopper Stop sem_reppercuter is_hitting sem_repstop Stop sem_rephit is_hitting Rules 7 8 9 applied Rule 7 applies intransitive verbs aﬃrmative form yields holdsis_moving author temp_refcirculer1 holdsis_moving author temp_refdrive1 holdsis_slipping author temp_refdéraper holdsis_slipping author temp_refskid holdsis_falling author temp_reftomber holdsis_falling author temp_reffall holdsis_moving veh_A temp_refcirculer2 holdsis_moving veh_A temp_refdrive2 Rule 8 transitive verbs negative form infers holdsStop veh_A temp_refstopper holdsStop veh_A temp_refstop The default 9 transitive verbs aﬃrmative form active voice gives holds combineis_hitting author veh_A temp_refpercuter holdscombineis_hitting author veh_A temp_refhit The default 10 example works transitive verbs negative form active voice Similar rules transitive verbs passive In addition rules deal directly trans latable verbs need speciﬁc rules rules 1112 Appendix C 55 Final semantic literals The thing obtaining set semantic literals represent text evokes explicitly replace temporal references linked words integers reﬂecting linear order events described text In general linear order events far linear order narration Our strategy consider default orders coincide constraints impose incompatibilities So linear order narration starting point bring changes necessary satisfy temporal constraints obtained appropriate inference rules 551 Inferring temporal constraints The temporal model adopted approach discussed Section 45 Let recall postulate linear order events described text suﬃcient purpose Moreover temporal model remains neutral temporal parameter stands interval time point Consequently relevant relations context immediate precedence simultaneity expressed respectively precR1 R2 simulR1 R2 R1 R2 temporal references need Allens relations 2 To extract automatically temporal relations written 50 inference rules exploit general linguistic markers common sense knowledge Again inference rules general easily reused domains based information grammatical tenses general common sense knowledge causes precede effects dependent particular domain car accidents rules 1314 Appendix C 552 Resolving temporal constraints At stage set atemporal semantic literals set precedence andor simultaneity constraints We sketch algorithm possibly alters temporal structure obtained merely following narration order satisfy temporal constraints Let refM1 refMn temporal references involved atemporal literals built far words M1 Mn appear text order R1 Rm temporal constraints Each reference temp_refMi ﬁrst associated integer goal ﬁnd integer Ti replaces end algorithm provisional parameter temp_refMi We deﬁne temporal structure S sequence T1 Tn The general schema algorithm follows details given 53 1172 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 Initial step Ti 1 cid2 cid2 n narrative order repeat ﬁnd smallest k 1 cid2 k cid2 m satisfyS Rk modifyS Rk temporal constraints satisﬁed Replace temp_refMi atemporal literal integer Ti satisfyS Rk trivially Rk prectemp_refMj temp_refMi Tj Ti1 return true return false Rk simultemp_refMj temp_refMi Tj Ti return true return false modifyS Rk Rk prectemp_refMj temp_refMi Tj Ti1 Rk simultemp_refMj temp_refMi Tj maxTj Ti close gap renumber Ti way S sequence multi set ﬁrst positive integers The choice maxTj Ti maximum values Ti ans Tj empirically proven good heuris tic Example continued The atemporal semantic literals inferred text B2B holdsis_moving author temp_refcirculer1 holdsis_moving author temp_refdrive1 holdsis_slipping author temp_refderaper holdsis_slipping author temp_refskid holdscombinecause_not_control gravels author temp_refsur2 holds combinecause_not_control gravels author temp_refon2 holdsis_falling author temp_reftomber holdsis_falling author temp_reffall holdsbend author temp_refdans holdsbend author temp_refin holdsis_moving veh_A temp_refcirculer2 holdsis_moving veh_A temp_refdrive2 holdsStop veh_A temp_refstopper holdsStop veh_A temp_refstop holdscombineis_hitting author veh_A temp_refpercuter holdscombineis_hitting author veh_A temp_refhit The initial structure S1 Fig 3 Among precedence relations inferred text relation prec temp_refsur2 temp_refderaper satisﬁed S1 To satisfy relation modify temporal structure S2 satisﬁes precedence relations15 Fig 4 Fig 3 Temporal structure S1 15 In example iteration algorithm satisfy temporal constraints However texts corpus iterations required satisfy D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1173 Fig 4 Temporal structure S2 The ﬁnal semantic literals text B2B holdsis_moving author 1 holdsbend author 2 holdscombinecause_not_control gravels author 2 holdsis_slipping author 3 holdsis_falling author 4 holdsis_moving veh_A 5 holdsStop veh_A 6 holdscombineis_hitting author veh_A 7 56 Discussion Our objective carry complete chain treatment going input text cause accident NL understanding achieved mainly inference process The linguistic reasoning ﬁrst step process Since role prepare input second step semanticopragmatic reasoning section represents main contribution work developed best seeking generality In order generalize approach domains obviously necessary delve deeply lexical syntactic phenomena implement generic solutions problems involved linguistic reasoning This requires general lexical morphological syntactic principles design metalevel abstract patterns inference enabling extract relevant semantic information explicitly conveyed text 6 The semanticopragmatic reasoner The semantic literals resulting previous stage supposed represent relevant information explicitly evoked text This information considered hard longer defeasible Unlike formal semantics kind information main objective case semantic literals starting point semantico pragmatic reasoning goes farther simulating human understanding NL In fact noticed explicit text seldom suﬃcient derive conclusions human reader draws text Human readers jump easily unwarranted conclusions generally conscious time unable tell read derived 10 But reproducing capacity program far obvious To appeal norms domain encode knowledge nonmonotonic inference rules The semanticopragmatic reasoning performs kind expansion process adds semantic literals We distinguish subsets normbased inference rules Fig 5 set general rules add literals expressing properties likely hold situation described set rules inferring duties agents respect avoid potential accident set rules infer agents capacity respect duties The expansion phase followed process aims pick conclusions obtained far contribute determination cause accident This process kind convergence variety predicates resulting analysis limited number semantic literals kernel In following section discuss ﬁrst ontological elements semanticopragmatic reasoning different steps process running example 61 Some ontological elements The semanticopragmatic reasoning handle NL words replaced concepts previous stages There different natures concepts addition statedependent predicates represent dynamic evolution situation need represent stateindependent predications deﬁne static classes properties involved static relations 1174 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 Fig 5 Architecture semanticopragmatic reasoning process Table 2 The literals kernel holds Stop A T holds Drives_app A T holds Control A T holds Has_driver A T holds Is_moving_off A T holds Is_moving_backwards A T holds On_normal_lane A T holds combine Disruptive_factor X A T A stopped A drives fairly slowly speed appropriate circumstances A control hisher vehicle vehicle A driver A moves hisher vehicle A moves backwards A drives hisher normal lane X disruptive factor A 611 Statedependent predications Statedependent predications truthvalue varies time As discussed Section 45 scene accident decomposed consecutive temporal states characterized set statedependent predications holding state Thus addition predicates described occur rences literals holds P A T duty P A T is_able_to P A T represent major statedependent predications Let focus small important subset predications constitutes kernel The kernel set 8 properties terms cause expressed semantico pragmatic reasoning process converges The kernel literals listed Table 2 The advantage kernel twofold works hand stopping criterion semanticopragmatic reasoning hand ensures kind homogeneity concepts involved expressing causes helpful want compare answers human readers The choice properties kernel guided following principles Suﬃciency The properties kernel suﬃcient express propositions reasonably consid ered causes accidents corpus There far need introduce properties express cause corpus Minimality The number properties kernel minimal No subset kernel able express causes evoked corpus Adequacy The kernel properties situated level granularity corresponds fairly answers expected ordinary human reader asked cause accident 612 Stateindependent predications The stateindependent predications provide variables occurring statedependent predications types Types predicates premises semanticopragmatic inference rules reasons increases level abstraction improves generality rule limits set concepts rules applied limiting range variable The main classes considered discussed D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1175 Effects We mean effects set properties characterize state agent given time Indeed agents state changes soon truthvalue effect changes Stopping driving controlling ones vehicle bumping obstacle examples effects The literal effect F expresses F effect Some effects persistent default truthvalue maintained forward time long action event alters This usual way handle famous frame problem known McCarthy Hayes 46 abundantly described literature The predicate persistent_effectF denotes F persistent effect simple default rule states long consistent F persistent effect holds F A T true resp false holds F A T1 Actions The literal action Act true Act action agent perform voluntarily order achieve effect Braking turning steering wheel examples actions normally lead respectively effects stopping turning right left In context number actions limited An agent want maintain hisher current state especially external event occurs leads undesirable state For purpose special action disposal agent effect F combine Keep_state F action 15 effect F action combine Keep_state F Events The literal event Evt true Evt event From agents standpoint occurs independently hisher considered event For instance outbreak proximity agent obstacle tree animal vehicle object lead himher lose control hisher vehicle example gravels icy patch oil considered events Kernel The fact predicate P belong kernel expressed language literal kernel P Relations concepts We list database number timeindependent relations concepts Let examine main relations To capture fact effects F F fulﬁlled simultaneously temporal state use literal incompatible F F A special case incompatibility relation concerns case effect negation Thus 16 effect F incompatible F notF We list database number facts form pot_cause P F F effect P action event As explained Section 46 relation means P cause comes probably mind ordinary reader learns F occurred Moreover limitation domain allows add following simplifying hypothesis exception given Hypothesis For effect F action Act satisﬁes pot_causeAct F Exception If F persistent abovementioned action keeping state F potential cause F 17 persistent_effect F pot_cause combineKeep_state F F For action Act reach effect F known potential cause agent perform appropriate circumstances qualiﬁcation problem mentioned As want list circumstances use default assumption actions performed situations expected succeed We write precond_act F P express P true supposedly unique action able yield effect F succeed The assumption expressed default case stateindependent predications derive statedependent ones 18 holds F A T precond_act F P holds P A T1 Symmetrically write precond_avoid_event F P P true agent succeed avoiding effect F event 1176 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 62 Inference implicit information Enriching explicit content text implicit information means new idea frames 49 scripts 58 proposed spirit time developed tools handle properly invented suffered lack formalization The remarkable advances AI terms modeling non monotonic reasoning enables adequate account knowledge norms given We explained Section 44 seminormal defaults good candidates express norms need cope with16 The inferred propositions different natures They concern agents duties capacities sections express fulﬁllment properties agents different temporal states scene We developed kind reasoning 200 inference rules concerning topics road domain lines traﬃc control vehicles loss predictability obstacles priority vehicles intersections The reader ﬁnd Appendix C rules 1929 running example treated rules 63 Inference duties In order determine cause accident know duty actions For instance knowledge stop presence red light vehicles The respect duty agent represents obviously important norm N1 In general expect agents respect duties According conception causality determination anomalies based hypothesis accident occurs external abnormal disturbing factor explain accident agent respect norm In case anomalies inevitably involve violation occurrence abstract norm N1 Other norms strengths depending taken primary causes accidents For example situation traﬃc light turns green ﬁrst vehicle second bumps norms violated N2 N3 N2 A vehicle long preceding vehicle N3 A vehicle stopped red light light turns green However prefer cause accident violation second vehicle norm N2 Actually N3 describes expected behavior violation excuse driver second vehicle The obstacle created failure ﬁrst respect N3 dispense himher respecting N2 failing perceived real cause So ﬁnd violation N2 primary anomaly Expressing agents duties required 25 inference rules Those apply running example rules 3033 Appendix C 64 Inference capacities A crucial point detecting anomaly violation norm primary derived consists assessing agent position avoid transition yielding undesired state is_able_to produce prevent given effect More information features actions events needed deﬁne properly predicate We developed 25 inference rules deal capacities agents Unlike rules described previous sections relatively dependent road domain rules concerning capacity characterized higher degree abstraction easily reused domains The literal predictable V A T expresses property event V stateindependent icy patches considered unpredictable causes loss control inferred speciﬁc situations means appropriate rules Xis obstacle A Xis control behavior Xis considered unpredictable A An event V said controllable agent A time T iff V occur time T predictable A position time T satisfy precondition avoidance 16 To preserve eﬃciency computations number default rules small possible This means knowledge represented known exceptions long restricted domain road accidents exceptions unlikely occur express material implication D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1177 34 Event V holds V A T predictable V A T precond_avoid_event F P holds P A T controllable V A T An agent undertake action Act knowing succeed The predicate available meant express far agent knows Act satisﬁes preconditions The literal available Act F A T true iff time T agent A decides execute Act belief effect F obtain A default assumption action available 35 pot_cause Act F action Act available Act F A T This assumption forces enumerate situations action available Several cases unavailability considered presence technical problems precondition action satisﬁed keepstate action available uncontrollable event leads state effect F holds F incompatible F loss control vehicle makes action driver obviously unavailable These cases respectively expressed rules 36 holds combine Tech_Pb Act A T holds Act A T pot_cause Act F available Act F A T 37 action Act precond_act F P holds P A T available Act F A T 38 FV pot_cause V F event V controllable V A T Incompatible F F available combine Keep_state F F A T 39 holds Control A T pot_cause Act F available Act F A T These predicates delimit states agent is_able_to undertake action Intuitively agent A able reach effect F time T iff exists action Act potential cause F available A T 40 is_able_to F A T Act action Act available Act F A T pot_cause Act F Example continued At previous stages duties derived temporal states T fact corresponding effects obtain states T 1 These pairs duty Control author 2 holds Control author 3 duty Has_driver author 4 holds Has_driver author 5 duty Stop author 6 holds Stop author 7 These pairs sign anomalies In order know primary possible causes accident remains seen agent able comply hisher duties Let start looking information capacity agent author control temporal state 2 depends availability action combineKeep_state Control himher state Since loss control resulted occurrence event presence gravels road availability action depends event controllable agent Rule 34 provides information predictable combinecause_not_control gravels author 2 holds Drives_app author 2 Moreover static relation 41 expresses driving slowly precondition able avoid effect event leading lose control 41 objectX precond_avoid_event combinecause_not_control X notControl Drives_app 1178 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 X gravels precond_avoid_event combinecause_not_control gravels notControl Drives_app In situation precondition fulﬁlled Therefore rule 34 infers controllable combinecause_not _control gravels author 2 Applying rule 38 V combinecause_not_control gravels F Control F notControl A author T 2 obtain available combineKeep_state Control Control author 2 With conclusion deduce 40 is_able_to Control author 2 For second pair capacity time 4 agent author inside hisher vehicle depends information controllability ejection author We inferred event predictable time 4 predictable is_falling author 4 Consequently deduce rule 34 controllable is_falling author 4 Analogously previous case obtain literal available combineKeep_state Has_driver Has_driver author 4 And consequently result is_able_to Has_driver author 4 The pair requires assessing capacity agent author stop time 6 To seek action braking available author time 6 The fact agent author control state 6 triggers following rule 42 42 holds Control A T pot_cause Act F kernelF available Act F A T This rule allows infer A author T 6 Act brake F Stop available brake Stop author 6 Eventually rule 40 provides wanted know agent author able state 6 stop order avoid collision is_able_to Stop author 6 65 Detecting anomalies Having enriched initial set semantic literals implicit information stage semanticopragmatic reasoning process consists selecting elements necessary detect primary derived anomalies It case elements lead primary anomaly derived ones In cases primary anomaly situated temporal states corresponds precondition hold necessary success action leading avoid accident Some inferences applied order solve case For detection anomalies written 8 inference rules We formal description primary derived anomalies introduced informally Section 43 running example sequence inferences enable detect primary anomaly As said earlier forms primary anomalies The ﬁrst 43 corresponds case agent A having duty capacity time T achieve effect F observe effect F incompatible F holds time T1 43 duty F A T is_able_to F A T holds F A T1 incompatible F F Primary_anomaly F A T1 The second form primary anomaly 44 detected disturbing event happens independently agents event explain accident As example events called disruptive factors mention presence road unpredictable oil puddle leading loss control consequently accident More generally unpredictable causes loss control considered disruptive factors17 effectively lead accidents unpredictable obstacles vehicles dogs technical problems arising executing actions necessary avoid accidents 44 holds combine Disruptive_factor C A T Primary_anomalyC A T Derived anomalies 45 correspond situations reason agent respecting hisher duty able Thus difference derived anomalies ﬁrst form primary anomalies lies polarity modality is_able_to 45 duty F A T is_able_to F A T holds F A T1 incompatible F F Derived_anomalyF A T1 17 We list static database different causes loss control information predictability D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1179 Appendix C develops steps enabling derive Derived_anomaly Control author 3 Derived_anomaly Has_driver author 5 Derived_anomaly Stop author 7 Primary_anomaly Drives_app author 1 The conclusion expressed follows The cause accident moment author entered road bend drive appropriate speed 66 Discussion We shown details text linguistic literals semantic literals kernel eventually action agent duty able The reader certainly noticed rules degrees generality looking ad hoc text consideration As validation section Section 8 impression correspond reality texts different time rules written nonetheless correctly processed rules The fact remains writing rules abstract homogeneous level far preferable But feel comforted history ﬁeld trying soon discover general rules fulﬁlling local goals safer way ﬁnd fruitful paths looking straightway universal reasoning patterns 7 Implementation issues This section discusses implementation issues We ﬁrst brief overview answer set programming paradigm explain transform inference rules presented extended logic programs 54 71 Answer Set Programming Answer Set Programming ASP recent paradigm covering different kinds logical programming seman tics 44 It allows representing solving standard problems Computer Science combinatorial problems kcoloring graph path ﬁnding scheduling But ASP concerned problems arising Artiﬁcial Intelligence available information incomplete nonmonotonic reasoning planning diagnosis The reader ﬁnd additional information ASP web site working group WASP httpwaspunimeit Here particularly interested ASP framework default reasoning For purpose use Extended Logic Programs ELP represent knowledge means rules containing positive information strong default nega tive information interpret answer set semantics 22 Formally ELP set rules form c a1 b1 bm n cid3 0 m cid3 0 c ai b j literals18 For given rule r c a1 b1 bm denote r a1 r b1 bm headr c body body c a1 r Deﬁnition Let R set rules default negation r R body Program r R called Deﬁnite Logic A set literals X closed wrt R r R body The set consequences R CnR minimal set literals consistent closed wrt R set r X headr X exist equal set literals language For given set literals A ELP P reduct P A deﬁnite Logic Program P A r r P body r A Let P ELP A set literals A answer set P A CnP A Examples P 1 b b c b answer sets b c P 2 answer set 18 Since c ai b j literals positive negative form p p p atom There important distinction hard negation proposition p negation failure p Hence expression p equivalent p 1180 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 Table 3 Translation classical formulas ELP Classical formulas fact conjunction facts a1 material implication a1 b Table 4 Translation default rules ELP Classical formulas normal default A1 An B seminormal default A1 An B C1 Cm ELP rule body n rules bodies a1 direct rule b a1 plus n contrapositives a1 b a2 b a1 an1 ELP rule B A1 An B rule B A1 An B C1 Cm We recalled basic notions answer set semantics case propositional rules But obviously ﬂexible knowledge representation requires rules contain variables In case rule considered global schema set instances obtained replacing variable constant language19 It important work point answer set semantics ELP viewed subcase default logic 226 translation rule r c a1 b1 bm default rule T r a1 cb1 bm As matter fact S answer set ELP P ThS extension default theory T P Conversely extension T P deductive closure answer set P Obviously generality default theory translated ELP But shown restricted default theories corresponding representation language translatable ELPs We advantage software packages ASP available today20 72 From default rules extended logic programs In section explain encode knowledge base originally expressed default theory extended logic program A important point note original knowledge base contain disjunctions Since default theory pair consisting set classical formulas set default rules distinguish types translation represented respectively Tables 3 4 We encoded rules default logic instead directly ASP default logic compact ASP needs rules especially contrapositives The translation default logic ASP easy perform automatically 73 The implementation The program written contains declarative imperative The declarative contains set nonmonotonic inference rules 615 inference rules altogether linguistic semantico pragmatic reasoning The imperative 8000 lines code represents implementation C parser posttreatment heuristics resolution temporal constraints To rough idea behavior terms execution time linguistic reasoning requires execution time varying broad fork depending size text analyzed 1 second 4 minutes 56 seconds CPU Pentium 30 GHz 1 Go RAM situation different semanticopragmatic reasoning execution time interval 3 8 seconds 19 Our implementation based SMODELS 59 answer set programming language As SMODELS works propositional rules inference rules ﬁrst treated LPARSE tool things instantiates variables inference rules values respective domains deﬁnition produce propositional rules SMODELS LPARSE available web page httpwwwtcshutﬁSoftwaresmodels 20 In addition SMODELS tools answer set programming developed For example DLV 41 httpwwwdbaituwienacatprojdlv Cmodels 43 httpwwwcsutexaseduuserstagcmodelshtml Nomore 3 httpwwwcsunipotsdamdewvnom D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1181 8 Validation 81 Methodology We consider levels validation ﬁrst consists evaluating point built consonant intuition concerning causality As said earlier corpus 160 texts reports considered cause accident relatively uncontroversial insofar report honest The corpus parts training sample 73 texts develop inference rules validation sample 87 texts kept assess performs applied new texts We report results section The second level way valuable consists checking output ﬁts answers provided human readers asked cause accident As answers dispersed objective validation diﬃcult spell frequent answer frequency 50 Or kind centroid answers distance deﬁned Or reproduce probability distribution answers In case report results experiment Section 83 82 Validation wrt intuition The validation considered subsection consists testing conformity answers given answers As discussed earlier different parts importance morpholexical syntactic analyzers developed ad hoc way mainly ensure complete chain treatment considered validation process The main work semanticopragmatic reasoning results validation corpus matter Another interesting test consists assessing degree semantico pragmatic reasoner tolerates errors previous steps The signiﬁcant measure concerns overall behavior frequently answer given receives input text corpus coincides judgment But interested evaluation intermediary results Fig 6 represents hierarchy tests performed test 1 corresponds evaluation posttreatment heuristics Section 51 tests 21 22 correspond evaluation linguistic reasoning Sections 53 55 respectively manual corrections results output previous steps Tests 31 32 analogous tests 21 22 concern semanticopragmatic reasoning Sections 62 65 Test 31 important corresponds global behavior 821 Test posttreatment heuristics There 346 subjectverb relations generated parser training sample 505 validation sample Table 5 gives number percentage subjectverb errors detected properly corrected Fig 6 Methodology test Table 5 Detection correction subjectverb errors 1 Number subjectverb relations 2 Errors parser 3 Errors detected heuristic 4 Errors correctly repaired Recall 42 Precision 43 Training sample Validation sample 346 34 10 28 26 76 92 505 37 7 25 20 54 80 1182 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 Table 6 Success rate anaphora resolution 1 Number anaphors 2 Number referents 3 Number correct referents Recall 31 Precision 32 Table 7 Success rate inference semantic literals 1 Literals expected 2 Literals 3 Literals incorrect predicate 4 Literals missing 1 2 3 5 Literals correct predicate incorrect temporal parameter 6 Literals correct predicate incorrect agent parameter 7 Literals correct 2 3 5 6 Recall 71 Precision 72 Training sample Validation sample 428 428 424 99 99 592 592 564 95 95 Training sample Validation sample Raw input Corrected input Raw input Corrected input 306 326 296 0 10 5 3 288 94 97 298 0 8 5 0 293 96 98 278 4 52 14 11 249 76 90 279 4 51 14 0 261 80 94 respect total number errors errors detected wrongly corrected training validation samples As table shows heuristics succeed correcting quarters erroneous relations training texts half validation texts However later remaining errors lead worsening global performance We notice heuristics overcorrects matrix mistakenly detects incompatibility subject verb correct relation Let examine results anaphora resolution heuristic Table 6 By construction heuristic ﬁnds referent anaphor recall precision value For training validation samples values satisfactory It clear good performance speciﬁcity domain limitation kind references need considered Looking higher level note 20 texts validation corpus contain subjectverb error applying posttreatment heuristics 22 contain incorrect reference 31 texts 36 contain subjectverb anaphora errors 822 Test linguistic reasoner To evaluate linguistic reasoner determined manually text set semantic literals expect extracted We compare set semantic literals inferred linguistic reasoner levels granularity literals texts What ensures extent manual determination correct set semantic literals base comparison affect objectivity validation set semantic predicates determined stage development built ad hoc The total number expected semantic literals 306 training sample 326 validation sample Level literals A literal contains predicate arguments We measured separately number literals having correct predicate possibly wrong arguments fully correct literals arguments The column corrected input corresponds texts manually rectiﬁed mistakes previous stages Table 7 gives results obtained linguistic reasoner inferring semantic literals For training texts predicate names correct For validation texts 4 erroneous Giving correct input raw result previous stages makes signiﬁcant difference This means errors posttreatment heuristics deep inﬂuence linguistic reasoner The table provides details different kinds errors linguistic reasoner The error rate remains limited general peak concerns inability linguistic reasoner infer semantic literals validation sample 52 literals 326 expected 16 inferred Although errors necessarily affect following steps remark incites improve future work generality linguistic rules working abstract level Once signiﬁcant difference resulting correcting input linguistic reasoner This conﬁrms fact fortunately D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1183 Table 8 Synthesis results linguistic reasoning text level Training sample Validation sample Raw input Corrected input Raw input Corrected input 73 87 60 82 8 11 0 2 3 5 7 63 86 5 7 0 0 5 7 35 40 38 44 4 5 8 9 12 14 39 45 37 40 4 5 0 12 14 Number texts Texts errors Texts expected literals Texts additional literals Texts literals having erroneous nontemporal parameters Texts literals having erroneous temporal parameter Table 9 Error rate semanticopragmatic reasoning Training sample Validation sample Raw input Corrected input Raw input Corrected input 1 Expected primary anomalies 2 Number primary anomalies 3 Correct primary anomalies Recall primary anomalies 31 Precision primary anomalies 32 6 Expected derived anomalies 7 Number derived anomalies 8 Correct derived anomalies Recall derived anomalies 86 Precision derived anomalies 87 76 71 95 93 47 46 96 98 75 48 75 74 99 99 48 48 100 100 89 75 85 84 17 16 67 94 88 24 90 83 94 92 22 21 87 95 subjectverb errors remained application posttreatment heuristics relevant inference expected semantic literals Text level Table 8 displays results text level We consider given text correctly analyzed contains error omission expected semantic literals Table 8 shows linguistic reasoner errors concentrated corpus half texts contain error This remark crucial evaluation semanticopragmatic reasoner Section 823 able ﬁnd correct answers presence errors input Let effect subjectverb errors unresolved anaphors performance linguistic reasoner text level Remember 31 texts validation corpus contain mistakes Without correcting input linguistic reasoner 10 31 texts 30 error inferred semantic literals The correction input linguistic reasoner avoids errors 10 21 remaining texts In 11 texts semantic literals change Thus 21 31 texts 70 errors subjectobject relations anaphora references effect linguistic reasoning 823 Test semanticopragmatic reasoner This section discusses results semanticopragmatic reasoner determination primary derived anomalies reﬂect respectively plausible cause accident possible causes resulting ﬁrst cause The performance evaluated according factors capacity treat new texts correctly robustness capacity inﬂuenced errors accumulated previous steps The percentages given following tables based manual analysis according 75 resp 88 primary anomalies 48 resp 24 derived anomalies detected training resp validation sample Table 9 Anomaly level For training texts determines directly correcting input received linguistic reasoner 95 expected primary anomalies When input correct ﬁnds 99 expected primary anomalies More signiﬁcant percentage primary anomalies directly validation texts 85 This value satisfactory shows able cover wide range phenomena relevant detection causes car crash reports Moreover correcting semantic literals obtained linguistic reasoner enables obtain 94 primary anomalies expected validation corpus This good percentage reﬂects performance semanticopragmatic reasoner independently parts 1184 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 Table 10 Synthesis results text level Number texts Texts errors Texts errors Text level Training sample Raw input 67 92 6 8 Validation sample Corrected input Raw input Corrected input 73 72 99 1 1 70 80 17 20 87 81 93 6 7 Finally Table 10 shows results semanticopragmatic reasoner text level These results signiﬁcant ones evaluation approach By texts errors mean texts ﬁnd exactly expected primary derived anomalies All texts class texts errors It clear attains good performance rate correct answers 80 case new texts validation sample Moreover interested ﬁnding correctly expected primary anomaly percentage success goes 85 824 Robustness If compare ﬁgures percentage texts errors semantic literals notice signiﬁcant difference 60 validation texts contain error semantic literals errors primary derived anomalies 20 This result proves robustness More precisely 52 texts validation sample contain errors semantic literals 7 13 lead erroneous determination primary derived anomalies 83 Validation wrt sample human subjects 831 Setting experiment 151 subjects mainly ﬁrstyear science students aged 18 23 taken test They received question naire 10 selected reports Appendix A printed average 151 answers report After reading report asked tick wanted 8 10 potential causes proposed cause explain The step circle potential causes main cause accident The subjects asked percentage responsibility assign drivers involved accident scale 1 complete disagreement 7 complete agreement extent agree given norm chosen relevance circumstances accident The potential causes proposed include factors related accident indirect way driver A took car day For text proposed causes expressed explicitly duty vehicle B stopped proposed causes referred implicitly duty vehicle B driving close vehicle A 832 Main results The task meaningful subjects age new drivers drive A small answers 10 look somewhat unreliable cause circled main cause belong set potential causes ticked given percentages responsibility inconsistent causes selected All sensible distinct subjects exactly opinion causes responsibilities accident Generally approximately half potential causes proposed ticked The box cause explain seldom case subject expressed general statement people drive cautiously The exception concerns Report B49 Appendix A excessive speed car3 proposed potential cause clearly plays role subjects box cause explain mention This shows subjects merely play kind elimination game causes proposed tried answer thoughtful way Another interesting feature answers subjects hesitate select potential causes main cause factors mentioned report This shows inferences performed causal reasoning far extraction elements text Rather summary analysis results gathered 10 reports deeper analysis variations answers considered superﬁcial differences expression unanimous opinion divergence fundamental Let consider ﬁrst Report A12 I driving vehicle A right lane reserved vehicles heading straight ahead Vehicle B left lane reserved vehicles turning left roadmarking arrows Vehicle B cut vehicle A hitting left D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1185 Table 11 Reactions subjects text A12 potential causes 1 9 0 box ticked 1 box ticked The norm suggested potential cause 5 Driver B checked cutting maneuver dangerous Subject Cause 1 2 3 4 5 6 7 8 9 Main cause resp A resp B Adhesion norm Age 1 1 0 0 0 1 0 0 0 0 5 30 70 7 20 2 1 1 0 0 1 0 0 0 0 1 10 90 6 18 3 1 0 1 1 1 0 1 1 0 8 30 70 5 19 4 1 1 1 0 1 0 1 1 Bad driver 9 10 70 5 21 5 1 1 1 1 1 1 1 1 0 2 0 100 7 19 6 1 0 0 0 0 0 1 0 0 7 0 90 7 18 7 1 0 1 0 1 0 1 1 0 5 0 100 7 18 8 1 0 0 1 1 0 0 0 0 3 0 100 7 22 9 1 1 1 0 1 0 0 1 0 5 20 80 7 18 10 1 0 1 0 1 0 1 1 0 8 10 90 5 20 11 0 0 1 0 1 1 1 0 5 0 100 7 18 12 0 1 1 1 1 0 1 1 0 3 40 60 7 18 13 1 0 0 0 1 0 1 1 0 5 30 70 7 20 14 0 1 0 0 1 0 0 1 0 5 20 80 6 18 15 0 0 1 0 1 0 0 1 0 5 20 70 7 19 The potential causes proposed 1 Vehicle B cut 2 A vehicle blocking left lane avoid vehicle B cut 3 Vehicle B changed lane putting indicator 4 Driver A avoid vehicle B came level 5 Driver B checked cutting maneuver dangerous 6 The presence parallel lanes 7 Vehicle B driving fast 8 Vehicle B respect road marking 9 Other cause explain___________________________ The answers 15 subjects received text given Table 11 Roughly half subjects took cause 5 main cause accident exactly cause expect accident agent comply hisher duty Only proposed cause suggested driver A share responsibility cause 4 subjects ticked Not surprisingly high percentage responsibility B average 81 Five subjects selected main causes different unfulﬁlled duties B appear explicitly duties modal absent causes nos 3 7 8 Causes nos 1 2 9 got vote 1 absolute violation norm understood context 2 provides explanation driver Bs behavior clearly subject selected 2 main cause explanation excuse gives 100 responsibility B Finally subject giving 9 bad driver main cause ticked potential causes incriminating B So B unanimously considered mainly entirely responsible accident Moreover 12 14 15 subjects depending causes nos 1 2 considered main cause accident fact agent comply hisher duties Even duty question selected driver B On_normal_lane time 3 able failed hisher lane time 4 clearly related agent respected hisher duty check maneuver dangerous stayed hisher normal lane Thus believe results validate work discrepancy observed resulting mainly choice motivated practical reasons express causes terms limited kernel concepts Our second example Report B6 While I moving green light I driver A hit vehicle ahead vehicle B I barely touched vehicle bumper slightly damaged As vehicle suffered damage The potential causes proposed 1 Driver A moved light turned green taking account vehicle 2 Driver A waited vehicle B proceeds 3 Driver A close vehicle B 1186 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 Table 12 Reactions subjects text B6 The suggested norm potential cause 2 Driver A waited vehicle B proceeds Subject Cause 1 2 3 4 5 6 7 8 9 10 Main cause resp A resp B Adhesion norm Age 1 1 1 1 1 0 0 0 1 0 0 8 80 20 6 21 2 1 1 0 1 1 1 0 1 0 0 100 0 7 20 3 0 1 0 1 1 0 0 1 stress 2 50 50 7 24 4 1 1 0 1 1 0 1 1 1 0 2 70 30 6 21 5 1 0 0 1 0 0 1 1 0 8 100 0 7 19 6 1 0 1 1 1 1 1 1 0 0 8 0 100 1 23 7 1 0 1 0 1 1 1 0 1 0 3 80 60 4 19 8 1 1 0 0 0 0 0 1 0 2 0 100 3 18 9 1 0 1 1 1 1 0 9 50 50 5 20 10 1 1 1 1 0 1 1 1 0 0 1 80 20 7 20 11 1 1 0 1 0 0 1 1 1 0 2 80 20 7 20 12 1 1 1 0 0 1 0 1 0 0 1 80 20 7 20 13 1 0 1 1 0 0 1 1 0 8 80 20 6 18 14 1 1 1 1 1 1 1 1 0 0 8 60 40 6 18 15 1 1 1 1 1 0 1 1 1 0 4 40 60 7 19 4 Vehicle B light turned green 5 The light turned green 6 Vehicle B preceding vehicle A 7 Driver B notice light turned green 8 Driver A paid attention vehicle 9 No cause damage barely touched 10 Other cause explain____________________________ The answers 15 subjects received text given Table 12 The duty appears explicitly cause 2 cause ticked 10 15 subjects 4 consider main cause However causes nos 1 3 4 8 correspond implicit duties fulﬁlled Altogether 13 15 subjects selected main cause unfulﬁlled duty But looking responsibilities clear 10 subjects consider accident inattention A As matter fact ﬁnds primary anomaly cause accident fact time 1 driver A duty able time 2 A moved Nonetheless 3 subjects consider B exclusively responsible accident 2 subjects share responsibility 5050 What noticeable fact text evokes causes nos 3 4 7 8 Despite 14 15 selected potential cause accident Causes nos 5 6 distractors course argue light turned green later A paid attention accident occurred similarly B preceding A A hit B So causal relation counterfactual sense explain 9 15 subjects ticked causes asked cause accident answered light turned green seriousness question A close examination results gathered 8 reports experiment reveals intermediaries quasiunanimity A12 signiﬁcant variations observed B6 The ascription causes abnormal factors massively validated cases 9 Conclusion perspectives The presented paper number interesting features weaknesses On positive accepts genuine car crash reports seen robust quick times ﬁve gives causes accident exactly elements But experiment reported Section 83 shows result signiﬁcant thought initially causal judgments widely agreed believed But cases answers subjects differ slightly answers difference signiﬁcant explained fact number subjects higher importance norms notion norm ascribe cause accident So case consider postulate relating cause norm validated Our initial objective broadened instead getting frequently stated causes accident try ﬁnd elements 10 percent subjects consider causes This kind investigations closer Cognitive Modeling AI For concerns NL semantics use regular compositional tools This work shows feasibility inferential approach NL requiring correct complete parser based norms preservation truth As perspective future work believe following questions priority D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1187 How portable If switch domain road accidents kinds reports causality plays important role postulates stated beginning paper remain valid More speciﬁcally agreed collecting norms given domain prominent importance kept implicit handbooks similar items concerning domain approach adopted try reproduce causal reasoning experts viable method gather norms mind How scalable Far presumptuousness works attempting incorporate signiﬁcant mankinds encyclopedic knowledge nonetheless sensible increase gradually domain covered In case goal improve performance domain change extend domain rework completely Natural Language analyzers incorporate generalpurpose resources add noise current success precisely fact tailored analyzers exact needs Answering questions requires work But reward step forward vexed question cause means better understanding reasons half century efforts incredible progress speed storage capacity computers Natural Language Understanding infancy Acknowledgements We express gratefulness Françoise Gayral François Lévy Catherine Recanati stimulating discussions sug gestions anonymous referees helpful criticisms ﬁrst version paper Philippe Chassy Denis Hilton Université Toulouse Le Mirail provided invaluable help design execution experiment described Section 83 analyzing data collected We thank Denis Hilton helpful suggestions improving English paper The work presented partially supported MICRAC project funded ANR Agence Nationale la Recherche Appendix A A sample corpus Report D1 En sortant mon domicile jai dû braquer pour éviter véhicule qui arrivait à vive allure et jai heurté une des bornes en ciment qui longent le trottoir lit As I driving home I forced swing avoid vehicle arriving high speed I bumped concrete markers border sidewalk Report D37 Je roulais sur la route Nom_De_Voie1 direction Nom_De_Lieu Le véhicule B venait dune voie circulation par la gauche Le véhicule B na pas respecté le stop et ma percuté à lavant gauche En plus des dégâts constatés pneu ma voiture été détérioré lit I driving road1 direction location1 Vehicle B coming traﬃc way left Vehicle B respect stop sign smashed left In addition recorded damages tire car deteriorated Report A4 Véhicule B venant ma gauche je trouve dans le carrefour à faible vitesse environ 40 kmh quand le véhicule B percute mon véhicule et refuse la priorité à droite Le premier choc atteint mon aile arrière gauche sous le choc et à cause la chaussée glissante mon véhicule dérape et percute la protection métallique dun arbre doù second choc frontal lit Vehicle B coming left I crossroads low speed 25 mph vehicle B smashes vehicle refuses yield I priority The ﬁrst shock hits left fender roadway slippery crash vehicle skids hits metal protection tree second headon shock Report B6 Alors que je redémarrais au feu vert jai heurté larrière du véhicule qui précédait Jai à peine touché ce véhicule puisque seul son parechocs est légèrement abîmé Mon véhicule nayant lui subi aucun dégât lit While I moving green light I hit vehicle ahead I barely touched vehicle bumper slightly damaged As vehicle suffered damage Report D2 Je venais quitter mon stationnement et jallais sortir du parking Jétais à larrêt car jattendais pouvoir mengager sur lavenue Nom_De_Voie Cest alors que le véhicule A en reculant ma heurté Je nai pas pu mavancer à cause la circulation sur lavenue ni reculer à cause des voitures derrière moi manière à éviter le choc lit I left parking place I leave parking lot I stationary I waiting opportunity step avenue1 At moment vehicle A moving backwards bumped I forward traﬃc avenue I backwards cars order avoid crash 1188 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 Report B16 Le véhicule A roulait lentement en ligne droite tout près son domicile le véhicule était en stationnement sur une bande réservée à cet effet et la conductrice ouvert la portière gauche avant provoquant ce fait choc le rétroviseur du véhicule A côté droit fut brisé au moment du passage du véhicule A lit Vehicle A driving slowly straight line close home vehicle parked lane reserved purpose driver opened left door causing reason shock vehicle As sideview mirror right broke moment vehicle A came past Report A12 Je circulais à bord mon véhicule A sur la ﬁle droite réservée aux véhicules allant tout droit Le véhicule B circulait sur la voie gauche réservée aux véhicules allant à gauche marquage au sol par des ﬂèches Celuici sest rabattu sur mon véhicule A heurtant à larrière gauche lit I driving board vehicle A right lane reserved vehicles going straight ahead Vehicle B moving left lane reserved vehicles turning left roadmarking arrows The cut vehicle A hitting left Report C3 Ma voiture véhicule B était stationnée sur le parking où je travaille Jétais sortie mon véhicule et tenais sur le parking lorsquune voiture garée derrière moi plus haut dévalé le parking sans conducteur à lintérieur et heurté ma voiture sur le côté gauche en la poussant lit My car vehicle B parked parking lot I work I vehicle standing parking lot car parked higher place hurtled parking lot driver inside bumped left car pushed Report C10 La voiture B glissé et sest retrouvée en travers la route perpendiculaire à la route Jarrivais derrière et à cause du verglas je nai pas pu marrêter Mon véhicule percuté le véhicule B et mon véhicule été projeté dans le fossé lit Vehicle B slipped ended crosswise road perpendicular road I arriving ice I unable stop My vehicle bumped vehicle B vehicle hurled ditch Report B49 Arrêtée à feu rouge avec le pied sur le frein frein à main levé jai reçu choc brutal à larrière provenant dune Nom_De_Véhicule1 immatriculée Numéro_D_Immatriculation1 Jai moimême alors été projeté contre la voiture précédant Nom_De_Véhicule2 immatriculée Numéro_D_Immatriculation2 Il pleuvait à verse et la chaussée était glissante Le premier choc venait en fait dune Nom_De_Véhicule3 immatriculée Numéro_D_Immatriculation3 qui initialement touché la Nom_De_Véhicule1 lit Stopped red light foot brake pedal handbrake I got violent shock brand1 car license plate no1 I hurled car ahead brand2 car license plate no2 It pouring roadway slippery The ﬁrst shock fact brand3 car license plate no3 initially hit brand1 Appendix B List semantic predicates A B agent metonymy refer vehicle person O object agent obstacle wall signpost C color P position D direction left right X cause loss control icy patch bits gravel L location parking garage R circulation area street lane road Predicate holds Is_approaching_Xroads A T holds Access_adj_lane A T holds Stop A T holds Is_arriving_on_file A T holds Has_driver A T holds Give_way A T holds Control A T holds Is_overtaking A T holds Is_moving_off A T holds Is_wrong_way A T holds Mistaken_command A T holds Is_braking A T holds Brake_release A T Meaning A approaching crossroads A accesses adjacent lane A stopped A arriving ﬁle A driver A presence way sign A control A overtaking A moves A takes wrong way A makes command mistake A brakes The brake A released Predicate Meaning D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1189 holds Is_slipping A T holds Police A T holds Door_open A T holds Pedestrian A T holds Is_moving_backwards A T holds Steer_release A T holds Drives_app A T holds Is_moving A T holds Signal A T holds Parked A T holds On_normal_lane A T holds Stop A T holds Is_falling A T holds Bend A T holds Change_dir A T holds combineAt_right_of B A T holds combineCause_not_control X AT holds combineShock O A T holds combineIs_cutting_road B A T holds combineAvoid O A T holds combineRed_light C A T holds combineIs_hitting O A T holds combineSame_file B A T holds combineSame_road B A T holds combineSame_direction B A T holds combineSame_line B A T holds combineIs_disturbing B A T holds combinePos_shock P A T holds combinePreceed B A T holds combineHas_priority B A T holds combineOpposite_direction B A T holds combineIs_leaving L A T holds combineFollows B A T holds combineIs_turning D A T holds combineIs_crossing R A T holds combineChange_dir D A T Foga Slow_down Slippery_road A slips A stopped police A door vehicle A open A presence pedestrian A going backwards A releases steering wheel A drives appropriate speed A moving A signals A parked A drives good normal lane A presence stop sign The driver A ejected outside vehicle A arrive road bend A change slightly direction B situated right A X potential cause control loss A There shock A O symmetric holds A cuts road vehicle B A avoid obstacle O There red light A A bumps obstacle O A B ﬁle A B drive road A B drive direction A B line A disturbs B The position shock A P A precedes B ﬁle B priority B A B run opposite directions A leaves place L A follows B ﬁle A turns direction D A crosses road A changes direction direction D There fog There general deceleration The road slippery The predicates list arity zero linked agent supposed remain true scene Appendix C Rules running example Rule 11 works expressions form vehicle skidded onbecause glazegravels allows inference predicate expressing loss control identiﬁed cause 11 type A vehicle type X cause_loss_control prep T sem_rep V is_slipping holds_I V A W holds_I combinecombineT V X A temp_refT holds combinecause_not_control X A temp_refT Rule 12 infers presence vehicle bend 12 type A vehicle sem_rep X bend verbe P prep T holds_I combinecombineT P X A temp_refT holds bend A temp_refT Given static predicate type gravels cause_loss_control gravels known potentially cause loss trol rules infer running example atemporal semantic literal holds combinecause_not_control gravels author temp_refsur2 holds bend author temp_refdans 13 type A vehicle type X cause_loss_control prep T sem_rep V is_slipping holds_I V A W holds_I combinecombineT V X A temp_refT prec temp_refT W 14 type A vehicle sem_rep X bend verbe P prep T holds_I combinecombineT P X A temp_refT prec temp_refT temp_refP 1190 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 Rule 13 simply expresses event appears causes loss control event precedes naturally loss control yields prec temp_refsur2 temp_refdéraper The second temporal relation inferred example expresses loss control happened access road bend driver prectemp_refdans temp_refdéraper This relation agrees text narrative order21 obtained thanks rule 14 The semantic literals obtained linguistic reasoner report B2B reproduced holds is_moving author 1 holds bend author 2 holds combinecause_not_control gravels author 2 holds is_slipping author 3 holds is_falling author 4 holds is_moving veh_A 5 holds Stop veh_A 6 holds combineis_hitting author veh_A 7 The semantic inference rules apply text 19 holds combinecause_not_control gravels A T holds bend A T predictable combinecause_not_control gravels A T22 It states presence gravels road bend represents predictable cause loss control entering bend anticipate presence unseen obstacles The application rule allows infer A author T 2 predictable combinecause_not_control gravels author 2 Rules 20 21 impose initial conditions time 0 vehicle control driver 20 agentA holds Control A 0 21 agentA holds Has_driver A 0 By applying rules obtain A author A veh_ A holds Control author 0 holds Control veh_A 0 holds Has_driver author 0 holds Has_driver veh_A 0 Rule 22 expresses fact driver falling hisher vehicle unpredictable event 22 holds is_falling A T predictable is_falling A T This rule provides A author T 4 predictable is_falling author 4 Rule 23 tells driver vehicle falls time T hisher vehicle driver time T 1 23 holds is_falling A T holds Has_driver A T1 We rule A author T 4 holds Has_driver author 5 The rule 24 allows infer agent author lost control hisher vehicle time 3 24 holds is_slipping A T holds Control A T Hence A author T 3 holds Control A 3 The forward persistence predicate Control allows infer agent author control times 1 2 agent veh_ A control temporal state scene In way applying forward persistence predicate Has_driver infer vehicle agent author driver times 1 2 3 4 predicate holds agent veh_ A states scene holds Control author T T 1 2 holds Control veh_A T T 1 7 holds Has_driver author T T 1 4 holds Has_driver veh_A T T 1 7 The forward persistence negation Control Has_driver yields holds Control author T T 3 7 holds Has_driver author T T 5 7 21 In cases rule infers temporal precedence opposition narrative order case example read The motorbike skidded curve instead In curve motorbike skidded obviously cases bike curve skidded 22 In fact rule blocks default according gravels belong general unpredictable causes loss control D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1191 Rules 25 26 state obvious facts vehicle A bumps vehicle B shock 25 predicate shock symmetric 25 holds combineis_hitting A B T holds combineshock A B T 26 holds combineshock A B T holds combineshock B A T Applying rules obtain A author B veh_A T 7 holds combineshock author veh_A 7 holds combineshock veh_A author 7 According rule 27 shock A B time T deduce default A represent obstacle B time T 1 know B avoided A time T 1 B vehicle 27 holds combineshock A B T holds combineobstacle A B T1 holds combineavoid A B T agentB By rule infer A author B veh_A T 7 A veh_A B author T 7 holds combineobstacle author veh_A 6 holds combineobstacle veh_A author 6 Rule 28 expresses X obstacle A time T X vehicle control state X unpredictable obstacle A time T 28 holds Control X T holds combineobstacle X A T predictable combineobstacle X A T This rule infers X author A veh_A T 6 predictable combineobstacle author veh_A 6 Finally rule 29 states time T agent A road bend temporal state T 1 A control default assumption A driving appropriate speed time T 29 holds bend A T holds Control A T1 holds Drives_app A T We obtain A author T 2 holds Drives_app author 2 The ﬁrst relevant rule example concerning duties 30 It states state driver control hisher vehicle control lost state 30 duty Control A T holds Control A T This default applicable yields A author T 2 duty Control author 2 Analogously rule 31 expresses state vehicle driver stopped driver 31 duty Has_driver A T holds Has_driver A T holds Stop A T This default applied A author T 4 yields duty Has_driver author 4 According rule 32 avoid obstacle appearing road 32 holds combineobstacle X A T duty combineavoid X A T The following literals obtain X author A veh_A T 6 X veh_A A author T 6 duty combineavoid author veh_A 6 duty combineavoid veh_A author 6 Rule 33 translates default duty avoid obstacle duty stop Many exceptions block default They listed justiﬁcation default 33 duty combineavoid B A T holds combineshock B A T1 duty Stop A T duty Drives_app A T holds Stop A T holds combinesame_file A B T duty notIs_moving_backwards A T1 duty notIs_moving_off A T1 predictable combineobstacleB A T We obtain applying rule B veh_A A author T 6 duty Stop author 6 However default blocked agent veh_A In fact agent author unpredictable obstacle agent veh_A state 6 28 negation justiﬁcations default Rule 46 performs propagation duties given duty respected predictable event avoiding event depends respecting precondition infer duty respect precondition 1192 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 46 effectF effectF1 eventEvt duty F A T1 pot_causeEvt F1 incompatibleF F1 holds Evt A T1 predictable Evt A T1 precond_avoid_eventEvt F1 P duty P A T This rule allows deduce duty state 1 agent author drive slowly T 1 A author P Drives_app F Control F1 notControl Evt combinecause_not_control gravels duty Drives_app author 1 This new duty leads calculate capacity agent author drive fairly slowly time 1 Knowing action braking potential cause fact driving fairly slowly exception block default 36 concerning default availability actions deduce available brake Drives_app author 1 The application rule 40 allows obtain is_able_to Drives_app author 1 Let sum anomalies detect From literals duty Control author 2 is_able_to Control author 2 holds Control author 3 rule 45 ﬁnds Derived_anomaly Control author 3 fact agent author lost control time 3 derived anomaly Analogously detect derived anomalies The ﬁrst concerns fact authors vehicle driver time 5 fact agent author stop time 7 Derived_anomaly Has_driver author 5 Derived_anomaly Stop author 7 Finally rule 43 premises duty Drives_app author1 is_able_to Drives_app author 1 holds Drives_app author 2 result Primary_anomaly Drives_app author 1 References 1 V Akman ST Erdogan J Lee V Lifschitz H Turner Representing zoo world traﬃc world language causal calculator Artiﬁcial Intelligence 153 12 2004 106140 2 J Allen HA Kautz A model naive temporal reasoning J Hobbs RC Moore Eds Formal Theories Commonsense World Ablex Series Artiﬁcial Intelligence 1985 pp 251268 3 C Anger M Gebser T Linke A Neumann T Schaub The nomore C Baral G Greco N Leone G Terracina Eds Proceedings 8th International Conference Logic Programming Nonmonotonic Reasoning LPNMR05 Diamante Italy LNAI vol 3662 SpringerVerlag Berlin 2005 pp 422426 4 S Benferhat et al A comparative study formal models causal ascription S Greco T Lukasiewicz Eds Proceedings 2nd Interna tional Conference Scalable Uncertainty Management Naples Italy LNAI vol 5291 SpringerVerlag Berlin 2008 pp 4762 5 B Bennett AP Galton A unifying semantics time events Artiﬁcial Intelligence 153 12 2004 1348 6 N Bidoit C Froidevaux General logical databases programs Default logic Semantics Stratiﬁcation Information Computation 91 1 1991 1554 7 DG Bobrow Natural Language input problem solving M Minsky Ed Semantic Information Processing The MIT Press 1967 pp 133215 8 M Boman Norms artiﬁcial decisionmaking Artiﬁcial Intelligence Law 7 1 1999 1735 9 S Boutouhami D Kayser Vers la construction descriptions argumentées dun accident la route analyse diverses stratégies argumentatives Corela 6 1 2008 available online httpedelunivpoitiersfrcoreladocumentphpid1887 10 JD Bransford JJ Franks The abstraction linguistic ideas Cognitive Psychology 2 1971 331350 11 G Brewka Cumulative default logic defense nonmonotonic inference rules Artiﬁcial Intelligence 50 2 1991 183205 12 K Chan W Lam Extracting causation knowledge natural language texts International Journal Intelligent Systems 20 2005 327358 13 G Chierchia S McConnellGinet Meaning Grammar An Introduction Semantics The MIT Press 1990 14 A Colmerauer Les systèmesQ formalisme pour analyser et synthétiser des phrases sur ordinateur publication n 43 département dInformatique lUniversité Montréal 1970 reprinted TAL 33 12 1992 105148 15 J De Kleer JS Brown A qualitative physics based conﬂuence Artiﬁcial Intelligence 24 13 1986 783 16 JP Delgrande An approach default reasoning based ﬁrstorder conditional logic Artiﬁcial Intelligence 36 1 1988 6390 17 F Dignum D Kinny L Sonenberg From desires obligations norms goals Cognitive Science Quarterly 2 34 2002 405427 18 D Dubois H Prade Modeling role abnormality ascription causality judgments agents Proceedings IJCAI05 Workshop Nonmonotonic Reasoning Action Change Edinburgh Scotland 2005 pp 2227 19 Sous la direction P Enjalbert Sémantique et traitement automatique du langage naturel Hermès Science Publications Paris 2005 20 DW Etherington Formalizing nonmonotonic reasoning systems Artiﬁcial Intelligence 31 1 1987 4185 21 D Garcia Analyse automatique des textes pour laide à lorganisation des phénomènes des activités et des actions Réalisation du système informatique COATIS Thèse lUniversité ParisIV Sorbonne 1998 22 M Gelfond V Lifschitz Classical negation logic programs disjunctive databases New Generation Computing 9 34 1991 363385 23 ML Ginsberg DE Smith Reasoning action II qualiﬁcation problem Artiﬁcial Intelligence 35 3 1988 311342 24 L Giordano C Schwind Conditional logic actions causation Artiﬁcial Intelligence 157 12 2004 239279 25 E Giunchiglia J Lee V Lifschitz N McCain H Turner Nonmonotonic causal theories Artiﬁcial Intelligence 153 12 2004 49104 26 B Green AK Wolf C Chomsky K Laughery BASEBALL An automatic question answerer EA Feigenbaum J Feldman Eds Computers Thought The MIT Press 1963 pp 207216 27 J Groenendijk M Stokhof Dynamic predicate logic Linguistics Philosophy 14 1991 39100 28 G Gross Verbes supports et conjugaison nominale Revue dEtudes Francophones 9 1999 7092 D Kayser F Nouioua Artiﬁcial Intelligence 173 2009 11541193 1193 29 Y Hagmayer D Hilton Causal reasoning practice causal assumptions affect explanations inferences decision making S Vosniadou D Kayser A Protopapas Eds Proceedings EuroCogSci 07 Delphi Greece Lawrence Erlbaum Ass 2007 p 40 30 JY Halpern J Pearl Causes explanations structuralmodel approach Part I Causes British Journal Philosophy Science 56 4 2005 843887 Part II Explanations British Journal Philosophy Science 56 4 2005 889911 31 DJ Hilton JL McClure BR Slugoski The course events counterfactuals causal sequences explanation D Mandel DJ Hilton P Catellani Eds The Psychology Counterfactual Thinking The Psychology Press London 2005 pp 4473 32 C Ioannides S Vosniadou The changing meanings force Cognitive Science Quarterly 2 1 2002 561 33 Y Iwasaki HA Simon Causality device behavior Artiﬁcial Intelligence 29 1 1986 332 34 R Johanson A Berglund M Danielsson P Nugues Automatic texttoscene conversion traﬃc accident domain Proceedings 19th International Joint Conference Artiﬁcial Intelligence IJCAI Edinburgh Scotland 2005 pp 10731078 35 H Kamp U Reyle From Discourse Logic Kluwer Dordrecht 1993 36 D Kayser A Mokhtari Time causal theory Annals Mathematics Artiﬁcial Intelligence 22 12 1998 117138 37 M Kistler Causalité et lois la nature Vrin collMathesis Paris 1999 English version Causation Laws Nature Routledge London 2006 38 S Kraus D Lehmann M Magidor Nonmonotonic reasoning preferential models cumulative logics Artiﬁcial Intelligence 44 12 1990 167207 39 D Lehmann M Magidor What conditional knowledge base entail Artiﬁcial Intelligence 55 1 1992 160 40 W Lehnert The Process QuestionAnswering Lawrence Erlbaum Ass Hillsdale 1978 41 N Leone G Pfeifer W Faber T Eiter G Gottlob S Perri F Scarcello The DLV knowledge representation reasoning ACM Transactions Computational Logic 7 3 2006 499562 42 D Lewis Philosophical Papers vol 2 Oxford University Press Oxford 1986 43 Y Lierler M Maratea Cmodels2 Satbased answer set solver enhanced nontight programs V Lifshitz I Niemelä Eds Proceedings 7th International Conference Logic Programming NonMonotonic Reasoning LPNMR04 Fort Lauderdale USA LNAI vol 2923 SpringerVerlag Berlin 2004 pp 346350 44 V Lifshitz Answer sets general nonmonotonic reasoning Proceedings 3rd International Conference Principles Knowledge Represen tation Reasoning KR92 MorganKaufmann Cambridge USA 1992 pp 603614 45 JL Mackie The Cement Universe A Study Causation Oxford University Press 1974 46 J McCarthy PJ Hayes Some philosophical problems standpoint artiﬁcial intelligence B Melzer D Michie Eds Machine Intelligence vol 4 Edinburgh University Press 1969 pp 463502 47 DV McDermott A temporal logic reasoning processes plans Cognitive Science 6 1982 101155 48 P McNamara H Prakken Eds Norms Logics Information Systems New Studies Deontic Logic Computer Science Frontiers Artiﬁcial Intelligence Applications vol 49 IOS Press 1999 49 M Minsky A framework representing knowledge AI Memo 306 MIT 1974 reprinted PH Winston Ed The Psychology Computer Vision McGraw Hill 1975 pp 211277 50 R Mitkov Anaphora Resolution Pearson Education 2002 51 R Montague R Thomason Ed Formal Philosophy Yale University Press 1974 52 A Nazarenko La cause et son expression en Français Ophrys Paris 2000 53 F Nouioua Extraction et Utilisation des normes pour raisonnement causal dans corpus textuel Thèse lUniversité Paris XIII 2007 54 F Nouioua P Nicolas Using answer set programming inferencebased approach natural language semantics Proceedings 5th International Workshop Inference Computational Semantics ICoS5 Buxton England 2006 pp 7786 55 J Pearl Causality Models Reasoning Inference Cambridge University Press 2000 56 R Reiter A logic default reasoning Artiﬁcial Intelligence 13 12 1980 81132 57 R Reiter G Criscuolo On interacting defaults Proceedings 7th International Joint Conference Artiﬁcial Intelligence IJCAI Vancouver Canada pp 270276 58 RC Schank RP Abelson Scripts Plans Goals Understanding Lawrence Erlbaum Ass Hillsdale 1977 59 T Syrjaänen I Niemelä The Smodels systems Proceedings 6th International Conference Logic Programming NonMonotonic Reasoning LPNMR01 Vienna Austria 2001 pp 434438 60 TAL Special issue Approches sémantiques Traitement Automatique des Langues 35 1 1994 61 M Thielscher Ramiﬁcation causality Artiﬁcial Intelligence 89 12 1997 317364 62 GH Von Wright Norm Action A Logical Enquiry Routledge Kegan Paul 1963 available httpwwwgiffordlecturesorgBrowse aspPubIDTPNORM 63 J Wu BG Heydecker Natural language understanding road accident data analysis Advances Engineering Software 29 79 1998 599610