Artiﬁcial Intelligence 170 2006 59113 wwwelseviercomlocateartint Robot introspection learned hidden Markov models Maria Fox Malik Ghallab b Guillaume Infantes b Derek Long Department Computer Information Sciences University Strathclyde 26 Richmond Street Glasgow G1 1XH UK b LAASCNRS 7 Avenue du Colonel Roche 31500 Toulouse France Received 1 December 2004 accepted 6 May 2005 Available online 1 September 2005 Abstract In paper machine learning approach acquiring model robot behaviour raw sensor data We interested automating acquisition behavioural models provide robot introspective capability We assume behaviour robot achieving task modelled ﬁnite stochastic state transition Beginning data recorded robot execution task use unsupervised learning techniques estimate hidden Markov model HMM predicting explaining behaviour robot subsequent executions task We demonstrate feasible automate entire process learning high quality HMM data recorded robot execution task The learned HMM monitoring controlling behaviour robot The ultimate purpose work learn models set tasks associated given problem domain integrate models generative task planner We want models successfully controlling execution plan However paper develop planning control aspects work focussing instead learning methodology evaluation learned model The essential property models seek construct probable trajectory model given observations robot accurately diagnoses explains behaviour robot actually performed making observations In work reported consider navigation task We explain Corresponding author Email address mariafoxcisstrathacuk M Fox 00043702 matter 2005 Elsevier BV All rights reserved doi101016jartint200505007 60 M Fox et al Artiﬁcial Intelligence 170 2006 59113 learning process experimental setup structure resulting learned behavioural models We evaluate extent explanations proposed learned models accord human observers interpretation behaviour exhibited robot execution task 2005 Elsevier BV All rights reserved Keywords Stochastic learning Hidden Markov models Robot behaviour 1 Introduction The goal work described paper automate process learning given robot executes task particular class dynamic environments We want learn abstract model behaviour robot executing task solely basis sensed data robot records performing task Having learned execution model task want use model reliably predict explain behaviour robot carrying task environment belonging class This paper describes approached goal context indoor navigation task successful learning reliable behavioural model 11 Motivation The work presented illustrates advantageous approach complex artifact autonomous robot usual viewpoint robotics designer observers point view Instead typical engineering question I design robot behave according speciﬁcations address different issue I model observed behaviour robot ignoring process intricacy design It sound strange roboticist engage observing modelling ro bot inferrable roboticists design However modular design complex artifact develops local models combined basis composition principle models seldom provides global behaviour models The design usually relies reasonable assumptions environment model explicitly changing openended environment hu man interaction Hence precise observation model robot behaviour varying open environment essential understanding robot operates environment We proposing paper machine learning approach acquiring particu lar class behaviour models robot The main motivation work build models robot task execution intermediate high level representations deliberative reasoning planning low level representations sensorymotor functions A highlevel action model collection planning operators abstract preconditions effects certainly needed high level mission planning However limited use monitoring controlling execution plans M Fox et al Artiﬁcial Intelligence 170 2006 59113 61 These functions need detailed model action breaks depending environment context lowlevel concurrent sequential sensorymotor primitives primitives controlled On hand representations designing modelling sensorymotor functions necessarily detailed They far complex dealt planning level execution moni toring The requires intermediate level models handprogrammed learned reﬁned speciﬁcation learning Other authors considered intermediate level descriptions task execution designing robot corresponding models encoded exploited plan execution framework We concerned programming low level control robot providing means robot intro spect development behaviour execution task We rely hidden Markov models HMMs 25 intermediate level representation behaviour Since models built empirically account dynamics uncer tainty real execution environment The resulting behavioural models provide way controller reason robot behaviour context executing task Our focus learning topological metric maps robot navigation Oth ers considered problem depth 14 shown navigation respect given environment dynamically improved robot interacts envi ronment The use stochastic learning techniques improve robot navigation given environment wellunderstood We concerned learning abstract models robot performs compound task task Navigation example compound task 12 Approach Our objective able predict explain robots behaviour undertakes compound task uncertain real world In reality robot passes number abstract behavioural states distinguished identiﬁed human observer For example picking object grippers robot state positioning respect object approaching grasping knocking lifting To illustrate kind model interested learning Fig 1 shows high level state transition model pickup task artiﬁcially simpliﬁed example learned real data Time abstracted model assumed monitoring process tracks robot revisits state It seen according model probability knocking object 02 robot positioning approaching state having positioned ready grasp object The probability looping positioning state high suggesting robot fumbles good grasping position The trajectories model actually followed robot revisit positioning state multiply state knocking object entered frequently case Using HMM identify probable trajectory leading current state provides monitoring 62 M Fox et al Artiﬁcial Intelligence 170 2006 59113 Fig 1 The compound task picking object powerful ability determine likely outcome robots current behaviour In Section 7 discuss structure HMM exploited monitoring The behavioural states model hidden sensed directly robot The robot equipped noisy sensors obtain estimate state A hidden Markov model HMM represents association noisy sensor readings possible behavioural states probabilities transitioning pairs states The HMM ideally suited objectives Our approach learn HMM relates sensor readings robot hidden real states traverses executing task order equip robot capacity monitor progress subsequent executions task Our work makes innovations First address problem learning struc ture parameters HMM structural learning approach based Kohonen network clustering We begin prior knowledge states HMM relationship states observations Second learn HMM independent physical locations activity takes place The states concerned abstractions behavioural states robot Expectation Maximization EM 5 estimate transition prob abilities based multiple sequences robot observations sequence corresponding observations robot execution compound task Fig 2 gives overview learning process suggests resulting model feed high level deliberative reasoning processes In paper focus processing clustering raw sensor data leading construction HMMs As discuss Section 7 models represent behavioural abstractions high level deliberative processes We possible learn high quality HMMs fully automated ap proach Although questions remain answered believe work consti tutes interesting step acquisition predictive explanatory model robot behaviour grounded actual sensed experience reality M Fox et al Artiﬁcial Intelligence 170 2006 59113 63 Fig 2 Learning HMM 13 Related work The work described paper builds varied literature concerned auto mated construction stochastic behavioural models This includes work probabilistic plan recognition 67 learning topological metric maps 12 learning stochastic models human activity 813 learning recognise facial expressions 10 gestures 111314 Previous authors considered automatic classiﬁcation interpretation sensed data 15 reﬁnement behavioural states introduce previously unaccountedfor distinctions world model 216 Our work combines number established approaches acquisition stochastic task models Koenig Simmons 1 use EM learn improve robots ability navigate suc cessfully speciﬁc environment Other approaches 1718 address problem learning map navigate environment active exploration strategies The technique described Koenig Simmons uses Partially Observable Markov Decision Process POMDP models represent robots understanding environment position given uncertainty topological structure environment The ac curacy robots navigation improved EM reestimate parameters model given navigation traces The GROWBW technique allows new states added model model fails account evidence observed trace Increasing lower bound length segment topological map corresponds adding states POMDP The learned POMDP accurate possible representation physical space Although work superﬁcially related EM estimate parameters stochastic model objectives different Koenig Simmons speciﬁcally interested learning improve navigation capability robot given environment whilst interested learning robot accomplishes task 64 M Fox et al Artiﬁcial Intelligence 170 2006 59113 task In work paper use navigation task simply example compound task The states learned model correspond abstract behavioural states obstacle avoidance physically grounded states metre corridor junction This signiﬁcant difference method taskindependent The states acquired automatically means cluster ing sensor input veracity established evaluating predictive power resulting HMM Several authors considered intermediate level models describing execution task For example RAPS 19 Structured Reactive Con trollers 20 provide low level programs actions taskplanning level decompose executive level robot architecture RMPL 21 TDL 22 examples languages developed speciﬁcation programs These programs handcoded acquired learning inter pretation learned models The Procedural Reasoning System PRS 23 example architecture supports relationship high level plans ex ecution The work gesture 111314 facial expressions 10 recognition closely related concern If HMM model probabilities human face transitioning different expressions expressions linked emotional states actions possible predict likely action person based interpretation facial expression Similarly gestures associated activities learned HMM enable immediate goals person predicted basis recent current gestures This work similar states learned HMMs behavioural states subject associated physical location subject Liao Fox Kautz 8 use learned models predict human transportation behaviours They detect persons behaviour deviates normal pattern evaluat ing likelihood observed behaviour context learned model Osentoski Manfredi Mahadevan 9 learn models human behaviours order provide robots functioning human environments capacity predict explain human activ ities In studies HMM predict probability certain activities undertaken certain physical locations The structure HMM hierarchical lowest level corresponding physical network locations higher levels corresponding activities typically place locations Thus work concerned relating activities physical space emphasis different In work association sensor readings robot behavioural states learned means Kohonen network clustering A closely related approach literature work Oates Schmill Cohen 15 dynamic time warping cluster multivariate time series sensor data experiences Oates et al present unsupervised method clustering experiences classiﬁcations action outcomes enabling robot interpret state way accords human judgements The objective work identify cluster prototypes form basis ontology activity lead automated construction operator models M Fox et al Artiﬁcial Intelligence 170 2006 59113 65 The way use results clustering phase different detailed comparison follows later paper 14 Layout paper In Section 2 formulate problem addressing specifying notation use paper introducing main methods algorithms deﬁning key terms use In Section 3 discuss data clustering Kohonen network clustering approach We initial collection behavioural states reﬁned clustering process We explain process building initial sensor model code book approach remaining parameters HMM initialised We review EM describing initial parameters iteratively reestimated Section 4 describes robot array sensors data collected class environments studied We explain observable outputs robot processed extract features clustering feature vectors constructed In Section 5 discuss implementation entire learning process showing EM process integrated clustering phase The EM process requires evidence provided explain sequences observations generated purpose In Section 6 evaluation strategy devised determining quality learned HMM terms power explain robots behaviour observations Using Viterbi algorithm 24 construct sequences states best explain observation sequences compare Viterbi sequences robot reality This comparison relies human observers interpretation robots real behaviour We discuss strengths weaknesses approach Finally Section 7 turn discussion learned models monitoring control robot behaviour Although focus current paper explain HMMs enable robot predict entry undesired state averting action time avoid failure We discuss HMMs combination policies plans support robot achieving high level mission goals 2 Formal problem statement There main problem components deﬁne model task ﬁnite state transition clustering observation space ﬁnite evidence space deﬁnition ﬁnite behaviour state space For component present assumptions concerning component role problem formal deﬁnition component brief introduction algorithm construct instances component In following section present details core algorithms introduced In deﬁnitions use n m index variables indicating lengths sequences context deﬁnition These variables interpreted locally deﬁned scope deﬁnition 66 M Fox et al Artiﬁcial Intelligence 170 2006 59113 21 Models tasks Assumption The robot behaviour task T conveniently modelled ﬁnite stochastic model Deﬁnition 1 A stochastic state transition model 5tuple λ Ψ ξ π δ θ Ψ s1 s2 sn ﬁnite set states ξ e1 e2 em ﬁnite set evidence items π Ψ 0 1 prior probability distributions Ψ δ Ψ 2 0 1 transition model λ δij Probqt1 sj qt si probability transitioning state si state sj time t qt actual state time t θ Ψ ξ 0 1 sensor model λ θik Probek si probability seeing evidence ek state si Under Markov assumption state robot time t depends state time t 1 λ produces hidden Markov model Deﬁnition 2 A history h cid3e1 encid4 ﬁnite sequence evidence items The algorithm build model wellknown technique Expecta tion Maximization EM 25 called BaumWelch algorithm 26 Given set histories initial parameters HMMan initial sensor model initial transition model prior state distribution states Ψ EM iteratively reestimates HMM parameters On iteration EM estimates probability likelihood ev idence seen given HMM estimated far It updates model parameters best account evidence When estimated likelihoods longer increasing EM converges The probability convergence represented maximal log likelihood best local estimate possible given evidence learned model Log likelihood probability particular observation sequence seen complex model typically low challenge arithmetic precision machine It known EM tendency converge local maxima careful selection initial HMM parameters help mitigate tendency The inputs EM algorithm ﬁnite set histories H h1 hn corre sponding training data associated n executions task T initial model λ0 Ψ ξ π δ0 θ 0 The output learned stochastic model λ corresponding hidden Markov model describing task T 22 Clustering observation space evidence Assumption A multidimensional nonﬁnite observation space meaningfully mapped ﬁnite set evidence items M Fox et al Artiﬁcial Intelligence 170 2006 59113 67 We refer collection sensor readings robot point time observation Each reading gives value certain primitive feature raw feature heading robot speed travelling The observation space deﬁned particular collection sensors robot equipped interaction means sensors environment Deﬁnition 3 A kdimensional observation space deﬁned Φ γ1 γ2 γk γi cid6 A raw feature deﬁned function fi robot env time γi mapping sensorymotor environmental context robot time t value range γi partially characterising behaviour robot instant t time Deﬁnition 4 An observation point observation space Although fi function robot environment access function control produces mapping raw feature values Raw feature values determined low level robot control software learning pursued project based interaction robot environment We sample fi speciﬁc values arguments Under assumption mappings exist observation space Φ set abstract observations ξ We elements ξ evidence items We ﬁrst deﬁne trajectory explain construction trajectories allows set ξ mapping constructed means clustering observation space Deﬁnition 5 A trajectory τ cid3o1 o2 oncid4 ﬁnite sequence observations charac terising single execution task T Our intention discretise nonﬁnite observations Φ robot ﬁnite collection distinct evidence items ξ determine mapping cluster Φ ξ This requires process abstraction combination raw feature values obser vations A single observation informative enable determine robots behaviour develops time If consider single observation taken time t raw feature values reveal little robots behaviour evolved time evolve For example robot reacting en vironment observation makes time t record heading degrees away general direction robot travelled interval including t We interested precise heading time t general direction robot travelled period time includes t In order behaviour robot changed time consider sub sequences trajectories containing c consecutive observations c constant chosen ensure sequences represent sufﬁcient time interesting behaviour 68 M Fox et al Artiﬁcial Intelligence 170 2006 59113 occur We combine raw feature values associated observations sequences features focus values features interested vary different sequences Deﬁnition 6 For given constant c feature abstraction raw feature values obtained combining subset raw features drawn c consecutive observations The combinations performed Deﬁnition 6 typical ﬁltering smoothing op erations signal processing Using features construct feature vectors trajectories data set Deﬁnition 7 A feature vector cid7fi mdimensional vector feature values The feature values obtained subsequence ﬁxed number consecutive observations starting observation trajectory The mdimensional feature vectors constructed raw features observation space kdimensional general m cid1 k depending ways raw features combined construction features The feature vectors constructed following way For trajectory possible consecutive sequences ﬁxed number observations typical sliding window approach shown Fig 3 We allow feature vectors cross boundaries trajectories This helps learn robot transitions state reached goal state Before clustering normalise feature vectors ensure variation vector magnitude distort clustering results We normalise ﬁeld feature vectors expressing value terms number standard deviations Fig 3 Sliding window construction feature vectors M Fox et al Artiﬁcial Intelligence 170 2006 59113 69 mean value ﬁeld This ensures gross differences ranges values interpreted magnitude differences clusterer The algorithm use clustering observation space Kohonen network cluster ing The Kohonen network performs unsupervised projection multidimensional data smaller dimensional space resulting identiﬁcation cluster landscape smaller dimensional space We chose use Kohonen selforganising network gives freedom avoid specifying number clusters advance We ﬁrst train network apply cluster selection function landscape identify signiﬁcant clusters Thus size network places upper bound number clusters need predetermine clusters data set contains In vector quantisation approaches 27 Kmeans clustering user supply number means K determines number clusters Similarly stochastic clustering techniques EM user supply number Gaussians use mixture determines number clusters learned In application important number evidence items determined autonomously structure observation data wish impose prior judgements observations robot making Furthermore selforganising network useful property clusters close network map concepts close reality We exploit property scalar product operations identify relationships evidence items behavioural states We process Section 32 The input clustering process ﬁnite set feature vectors constructed trajectories The outputs set evidence items ξ mapping cluster Φ ξ Using cluster mapping construct set histories H 23 Deﬁning state space Ψ Assumption It possible determine priori collection behavioural states associ ated task T We distinguish states unambiguously visible observer s0 starting state sg ﬁnishing state sf failure states identi ﬁed subjectively hesitating These denote subjective states The reﬁnement process replaces subjective states optionally visible states hidden states unknown human observer A human observer label observations robot performing T The labels associated observations occur real time The labelling indicates association observation behavioural state perceived human observer The set labels corresponds priori state set We set labels human observer L Given L deﬁne partial labelling trajectories human operator Deﬁnition 8 A partial labelling maps trajectory τ cid3o1 o2 oncid4 labelled trajec tory τ cid8 cid3o1 l1 o2 l2 lncid4 70 M Fox et al Artiﬁcial Intelligence 170 2006 59113 oi Φ li L nomark nomark label applied unlabelled ob servation We identify set states Ψ reﬁning label set L labelled trajec tories set evidence items ξ mapping cluster Φ ξ The algorithm use state splitting described Section 32 It works ﬁnding maximal cliques graph nodes correspond evidence items ξ A separate graph constructed state labels L The structure graph determined cluster mapping An edge constructed nodes ei ej cos1ei ej cid1 ρ ρ constant threshold angle vectors feature vector space ξ Each maximal clique corresponding subset evidence items ξ interpreted state Ψ The elements Ψ substates label set L nomark The inputs maximal clique ﬁnding algorithm set labels L set partially labelled trajectories set evidence items ξ mapping cluster Φ ξ The output set Ψ states state space task T 3 The core algorithms We main algorithmic components showing construct components described Section 2 We present al gorithms components way independent speciﬁc task environment robot platform considered Our objective emphasise generality approach taken In section explain data collected prepared presentation Fig 4 depicts entire process data collection output learned hidden Markov model representing behavioural transitions robot execution navigation task Fig 4 Learning HMM raw sensor data The bold arrows input output entire learning process M Fox et al Artiﬁcial Intelligence 170 2006 59113 71 31 Kohonen network clustering As stated Section 22 input clustering process set feature vectors constructed smoothing trajectories intervals time The outputs set evidence items ξ mapping cluster Φ ξ 311 The clustering process We performed clustering twodimensional selforganising map Kohonen net work 28 The Kohonen network identiﬁes patterns feature vector data way independent human inﬂuence The number clusters depends purely form data parameters network The parameters dimension network square grid learning rate neighbourhood size ran dom number seed initialise network vectors This independence important way deciding priori observations raw data contains relationship Kohonen clustering performs projection ndimensional data smaller k dimensional space k n determined user We use k 2 projecting multidimensional structure data 2dimensional space Within framework dimension network affects clusters interrelate The dimensions network 500 times smaller size data set 28 allow space clusters distinguished begin degenerate noise Our data set consists 15000 feature vectors experimented dimensions varying tween 15 45 Increasing dimension 35 increase noise cluster landscape negative effect quality learned HMM Using dimension 20 causes clusters combine reduces level discrimination resulting negative effect learning Networks dimension 25 30 best results data set demonstrate Section 6 Appendix B The map initialised random unit vectors appropriate dimension We initialised network random vectors cover network adequately insist initial vectors pairwise separated d degrees d constant chosen depending size network This reduce effects initial bias network Initial bias widely recognized problem use clustering algorithms All results presented averages 20 random number seeds discussed Section 6 The network trained presenting feature vectors turn aligning network vectors feature vectors closest Scalar multiplication determine closeness Alignment performed adding network vector pro portion sequence vector determined learning rate A neighbourhood value determines neighbourhood network vectors inﬂuenced input feature vector We implemented neighbourhood decay rate negative exponential function The effect reduce impact training vectors time Using function iterate training data times overlearning We learning rate decay form MacQueens averaging law 29 Thus way 72 M Fox et al Artiﬁcial Intelligence 170 2006 59113 Fig 5 Training Kohonen network determined learning rate neighbourhood value chosen 2dimensional space partitions regions The training set presented 100 times assist convergence training process After ﬁrst 50 iterations shufﬂe order feature vectors presented network order reduce extent resulting cluster landscape sensitive order presentation We experimented frequent shufﬂing noticed slightly reduces sensitivity ordering presentation results greater sensitivity unequal distribution different robot behaviours data set Each trajectory produces fewer examples smoothed observations associated starting ﬁnishing behaviours robot examples observations associated intermediate behaviours Experiments showed shufﬂing frequently led network failing distinguish starting ﬁnishing observations observations associated intermediate behaviours After training 2dimensional space mapped vector space dim2 vec tors dim dimension network In order identify clusters vector space apply cluster selection strategy network draws vectors highest peaks Our ﬁrst attempt strategy counted given cell M Fox et al Artiﬁcial Intelligence 170 2006 59113 73 cid3i j cid4 number cells ﬁxed radius 0085 cid3i j cid4 This count measure inﬂuence cid3i j cid4 network We hillclimbing strategy associate plateau cells ﬁrst closest peak There weaknesses associated approach The ﬁrst strategy composition peaks ends sensitive noisiness cells network We noticed different random initialisations got differ ent cluster landscapes A cell pulled way depending random factors small change initialisation network lead huge dif ferences cluster landscape Large variations later learning results highly dependent arbitrarily chosen random numbers Another weakness cells exerting inﬂuence terms network necessarily cells attracted input training Using method end throwing clusters interested favour ones attracted little input good indicators behaviour robot Further associating cells plateau nearest peak caused network distort badly cases large plateaus A better approach restrict draw cell spread clusters evenly landscape To address problems developed different cluster selection strategy uses number inputs attracted cell way identifying cluster landscape The cells attracted inputs highest peaks landscape Given cluster landscape intended represent structure data set decided cell attracts inputs unlikely interesting focus attention high peaks To achieve focus associate varying neighbourhood size peaks network considering peaks descending height order This neighbourhood different learning neighbourhood training We ﬁrst order peaks choosing largest ﬁrst remove network cells neighbourhood The size neighbourhood determined cid11 H cid12 C H number inputs attracted highest overall peak network C number inputs attracted current peak This value radius peak cell The process repeated highest peak cells remain considered Let C current peak H height highest peak network Clearly H C large values C risk losing interesting structure network This obviously undesirable resulting small collection clusters unlikely discriminating We require value H C slow smooth gradient sufﬁciently large collection discriminating clusters For size data set sufﬁciently large means tens clusters To achieve gradient require ratio H C small tens Cs By examining cluster landscapes constructed data set conﬁrmed requirement satisﬁed Fig 6 gives example typical cluster landscape generated network size 30 We strategy improve clustering stability reducing sensitivity noisiness randomly generated vectors Peaks network random initialisation expected The experiments 74 M Fox et al Artiﬁcial Intelligence 170 2006 59113 Fig 6 A clustering landscape obtained 30 30 Kohonen network presented Section 64 achieve high degree stability clustering results different random number initialisations Following training feature vectors reintroduced network classiﬁcation During classiﬁcation input sequence vector associated peak vector closest according scalar multiplication comparison feature vector peak vector The cells network correspond peaks contain vectors characterize evidence items clustering process These elements set ξ correspond evidence items observed robot executes task We refer vectors characteristic vectors Our clustering approach related Oates et al 15 considered prob lem clustering experiences robot qualitatively different action outcomes Their cluster prototypes closely related characteristic vectors constitute ontology activity It intended correspond qualitatively different states robot ﬁnd following execution action provide basis automating description actions taskplanning level By contrast characteristic vectors interpreted high level observations evidence items associated states intermediate level description task planning level As observations contribute identiﬁcation states intermediate level interpretation human observer critical accurately modelling behaviour robot respect task At end classiﬁcation phase feature vectors data set classiﬁed characteristic vectors network This puts position construct observation code book 312 Constructing sensor model A code book 27 mapping input values ﬁnite collection observation codes To build code book necessary associate characteristic vectors labels L nomark To facilitate annotate feature vector label associated observation sliding window feature vector M Fox et al Artiﬁcial Intelligence 170 2006 59113 75 constructed If labelled observations sliding window feature vector labelled mark The association feature vector label results new structure sequence vector The structure sequence vector deﬁned Deﬁnition 9 Deﬁnition 9 A sequence vector sv cid7fi l mdimensional feature vector associated label l set L taken labelled observation subsequence partially labelled trajectory cid7fi constructed If labels subsequence l mark label In construction code book input values sequence vectors deﬁned Deﬁnition 9 characteristic vectors identiﬁed clustering phase codes The mapping deﬁned classiﬁcation behaviour Kohonen network Deﬁnition 10 Given trajectory t cid3o1 oncid4 ladder lt sequence cid3 cid7f1 cid7fncid4 sequence vectors constructed trajectory t The sequence vector construction phase deﬁnes mapping trajectories ladders deﬁned Deﬁnition 10 socalled way sequence vectors overlap sliding window shown Fig 3 We construct association evidence items ξ labels L nomark counting number sequence vectors carrying label feature vectors classiﬁed evidence item This association turned probabilistic observation function following way Let s0 sn behav ioural states labelled L e0 em evidence items We interpret number associations given pair si ej proportion probability seeing evidence ej state si easily calculated Let Vjsi set sequence vectors associated evidence item ej labelled si Vsi set sequence vectors labelled si Now probability seeing evidence ej state si θij Vjsi Vsi The resulting function interpreted sensor model specifying probability seeing evidence item given state The sensor compound sensor capable observing evidence items clusterer This means subsequently model robots raw sensor data processed construction se quence vectors classiﬁcation means cluster Φ ξ In Section 6 present results showing quality HMMs learned basis sensor models constructed way reﬁned state splitting As seen Fig 19 quality HMMs learned basis poor We hypothesised states identiﬁed human observer fact states important distinguishing behaviours robot better results obtained subdividing humanobserved labels The labels L nomark abstract great deal potentially important variation behaviour including transitionary behaviour robot exhibits passes state 76 M Fox et al Artiﬁcial Intelligence 170 2006 59113 To explore hypothesis developed state splitting strategy brieﬂy described Section 23 decomposes original labels groups evidence items strongly associated states according code book sensor model constructed 32 Maximal cliques As stated Section 23 inputs maximal clique ﬁnding algorithm set labels L set partially labelled trajectories set evidence items cluster Φ ξ The output set states Ψ In code book multiple evidence items associated behavioural state This occurs evidence items perfect discriminators states Sometimes characteristic vectors evidence items separated vector space signiﬁcantly large angles When angles exceed 30 40 degrees plausible association clearly different evidence items havioural state indicate decomposition behavioural state substates possible The idea statesplitting distant groups characteristic vectors illustrated Figs 7 8 The procedure reﬁneθ Fig 7 begins constructing label s L graph nodes characteristic vectors evidence items associated label code book θ The edges graph angles vector space evidence items endpoints If vectors predetermined threshold apartfor example 40 degreesan edge corresponding nodes added graph maximal cliques remaining graph These steps illustrated lines 6 15 constructGraph procedure The maximal cliques contain evidence items 40 degrees Each maximal clique subset characteristic vectors associated original label suggesting substate behavioural state corresponding label The proce dure reﬁneθ shows ﬁnding maximal cliques leads construction reﬁned sensor model The sensor model θ 0 constructed code book identiﬁed substates We want replace original behavioural states labelled L nomark substates share association evidence item label substates label Thus evidence item e k association label s state s p substates quantity k shared p substates This case dividing k p equal partsthe sharing way reﬂects proximity substate evidence item e To need identify centre mass substate measure distance e centres mass We obtain average characteristic vectors substate obtain centre mass substate We scalar product resulting vector characteristic vector evidence item e obtain proximity e substate Finally substate given proportion association e label depending proximity e This calculation shown line 39 procedure reﬁneθ Fig 8 shows sharing achieved M Fox et al Artiﬁcial Intelligence 170 2006 59113 77 add edge ij G end end cluster node j G cluster node G angleij THRESHOLD initialise graph G cluster c ξ assocθ s c 0 add node c G 1 Procedure constructGraphθ sξ 2 Input code book θ label s evidence items ξ 3 Output graph structure G 4 5 6 7 8 9 end 10 end 11 12 13 14 15 16 17 end 18 return G 19 20 Procedure reﬁneθ θ Lξ 21 Input code book θ labels L evidence items ξ 22 Output sensor model θ 0 23 24 25 26 27 28 29 30 31 32 33 34 Record distance centre clique characteristic vector c 35 36 37 38 39 40 41 42 end 43 return θ 0 G constructGraphθ sξ First identify maximal cliques G Cs maxCliquesG initialise 2d array doubles ds cliques clq Cs Find mean clusters representing nodes clq avC computeAverageclq characteristic vectors c ξ end normalise dsclq cluster c ξ initialise sensor model θ 0 label s L θ 0clqc assocθ scdsclqc dsclqc scalarProductavCc end end Fig 7 Pseudo code showing state splitting procedure For routines assocθ s c association code book θ label s evidence item c 78 M Fox et al Artiﬁcial Intelligence 170 2006 59113 Fig 8 The state splitting procedure As result state splitting process code book rewritten terms substates The number evidence items change result state split ting number states increases determined structure vector space following clustering Interestingly states reﬁned set interpretation human obtained decomposition original set humanobserved labels Nevertheless new states represent interesting transitionary states important learning good state transition function improve results obtained EM phase The state collection results reﬁnement initial state labels state set Ψ sensor model constructed relationship Ψ ξ function θ 0 The relationship deﬁnes function ab Ψ L maps states Ψ labels initial collection ab indicates abstraction step We deﬁne function ev Ψ Pξ given state Ψ produces set evidence items constitute The following property holds s1 s2 Ψ abs1 abs2 evs1 cid15 evs2 means states map ab label contain evidence items We identify mapping labels sets substates given label produces set substates decomposition We mapping reﬁne L nomark PΨ It noted different substates Ψ composed exactly evidence items Their association different labels distinguishes However fact labels contain substates composed identical evidence items taken indicate sharing content labels Part power statesplitting M Fox et al Artiﬁcial Intelligence 170 2006 59113 79 procedure resides ability identify shared substructure abstract states characteristics distinguish We explain Section 6 recognition shared substructure exploited evaluation learned HMM The idea decomposing augmenting states HMM considered authors 116 In particular Koenig Simmons GROWBW algorithm allows new states added HMM needed account observations navigating robot Chrisman 16 shows dynamic partitioning state space model overcome problem perceptual aliasing occurs model contains states discriminate different observations Stolcke Omohundro 30 states dynamically merged generalise HMM In works HMM starts collection states determined priori known inadequate account observations State splitting merging applied learning process increase adequacy state set observations By contrast propose static state splitting strategy performed prior EM learning process Its purpose increase information content λ0 im prove quality learned model Indeed results present Fig 19 Section 6 demonstrate quality models learned state splitting signiﬁcantly higher obtained state splitting Once state set HMM decided changedonly nextstate observation probability distributions affected reestimation The states splitting algorithm applied labels L nomark Splitting allows states reﬁned transitionary states emerge structure accessible apparent human observer It intended state splitting algorithm identify complete respect available sensors set hidden states accounts behaviour robot respect task 33 Expectation maximisation We require way reestimate parameters HMM follow work Dempster et al 25 EM algorithm perform reestimation Our im plementation closely follows presentation HMM reestimation given Rabiners tutorial 5 In section paper focus issues arose EM perform reestimation initial HMM These issues initialisation HMM parameters effects results obtained need scaling way scaling performed multiple histories reestimation ﬁnally use learned HMM diagnose state given history In order selfcontained clarify contribution summarise main aspects EM technique In EM implementation reestimation key steps E step calculation maximum likelihood seeing evidence given model far M step process updating model maximize probability seeing evidence The E step performed socalled forwardbackward algorithm originally described 3132 clearly presented Rabiner 80 M Fox et al Artiﬁcial Intelligence 170 2006 59113 The M step transition sensor model components HMM updated affected scaling values generated forwardbackward algo rithm As Rabiner discusses scaling necessary E step avoid underﬂow Without scaling underﬂow occurs probability seeing long sequence evidence small history lengths grow E step calculations tend zero It neces sary demonstrate scaled values change interpretation update operations This straightforward single history learning subtle multiple histories In work paper multiple histories data set contains multiple separate independent trajectories In Appendix A discuss implemented scaling mechanism fol lowing Rabiners presentation In section present core components E M steps showing scaling managed case multiple histories 331 Basic framework We begin providing deﬁnitions Rabiners tutorial necessary presentation The forward backward variables deﬁned The M step EM procedure performs updating model deﬁned terms forward backward variables Deﬁnitions 11 12 13 14 Eqs 1 2 taken Rabiners paper Deﬁnition 11 Given history h cid3e1 e2 eT cid4 collection states Ψ model λ Ψ ξ π δ θ forward variable αt deﬁned probability state si time t having seen ﬁrst t elements h given model λ This formalised αt P e1 et qt si λ The forward variable constructed recursively follows Initialisation α1i πiOie1 1 cid1 cid1 N Induction αt1j Ncid1 Termination αt iδi j θj et1 1 cid1 t cid1 T 1 1 cid1 j cid1 N P h λ Ncid1 i1 αT Deﬁnition 12 Given history h cid3e1 e2 eT cid4 collection states Ψ model λ Ψ ξ π δ θ backward variable βt deﬁned probability seeing T t elements h given state time t si given model λ This formalised βt P et1 eT qt si λ M Fox et al Artiﬁcial Intelligence 170 2006 59113 81 The recursive construction backward variable follows Initialisation βT 1 1 cid1 cid1 N Induction βt Ncid1 j 1 δi j θj et1βt1j t T 1 T 2 1 1 cid1 cid1 N With variables deﬁne transition model sensor model update components M step The prior probability distribution π reestimated unambiguous initial state identiﬁed probability 1 We assume case explain Section 333 We begin basic transition model update In following primed notation δcid8i j θ cid8 j k denotes updated values δi j θj k respectively Deﬁnition 13 The transition model component δ λ updated according following equation cid2 cid8 δ j T 1 t1 αt iδi j θj et1βt1j T 1 t1 αt iβt cid2 Deﬁnition 13 speciﬁes j th element δcid8 given expected frequency transitions state state j divided expected frequency state The sensor model updated according similar rule Deﬁnition 14 The sensor model component θ λ updated cid8 j k θ αt j βt j cid2 T t1 stet k cid2 T t1 αt j βt j Deﬁnition 14 states probability observing evidence k state j given expected frequency state j observing evidence k divided expected frequency state j We turn scaling issue effect update equations The tth ward scaling term deﬁned likelihood seeing ﬁrst t elements history state This expressed Ct tcid3 v1 cv cv normalisation term cid2 1 N i1 αvi 82 M Fox et al Artiﬁcial Intelligence 170 2006 59113 The t 1th backward scaling term deﬁned Dt1 Tcid3 vt1 cv The normalisation term cv calculated E step The update equations deﬁning δcid8i j θ cid8 j k rewritten incorporate scaling terms M step Eq 1 shows transition model update modiﬁed cid2 T 1 t1 cid8 δ j cid2 T 1 t1 Ct αt iδi j θj et1Dt1βt1j cid2 N j 1 Ct αt iδi j θj et1Dt1βt1i The variables αt βt scaled multiplying Ct Dt respectively The scaled forms written notation ˆα ˆβ Thus 1 Ct αt ˆαt Dt βt ˆβt The sensor model update θ cid8 j k modiﬁed similar way Rabiner shows terms Ct Dt1 expressed form independent t cancel leaving update operations shown Deﬁnitions 13 14 332 Scaling multiple sequences Rabiner discusses fact depending kind HMM learned need learn multiple histories preference long sequence evidence In case necessary modify reestimation formulas add individual frequencies occurrence sequence Before sum expected frequency transitions j sequence k scaled dividing likelihood sequence k given model The expected frequency state sequence k divided likelihood If Pk likelihood sequence k achieved multiplying contributions sequence numerator denominator 1 Pk cid2 K k1 1 Pk cid2 cid2 cid8 δ j Tk1 t iδi j θj ek t1 αk cid2 T 1 K 1 t iβk t1 αk k1 Pk t1βk t t1j 2 From Rabiner CTk 1 Pk writing Eq 2 terms scaled forward backward variables obtain cid2 cid2 cid8 δ K k1 j ˆαk t iδi j θj ek cid2 t ˆβk ˆαk Eq 3 corrects Rabiners equation 111 5 erroneously leaves place 1 terms These removed taken account Pk t1j t1 ˆβk t Tk1 t1 cid2 K k1 T 1 t1 3 M Fox et al Artiﬁcial Intelligence 170 2006 59113 83 scaled variables This observation Kevin Murphy implementation HMM code BNT package 33 333 Initialising model parameters In order help EM avoid converging local maximum far global maximum try initial model λ0 Ψ ξ π δ0 θ 0 informative pos sible Ψ created state splitting applied initial set state labels L We split visible subjective states consequence visible states subdivided sets substates This makes difﬁcult ensure useful ordering exists visible subjective states maintained A simple way avoid problem include visible states splitting process However wish allow interesting substates starting ﬁnishing haviours identiﬁed exist data We restore ordering property introducing supplementary start end states ordered respectively states Ψ During statesplitting process visible states starting ﬁnishing replaced sets states Ψ We specify supplementary start sstart precedes states Ψ associated state splitting visible state labelled starting supplementary end send succeeds states Ψ associated visible state labelled ﬁnishing These supplementary states added Ψ allow deﬁne δ0 follows δ0x sstart 0 δ0send send 1 δ0send x 0 states x states x cid15 send The initial probabilities transition supplementary states states model arranged transitions supplementary start state associ ated high probability entering substates original visible starting state transitions substates original ﬁnishing state associated high probability entry supplementary end state The probability transitions remaining pairs states assumed equal The details construction discussed Appendix A Introduction supplementary states slightly complicates construction initial sensor model θ 0 We specify observation probability associated supplementary states These states artiﬁcially introduced particular association real evidence However associated distribu tions evidence items way distort learning process Our solution problem introduce supplementary start observation supplementary end observation estart eend associate high probabil ity supplementary states corresponding supplementary observations These details discussed Appendix A Finally π extended include supplementary states probability 1 associated supplementary start state 84 M Fox et al Artiﬁcial Intelligence 170 2006 59113 Using supplementary states construct initial model cid4 Ψ sstart send ξ estart eend π δ0 θ 0 λ0 cid5 334 Finding best state sequence In order use learned HMM diagnose state robot given history cid3e1 e2 encid4 need able ﬁnd optimal state sequence associated history state sequence best explains cid3e1 e2 encid4 The Viterbi algorithm 24 dynamic programming algorithm ﬁnds best state sequence cid3q1 q2 qncid4 given history The Viterbi procedure relies quantity δt max q1q2qt1 P q1 q2 qt e1 e2 et λ corresponds highest probability given model λ single path q1 q2 qt time t accounts ﬁrst t evidence items ends state Rabiner presents inductive deﬁnition δt identical deﬁnition forward variable αt reported Deﬁnition 11 maximisation previous states instead summation inductive deﬁnition αt The Viterbi procedure track states highest probability path maintains array path extracted end maximisation process We use Viterbi procedure evaluate quality learned HMM The details evaluation procedure presented Section 6 4 Experimental setup 41 Robotics environment Although approach taskindependent chose experiment learning model navigation task This fairly complex task behavioural modelling whilst time wellunderstood easily experimented The low level functionalities comprising navigation thoroughly explored mobile robotics providing ﬁrm foundation support learning process To performed robustly navigation involves different capabilities including localisation terrain modelling motion generation adapted presence obstacles Our approach built level Given basic navigation capabilities learn passive model havioural states robot visits navigating certain distance certain class environments We trying improve way robot navigates understand navigates order able predict explain robots behaviour future executions navigation task In order build coherent model navigation action performed large number experiments nomadic XR4000 platform The software original architecture developed LAAS 34 The sensorymotor functions separately programmed functional modules tool named GenoM 35 M Fox et al Artiﬁcial Intelligence 170 2006 59113 85 Fig 9 A typical environment conﬁguration robots point view We chose particular navigation technology suited environments robot manoeuvre The technology based use odometry localisation Sick laser range scanner obstacle detection Nearness Diagram technique described 3638 map building obstacle avoidance motion gener ation This technique navigation behaves highly cluttered dynamic indoor environments It course suited kind environment We recorded 58 trajectories taking 30 90 seconds complete robot navigating approximately 10 metres Our environment unstructured sisting cluttered open space open human trafﬁc We environment vary trajectories sparsely highly cluttered dynamic Fig 9 shows typical environment conﬁguration The space open area busy laboratory Obstacles placed space The picture shows positions obstacles desks walls bounding area according laser readings robot The positions obstacles plotted according readings taken different points trajectory The localisation technique robot based odom etry explains inaccuracies alignments obstacle positions seen different locations The approximate trajectory robot shown travels starting point destination given run At points shown laser scan represented collection sectors represents segment devoid obstacles according laser scanner The state sampled frequency 5 Hz Each sampling recorded values 16 variables including following raw features coordinate position robot relative starting position given coordinate laser readings indicating positions obstacles proximity robot speed 86 M Fox et al Artiﬁcial Intelligence 170 2006 59113 robot travelling x y directions angular velocity robot Euclidean distance travelled measurement The choice variables record use construction feature vectors course highly dependent task functional level chosen modelling sensory capacity executive question However methodology followed research described paper restricted particular task robot considered It applied learning different tasks alternative robot platforms different sensory capabilities 42 The navigation states In experiment priori set labels consisting visible states starting ﬁnishing states subjective states hesitation obstacle avoidance progress search The progress state state robot moving unen cumbered environment Hesitation state robot temporarily trapped highly cluttered region unsure proceed Searching represents robot embarking routes turn dead ends effort ﬁnd path Obstacle avoidance visually distinguishable hesitation searching robot typically making progress veers avoid path We identify failure states experiment straightforward include failing trajectories robot collides obstacle prematurely termi nates trajectory identify corresponding failure states We limiting assumptions prevent inclusion failure states However robot rarely col lided obstacles thanks efﬁcacy control software gather data representative failures experiment 43 Sensorymotor data features We identiﬁed features important discriminating behaviours robot execution navigation task These distance origin curvilinear distance travelled sequence change heading sequence total rotation clutteredness distance goal speed travel acceleration These features ob tained smoothing integration 6second intervals time These standard techniques signal processing 39 The variables distance origin distance goal useful help discriminate visible states start end The distance origin calcu lated Euclidean distance position robot start trajectory starting coordinate position start fragment trajectory cap tured feature vector The distance goal calculated Euclidean distance position end fragment goal coordinate Curvilinear distance segmented approximation actual curvilinear distance travelled robot fragment trajectory represented feature vector It estimated sum Euclidean distances travelled successive obser vations fragment Change heading measure magnitude angular change fragment A large change heading indicates robot turning fre M Fox et al Artiﬁcial Intelligence 170 2006 59113 87 quently large angles This tend indicate robot avoiding obstacle searching viable path Total rotation measures extent change heading cancelled turning forth turning pre dominantly direction Rapid oscillating associated hesitating searching behaviours giving rise small angular turns sum close zero Cluttered ness measure density obstacles robots immediate vicinity duration sequence It smoothed representation clutteredness associated individual observations fragment represented feature vector Speed travel smoothed representation speed robot travelling fragment corresponding feature vector Acceleration measure change speed robot fragment obtained taking difference maximum minimum speeds robot travelled consecutive observations If speed low acceleration high indicate robot braking speeding occur robot negotiating way obstacles Finding discriminating set features complex data set challenging problem We experimented different combinations arriving collec tion features Our choice features inﬂuenced particular task hand different task require different set discriminating features characterise 5 Learning hidden Markov model The preceding sections described components necessary learn hidden Markov model raw signals emitted physical We bring components learning process receives signals emitted robots sensors outputs learned HMM In rest paper discuss quality models navigation task learned methodology However accurate readings observations robot precisely correspond reality robot operating The robot observe world partially means sensors Since interested knowing robot behave reality necessary connection internal world robot external world acts senses We approached problem use simple labelling strategy 51 Labelling feature vectors To connection robots observations states HMM devised method labelling observations identiﬁers set L described Section 2 In experiments L consisted labels identiﬁed Section 42 visible subjective These labels correspond behaviours experimentors able recognise distinguish reasonable certainty Any visually distinguishable behaviours labelling As described Section 31 priori collection labels reﬁned according patterns identiﬁed automatically data set clustering phase 88 M Fox et al Artiﬁcial Intelligence 170 2006 59113 Fig 10 A labelled trajectory During robot runs robot displayed distinguishable behaviour terrupted recording associate observation correspond ing label identiﬁed experimentor Each trajectory partially labelled This labelling process coarse gives way relating recorded data sub jective judgement external reality acquired Fig 10 shows partially labelled robot trajectory The experimentor tended introduce slight delay labelling taking time recognise behaviour displayed Thus labels tend occur slightly later trajectories points associated behaviours occurred This taken account interpretation labelled trajectories explain Sec tion 6 The subjective nature judgements experimentor course means judgements precisely correspond reality We discuss consequences evaluation learned model Section 6 It important emphasise labels play role clustering data The clusterer concerned feature vectors ignores labels training classiﬁcation processes The labels clustering complete construction sensor model described Section 312 It course surprising human observers select collection hid den states turned chance useful ones learning accurate nextstate transition function We believe statesplitting technique Section 32 helps mitigate effects choosing priori label set introducing missing states important determining behaviour robot necessarily susceptible interpretation human observer 52 Constructing evidence sequence The EM algorithm learns improve given initial model respect evidence observed signal source case robot Evidence presented single sequence multiple sequences depending properties model Our experiments divided separate trajectories robot terminating robot reached goal position Because structure trajectory properties model fully ergodicthe robot progresses start state end state We chose present evidence set separate histories derived different trajectory This presentation excludes transitions end state start state enables construct δ0 deﬁned Section 333 M Fox et al Artiﬁcial Intelligence 170 2006 59113 89 Each history ht derived ladder lt obtained sequence vector construction given trajectory t Our strategy build sparse ladder slt taking kth sequence vector lt k density value determined experimentally For example k 1 slt identical lt whilst k 15 slt thinned version lt containing 15th step lt Following construction slt feature vectors obtained sequence vectors slt presented Kohonen network classiﬁcation Thus step cid7fk sparse ladder slt cid3 cid7f1 cid7fncid4 slt classiﬁed evidence item ξsltk produces history ht cid3ξslt1 cid4 evidence associated trajectory t We expect quality learning improve frequency k increases When evidence sampled low frequency robots behaviour omitted history association evidence items sampled observed behaviour likely missed With higher frequencies history richer association likely The results present Section 6 point higher frequencies result better models learned ξsltn Fig 11 shows example learned HMM evidence sampled 06 sec ond intervals The picture shows statesplitting process produces 65 states initial set 7 labels including mark label To simplify interpretation graph states grouped rectangles associated labels reﬁne Dark transitions represent highest probability transitions states whilst lighter edges represent lower probability transitions 53 Parameter settings Before discussing results explain chose values parameters govern important aspects clustering learning processes When decomposing initial set labels L nomark evidence items ξ necessary decide characteristic vectors participate decomposi tion label For label l L nomark ﬁxed threshold association characteristic vectors label determine vectors partition substates label The association characteristic vector c label l given number sequence vectors labelled l classiﬁed c network training process The reason setting threshold characteristic vectors turn marginally associated labels There orders magnitude difference low association mean given label We judged low associations consequence noise effects training process The threshold deﬁned ml µl σl4 µl mean association characteristic vectors l σl standard deviation association Experiments showed mean association threshold led vectors excluded decomposition label improved results obtained lowering threshold slightly We achieved 90 M Fox et al Artiﬁcial Intelligence 170 2006 59113 Fig 11 A learned HMM navigation task The rectangles tall narrow labelled high level labels associated collections states inside The Initial End states dummy states construct θ 0 good results subtracting σ4 Our goal lower threshold increase robustness noise training classiﬁcation processes Having selected group characteristic vectors partition substates label need decide degree separation substates We angular separation 40 degrees determine vectors considered substate A larger angle causes substates fragment destroys structure label Too small angle results large substates inadequate decomposition The importance parameter discussed Section 32 To construct evidence histories took sequence vector collec tions sequence vectors generated 58 trajectories data set We considered lower frequencies present comparative results section Because obser vations sampled 5 Hz selecting vector corresponds taking evidence 06 seconds trajectory M Fox et al Artiﬁcial Intelligence 170 2006 59113 91 6 Results discussion We present analyses sets results We ﬁrst consider quality learned HMM terms ability produce traces abstract state space corre spond robot observed follow reality The quality HMM highly dependent clustering phase As second stage evaluation examine stability clustering results The clustering process mainly affected parameters size network random initialisation As noted Section 31 results clustering phase slightly sensitive order presentation training data discuss issue We experimented range different network sizes noted affect quality traces produced consequent learned HMM In discussion present results obtained network size 30 In Appendix B present evaluation HMMs learned networks different sizes We clustering results sensitive random initialisation leading varying sized sets ξ Ψ We average results given network size 20 different random initialisations network 61 Evaluation HMM The Viterbi algorithm provides way diagnosing behaviour robot observations makes execution task Given histories evidence items constructed clustering process learned state transition sensor mod els diagnose probable state transitions robot ﬁnding probable explanation evidence item given states visited far One way evaluate quality learned HMM compare sequences states constructed Viterbi algorithm human observed robot visiting execution task We refer sequence states visited Viterbi algorithm Viterbi sequence states sequence Viterbi states The human observer drew observations set visible subjective states L deﬁned Section 2 The way identifying states actually visited robot given trajectory use labelled observations trajectory The labelling process inaccurate difﬁculty human observer distinguishing sim ilar states robot example hesitation searching Furthermore human observer tended label late took time interpret robots behav iour select appropriate label This means label ended associated data recorded robot transitioned different state Finally fewer sequence vectors data set labelled visible states labelled subjective states robot entered visible states frequently The learning process slightly biased recognising starting ﬁn ishing behaviours distinct behaviours model However labelling process ﬂawed labels provide way connect Viterbi sequences observed somewhat noisy reality 92 M Fox et al Artiﬁcial Intelligence 170 2006 59113 We evaluate given Viterbi sequence V comparing labelled trajectory corresponds The states V separated kr seconds k frequency sequence vectors sampled trajectories construction histories r rate Hz observations sampled robot The chosen frequency determines density evidence items histories The Viterbi sequence V obtained given history H exactly Viterbi state V evidence item H For history record trail Viterbi states corresponding evidence items superimpose humanobserved labels times trails occur underlying trajectory We deﬁne association history trail follows Deﬁnition 15 A trail T cid3t1 thcid4 sequence Viterbi states corresponding history H h evidence items For evidence item H exactly Viterbi state T Deﬁnition 16 A labelled trail trail humanobserved labels super imposed These labels necessarily coincide states trail Deﬁnition 17 The trail fragment preceding label l labelled trail sequence Viterbi states V cid3vk vmcid4 intervening humanobserved label l trail l If l coincident vm add fragment Viterbi state vm1 immediately following l As Deﬁnition 17 shows trail fragment preceding label l actually contain ﬁrst Viterbi state following l trail The reason l lies Viterbi states correspond Viterbi state The human labelling process sufﬁciently reactive possibility ruled We increment score trail time match human observed label preceding trail fragment The superimposition humanobserved labels trail association label preceding trail frag ment seen Fig 12 Care taken deﬁning meant match Because problem late labelling discussed Section 51 look preceding trail fragment substate identical structure substates comprising label l Deﬁnition 19 states precisely Fig 12 The structure trail M Fox et al Artiﬁcial Intelligence 170 2006 59113 93 Deﬁnition 18 Two states si sj Ψ ξ identical contain exactly elements ξ Deﬁnition 19 A humanobserved label l L associated set substates S s1 sm means mapping reﬁne L PΨ We l matches preceding trail fragment V substates V ξ identical set S Given preceding trail fragment long Deﬁnition 19 permissive It suggests scoring rate poor Viterbi sequences artiﬁcially increased long preceding trail fragment likelihood seeing matching substate high This case preceding trail fragments tended ex hibit ﬂuctuation states level humanobserved labels However Fig 13 shows network sizes preceding trail fragments highly stable granularity despite occurrence subtle state changes granularity substates We compared ﬂuctuation Viterbi states trail fragment corresponding interpretations states application ab Ψ L In Fig 13 rows correspond different sizes clustering network The columns degree state variation observed trail fragments generated Viterbi algo rithm model learned bases networks Variation measured counting times value changes trail fragment The ﬁnal columns mean variability ratio substates labels centage standard deviation It observed network size 30 times variation substate level label level picture fairly consistent different network sizes Furthermore variability label level low consistently state change We ﬁnd results encouraging expect rational signiﬁcant state change ﬁne levels granularity stability increasing granularity increases 62 Precision measurements Analysis relationship substates labels demonstrates substate associated multiple labels revealing confusion models ability distinguish similar behaviours Consider substate s shared k different labels During evaluation Viterbi sequence score incremented human observed Label variability Substate variability Variability ratios Mean 082 080 081 079 078 Std 029 030 029 028 027 Mean 181 196 213 220 228 Std 060 069 074 075 077 Mean Std 229 255 274 295 307 60 73 82 96 86 15 20 25 30 35 Fig 13 Table showing state ﬂuctuation trail fragments 94 M Fox et al Artiﬁcial Intelligence 170 2006 59113 k labels Viterbi sequence visited s preceding trail fragment The usefulness evaluation depends k close 1 possible We observed case substate maps 4 labels add points evaluation regardless label applied human observer This makes substate completely undiscriminating artiﬁcially inﬂating corre spondence Viterbi sequences label sequences This led devise method measuring degree precision ab Ψ L mapping The measure obtained calculating substate number n labels associated This number number pairwise comparisons Viterbi sequences containing substate beneﬁt We sum value m substates giving following quantity mcid1 i0 ni ni 1 This quantity divided total number substate pairs cid2 m i0 ni ni 1 m m 1 resulting proportion possible comparisons Viterbi sequence beneﬁt undeservedly visiting substate The higher value lower preci sion mapping We value confusion factor As observed comparison presented Appendix B confusion factor highest small networks This explained small clustering networks lead distinct characteristic vectors statesplitting results high degree sharing vectors states 63 Results Fig 14 shows Viterbi sequence evaluations obtained HMM learned basis 20 randomly initialised networks size 30 The results presented dis tribution 58 trajectories 20 random numbers 1160 values The mean score 7618 promising However precision issue account extent confusion exhibited model A high degree confusion undermine apparently high score In order evaluate good score account consistency agreement Viterbi sequences generated different random number seeds Low consistency indi cating quality HMM sensitive random initialisation clustering network undermine goodness score Fig 15 shows beneﬁt percentage overall score obtained confusion resulting network size 30 The rows table correspond human observed labels columns correspond states L nomark obtained applying ab Ψ L winning states preceding trail fragments Viterbi sequences Viterbi state wins comparison responsible incrementing score comparison We denote mark state NM This state observed experimentor identiﬁed probable M Fox et al Artiﬁcial Intelligence 170 2006 59113 95 Fig 14 Comparison Viterbi sequence evaluations network size 30 Performance shown account confusion consistency affect true quality learned HMM Humanobserved label Viterbi state 1 2 3 4 5 6 1 0 0 0 00 0 2 0 17 0 01 14 3 01 06 0 11 14 4 0 0 0 83 0 5 03 01 08 00 13 6 00 08 18 0 20 7 00 11 17 0 08 06 Fig 15 Table showing beneﬁt obtained confusion network size 30 Most beneﬁt obtained 54 confusion Other beneﬁts minimal Viterbi state It observed far greatest beneﬁt obtained humanobserved label 5 winning Viterbi state 4 All beneﬁts obtained confusion minimal We calculated confusion factors 20 HMMs obtained size 30 networks 20 different random number seeds The upper bound confusion factor computed 20 models formula presented Section 62 0023 median value 0008 By contrast upper bound confusion factor 20 models learned size 20 networks 0052with median value 0017 twice confusion size 30 networks Models learned size 35 networks exhibit lower level confusion upper bound 0015 median value 0006 However differently randomly initialised size 35 networks lead lower consistency corresponding learned HMMs discuss 96 M Fox et al Artiﬁcial Intelligence 170 2006 59113 The high degree 54 confusion explained following way The label 4 corresponds ﬁnishing state robot normally entered ﬁnishing state im mediately visiting state labelled 5 Thus sequence vectors labelled 5 features common labelled 4 causing clusterer confuse correspond ing observations A sequence vector labelled 5 likely classiﬁed evidence item associated substate state 4 This occurring Viterbi se quence proposes 4 humanobserved label 5 This confusion rarely occurs way δ0 Bakis model 40 partially ordered model strongly reinforces recognition terminal state For given network size trajectory consistency measure agreement Viterbi sequences generated trajectory 20 different random numbers Clearly reliable performance obtained confusion low consistency high We obtained best combination factors network size 30 Fig 16 shows consistency obtained 20 size 30 networks This graph depicts mean percentage Viterbi sequences agree state visited 58 trajectories It shows highest degree consistency reached 92 whilst models demonstrated 77 consistency 90 trajectories The frequency evidence items sampled data signiﬁcantly af fects quality learned HMM according evaluation Fig 17 shows performance quickly declines frequency decreases consistent hypothesis proposed Section 52 Fig 16 Consistency agreement Viterbi sequences models based networks size 30 The xaxis shows percentage agreement obtained The yaxis shows cumulative percentage trajectories bounded corresponding degree consistency M Fox et al Artiﬁcial Intelligence 170 2006 59113 97 Fig 17 Comparisons Viterbi sequence evaluations different evidence frequencies The frequency number indicates separation successive sequence vectors 1 5 seconds raw data sampled 5 Hz Thus large frequency number corresponds lower frequency evidence sampling Lower frequencies lead degradation performance We performed experiment determine construction initial sensor model code book approach gives advantages random initial sensor model Fig 18 shows clear advantage obtained We tested advantage obtained statesplitting comparing results obtained state splitting obtained initial set usersupplied labels Fig 19 allows conclude statesplitting yields highly signiﬁcant advantage 64 Evaluation clustering phase We focus discussion stability clustering results obtained given network size Different random initialisation led marked difference sizes sets ξ Ψ We seen Fig 16 differences observed sizes ξ Ψ lead consequent divergence behaviour learned models We cluster structures stable despite variation sizes ξ s constructed different random initialisations In table Fig 20 extent identity states L preserved different random initialisations We require following deﬁnitions Deﬁnition 20 The weight element s Ψ computed sum associations s element e ξ e evs The association determined cell s e matrix deﬁned θ 0 We denote weight s ωs 98 M Fox et al Artiﬁcial Intelligence 170 2006 59113 Fig 18 Comparing random initial sensor model code book generated Kohonen network clustering Random initial sensor models lead highly signiﬁcantly poorer performance code book sensor models Fig 19 Comparing results statesplitting results obtained splitting M Fox et al Artiﬁcial Intelligence 170 2006 59113 99 Net size 30 Label 1 2 3 4 5 6 NM 1 6628 05 089 0 1465 381 34 2 059 3618 549 037 013 755 1286 3 053 823 3049 011 235 1395 866 4 0 029 005 508 2557 024 057 5 1944 028 604 4577 4682 289 786 6 64 2118 3596 044 293 5907 1312 NM 676 3334 2108 251 754 1248 5353 Fig 20 Table showing strength identity states L random initialisations clustering network Values percentages We consider confusion mark state NM problematic Deﬁnition 21 The combined weight element l L computed sum weights ωs element s reﬁnel We deﬁne measure association substates drawn different state sets Ψ1 Ψ2 Deﬁnition 22 The association product substates s1 Ψ1 s2 Ψ2 computed product combined weights labels l1 l2 obtained abΨ1s1 abΨ2s2 respectively Deﬁnition 23 The centre point substate s Ψ computed average evidence items evs We denote centre point cps To measure degree preservation identity states L construct square matrix cell j indicates extent j s coincided random initialisations cluster network The matrix indicates states L preserve identity values diagonal high preferably highest values row Given collections substates ΨA ΨB computed different random num ber seeds A B ﬁrst compute centre points elements collections We sample centre point cpsA ΨA measure closeness cen tre points computed ΨB The closest centre point ΨB denoted cpscid8 The matrix B entry s scid8 increased association product s scid8 The results analysis shown table Fig 20 observed values diagonal highest case label 3 signiﬁcant confusion label 6 The table shows percentages associations row attaching label We include mark label denote NM Some confusion certain pairs states 3 6 evident observed discussions confusion Section 61 Nevertheless results overall indicate variation number evidence items substates constructed clusterer different random initialisations translate instability recognition key behavioural states 100 M Fox et al Artiﬁcial Intelligence 170 2006 59113 7 Future work In future work intend use learned HMMs monitoring controlling execution corresponding tasks We developing plan execution architecture learned HMMs provide low level state estimation capability supports monitoring execution speciﬁc planned action task As robot executing task Viterbi algorithm online track likely trajectory followed robot provide detailed picture execution path likely unfold The key advantage HMM allows failure predicted occurs enabling appropriate response early termination activity Fig 21 shows architecture plan policy execution uses learned HMMs monitoring controlling execution dispatched actions At simplest controlling execution task limited aborting execution probability failure predicted given threshold The component architecture labelled state estimation component tracks traversal current HMMs reports behavioural state robot execution monitor regular intervals On state report monitor sends command execution sub abort task execution continue following low level program associated task handprogrammed control strategy policy low level control strategy followed robot HMM learned When reported state terminal states task execution monitor reports task having successfully completed HMM correspond ing dispatched action accessed The relationship monitor state estimation component inspired modelbased diagnosis work Williams coauthors 2141 These tech niques underpin plan execution monitoring capability Remote Agent 42 remains prominent successful applications plan execution Fig 21 A plan execution architecture behavioural state monitoring When action dispatched exe cution corresponding learned model dispatched state estimation module allow behaviour tracking The heavy line model suggests probable trajectory followed There feedback state estimation execution monitor dispatcher communicate successful termination task probable failure M Fox et al Artiﬁcial Intelligence 170 2006 59113 101 technology Livingstone modelbased reasoning component Remote Agent dis crete modelbased controller single declarative spacecraft model detect failures execution planned steps propose strategies repair replacement failed components In work models behavioural physical diagnosis identiﬁes deviant behaviour disfunctional components Once recognised deviant behaviour terminated avoid task failure unnec essary waste resources committed failing endeavour We taken care paper work navigation task speciﬁc particular robot platform environmental setup learned model dependent factors To explore generality approach begun consider tasks belonging application areas In particular successfully applied learning process learning models navigation simulated sciencegathering actions different robot platform 8 Conclusions We shown stochastic learning techniques signal processing learn hidden Markov model robots behaviour executes given task The model provides introspective capability integrated high level mission planning reasoning The learning model completely automated point acquisition sensor readings robot Although presented work terms speciﬁc task indoor navigation speciﬁc robot platform approach generalised different tasks platforms We assumptions sensorymotor equipment robot The initial clustering phase completely general resulting organisation raw sensor readings discretized collec tion codes The codes taken abstractions robots observations sensed means abstract sensor described codebook based sensor model A prob abilistic state transition model learned reﬁned sensor model Expectation Maximization algorithm Although EM learn models behaviour innovations First deﬁne state set advance leave deter mined following clustering phase Thus number states transition model determined dynamically human makes prejudgements nature behavioural model Second states model correspond substates behaviours hesitation obstacle avoidance search robot conﬁgurations robot respect physical features environment Thus learned HMM model robot behaves applies equally physical environment sharing structural features ones learning took place We far evaluated learned HMMs Viterbi algorithm explain histories evidence obtained classiﬁcation observations recorded robot executions task We compared Viterbi sequences generated labels applied human observer robot observations These labels provide connection reality perfect allows estimate extent 102 M Fox et al Artiﬁcial Intelligence 170 2006 59113 learned HMM accounts uncertainty actual execution environment Our step evaluate learned HMMs basis execution monitoring strategy onboard robot Much remains believe important ﬁrst step learning reliable connection raw sensed data recorded robot symbolic reasoning level Acknowledgements We like thank Felix Ingrand Derik Schröter Brian Williams Nicola Muscettola helpful discussions suggestions We grateful Jonathan Gough helping explore generality approach considering application learning models different tasks We like thank anonymous reviewers ob servations suggestions Finally Maria Fox wishes thank CNRS funding sabbatical visit LAAS work possible Appendix A Implementation A1 Implementing scaling reestimation mechanism As described Section 331 forward backward variables αt βt scaled scaling coefﬁcient 1 N i1 αt ct cid2 Thus term scaling βt normalising αt simple strategy collect normalisation terms computed forward compu tation use scale backward variables backward computation To reestimate δ component model simply calculate sum times t expected frequency transitions state state j divided sum times t expected frequency transitions state The accumu lation ﬁrst sum performed line 15 second line 10 procedure updateδ Fig A3 The division computed line 6 procedure doδupdate Fig A5 A similar update function deﬁned θ calculates expected frequency state observing evidence e divided expected frequency state These functions implement equations presented Deﬁnitions 13 14 When multiple histories situation complicated need calculate frequencies independently different histories In Fig A1 reestimation mechanism typically presented single histories evidence Fig A2 contrasts multiple histories case To implement equation shown Section 332 distinguish local global frequencies occurrence For transition model update function requires square matrix vector deﬁned history hk Fijk local frequencies j transitions Fik local frequencies transitions state A global matrix Fij deﬁned global vector Fi The dimensions structures determined number states δ M Fox et al Artiﬁcial Intelligence 170 2006 59113 103 1 Procedure reEstimateMhP 2 Input model M single history h T evidence items prior state distribution P 3 Output updated model M 4 repeat 5 6 7 8 9 10 M doδupdateMFij Fi 11 M doθ updateMCFij Fi 12 convergence 13 return M forwardBackward returns array T state distributions sv Note forwardBackward initialises α β terms updateδ sv forwardBackwardhP Fi Fij Fi updateδMhsv CFij updateθ Mhsv Fig A1 The reestimation function single history case The array Fi expected frequency T 1 timepoints transitioning state Fij expected frequency transitioning state state j Fi expected frequency T time points transitioning state The array CFij expected frequency state observing evidence j For history hk values Fijk Fik calculated local update procedure single history case shown Fig A3 These summed Fij Fi end iteration lines 13 16 Fig A2 The division Fij Fi takes place summation complete seen examination equation Section 332 This implemented line 6 Fig A5 single history case Finally iteration reestimate procedure update δ θ lines 26 27 Fig A2 reset local global matrices vectors zero The sensor model θ updated similar way Given history hk matrix CFijk stores local frequencies evidence items j seen states These values summed global matrix CFij line 22 Fig A2 On line 17 doθ update Fig A5 seen CFij divided array Fi Fi doδupdate The reason Fi store expected frequency exiting T th state transitions T th state possible However evidence observed T th state correct updating θ relies division CFij expected frequency transitions accumulated timepoints We accumulate values array line 14 reEstimate procedure shown Fig A2 The need construct additional array storing additional value applies single multiple histories Fig A2 auxilliary procedures correctly implement Rabiners scaling rees timation mechanism case multiple evidence sequences presented EM procedure A2 Dealing split starting ﬁnish states When known process characterised distinct start end states best estimation underlying HMM obtained leftright 5 model In 104 M Fox et al Artiﬁcial Intelligence 170 2006 59113 initialise Fi Fi Fij CFij reset Fi reset Fi j reset CFij h H sv forwardBackwardhP Fih Fijh Fih updateδMhsv 0NUMSTATES1 1 Procedure reEstimateMHP 2 Input model M set histories H prior state distribution P 3 Output updated model M 4 5 repeat 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 M doδupdateMFij Fi 27 M doθ updateMCFij Fi 28 convergence 29 return M end CFijh updateθ Mhsv 0NUMSTATES1 j 0NUMOBS1 CFij ij CFijh ij Fi Fih Fi Fih j 0NUMSTATES1 Fij ij Fijh ij end end end end Fig A2 The modiﬁed reestimation function multiple history case The array Fih expected frequency transitioning state calculated local context history h Fijh expected frequency transitioning j context h CFijh expected frequency state seeing evidence j calculated context h model ordering states excludes certain state transitions If estimation process begins knowing ordering converge better estimation state transition function higher log likelihood possible begins equal probabilities transition model prior state distribution In experiments robot begins trajectory starting position ends trajectory soon judges given tolerance goal coordinate Having ended trajectory enters states It impossible robot enter starting state state Therefore ordering imposed states starting state visited state ﬁnishing state visited state The states ordered model strictly leftright model If ﬁx state collection advance identify starting ﬁnishing states enforce ordering exists initialising EM M Fox et al Artiﬁcial Intelligence 170 2006 59113 105 t 0T2 initialise Fij Fi Fi 0NUMSTATES1 1 Procedure updateδMhsv 2 Input model M single history h T evidence items array state distributions sv 3 Output triple containing 4 array expected number transitions state Fi 5 array expected number transitions state pairs Fij 6 array expected number times state Fi 7 8 9 10 11 12 13 14 15 16 17 18 end 19 return Fi Fij Fi end Fi Fi svT1i j 0NUMSTATES1 Fij ij αt βt1j pqt1 j qt pht1qt1 j Fi svti t 0T2 end end Fig A3 The procedure calculating expectation values δ update t 0T1 initialise cprobij 0NUMSTATES1 c 0NUMOBS1 1 Procedure updateθ Mhsv 2 Input model M single history h T evidence items array state distributions sv 3 Output array expected number times state seeing evidence j CFij 4 5 6 7 8 9 10 11 12 13 end 14 return CFij CFij ic svti end end ht c end Fig A4 The procedure calculating expectation values θ update process state transition model column associated starting state set zero row associated ﬁnishing state set zero position Because row matrix distribution ﬁnal stateﬁnal state position set 1 Unfortunately acceptable approach ﬁx state collection advance want learning process identify states necessarily apparent human observer learn important explaining behaviour 106 M Fox et al Artiﬁcial Intelligence 170 2006 59113 1 Procedure doδupdateMprobijprobi 2 Input model M array expected number transitions state pairs probij array expected number transitions state Fi 0NUMSTATES1 end normaliseδrowiMtm j 0NUMSTATES1 Mtmij Fij ijFi 3 Output updated model M 4 5 6 7 8 9 end 10 return M 11 12 Procedure doθ updateMcprobijallprobi 13 Input model M array expected number times state seeing evidence j cprobij array expected number times state Fi 0NUMSTATES1 j 0NUMOBS1 14 Output updated model M 15 16 17 18 19 20 end 21 return M end normaliseθ rowiMsm Msmij CFij ijFi Fig A5 The procedures updating δ θ These shared single multiple history reestima tion procedures robot As described Section 32 use automated statesplitting procedure enable identiﬁcation states Thus begin initial set states deﬁned starting ﬁnishing states statesplitting frequently starting ﬁnishing substates In experiments selection terminal states complicated state splitting procedure If starting ﬁnishing states associated distant groups observations clustering process split sub states groups When starting ﬁnishing state split possible identify substates deﬁnitive terminal states distorting transition model biasing outcome estimation process One possibility initialise transition network equal probabilities instead zero column row The problem equalprobability network uninformative quality resulting HMM degraded A better solution problem deﬁne supplementary terminal states model We identify different cases case state split case starting state split case ﬁnishing state split case states split It possible treat cases uniform way introduction supplementary states This requires modify sensor model constructed following statesplitting phase In addition create initial transition model prior state distribution contain supplementary states M Fox et al Artiﬁcial Intelligence 170 2006 59113 107 Modifying sensor model straightforward simply add additional rows columns sensor model associate corresponding supplementary observations The supplementary observations observed corresponding supplementary states The new rows normalised Creating initial transition model somewhat complex We begin allocating equal probabilities state transitions adjust model contain ad ditional columns rows The supplementary starting state zero probability entry state model tiny nonzero probability exit state deﬁned starting substates There equal probability transi tion The supplementary ﬁnishing state zero probability entering state enters probability 1 states transition ﬁnishing substates Each ﬁnishing substate enter ﬁnishing substates supplementary ﬁnishing state equal probability If n ﬁnishing substates 1n 1 probability entry supplementary ﬁnishing state Of course case original ﬁnishing state split means probability 05 ﬁnishing state entering supplementary ﬁnishing state equal probability reenter Simi larly original starting state split supplementary starting state enters starting state probability 1 Fig A6 shows supplementary starting ﬁnishing states connected rest states transition model Every row transition table needs normalised ensure valid state distribution At end process supplementary starting ﬁnishing states indistinguishable states model The prior probability distribution needs modiﬁed enforce fact starts supplementary starting state From enter transition model described highest probability associated transition Fig A6 The use supplementary terminal states supplementary observations 108 M Fox et al Artiﬁcial Intelligence 170 2006 59113 starting substates We eliminate possibility starts state It happen substates associated original nomark state entered starting state This happen real data sequences happen starting state marked late ﬁrst sequence vectors constructed marked nomark identiﬁer There ﬁnal modiﬁcation The evidence HMM estimated modiﬁed observations corresponding supplementary starting ﬁnishing states appear start end respectively history Having modiﬁcation possible treat cases uniform way Appendix B Further experimental comparisons In Fig B3 examine effect varying network size quality HMM ﬁnally learned We experimented ﬁve different network dimensions 15 35 compared differences results exact match evaluation strategy described We ran ANOVA test discover signiﬁcant differ ence performances 5 different sizes We computed F value 4033 giving p value 0003 This shows difference highly signiﬁcant Furthermore observed Fig B5 small network sizes tend result greater sharing substates labels leading relatively high confusion factor The table Fig B1 shows means standard deviations median values obtained ﬁve network sizes It seen standard deviation increases network size increases showing ability learned HMM reliably explain behaviour robot decreases Kohonen network gets larger The pattern seen Figs B5 B2 showing confusion consistency respectively The confusion factor decreases network size increases shows mapping ab Ψ L increasingly precise network size increases It seen consistency greatest sizes 20 25 30 Network size 15 shows reduced consistency highest confusion factor network sizes Its deceptively strong performance shown Fig B3 undermined factors dismiss 15 small ade quate reliability At extreme network size 35 shows weakest performance Fig B3 lowest confusion factor It argued loss performance arises fact beneﬁtting imprecision Size 15 20 25 30 35 Mean 7931 7743 7712 7618 7463 Std 1274 1295 1290 1309 1389 Median 8000 7857 7857 7647 75 Fig B1 Means standard deviations median values evaluation distributions 20 random numbers 5 network sizes We note median value larger mean network sizes 15 20 25 M Fox et al Artiﬁcial Intelligence 170 2006 59113 109 Fig B2 Consistency agreement Viterbi sequences given network size run 20 different random numbers Fig B3 Comparison Viterbi sequence evaluations 5 different Kohonen network sizes Best performance obtained HMMs based smallest networks steadily declines network size increases However performance shown account confusion consistency affect true quality HMMs 110 M Fox et al Artiﬁcial Intelligence 170 2006 59113 ab Ψ L However Fig B2 shows consistency agreement Viterbi sequences based size 35 network slightly lower smaller networks Our best results obtained networks size 25 30 These networks similar terms performances shown Figs B3 B1 In cases consistency high The network size 30 beneﬁts slightly lower confusion factor obtained 25 said produce slightly better overall picture We observed standard deviation scores generally higher expected networks consistency high standard deviation consistency low For network size 30 standard deviation consistency 34 mean 806 For network size 25 statistics 34 804 respec tively Given small standard deviations sought explanation high standard deviations performance network sizes The parameter result variation history considered The implication histories correspond Viterbi sequences score consistently whilst correspond sequences score consistently badly An examination scores individual Viterbi sequences conﬁrmed case To illustrate sig niﬁcance removed ﬁve consistently badly scoring sequences compared resulting distribution results distribution It seen Fig B4 removal ﬁve sequences results highly signiﬁcantly improved performance networks size 25 t 103 30 t 102 We performed experiment compare results obtained exact match test obtained weaker subset match test In subset match score incremented Viterbi state trail fragment preceding l subset substate Fig B4 Comparison results obtained sequences results obtained best 95 The removal consistently poor scoring sequences results signiﬁcantly better overall performance M Fox et al Artiﬁcial Intelligence 170 2006 59113 111 Fig B5 Comparison confusion factors network sizes grow For network size 20 Ψ s generated The graph shows cumulative percentage 20 models reaching increasing confusion factors shown horizontal axis Small networks greatest confusion confusion factors 0052 reached Using network size 30 confusion factor 0023 highest obtained Fig B6 Comparing exact matching subset matching It observed weaker subsetbased test yields signiﬁcantly better results exact match 112 M Fox et al Artiﬁcial Intelligence 170 2006 59113 l Fig B6 shows comparative results obtained network size 30 This graph shows great advantages obtained subset test mean score increases 7618 8897 standard deviation 849 comparison 1309 If accepted subset test adequately rigorous means general Viterbi sequences consistent humanobserved behaviour 89 time Preliminary investigations suggest transitionary states robot visits tween recognised substates identiﬁable subset test We believe state represents transition previous state s share features com mon s commonality accessible subset test This needs investigation focus work References 1 S Koenig RG Simmons Unsupervised learning probabilistic models robot navigation Proceed ings International Conference Robotics Automation 1996 pp 23012308 2 S Koenig RG Simmons Passive distance learning robot navigation Proceedings International Conference Machine Learning ICML 1996 pp 266274 3 H Shatkay LP Kaelbling Learning geometrically constrained hidden Markov models robot navigation Bridging geometricaltopological gap J AI Res 16 2002 167207 4 G Theocharous K Rohanimanesh S Mahadevan Learning hierarchical partially observable Markov cision process models robot navigation Proceedings IEEE International Conference Robotics Automation ICRA 2001 pp 511516 5 LR Rabiner A tutorial hidden Markov models selected applications speech recognition Proc IEEE 77 2 1989 257286 6 H Bui A general model online probabilistic plan recognition Proceedings 18th International Joint Conference AI IJCAI03 Acapulco Mexico 2003 pp 13091318 7 H Bui S Venkatesh G West Policy recognition abstract hidden Markov model J AI Res 17 2002 451499 8 L Liao D Fox H Kautz Learning inferring transportation routines Proceedings 19th Na tional Conference AI AAAI04 San Jose CA 2004 pp 348354 9 S Osentoski V Manfredi S Mahadevan Learning hierarchical models activity Proceedings IEEERSJ International Conference Intelligent Robots Systems IROS 2004 10 I Cohen N Sebe L Chen A Garg TS Huang Facial expression recognition video sequences Temporal static modelling Computer Vision Image Understanding Special Issue Face Recog nition 91 2003 160187 11 A Wilson A Bobick Hidden Markov models modeling recognizing gesture variation Inter nat J Pattern Recognition Artiﬁcial Intelligence 15 1 2001 123160 12 A Bobick J Davis The recognition human movement temporal templates IEEE Trans Pattern Anal Machine Intelligence 23 3 2001 257267 13 A Wilson A Bobick Parametric hidden Markov models gesture recognition IEEE Trans Pattern Anal Machine Intelligence 21 9 1999 884900 14 Y Nam K Wohn Recognition spacetime hand gestures hidden Markov models ACM Sym posium Virtual Reality Software Technology 1996 pp 5158 15 T Oates M Schmill P Cohen A method clustering experiences mobile robot accords human judgements Proceedings 17th National Conference AI AAAI00 Austin TX 2000 pp 846851 16 L Chrisman Reinforcement learning perceptual aliasing Proceedings 10th National Confer ence AI AAAI92 San Jose CA 1992 pp 183188 M Fox et al Artiﬁcial Intelligence 170 2006 59113 113 17 K Basye T Dean JS Vitter Coping uncertainty map learning Proceedings 11th Interna tional Joint Conference AI IJCAI89 Detroit MI 1989 pp 663668 18 T Dean D Angluin K Basye S Engelson L Kaelbling E Kokkevis O Maron Inferring ﬁnite automata stochastic output functions application map learning Proceedings 10th National Conference AI AAAI92 San Jose CA 1992 pp 208214 19 J Firby Modularity issues reactive planning Proceedings 3rd International Conference AI Planning Systems AIPS 1996 pp 7885 20 M Beetz Structured reactive controllers A computational model everyday activity Proceedings 3rd International Conference Autonomous Agents 1999 pp 228235 21 BC Williams PP Nayak A modelbased approach adaptive selfconﬁguring systems Proceedings 13th National Conference AI AAAI96 Portland OR 1996 pp 971978 22 RG Simmons D Apfelbaum A task description language robot control Proceedings Intelligent Robotics Systems 1998 pp 19311937 23 FF Ingrand M Georgeff AS Rao An architecture realtime reasoning control IEEE Expert 7 6 1992 3444 24 GD Forney The Viterbi algorithm Proc IEEE 61 1973 268278 25 AP Dempster NM Laird DB Rubin Maximum likelihood incomplete data EM algorithm J Roy Statist Soc 39 1 1977 138 26 LR Rabiner An introduction hidden Markov models IEEE ASSP Magazine 1986 416 27 J Makhoul S Roucos H Gish Vector quantization speech coding Proc IEEE 73 11 1985 1551 1588 28 T Kohonen SelfOrganisation Associative Memory SpringerVerlag Berlin 1984 29 JB MacQueen Some methods classiﬁcation analysis multivariate observations Proceedings 5th Berkeley Symposium Mathematical Statistics Probability 1967 pp 281297 30 A Stolcke S Omohundro Hidden Markov model induction Bayesian model merging Advances Neural Information Processing Systems 5 NIPS Conference 1992 pp 1118 31 LE Baum JA Egon An inequality applications statistical estimation probabilistic functions Markov process model ecology Bull Amer Meteorolog Soc 73 1967 360363 32 LE Baum GR Sell Growth functions transformations manifolds Paciﬁc J Math 27 2 1968 211227 33 K Murphy The Bayes net toolbox MATLAB Computing Science Statistics 2001 34 R Alami R Chatila S Fleury M Ghallab F Ingrand An architecture autonomy Internat J Robotics Res 17 4 1998 315337 35 S Fleury M Herrb R Chatila GenoM A Tool speciﬁcation implementation operating modules distributed robot architecture Proceedings International Conference Intelligent Robots Systems IROS Grenoble France vol 2 1997 pp 842848 36 J Minguez J Osuna L Montano A divide conquer strategy based situations achieve reactive collision avoidance troublesome scenarios Proceedings International Conference Robotics Automation ICRA New Orleans USA 2004 37 J Minguez L Montano T Simeon R Alami Global nearness diagram navigation GND Proceedings International Conference Robotics Automation ICRA Korea 2001 pp 3339 38 J Minguez L Montano Nearness diagram navigation ND Collision avoidance troublesome scenarios IEEE Trans Robotics Automation 20 1 2004 4559 39 AV Oppenheim RW Shafer JR Buck Discrete Time Signal Processing second ed PrenticeHall En glewood Cliffs NJ 1999 40 F Jelinek Continuous Speech recognition statistical methods Proc IEEE 64 1976 532536 41 P Kim BC Williams M Abramson Execution reactive modelbased programs graphbased temporal planning Proceedings 17th International Joint Conference AI IJCAI01 Seattle WA 2001 pp 487493 42 N Muscettola PP Nayak B Pell BC Williams Remote agent To boldly AI gone Artiﬁcial Intelligence 100 1998 547