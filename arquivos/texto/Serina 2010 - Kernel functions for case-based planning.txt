Artiﬁcial Intelligence 174 2010 13691406 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Kernel functions casebased planning Ivan Serina Free University BozenBolzano Viale Ratisbona 16 I39042 Bressanone Italy r t c l e n f o b s t r c t Article history Received 5 September 2008 Received revised form 14 July 2010 Accepted 16 July 2010 Available online 30 July 2010 Keywords Casebased planning Domainindependent planning Casebased reasoning Heuristic search planning Kernel functions Casebased planning advantage problemsolving experiences storing plan library previously generated plans reused solve similar planning problems future Although comparative worstcase complexity analyses plan generation reuse techniques reveal possible achieve provable eﬃciency gain reuse generation casebased planning approach effective alternative plan generation similar reuse candidates chosen In paper innovative casebased planning called OAKplan eﬃciently retrieve planning cases plan libraries containing thousand cases choose heuristically suitable candidate adapt provide good quality solution plan similar retrieved case library Given planning problem encode compact graph structure Planning Encoding Graph gives detailed description topology planning problem By graph representation examine approximate retrieval procedure based kernel functions effectively match planning instances achieving extremely good performance standard benchmark domains The experimental results point effect case base size importance accurate matching functions global performance Overall OAKplan competitive stateoftheart plan generation systems terms number problems solved CPU time plan difference values plan quality cases similar current planning problem available plan library 2010 Elsevier BV All rights reserved 1 Introduction Planning process usually involves use lot resources The eﬃciency planning systems improved avoiding repeating planning effort strictly necessary For example speciﬁcation goals undergoes variation plan execution execution time failures turn advisable change existing plan replanning scratch One think basing planning process modiﬁcation plans procedure known planning second principles 47 In fact method generate plan scratch aims exploiting knowledge contained plans generated The current problem instance Π employed search plan library maybe number changes turn useful solve Π In CaseBased Planning CBP previously generated plans stored cases memory reused solve similar planning problems future CBP save considerable time planning scratch offering po tential heuristic mechanism handling intractable problems Similarly CaseBased Reasoning CBR systems CBP based assumptions nature world 38 The ﬁrst assumption world regular sim Email address ivanserinaunibzit 00043702 matter 2010 Elsevier BV All rights reserved doi101016jartint201007007 1370 I Serina Artiﬁcial Intelligence 174 2010 13691406 ilar problems similar solutions consequence solutions similar problems useful starting point new problemsolving The second assumption types problems agent encounters tend recur future problems likely similar current problems Different casebased planners differ store cases adapt solution new problem use cases building new solution 58 From theoretical point view worst case adapting existing plan solve new problem eﬃcient complete regeneration plan 47 More ﬁnding good reuse candidate plan library expensive leads computational costs saved reusing candidate In fact retrieval good plan library plans represents bottleneck plan reuse domain independent casebased planning systems This happens problem deﬁning best matching objects planning problems NPhard In paper present data structures new matching functions eﬃciently address problem matching planning instances NPhard general case These functions lead new casebased planner called OAKplan acronym Object Assignment Kernel casebased planner competitive state art plan generation systems suﬃciently similar reuse candidates chosen Following formalisation proposed Liberatore 39 planning case pair cid2Π0 π0cid3 Π0 planning problem π0 plan plan library set cases cid2Πi πicid3 1 cid2 cid2 m Our approach based compact graph representation uses initial goal facts order deﬁne detailed description topology planning problem examined On basis graph representation use ideas different research areas In particular lot work molecular biology analyse eﬃciently chemical databases typically contain thousands molecules encoded graphs Similarly rascal 51 use graph degree sequences 55 order ﬁlter unpromising planning cases reduce set Cds cid2Πi πicid3 cases examined accurately suitable number1 Following Nebel Koehlers formalisation matching functions 47 examine problem deﬁning match objects current planning problem selected planning cases Since exact matching evaluation infeasible computational point view limited number candidate cases 47 develop approximate evaluation based kernel functions 56 deﬁne match objects planning problems considered Our kernel functions inspired Fröhlich et als work 1921 kernel functions molecular structures kernel function thought special similarity measure deﬁned arbitrarily structured objects like vectors strings trees graphs 3565 The computational attractiveness kernel methods comes fact applied highdimensional feature spaces suffering high cost explicitly computing mapped data 56 In contrast CBP approaches deﬁne exact matching functions objects Π0 plan library computation requires exponential time 293447 kernel functions compute polynomial time approximate matching function element set Cds matching function choose subset candidate plans eﬃciently successive plan evaluation phase These plans evaluated accurately simulated execution determines capacity plan πi solve current planning problem This phase performed executing πi evaluating presence inconsistencies corresponding unsupported preconditions actions πi way presence unsupported goals identiﬁed The best plan adapted necessary order applicable current initial state solve current goals This phase based lpgadapt 16 shown excellent performance domains When adaptation phase concluded new planning case corresponding current planning problem solution plan inserted library discarded OAKplan eﬃciently retrieve planning cases plan libraries thousand elements heuristically choose suitable candidate possibly best adapt provide good quality solution plan similar retrieved case base We hope work able renew casebased planning approach Current research planning devoted primarily generative planning effective retrieval functions available past To best knowledge ﬁrst casebased planner performs eﬃcient domain dependent objects matching evaluation We examine comparison state art plan generation systems showing casebased planning approach effective alternative plan generation suﬃciently similar reuse candidates chosen This major improvement previous approaches CBP handle small plan libraries Section 5 hardly compared plan generation systems The paper organised follows Section 2 introduces essential notions required paper In particular expose notion union graphs fundamental deﬁnition graphs matching functions introduce basic concepts kernel functions Section 3 presents main phases casebased planner examining different steps required Retrieval Evaluation phases In Section 4 detailed analysis importance accurate matching function case base size global performance provided 1 The rascal uses degree sequences rigorous maximum common edge subgraph MCES detection algorithm based maximum clique formulation compute exact degree composition similarity chemical databases Our techniques use degree sequences approximate maximum common subgraph MCS detection algorithm based kernel functions analyse cases huge plan libraries choose good candidate adaptation I Serina Artiﬁcial Intelligence 174 2010 13691406 1371 Then examine results produced OAKplan comparison state art plan generation systems Finally Section 6 gives conclusions indicates future work 2 Preliminaries In following present notation paper analysis computational com plexity problems considered 21 Planning formalism Similarly Bylanders work 8 deﬁne instance propositional planning Deﬁnition 1 A propositional STRIPS planning problem tuple Π cid2Pr I G O pcid3 Pr ﬁnite set ground atomic propositional formulae I Pr initial state G Pr goal speciﬁcation O p ﬁnite set operators operator o O p form o p o o o p Pr propositional preconditions o Pr positive postconditions add list o Pr negative postconditions delete list o o We assume set propositions Pr particular structure Let O set typed constants ci understanding distinct constants denote distinct objects corresponding individual entities following Conceptual Graphs notation 11 Let P set predicate symbols PrO P set ground atomic formulae signature Note use manysorted logic formalisation signiﬁcantly increase eﬃciency deductive inference eliminating useless branches search space domain 121367 A fact assertion individual entities exist entities related relationships cid9 1 cid9 m precondition f plan action cid9 supported f cid9 k j cid2 k ii f true initial state cid2a A plan π partially ordered sequence actions π a1 C ai action completely instantiated operator π C deﬁnes ordering relations actions π A linearisation partially ordered plan total order actions plan consistent existing partial order In totally ordered plan cid9 π j deleted cid9 cid9 k k st f dela k In partially intervening action ordered plan precondition action possibly supported exists linearisation supported action precondition necessarily supported supported linearisations An action precondition necessarily unsupported possibly supported A valid plan plan action preconditions necessarily supported The complexity STRIPS planning problems studied extensively literature Bylander 8 deﬁned PLANSAT decision problem determining instance Π propositional STRIPS planning solution PLANMIN deﬁned problem determining exists solution length k decision problem corresponding search problem generating plans minimal length Based framework analysed computational complexity general propositional planning problem number generalisations restricted problems In general form PLANSAT PLANMIN PSPACEcomplete Severe restrictions form operators necessary guarantee polynomial time NPcompleteness 8 added earlier action It important remark approach related generative casebased planning approach transformational approach plan library assumed useful process searching new plan necessarily provide starting point search process If planning case cid2Π0 π0cid3 known current planning problem Π diﬃcult simply disregard case ﬁnd plan Π Essential trivial result similarly modern plan adaptation casebased planning approaches 2286162 enforce plan adaptation conservative sense require reuse starting plan π0 solve new plan The computational complexity plan Reuse Modiﬁcation STRIPS planning problems analysed number papers 89363947 While problem diﬃcult presence hint corresponds context solution planning case easier Unfortunately following theorem shows case plan adaptation Theorem 1 See 39 Deciding exists plan STRIPS instance Π given case cid2Π0 π0cid3 PSPACEcomplete Π0 Π differ condition initial state Moreover empirical analyses plan modiﬁcation similar planning instances somewhat eﬃcient plan generation average case 7162728475962 1372 22 Graphs I Serina Artiﬁcial Intelligence 174 2010 13691406 Graphs provide rich means modelling structured objects widely reallife applications represent molecules images networks On basic level graph deﬁned set entities set connections entities More formally Deﬁnition 2 A labeled graph G 3tuple G V E λ V set vertices E V V set directed edges arcs λ V E sLλ function assigning labels vertices edges Lλ ﬁnite set symbolic labels sLλ represents set multisets Lλ Note label function considers multisets symbolic labels corresponding operations union intersection join 5 context suitable standard sets symbolic labels order compare vertices edges accurately described later The deﬁnition corresponds case directed graphs undirected graphs obtained require edge v 1 v 2 E existence edge v 2 v 1 E label G V E denotes size graph G graph G 0 denoted An arc e v u E considered directed v u v called source node u called target node arc u said direct successor v v said direct predecessor u v said adjacent vertex u vice versa Here present notion graph union essential deﬁnition graphs matching functions Deﬁnition 3 The union graphs G 1 V 1 E1 λ1 G 2 V 2 E2 λ2 denoted G 1 G 2 graph G V E λ deﬁned V V 1 V 2 E E1 E2 λx λ1x λ2x λ1x cid13 λ2x x V 1V 2 x E1E2 x V 2V 1 x E2E1 cid13 indicates join called sum multisets 5 λ associates multiset symbolic labels vertex edge In applications necessary compare objects represented graphs determine similarity objects This accomplished graph matching isomorphism techniques Graph isomorphism formulated problem identifying onetoone correspondence vertices graphs edge exists vertices graph edge exists corresponding vertices graph Graph matching formulated problem involving maximum common subgraph MCS collection graphs considered This referred maximum common substructure problem denotes largest substructure common collection graphs consideration More precisely Deﬁnition 4 Two labeled graphs G V E λ G f V V cid9 cid9 V cid9 E cid9 λcid9 isomorphic exists bijective function v V λv λcid9 f v v 1 v 2 E λv 1 v 2 λcid9 f v 1 f v 2 u v E f u f v E cid9 We shall f isomorphism function Deﬁnition 5 An Induced Subgraph graph G V E λ graph S V cid9 E cid9 λcid9 cid9 V v V cid9 cid9 E e E cid9 V E v u V v u E cid9 cid9 λcid9v λv λcid9e λe v u E I Serina Artiﬁcial Intelligence 174 2010 13691406 1373 A graph G Common Induced Subgraph CIS graphs G 1 G 2 G isomorphic induced subgraphs G 1 G 2 A common induced subgraph G V E λ G 1 G 2 called Maximum Common Induced Subgraph MCIS exists λv greater G Similarly common induced subgraph common induced subgraph G 1 G 2 vV G V E λ G 1 G 2 called Maximum Common Edge Subgraph MCES exists common induced λe greater G Note considering multiset labeled graphs subgraph G 1 G 2 require stronger condition standard MCIS MCES labeled graph fact want maximise total cardinality multiset labels verticesedges involved instead simple number verticesedges eE cid5 cid5 As known subgraph isomorphism MCS graphs NPcomplete problems 22 open question graph isomorphism NPcomplete problem As consequence worstcase time requirements matching algorithms increase exponentially size input graphs restricting applicability graph based techniques small graphs 23 Kernel functions labeled graphs In recent years large number graph matching methods based different matching paradigms proposed ranging spectral decomposition graph matrices training artiﬁcial neural networks continuous optimisation algorithms optimal tree search procedures The basic limitation graph matching lack mathematical structure space graphs Kernel machines new class algorithms pattern analysis classiﬁcation offer elegant solution problem 56 The basic idea kernel machines address pattern recognition problem related vector space instead original pattern space That deﬁning mathematical operations space graphs graphs mapped vector space operations readily available Obviously diﬃculty ﬁnd mapping preserves structural similarity graphs certain extent In words graphs structurally similar vectors representing graphs similar objective obtain vector space embedding preserves characteristics original space graphs A key result theory underlying kernel machines states explicit mapping pattern space vector space required Instead deﬁnition kernel function follows exists vector space embedding kernel function extract information vectors relevant recognition As matter fact family kernel machines consists algorithms formulated terms kernel function including standard methods pattern analysis classiﬁcation principal component analysis nearestneighbour classiﬁcation Hence deﬁnition graph similarity measure obtain implicit embedding entire space graphs vector space A kernel function thought special similarity measure deﬁned mathematical properties 56 Considering graph formalism possible deﬁne kernel function measures degree similarity graphs Each structure represented means similarity structures graph space Moreover kernel function implicitly deﬁnes dot product space 56 deﬁning kernel function graphs implicitly deﬁne vector representation need explicitly know cid9 X holds kx x From technical point view kernel function special similarity measure k X X R patterns lying arbitrary domain X represents dot product denoted cid2cid3 Hilbert space H 56 cid9cid3 φ X H arbitrary mapping patterns arbitrary patterns x x domain X feature space H In principle patterns domain X necessarily vectors strings graphs trees text documents objects The vector representation objects given map φ Instead performing expensive transformation step explicitly kernel calculated directly performing feature transformation implicitly known kernel trick This means set linear space admits positive deﬁnite kernel embedded linear space cid9 cid2φx φx More speciﬁcally kernel methods manage nonlinear complex tasks making use linear methods new space For instance consideration classiﬁcation problem training set S u1 y1 yn ui yi X Y 1 n X innerproduct space Rd Y 1 1 In case learning phase corresponds training set S associating class y Y pattern u X generalisation building function f Y error f low possible A functional form f consists hyperplane f u signcid2w ucid3 b sign refers function returning sign argument The decision function f produces prediction depends hyperplane cid2w ucid3 b 0 input pattern u lies The individuation best hyperplane corresponds convex quadratic optimi sation problem solution vector w linear combination training vectors X w ncid6 i1 αi yi ui αi R 1 n In way linear classiﬁer f rewritten cid8 f u sign αi yicid2ui ucid3 b cid7 ncid6 i1 1374 I Serina Artiﬁcial Intelligence 174 2010 13691406 Fig 1 The kernel approach classiﬁcation Left nonlinearly separable input provided dots crosses Middle perfect approximate linear separability achieved feature space mapping φ Right linear decision surface feature space deﬁnes complex decision surface input space As regards complex classiﬁcation problems set possible linear decision surfaces rich der provide good classiﬁcation independently values parameters w X b R Fig 1 The aim kernel trick overcoming limitation adopting linear approach transformed data φu1 φun raw data Here φ indicates embedding function input space X feature space H provided dot product This transformation enables alternative kernel representation data equivalent mapping highdimensional space classes data readily separable The mapping achieved replacement inner product cid2ui ucid3 cid9 cid10 φui φu separating function rewritten cid8 cid7 ncid6 αi yi i1 cid10 cid9 φui φu f u sign b 1 The main idea kernel approach consists replacing dot product feature space kernel ku v cid2φv φucid3 functional form mapping φ actually need known implicitly deﬁned choice kernel A positive deﬁnite kernel 23 Deﬁnition 6 Let X set A symmetric function k X X R positive deﬁnite kernel function X iff n N x1 xn X c1 cn R cid6 cic jkxi x j cid3 0 j1n N set positive integers For given set S u u1 matrix K kui u ji j known Gram matrix k respect S u Positive deﬁnite kernels called Mercer kernels Theorem 2 Mercers property See 44 For positive deﬁnite kernel function k RX X feature space H equipped inner product cid2cid3H exists mapping φ HX u v X ku v cid10 cid9 φu φv H The kernel approach replaces inner products Eq 1 related expressions compute real coeﬃcients αi b means Mercer kernel k For input pattern u relating decision function f given 2 f u sign αi yikui u b cid8 cid7 ncid6 i1 This approach transforms input patterns u1 corresponding vectors φu1 φun H cf Mercers property Theorem 2 uses hyperplanes feature space H purpose i1 ui v Rd actually Mercer kernel commonly mapping φ HX classiﬁcation Fig 1 The dot product cid2u vcid3 cid5 d I Serina Artiﬁcial Intelligence 174 2010 13691406 1375 Mercer kernels like polynomial Gaussian kernels generally correspond nonlinear mappings φ highdimensional feature spaces H On hand Gram matrix implicitly deﬁnes geometry embedding space permits use linear techniques feature space derive complex decision surfaces input space X While easy prove positive deﬁniteness given kernel positive deﬁnite kernels characterised interesting closure properties More precisely closed sum direct sum multiplication scalar tensor product zero extension pointwise limits exponentiation 56 A remarkable contribution graph kernels work convolution kernels provides general framework deal complex objects consisting simpler parts 31 Convolution kernels derive similarity complex objects similarity parts Given kernels k1 k2 set objects new kernels built operations convex linear combinations convolutions The convolution k1 k2 new kernel k form cid6 k1 cid8 k2u v u1u2u v1v2v k1u1 v 1k2u2 v 2 u u1 u2 refers partition u substructures u1 u2 3156 The kind substructures depends domain course instance subgraphs subsets substrings case kernels deﬁned graphs sets strings respectively Different kernels obtained considering different classes subgraphs directedundirected labeledunlabeled pathstreescycles deterministicrandom walks ways listing counting 354849 The consideration space time complexity compute convolutionspectral kernels important owing combinatorial explosion linked variablesize substructures In following section present Optimal Assignment Kernel symmetric positive deﬁnite similarity measure directed graph structures order deﬁne correspondence vertices directed graphs For introduction kernel functions related concepts notation reader referred Scholkopf Smolas book 56 3 Casebased planning A casebased planning solves planning problems making use stored plans solve analogous problems CBP type casebased reasoning involves use stored experiences cases strong evidence people frequently employ kind analogical reasoning 245466 When CBP solves new planning problem new plan added case base potential reuse future Thus learns experience In general following steps executed new planning problem solved CBP 1 Plan Retrieval retrieve cases memory analogous current target problem Section 31 description approach 2 Plan Evaluation evaluate new plans execution simulated execution analysis choose Section 32 3 Plan Adaptation repair faults new plan Section 33 4 Plan Revision test solution new plan π success repair failure occurs execution Sec tion 34 5 Plan Storage eventually store π new case case base Section 34 In order realise beneﬁts remembering reusing past plans CBP needs eﬃcient methods trieving analogous cases adapting retrieved plans case base suﬃcient size coverage yield useful analogues The ability search library plan suitable adaptation2 depends eﬃciencyaccuracy implemented retrieval algorithm data structures represent elements case base Similarly Aamodt Plazas classic model problem solving cycle CBR 1 Fig 2 shows main steps casebased planning cycle interactions different steps case base In following illustrate main steps casebased planning approach examining different implementation choices adopted 31 Plan retrieval Although plan adaptation phase central component CBP retrieval phase critically affects performance As matter fact retrieval time component total adaptation time quality retrieved plan fundamental performance successive adaptation phase With OAKplan number 2 A plan suitable adaptation adaptation cost lower respect candidates case base respect plan generation 1376 I Serina Artiﬁcial Intelligence 174 2010 13691406 Fig 2 The casebased planning cycle functions management plan library matching functions selection candidate plan adaptation implemented The retrieval phase consider elements plan library order choose good allow solve new problem easily Hence necessary design similarity metric reduce number cases evaluated accurately improve eﬃciency retrieval phase Anyway eﬃciency plan adaptation undoubtedly linked distance problem solve plan adapt In order ﬁnd plan useful adaptation reach following objectives The retrieval phase identify candidates adaptation The retrieval time small possible added adaptation time particular attention given creation eﬃcient data structures phase The selected cases actually contain plans easier adapt assume world regular similar problems similar solutions look cases similar problem solve respect candidates case base In sense important deﬁne metric able accurate measure similarity planning problem solve cases plan library To end applying reuse technique necessary provide plan library suﬃciently similar reuse candidates chosen In case suﬃciently similar means reuse candidates large number initial goal facts common new instance However want consider reuse candidates similar new instance objects selected candidates systematically renamed As matter fact plan reuse contain matching component tries ﬁnd mapping objects reuse candidate objects new instance number common goal facts maximised additional planning effort achieve initial state plan library minimised Following Nebel Koehlers formalisation 47 closer look matching problem 311 Object matching As previously said use manysorted logic order reduce search space matching process assume operators ordinary STRIPS operators variables If instances cid9 Π cid11 cid9 Pr cid9 cid9 P O cid12 Icid9 Gcid9 Ocid9 p cid10 cid9 Π PrO P I G O p cid10 loss generality cid9 O O cid9 P P Ocid9 p O p mapping matching function Π cid9 Π function μ O cid9 O The mapping extended ground atomic formulae sets formulae canonical way I Serina Artiﬁcial Intelligence 174 2010 13691406 1377 cid12 cid11 pc1 t1 cn tn μ cid14cid12 cid11cid13 cid11 p cid13 μc1 t1 μcn tn cid11 cid11 μ μ cid12 p1 cid12 cid12cid14 μ p1 pm pm If exists bijective matching function μ Π cid9 cid9 I obvious solution plan π cid9 Π identical renaming constant symbols μπ cid9 solves Π Even μ match goal initialstate facts μπ cid9 starting point adaptation process solve Π directly reused solving Π Π cid9 Π μG cid9 G μI Π cid9 In order measure similarity objects intuitive usual compare features common objects 40 The Jaccard similarity coeﬃcient information retrieval particularly interesting Here examine extended version considers pairs disjoint sets complete_similμ cid11 cid9 Π Π cid12 μGcid9 G μIcid9 I μGcid9 G μIcid9 I 3 In following present variant previous function overcome problems related presence irrelevant facts initial state description current planning problem Π additional goals present Π cid9 In fact irrelevant facts ﬁltered initial state description casebased planning problem Π cid9 possible initial state description current planning problem Π Similarly want consider possible irrelevant additional goals G happen Π cid9 solves diﬃcult planning problem respect Π We deﬁne following similarity function address issues cid12 corresponding solution plan π cid9 cid9 4 cid11 Π cid9 Π similμ μGcid9 G μIcid9 I G μIcid9 Using similμ obtain value equal 1 exists mapping μ st f I st g μg μ f I guarantee cid9 guarantee achievement goals current planning g G g cid9 G cid9 cid9 applicability π cid9 problem Finally deﬁne following optimisation problem obj_match Instance Two planning instances Π cid9 Question Does mapping μ Π cid9 Π real number k 0 1 Π similμΠ cid9 Π k exist mapping μcid9 similμcid9 Π cid9 Π k Π cid9 Π It noted matching problem solved potentially relevant candidate plan library select corresponding best reuse candidate Of course use structuring indexing techniques avoid considering plans library Nevertheless unavoidable solving problem considerable number times appropriate reuse candidate identiﬁed For reason eﬃciency matching component crucial overall performance Unfortunately similarly Nebel Koehlers analysis 47 easy matching problem NPhard problem Theorem 3 obj_match NPhard The proof theorem following ones Appendix B This NPhardness result implies matching bottleneck plan reuse systems As matter fact case planning instances complex goal initialstate descriptions beneﬁt planreuse techniques matching retrieval expensive In fact existing similarity metrics address problem heuristically considering approximations 4663 However theorem interesting captures limit case approximations We deﬁne particular labeled graph data structure called Planning Encoding Graph encodes initial goal facts single planning problem Π perform eﬃcient matching objects planning case objects current planning problem The vertices graph belong set VΠ elements representation objects O current planning problem Π predicate symbols P Π cid15 cid15 VΠ O I p Gq pP qP predicate deﬁne additional nodes associated corresponding initial fact predicate called I p associated corresponding goal fact predicate called Gq The labels graph derived predicates facts sorts manysorted logic The representation entity object planning terminology application domain traditionally called concept conceptual graph community 11 Following notation Planning Encoding Graph composed kinds nodes concept nodes representing entities objects occur application domain initial fact relation nodes representing relationships hold objects initial facts goal fact relation nodes representing relationships hold objects goal facts 1378 I Serina Artiﬁcial Intelligence 174 2010 13691406 Fig 3 Initial Fact Encoding Graph E I p propositional initial fact p pc1 t1 cn tn Fig 4 Initial Fact Encoding Graph E I A B propositional initial fact A B The Planning Encoding Graph planning problem ΠI G built corresponding initial goal facts In particular propositional initial fact p pc1 t1 cn tn I deﬁne data structure called Initial Fact Encoding Graph corresponds graph represents p More precisely Deﬁnition 7 Given propositional typed initial fact p pc1 t1 cn tn I Π Initial Fact Encoding Graph E I p V p Ep λp fact p directed labeled graph V p I p c1 cn VΠ Ep I p c1 c1 c2 c1 c3 c1 cn c2 c3 c2 c4 cn1 cn I p c1 λpI p I p λpci ti 1 n λpI p c1 I 01 ci c j Ep λpci c j I j p p cid16 i1n ji1n ci c j ﬁrst node graph E I p Fig 3 initial fact relation node I p labeled multiset λpI p I p 1 I p3 connected direct edge second node graph concept node c1 labeled sort t1 λpc1 t1 1 t1 node c1 connected node graph c2 labeled sort t2 λpc2 t2 1 t2 remaining concept nodes node graph c2 connected c3 c4 cn The ﬁrst edge graph I p c1 labeled multiset I 01 similarly generic j edge ci c j Ep labeled multiset I p p 1 I 01 p For example Fig 4 Initial Fact Encoding Graph fact p A B BlocksWorld domain The ﬁrst node named Ion label multiset λpIon Ion 1 Ion second node represents object A label λp A Obj 1 Obj ﬁnally node represents object B label λpB Obj label Ion A arc multiset I 01 1 I 12 Similarly Deﬁnition 7 deﬁne Goal Fact Encoding Graph E G q fact q qc label A B arc multiset I 12 1 I 01 t t cid9 1 cid9 1 c cid9 m cid9 m G Gq labeling procedure Given planning problem Π initial goal states I G Planning Encoding Graph Π indicate EΠ directed labeled graph derived encoding graphs initial goal facts cid15 cid15 EΠ IG E I p E G q 5 pI qG Planning Encoding Graph ΠI G graph obtained merging Initial Goal Fact Encoding Graphs For simplicity following visualise threelevel graph The ﬁrst level derived predicate symbols 3 In following indicate multiset x 1 x sake simplicity I Serina Artiﬁcial Intelligence 174 2010 13691406 1379 Fig 5 Planning Encoding Graph Sussman anomaly planning problem BlocksWorld domain initial facts second level encodes objects initial goal states level shows goal fact nodes derived predicate symbols goal facts4 Fig 5 illustrates Planning Encoding Graph Sussman anomaly planning problem BlocksWorld domain The nodes ﬁrst levels initial goal fact relation nodes vertices Ion Iclear Iontable derived predicates initial facts G predicates goal facts The nodes second level concept nodes represent objects current planning problem A B C label Obj corresponds type The initial fact C A determines arcs connecting Ion vertex C second connecting C A labels arcs derived predicate symbol determining multisets I 01 I 12 respectively In way arcs deﬁned Moreover overlapping edges Initial Goal Fact Encoding Graphs multiplicity edge label multisets equal 1 contrary label multisets vertices associated objects λ A cid13 cid14 Obj 3 λB cid13 cid14 Obj 4 λC cid13 cid14 Obj 3 This graph representation detailed description topology planning problem requiring priori assumptions relevance certain problem descriptors graph Furthermore allows use Graph Theory based techniques order deﬁne effective matching functions In fact matching function Π cid9 Π derived solving Maximum Common Subgraph problem corresponding Planning Encoding Graphs A number exact approximate algorithms proposed literature solve graph problem eﬃciently With respect normal conceptual graphs 11 Graphbased Knowledge Representation use richer label representation based multisets A single relation node represent predicate initial goal facts reduces total number nodes graphs considerably This extremely important computational point view following sections matching process repeated times directly inﬂuences total retrieval time In following examine procedure based graph degree sequences useful derive upper bound size MCES graphs eﬃcient way Then present algorithm based Kernel Functions allows compute approximate matching graphs polynomial time 312 Screening procedure As explained previously retrieval phase expensive computational point view developed screening procedure conjunction object matching algorithm Similarly rascal 51 use degree sequences 55 calculate upper bound size Maximum Common Edge Subgraph MCES pair graphs Note degree sequences graph authors establish upper bounds graph invariants 3041 indexing graph databases 50 First set vertices graph partitioned l partitions label type sorted nonincreasing total order degree5 Let Li 2 denote sorted degree sequences partition Planning Encoding Graphs G 1 G 2 respectively An upper bound number vertices VerticesG 1 G 2 edges EdgesG 1 G 2 MCES graph computed follows 1 Li 4 Following conceptual graph notation ﬁrst level nodes correspond initial goal fact relation nodes nodes second level correspond concept nodes representing objects initial goal states 5 The degree valence vertex v graph G number edges touch v 1380 I Serina Artiﬁcial Intelligence 174 2010 13691406 Fig 6 Planning Encoding Graphs degree sequences corresponding similarity value planning problems BlocksWorld domain VerticesG 1 G 2 cid11cid17 cid17Li 1 min cid17 cid17 cid17 cid17Li 2 cid17 cid12 cid17 lcid6 i1 cid18 lcid6 minLi 1 cid6 Li 2 minEv EdgesG 1 G 2 i1 j1 cid19 j 1 Ev 2 j 2 v j 1 indicates jth element vertex Li j 1 indicates set arcs 1 sorted degree sequence Ev An upper bound similarity G 1 G 2 expressed Johnsons similarity nected vertex v coeﬃcient 33 j 1 simildsG 1 G 2 VerticesG 1 G 2 EdgesG 1 G 22 V G 1 EG 1 V G 2 EG 2 VerticesG 1 G 2 EdgesG 1 G 22 G 1 G 2 6 Since VerticesG 1 G 2 EdgesG 1 G 2 determine upper bound number nodes arcs MCES G 1 G 2 simildsG 1 G 2 similarity measure ranges 0 1 easy obeys following inequality simildsG 1 G 2 cid3 V G 12 EG 122 G 1 G 2 G 122 G 1 G 2 G 12 MCES graphs G 1 G 2 Clearly simildsG 1 G 2 upper bound size MCES G 1 G 2 procedure provides rapid screening mechanism takes advantage local connectivity vertex labels help eliminate unnecessary costly MCES comparisons For screening purposes necessary specify minimum acceptable value MCES based graph similarity measure If value determined simildsG 1 G 2 minimum acceptable similarity object matching comparison avoided This procedure performed quick sort algorithm O n log n time n maxiLi 1 Li 2 A v 13 C degree 5 4 4 respectively Similarly second degree sequence L2 1 degree sequence type Obj elements vertices v 11 Fig 6 shows degree sequences Planning Encoding Graphs corresponding similarity value similds To compute degree sequences vertices graphs ﬁrst separated partitions according label type B Considering G 1 graph L1 1 v 12 1 G 1 type 1 G element vertex v 21 D graph G 2 belongs sorted degree sequence L1 2 type Obj position degree sequence degree equal 4 entry v 31 2 type Iclear ﬁrst position degree sequence L3 2 degree 3 VerticesG 1 G 2 calculated summing size set Li fewest nonnull elements graphs G 1 G 2 Since L1 1 3 elements L1 2 4 elements ﬁrst term VerticesG 1 G 2 equal minL1 1 3 Considering partitions L2 L6 obtain VerticesG 1 G 2 8 Iclear graph G 2 belongs degree sequence L3 G degree 2 Moreover entry v 13 L1 2 1 2 1 2 I Serina Artiﬁcial Intelligence 174 2010 13691406 1381 Fig 7 Possible assignments vertices G graph G ﬁnd optimal assignment vertices G G bipartite graph edge cid9 The kernel function k measures similarity pair vertices v u The goal maximises overall similarity score sum edge weights cid9 Besides EdgesG 1 G 2 determined summing minEv j 2 values partition adding sulting values integer dividing result For example ﬁrst term EdgesG 1 G 2 obtained dividing following value cid12cid17 cid17 j 1 Ev min cid11cid17 cid17E cid11cid17 cid17E cid11cid17 cid17E cid12cid17 cid17 cid12cid17 cid17 cid12cid17 cid12 cid17 cid12cid17 cid12 cid17 cid17 cid17E cid17 cid17E cid17 cid17E min cid12cid17 cid17 cid12 cid11 cid11 cid11 cid11 cid11 cid11 v 13 1 v 13 2 v 11 1 v 12 2 min5 6 min4 5 min4 5 5 4 4 min v 11 2 v 12 1 If consider elements partitions obtain EdgesG 1 G 2 10 V G 1 8 EG 1 10 V G 2 9 V G 2 15 degree similarity value G 1 G 2 simildsG 1 G 2 equal 075 313 Kernel functions object matching As previously exposed obj_match NPhard problem exact resolution infeasible computational point view limited number candidates case base In following present approximate evalu ation based kernel functions Our kernel functions inspired Fröhlich et als work 202119 kernel functions molecular structures Their goal deﬁne kernel function measures degree similarity chemical structures encoded undirected labeled graphs Our goal deﬁne matching function objects planning problems encoded directed graphs The intuition kernel functions similarity graphs depends mainly matching pairs vertices corresponding neighbourhoods graphs similar structural elements graphs ﬁt better structural elements connected similar way graphs Thereby graph properties single vertex edge structures considered On vertex level leads idea looking vertices graphs best match regard structural properties In way possible consider direct neighbours neighbours farther away maximal topological distance We want associate vertex graph exactly vertex graph overall similarity maximised This problem modeled maximum weight bipartite matching problem kernel function determines similarity pairs vertices From algorithm know vertex graph vertex graph assigned This guarantees easy way interpreting understanding kernel function matching object planning problem Π object Π cid9 directly derives matching vertex Planning Encoding Graph GΠ vertex GΠ cid9 Let assume graphs G G vertices v 1 vn u1 um respectively Let assume kernel function k compares pair vertices v u j graphs including information neighbourhoods We want assign vertex smaller graphs exactly vertex bigger overall similarity score sum kernel values individual vertices maximised Mathematically formulated follows let ζ denote permutation nsubset natural numbers 1 m permutation msubset natural numbers 1 n respectively Then looking quantity cid9 cid20 cid5 cid11 K G G cid12 cid9 maxζ maxζ m h1 kvζ h uh cid5 n h1 kvh uζ h n cid3 m 7 K valid kernel function shown 19 similarity measure graphs Implicitly computes dot product vector representations graphs Hilbert space Fig 7 illustrates idea pair vertices upper lower structure similarity thought edge weights bipartite graph We ﬁnd combination edges sum edge weights maximised Thereby edge That means end exactly minn m n m edges We deﬁne kernel function k For purpose let suppose kernel functions kv ke compare vertex edge labels λ respectively In following e jv denotes jth edge vertex v io j v denotes n jv denotes node adjacent vertex v associated jth edge e jv In way e 1382 I Serina Artiﬁcial Intelligence 174 2010 13691406 jth incomingoutgoing edge n io j v denotes direct predecessorsuccessor vertex v associated io j v N v j denotes set vertices adjacent vertex v j Ev j denotes jth incomingoutgoing edge e set incoming outgoing edges vertex v j Similarly N iov j denotes set direct predecessorsuccessor vertices vertex v j Given pairs vertices v u use kernel function kv v u γ0v u λvλu λvλu γ0v u equal 11 u v correspond object veriﬁed considering names objects represented vertices u v equal 10 The γ0 coeﬃcient introduced kernel functions order allow greater stability activity assignment useful especially human agents handled planner For example logistic domain like drivers assigned set activities possible While pairs edges use keekv e ju λekvλe j u λekvλe j u ekv e ju incoming outgoing edges vertices v u keekv e ju equal 0 Formally corresponds multiplication socalled δkernel We deﬁne base kernel vertices v u including direct neighbourhoods kbasev u kv v u cid6 1 N iv N iu cid11 hv cid6 hhcid9 kv kv 1 N ov N ou hhcid9 cid11 hv ni ni cid12 hcid9 u cid11 hv ei ei cid12 hcid9 u ke cid12 hcid9 u cid11 hv eo eo cid12 hcid9 u ke 8 This means similarity vertices consists parts ﬁrst similarity labels vertices second similarity neighbourhood structure It follows similarity pair neighbours io io hcid9 u weighed similarity edges leading The normalisation factors sums h v n n introduced ensure vertices higher number arcs automatically achieve higher similarity Hence divide sums number addends It interesting point previous deﬁnition classical convolution kernel introduced Haussler 31 In following deﬁne accurate kernel R1 compares direct neighbours vertices v u optimal assignment kernel neighbours v u edges leading improve similarity values obtained simply kbase precisely cid5Ev cid5Eu 1 Ev maxζ R1v u i1 kv nζ iv niu keeζ iv eiu i1 kv niv nζ iu keeiv eζ iu Similarly graph kernel K Eq 7 intuition kernel function similarity nodes depends nodes structure matching corresponding neighbourhoods nodes similar neighbourhood elements connected similar way nodes Ev cid3 Eu Eu maxζ 9 1 Theorem 4 R1 kernel function Of course beneﬁcial consider match direct neighbours indirect neighbours vertices having larger topological distance For purpose evaluate R 1 v u pairs neighbours indirect neighbours topological distance L The weighed average values corresponds weighed mean match indirect neighbours vertices larger topological distance Adding kv v u leads following deﬁnition neighbourhood kernel kN kN v u kv v u γ 1R1v u Lcid6 l2 γ lRlv u 10 γ l denotes decay parameter reduces inﬂuence neighbours topological distance l6 simi larly Rl denotes average R1 evaluated neighbours distance l computed Rl1 recursive relation Rlv u 1 N iv N iu 1 N ov N ou cid6 hhcid9 cid11 hv ni ni cid12 hcid9 u cid11 hv ei ei cid12 hcid9 u ke Rl1 cid11 hv cid12 hcid9 u cid11 hv eo eo cid12 hcid9 u ke Rl1 cid6 hhcid9 11 6 The γ function experimental evaluation deﬁned Section 41 I Serina Artiﬁcial Intelligence 174 2010 13691406 1383 compute kN v u iteratively revisiting direct neighbours v u The ﬁrst addend Eq 10 takes account nodes v u second addend takes account direct neighbours v u computing R1v u kernel function addend γ 2 R2v u computes average match neighbours topological distance 2 evaluating R1 direct neighbours v u The fourth addend γ 3 R3v u neighbours topological distance 3 Finally addend considers neighbours topological distance L evaluating R1 neighbours topological distance L 1 Furthermore easily Theorem 5 Let γ l pl p 0 05 If exists C R e1 e2 Eq 10 converges L kv v 1 v 2 cid2 C v 1 v 2 kee1 e2 cid2 1 To brieﬂy summarise approach works follows ﬁrst compute similarity vertex edge features kernels kv ke Having results compute match direct neighbours R 1 pair vertices graphs means Eq 9 From R1 compute R2 R L iteratively revisiting direct neighbours pair vertices computing recursive update formula 11 Having kv R1 R L directly gives kN ﬁnal similarity score pair vertices includes structural information neighbourhood properties With kN ﬁnally compute optimal assignment kernel graphs G G Eq 7 Moreover 7 calculated eﬃciently Hungarian method 37 O n3 n maximum number vertices graphs The kernel functions kbase kN Eq 7 deﬁne optimal assignment kernels Kbase KN respectively Our optimal assignment kernel functions deﬁne permutation ζ allows easily determine matching function μ associating object smaller planning problem exactly object planning problem cid9 The worst case scenario determined consider complete graphs number nodes n In case Eq 8 computational complexity O n2 examined n2 time Eq 7 obtain computational complexity n2 O n2 O n3 O n4 Kbase kernel function Moreover function R1 compu tational complexity O n3 use Hungarian method computation similarly kbase Rl function computational complexity O n2 limiting kN evaluation topological distance L polynomial n obtain computational complexity kN equal 1 O n3 O n O n2 O n3 The kN kernel function examined n2 times Eq 7 determining computational complexity KN equal n2 O n3 O n3 O n5 As described section OAKplan Kbase KN Kbase lower computational complexity order prune unpromising case base candidates It allows deﬁne ﬁrst matching function μbase corresponding similarity function similμbase described following section On hand KN deﬁne ﬁnal matching function μ corresponding similarity function similμ 32 Plan evaluation phase The purpose plan evaluation deﬁning capacity plan π resolve particular planning problem It performed simulating execution π identifying unsupported preconditions actions way presence unsupported goals identiﬁed The plan evaluation function easily deﬁned number inconsistencies current planning problem Unfortunately kind evaluation considers uniform cost order resolve different inconsistencies assumption generally restrictive Then considers accurate inconsistency evaluation criterion improve plan evaluation metric The inconsistencies related supported facts evaluated computing relaxed plan starting corresponding state RelaxedPlan algorithm lpg 25 The number actions relaxed planning graph determines diﬃculty selected inconsistencies supported number actions ﬁnal relaxed plan determines accuracy input plan π solve corresponding planning problem cid9 Fig 8 describes main steps RelaxedPlan function7 It constructs relaxed plan backward process Bestactiong action ii precon ditions requires minimum number actions evaluated maximum heuristically estimated minimum number actions required sup subverts minimum number supported precondition nodes A port precondition p size set Threatsa reachable current state INIT iii reachability preconditions chosen achieve subgoal g g effect cid9 minimal INIT iv cid9 cid9 cid9 cid9 cid9 Fig 9 describes main steps EvaluatePlan function For actions π checks precondition supported In case uses RelaxedPlan algorithm step 4 identify additional actions required satisfy unsupported preconditions If Rplan contains number actions greater Climit 7 RelaxedPlan described 25 It computes estimation earliest time facts G achieved described paper sake simplicity 1384 I Serina Artiﬁcial Intelligence 174 2010 13691406 Algorithm RelaxedPlan Input set goal facts G set facts true current state INIT possibly relaxed plan A cid16 G G INIT ACTS A F aACTS Adda G F cid17 Output relaxed plan ACTS estimating minimal set actions required achieve G 1 2 3 4 5 6 7 8 9 g fact G F bestact Bestactiong Rplan RelaxedPlanPrebestact INIT ACTS ACTS AsetRplan bestact F return ACTS aACTS Adda cid16 Fig 8 Algorithm computing relaxed plan estimating minimal set actions required achieve set facts G state INIT Bestactiong action heuristically chosen support g described 25 CState I Rplan forall πi Algorithm EvaluatePlan Input planning problem Π I G input plan π adaptation cost limit Climit Output relaxed plan adapt π order resolve Π 1 2 3 4 5 6 7 8 Rplan RelaxedPlanPrea CState Rplan f Prea st f CState CState CStateDela Adda g G st g CState Rplan Climit return Rplan Rplan RelaxedPlanG CState Rplan 9 return Rplan Fig 9 Algorithm evaluate ability π solve planning problem Π Algorithm RetrievePlan Input planning problem Π case base C cid2Πi πi cid3 Output candidate plan adaptation phase πR Evaluate_planΠ empty_plan 11 I Deﬁne set initial relevant facts Π πR IπR 12 Compute Planning Encoding Graphs EΠ EΠR ΠI G ΠR IπR G respectively degree sequences L forall Πi C prea aπR cid16 j ΠR 13 14 15 16 17 21 22 23 24 31 32 33 34 35 41 42 43 44 45 46 47 51 simili simildsEΠi EΠR pushΠi simili queue best_ds_simil maxbest_ds_simil simili forall Πi simili queue st best_ds_simil simili cid2 limit Load Planning Encoding Graph EΠi compute matching function μbase KbaseEΠi EΠ pushΠi μbase queue1 best_μbase_simil maxbest_μbase_simil similμbase Πi Π forall Πi μbase queue1 st best_μbase_simil similμbase Πi Π cid2 limit Compute matching function μN KN EΠi EΠ similμN Πi Π cid3 similμbase Πi Π μi μN μi μbase pushΠi μi queue2 best_simil maxbest_simil similμi Πi Π best_cost πR best_plan empty_plan forall Πi μi queue2 st best_simil similμi Πi Π cid2 limit Retrieve πi C costi EvaluatePlanΠ μi πi best_cost similμi Πi Π best_cost similμi Πi Π costi best_cost costi similμi Πi Π best_plan μi πi return best_plan We limited evaluation best 700 cases queue Fig 10 Algorithm ﬁnd suitable plan adaptation phase set candidate cases plan case generative approach considered suitable stop evaluation update current state CState step 7 Finally examine goal facts G step 8 identify additional actions required satisfy necessary Fig 10 describes main steps retrieval phase We initially compute relaxed plan πR Π step 11 EvaluatePlan function plan needed deﬁne generation cost current planning I Serina Artiﬁcial Intelligence 174 2010 13691406 1385 problem Π step 41 estimate initial state relevant facts step 12 In fact use relaxed plan πR ﬁlter irrelevant facts initial state description8 This easily considering preconditions actions πR cid15 IπR I prea aπR Then step 13 Planning Encoding Graph current planning problem Π degree sequences screening procedure precomputed Note degree sequences computed considering Planning Encoding Graph EΠR planning problem ΠR IπR G uses IπR instead I initial state This extremely useful practical applications automated tools deﬁne initial state description distinguishing relevant irrelevant initial facts Steps 1417 examine planning cases case base reduce set candidate plans suitable number It important point phase necessary retrieve complete Planning Encoding Graphs case base candidates GΠ cid9 sorted degree sequences Li Π cid9 precomputed stored case base On contrary Planning Encoding Graph degree sequences input planning problem computed initial preprocessing phase step 13 All cases similarity value suﬃciently close9 best degree sequences similarity value best_ds_simil examined steps 2124 Kbase kernel function Then cases selected steps 2x similarity value suﬃciently close best similμbase similarity value best_μbase_simil step 31 accurately evaluated KN kernel function corresponding μN function deﬁned step 32 In steps 3335 select best matching function Πi best similarity value We use relaxed plan πR order deﬁne estimate generation cost current planning problem Π step 41 The best_cost value allows select good candidate plan adaptation plan This value useful computation adaptation cost EvaluatePlan fact limit exceeded wasteful use CPU time memory carry estimate current evaluation terminated The computation adaptation cost plan allows choose adaptive approach generative approach plan gives adaptation cost smaller plan For cases previously selected similarity value suﬃciently close best_simil step 42 adaptation cost determined step 44 If case case base determines adaptation cost lower best_cost similμi Πi Π selected current best case best_cost best_plan updated steps 4547 Note store encoded plan μiπi best_plan plan adaptation phase solving current planning problem Π Moreover use similμi Πi Π value steps 4446 indicator effective ability selected plan solve current planning problem maintaining original plan structure time obtaining low distance values 33 Plan adaptation As previously exposed plan adaptation fundamental component casebased planner It consists reusing modifying previously generated plans solve new problem overcome limitation planning scratch As matter fact planning scratch planner receives exactly planning problem repeat planning operations In context input plan provided plan retrieval phase previously described applicability plan adaption general For example need adapting precomputed plan arise dynamic environment execution planned action fails new information changing description world prevents applicability planned actions goal state modiﬁed adding new goals removing existing ones 1625 From theoretical point view worst case plan adaptation eﬃcient complete regeneration plan 47 conservative adaptation strategy adopted However adapting existing plan practice eﬃcient generating new scratch addition worst case scenario hold exposed 2 Derivation Analogy adaptation approach Plan adaptation convenient new plan similar possible original Our work uses lpgadapt given good performance planning domains plan adaptation systems lpgadapt localsearchbased planner modiﬁes plan candidates incrementally search ﬂawless candidate It important point paper relates description new eﬃcient case based planner particular deﬁnition effective plan matching functions signiﬁcant changes plan adaptation component detailed description 16 8 In relaxed planning graph analysis negative effects domain operators considered solution plan πR relaxed planning problem computed polynomial time 32 9 In experiments limit 01 1386 I Serina Artiﬁcial Intelligence 174 2010 13691406 Fig 11 Retrieval Adaptation phases Quite interesting lpgadapt planner anytime behaviour fact produce succession valid plans plan improvement previous ones terms adaptation quality This process incre mentally improves total quality plans stopped time best plan computed far πbest Each time start new search input plan π0 provided retrieval phase initialise data structures Furthermore search random inconsistencies forced plan currently undergoing adaptation valid plan improve πbest reached This mechanism leaving local optima In adaptation context total quality plan derived considering weighed evaluation metric quality distance π π0 Q π0 π πbest α Qualityπ Qualityπbest 1 α π π0 πbest π0 12 rationale choice trying balance quality plan produced distance input plan π010 The Q π0 value choose new valid plan π best plan πbest Fig 11 visualises main steps retrieval adaptation phases The screening procedure computes similds distance function ﬁlter dissimilar cases reduce number planning cases examined accurately suitable number Then compute Kbase KN kernel functions corresponding μbase μN matching functions deﬁne corresponding similμ similarity values identify candidate plans adaptation phase These plans evaluated EvaluatePlan procedure best case adaptation cost inferior generation cost lpgadapt order ﬁnd suitable solution complete generation phase performed providing plan lpgadapt 34 Plan revision case base update Any kind planning works dynamic environments account failures arise plan generation execution In respect casebased planning exception capability called plan revision When failure discovered react looking repair aborting plan In case lpgadapt invoked remaining plan 10 In tests α 05 I Serina Artiﬁcial Intelligence 174 2010 13691406 1387 Algorithm Insert_CaseCase π ΠI G Input case base Case solution plan π planning problem Π initial state I goal state G Output insert planning case Case present 1 2 3 4 5 6 7 8 9 Deﬁne set initial state relevant facts Iπ Π input plan π Compute Planning Encoding Graph Eπ Ππ Iπ G case Πi πi Case Compute matching function μi KN EΠi Eπ complete_similμi Πi Ππ 1 πi cid2 π return FALSE enfor Insert planning problem Ππ Iπ G solution plan π Planning Encoding Graph Eπ data structures screening procedure Case return TRUE Fig 12 Highlevel description Insert_Case After ﬁnding plan library repairing lpgadapt techniques solution plan inserted library discarded Fig 12 describes main steps function evaluate insertion planning problem Π solved case base First compute set initial state relevant facts Iπ input plan π set corresponds subset facts I relevant execution π It easily computed described Section 32 preconditions actions π Iπ I cid15 prea aπ Note Iπ identiﬁes facts required execution plan π deﬁnition consistent procedure RetrievePlan algorithm relaxed plan πR Then compute Planning Encoding Graph Eπ new planning problem Ππ Iπ G having Iπ initial state instead I At steps 36 algorithm examines cases case base ﬁnds case solves Π plan better quality respect π stops exits In order use similarity function complete_similμi described Section 311 compares initial goal facts planning problems Otherwise case solve Ππ plan better quality respect π insert solved problem case base As observe step 8 planning case Ππ π additional data structures precomputed added case base recomputation Retrieval Phase avoided 4 Experimental results In section present experimental study aimed testing effectiveness OAKplan number standard benchmark domains In ﬁrst subsection experimental settings second subsection present overall results In particular examine behaviour OAKplan different matching functions experimentally analyse impact size case base number planning cases overall performance In subsection experimentally investigate similarity values matching functions case base objects progressively renamed Finally compare planner stateoftheart planners 41 Experimental settings Here present discuss general results experimental comparison examine importance matching functions size case base overall performance OAKplan written C uses SQLite3 library11 storing retrieving data structures case base VFLIB library 14 create elaborate graph data structures12 The OAKplan code benchmark planning problems available OAKplan website httpprounibzitstaffiserinaOAKplan We conducted experimental tests AMD Semprontm Processor 3400 effective 2000 MHz rating 1 Gbyte RAM Unless speciﬁed CPUtime limit run 10 minutes OAKplan 30 minutes planners termination forced13 In following tests maximum topological distance L considered computation kN kernel function Eq 10 set half number nodes 11 SQLite software library implements selfcontained serverless zeroconﬁguration transactional SQL database engine information httpwwwsqliteorg 12 Although VFLIB library solve subgraphisomorphism problems use turns computationally expensive kernel functions described Section 313 instead 13 We use 10 minutes OAKplan experimental tests conducted CPU limit 30 minutes turned computationally expensive However Table 1 CPU limit 10 minutes OAKplan solve 95 problems attempted additional CPUtime modify number solved problems plan quality difference values obtained slightly 1388 I Serina Artiﬁcial Intelligence 174 2010 13691406 smaller graphs examined L cid19 minV 1V 2 problems γ l coeﬃcient Eq 10 set equal γ l 1 1 2 L l cid20 value suﬃciently small avoid convergence Since planner lpg use randomised search algorithm corresponding results median values ﬁve runs problem considered Moreover OAKplan lpg incremental planners evaluate performance respect different main criteria CPUtime required compute valid plan plan stability 16 generated plans respect corresponding solutions target plans quality best plan generated given CPUtime limit In tests solution plans planning cases obtained domain dependent planner tlplan 3 speciﬁed tlplan planning utilises domain speciﬁc search control information guide simple forward chaining search winner Hand Coded track 3rd IPCs Its use allows use high quality input plan comparatively low investment initial computation time Using plan different planner ensures artiﬁcially enhancing stability relying way planner explores search space Our tests conducted series variants problems different domains BlocksWorld Logistics Additionals 2nd International Planning Competition DriverLog ZenoTravel Strips 3rd IPC RoversIPC5 TPP Propositional 5th IPC These tests generally performed taking problems benchmark test suite case thodically generating series variants problems total 216 planning problems domain In case medium size problems largest size problem instances base problems question casebased planning versus replanning interesting one14 The variant problems generated modifying initial goal facts original problem These modiﬁcations performed randomly number modiﬁcations increased systematically consider zero ﬁve modiﬁcations goal set zero ﬁve modiﬁcations initial state15 Although use base problems domain generate large number variants consider problems domains results considered representative behaviour similarly sized base problems To conﬁrm results artifact particular problem instances chosen adopt different problem generation strategy creating problem instances Logistics domain Thus select problems randomly benchmark suites considering Additionals planning problems created 2nd IPC Domain Dependent planners distributed smallest largest problem instances generate variant problems case We use scheme determine combination modiﬁcation values initial state goals select base problem apply modiﬁcations randomly The list base problems selected domain random modiﬁcations applied described Appendix C Supplementary material complete description random modiﬁcations applied For benchmark domains build case base library OAKplan All problems generated different IPCs belong libraries Using problem generators provided IPC organisers number planning problems features IPC planning problems considered generated added libraries total 10000 planning problems benchmark domains considered TPP use original IPC planning problems possible use tlplan solve planning problems domain use SGPlanipc5 determine solutions TPP planning cases In following report summary results obtained OAKplan considering 1 case base libraries cases use objects planning problems test set verify behaviour matching function OAKplan simply obtained identity function add suﬃx Ons stands Original object names corresponding results OAKplanOns 2 case base libraries object names planning cases randomly modiﬁed respect objects planning problems test set verify behaviour completely new problems provided OAKplan add suﬃx Nns stands New object names corresponding results OAKplanNns 3 case base libraries contain base problems generate variants benchmark set add suﬃx small corresponding results OAKplansmall16 See Supplementary material detailed comparison results produced different domains 14 For small problems difference strategies particularly interesting situation stability plan produced fundamental 15 In following experimental results planning problem solved OAKplan inserted case base simply discarded 16 The number cases plan libraries small tests lower 15 Logistics domain consider 170 base planning problems I Serina Artiﬁcial Intelligence 174 2010 13691406 1389 Table 1 Results OAKplanNns different domains number solutions average CPUtime ﬁrst solutions milliseconds corresponding average matching time average best plan quality average best plan stability average best plan differences Domain BlocksWorld Logistics DriverLog ZenoTravel Rovers TPP TOTAL Solutions 187 86 213 98 197 91 211 97 214 99 210 97 1232 95 Speed 2142448 889284 1125566 867221 624213 268378 961620 Matching time Quality Stability Differences 1215356 696063 311074 341230 537195 8592 507774 3460 3902 2302 1946 3744 3088 3078 092 088 091 084 098 096 092 496 766 236 472 114 209 382 42 Overall results In section report overall results OAKplan considering number solutions CPUtime plan quality plan stability 16 solutions produced adaptation process respect plan obtained RetrievePlan function best_plan While ﬁrst terms standard evaluation parameters commonly adopted planning plan stability deserves additional considerations The importance plan stability examined Fox et al 16 context plan adaptation authors use term plan stability refer measure difference process induces original source plan new target plan In 16 plan stability measured considering distance expressed terms number different actions source plan π target plan π0 In paper consider additional plan stability function cid12 derived formalisation presented Srivastava et al 59 cid12π π0 1 cid21 π π0 π π0 π0 π π π0 cid22 The second term represents contribution actions π plan stability term indicates contribution π0 cid12 This function assumes 0 value plans completely different value equal 1 π π0 exactly actions From practical point view think plan stability important different real world applications For example stable plans offer greater opportunity graceful elision activities stress execution components Preserving plan stability reduces cognitive load human observers planned activity ensuring coherence consistency behaviours face dynamic environments 16 Finally casebased approach high plan stability clear indicator correctly selects plans easily adapted In Table 1 present results OAKplanNns different benchmark domains Here consider average CPUtime Matching Time ﬁrst solutions generated milliseconds In ﬁfth column present average plan quality best solution generated different variants ﬁnally average plan stability plan distance terms number different actions best solution produced respect plan obtained RetrievePlan function best_plan OAKplanNns solves 95 problems attempted average difference respect target plans 382 considering 1232 planning problems solved OAKplan average 38 actions introduced removed respect target plans corresponds stability 92 It requires 96 seconds solve different benchmark planning problems 51 seconds required matching process It important point 10000 cases belong plan library considered matching process We think high number cases hardly required real applications fact case base maintenance policies 57 real word applications order reduce number cases handled casebased planner signiﬁcantly In following section examine relevance kernel functions OAKplan considering Kbase kernel function described Section 313 new kernel function Knode simply uses kv kernel function Eq 7 compares labels pairs nodes considered Finally examine inﬂuence case base size performance OAKplan performs planning problem objects names case base considered 421 Matching functions To verify relevance matching functions compare OAKplan simpler matching functions particular examine behaviour considering Kbase Knode kernel functions In Table 2 compare OAKplanNns reduced versions called OAKplanNnsKbase avoids compu tation steps 3x RetrievePlan procedure best matching function obtained considering Kbase 1390 I Serina Artiﬁcial Intelligence 174 2010 13691406 Table 2 Results OAKplanNnsKbase vs OAKplanNns Domain BlocksWorld Logistics DriverLog ZenoTravel Rovers TPP TOTAL Solutions 680 64 123 42 157 20 142 33 216 093 198 57 904 27 Speed Matching 244907 173 101027 362 113622 110 142705 252 47931 25 73923 198 122391 198 87582 390 18982 33 51823 176 38183 30 928 94 Quality 330 56 293 14 209 19 191 31 374 008 332 94 101961 122 41886 69 293 13 Stability 071 19 059 31 060 33 025 69 097 07 020 79 055 39 Table 3 Results OAKplanNnsKnode vs OAKplanNns Domain BlocksWorld Logistics DriverLog ZenoTravel Rovers TPP TOTAL Solutions 650 65 103 52 108 45 108 49 214 00 400 98 602 51 Speed Matching Quality 275902 244 129886 620 54862 353 98908 245 36560 42 502450 10901 147690 317 125599 725 46725 553 78695 290 18985 65 740 24 317 57 241 78 946 41 966 25 346 75 520 106 95935 133 66690 120 236 33 Stability 041 54 031 63 007 91 017 78 015 85 020 79 019 78 Differences 280 407 328 415 989 401 161 290 296 136 765 267 132 338 Differences 293 462 282 320 137 676 151 267 345 2940 504 2701 258 708 kernel function In table following ones report percent error brackets17 respect OAKplan Nns column solutions consider problems solved planners By accurate matching function number problems solved 904 27 average CPUtime required 101 seconds 122 considering problems solved systems important plan difference 132 actions 338 plan stability 055 39 Note CPUtime required matching process increases signiﬁcantly plus 69 accurate matching function determines greater number problems examined steps 4247 RetrievePlan procedure In Table 3 compare OAKplanNns relaxed version called OAKplanNnsKnode avoids com putation steps 3x RetrievePlan procedure uses Knode kernel function instead Kbase function step 22 In test want examine behaviour simple matching function The number problems solved 602 51 CPUtime required solve planning problems 959 seconds 133 considering problems solved systems plan difference 258 actions 708 plan stability 019 78 This clearly indicates extraordinary importance accurate matching function global performance order obtain low distance values solve reasonable number planning problems In Tables 4 5 examine situation best planning case selected standard RetrievePlan procedure best_plan step 47 identiﬁed best matching function applying corresponding μbaseπi μnodeπi18 matching functions The relating results indicated respectively OAKplanNnsadaptKbase OAKplanNnsadaptKnode In way provide planning case OAKplan Nns adaptation process encoded solution plan step 47 Fig 10 obtained Kbase Knode kernel functions The number problems solved increases considerably correct planning case provided lpg adapt average CPUtime average plan differences remain signiﬁcantly greater corresponding ones OAKplanNns In particular OAKplanNnsadaptKbase determines average plan distance 180 actions 434 OAKplanNnsadaptKnode determines average plan distance 338 actions 781 plan stability 017 The plan distance values greater ones obtained previous tests essentially able solve diﬃcult planning problems We carried statistical analysis based Wilcoxon signed rank test 68 understand signiﬁcance performance gaps planners compared experiments The organisers IPC3 utilised statistical test study performance planners competition 42 The data necessary effect Wilcoxon test obtained following way The difference CPUtimes planners compared computed samples test CPUtime analysis deﬁned The absolute values differences ranked increasing numbers starting lowest value The lowest value ranked 1 lowest value ranked 2 After ranks positive differences ranks negative differences summed respectively Should happen performance planners compared different number positive 17 Given values b percent error respect b equal absolute value previous formula negative percent error indicates b 18 The μbase matching function computed Kbase kernel function similarly μnode matching function computed Knode kernel function 100 Since values positive considered ab b I Serina Artiﬁcial Intelligence 174 2010 13691406 1391 Table 4 Results OAKplanNnsadaptKbase vs OAKplanNns Domain BlocksWorld Logistics DriverLog ZenoTravel Rovers TPP TOTAL Solutions 650 65 178 16 157 20 160 24 214 00 203 33 977 21 Speed Matching 172152 117 130661 132 112493 112 156323 198 63247 13 79418 225 109291 112 35607 020 45745 043 18328 01 21714 02 53737 003 858 035 29153 011 Quality 338 67 411 21 209 19 214 31 375 008 340 11 319 16 Stability 044 49 030 66 074 18 044 47 096 21 088 85 067 27 Table 5 Results OAKplanNnsadaptKnode vs OAKplanNns Domain BlocksWorld Logistics DriverLog ZenoTravel Rovers TPP TOTAL Solutions 690 63 181 15 108 45 126 40 214 00 400 98 702 43 Speed Matching Quality 181379 111 133987 133 15154 25 109391 169 71984 15 437260 9463 98775 92 36344 008 45543 10 7146 02 21098 10 53745 004 585 17 36588 04 348 68 410 19 950 47 139 89 351 62 518 109 289 11 Stability 042 52 018 80 006 93 009 88 019 81 019 81 017 81 Differences 294 447 488 574 990 406 194 347 268 136 867 325 180 434 Differences 314 455 523 617 144 716 223 419 351 2986 507 3460 338 781 Fig 13 Partial order performance OAKplanNns OAKplanNnsKbase OAKplanNnsKnode OAKplanNnsadaptKbase OAKplanNnsadapt Knode according Wilcoxon signed rank test benchmark problems differences equal number negative differences Moreover sum ranks set positive differences approximately equal sum ranks set From intuitive point view test takes consideration weighted sum number times planner performs better The test makes use performance gap rank performance difference sum weighted Fig 13 gives graphical summary Wilcoxon results relative performance OAKplanNns OAKplan NnsKbase OAKplanNnsKnode OAKplanNnsadaptKbase OAKplanNnsadaptKnode terms CPUtime plan quality difference values benchmark problems Supplementary material detailed results Figs A1A3 A solid arrow planner A planner B cluster planners B indicates performance A statistically different performance B planner B A performs better B planner B conﬁdence level 999 A dashed arrow A B indicates A better B conﬁdence level 99 Here observe expected OAKplanNns statistically better OAKplan variants terms CPUtime plan distance values Quite interesting note OAKplanNnsKnode statistically eﬃcient planner terms quality plans generated followed OAKplanNns This explained fact incremental adaptation process able reduce signiﬁcantly plan distance values quality plans produced 1392 I Serina Artiﬁcial Intelligence 174 2010 13691406 Table 6 Summary Table OAKplanOns vs OAKplanNns Domain Solutions BlocksWorld Logistics DriverLog ZenoTravel Rovers TPP 213 14 211 09 199 10 211 00 214 00 211 047 Speed 66831 73 33729 62 112552 42 39625 54 61688 12 24537 13 Matching 10648 92 17804 74 29052 91 7989 77 52975 14 748 13 TOTAL 1259 22 55988 45 19846 61 Table 7 Summary Table OAKplansmallNns vs OAKplanNns Domain Solutions BlocksWorld Logistics DriverLog ZenoTravel Rovers TPP TOTAL 200 69 214 046 205 41 216 24 216 093 210 00 1261 23 Speed 118823 56 30131 67 97810 28 56226 39 27221 56 26604 09 58584 47 Matching 1596 99 11436 84 4724 86 3146 92 22527 58 858 01 7502 85 Quality 335 73 371 43 233 01 178 88 374 00 308 05 301 32 Quality 359 03 392 003 242 005 196 04 374 00 309 00 312 01 Stability 098 68 094 68 091 027 091 88 098 01 097 031 095 36 Stability 091 012 088 01 092 17 084 055 098 00 096 00 092 037 Differences 139 76 317 59 228 43 198 58 112 13 173 18 194 50 Differences 545 22 769 037 243 42 463 33 113 00 209 01 390 14 422 Object names renaming analysis In Table 6 compare OAKplanOns OAKplanNns The CPUtime required OAKplanOns lower CPU time OAKplanNns Kbase kernel function OAKplanNns produces lower similarity values OAKplan Ons precisely following subsection These lower values determine greater number cases evaluated KN number solutions produced plan qualities close On contrary difference values decrease considerably respect values Table 1 382 vs 194 important point OAKplanOns possible use solution plans stored case base directly compute distance values test problems planning cases domain objects In particular DriverLog Rovers TPP plans produced OAKplanNns OAKplanOns similar BlocksWorld Logistics plans produced OAKplanNns clearly worse corresponding ones produced OAKplanOns respect difference values In BlocksWorld domain main diﬃculties related simple typed encoding allow kernel functions easily identify best object matching function In domain initial goal state descriptions homogeneous objects type Obj leads different matching possibilities As regards Logistic domain main drawbacks related fact trucks assigned different cities respect original ones unfortunately domain trucks positioned speciﬁc cities incorrect truck assignments determine high number applicable actions Considering real word applications think effective performance OAKplan placed results obtained OAKplanNns OAKplanOns Although realistic current planning problem objects belong case base common domain topology change signiﬁcantly evolution For example considering department robotics domain robots packages different locations reasonable department locations corresponding connections change signiﬁcantly time goes Supplementary material detailed results Figs A16A21 423 Case base size analysis In Table 7 compare OAKplansmallNns OAKplanNns We observe small version clearly faster complete version number cases considerably lower OAKplansmallNns able solve 29 problems OAKplanNns 23 average CPUtime 585 seconds 47 respect OAKplanNns consider matching CPUtime requires 75 seconds 85 respect OAKplanNns It follows number problems solved plan quality difference values close Supplementary material detailed results graphical summary Wilcoxon test Figs A4A6 A7 A22A38 Hence observe OAKplan signiﬁcantly faster solves problems runs small large case bases minimal impact solution quality stability differences This clearly indicate importance CBP developing highly scalable retrieval mechanisms analyse eﬃciently case base fact CBP systems retrieval component success given depends critically eﬃcient retrieval right case right time In paper consider relatively simple screening procedure ﬁlters eﬃciently irrelevant cases procedure combined retrieval techniques based model case competence 5761 improve global eﬃciency left future work I Serina Artiﬁcial Intelligence 174 2010 13691406 1393 Fig 14 Cumulative CPUtimes seconds required different phases OAKplanNns vs number planning cases case base Here examine CPUtime seconds required different phases OAKplanNns vs number elements corresponding case base considering speciﬁc benchmark planning problems In particular Fig 14 cumulative CPUtime required different phases OAKplanNns CPUtimes simply derived considering distance corresponding line previous So obtain CPUtimes required 1 preprocessing phase instantiate data structures OAKplan compute mutex relations connect case base load objects predicated indexes 2 screening procedure retrieve degree sequences case base compute similds values steps 1417 RetrievePlan procedure 3 Planning Encoding Graph retrieval procedure computation Kbase kernel function cases selected previous phase steps 2124 RetrievePlan procedure 4 computation KN kernel function corresponding matching function cases selected previous phase steps 3135 RetrievePlan procedure 5 evaluation selected plans deﬁne corresponding adaptation cost steps 4247 Retrieve Plan procedure 6 lpgadapt ﬁnd ﬁrst solution adaptation time obtained difference Total time required ﬁnd ﬁrst solution total Evaluation time Here observe screening procedure extremely fast CPUtime required preprocessing evaluation phases limited Quite interesting BlocksWorld variant CPUtime required KN computation particularly relevant Kbase kernel function precise ﬁlter signiﬁcant number cases In fact domain correct matching objects different planning problems particularly diﬃcult objects type called Obj exposed previously We observe BlocksWorld variant CPUtime required matching phase stabilises case base size nearly 5500 cases This caused maximum number cases examined step 21 RetrievePlan Besides Rovers domain CPUtime required ﬁnd ﬁrst solution plan limited case CPUtimes computation Kbase KN kernel functions comparable In DriverLog ZenoTravel domains matching 1394 I Serina Artiﬁcial Intelligence 174 2010 13691406 Fig 15 Similarity values Neighbourhood kernel function Base kernel function Knode kernel function direct matching hardest problems ZenoTravel RoversStripsIPC5 domains evaluation times clearly dominated CPUtime required ﬁnd ﬁrst solution Finally note ﬁrst solution produced lpgadapt simply represents ﬁrst step potentially longer incremental process At observe drop CPUtime required computation kernel functions Rover domain Fig 14 case base size close 4000 cases This drop related insertion case base planning case high similds screening value case base size varies 3900 4000 instances This screening value determines new best_ds_simil value consequently number cases satisfy constraint best_ds_simil simili cid2 limit step 21 Algorithm RetrievePlan page 1384 decreases 600 250 So number Planning Encoding Graphs loaded number kernel functions computed clearly previous iteration corresponding CPUtime required computation Supplementary material detailed results Fig A11 43 Matching functions similarity results Here examine similarity values obtained Neighbourhood kernel function KN Base kernel function Kbase Knode kernel function direct matching function produced OAKplan hardest problems benchmarks relation progressive renaming domain objects involved In way analyse effectiveness matching processes comparison direct matching process simply based object names planning problems In Fig 15 initial similarity values matching functions equal 1 plots left correspond original problems case base close 1 plots right change 5 initial facts 5 goal facts respect corresponding element case base As expected similarity value direct matching progressively reduces zero similarity value KN kernel function remains greater 09 If consider Kbase Knode kernel functions corresponding similarity values progressively decrease increase number renamed objects This acceptable crucial OAKplan Kbase function essentially order reduce number cases I Serina Artiﬁcial Intelligence 174 2010 13691406 1395 Fig 16 Plan similarity values KN vs Kbase evaluated accurately KN Considering plots left associated original problem case base observe similμN values equal 1 showing KN able match planning problem objects correctly Supplementary material additional results Figs A12A13 In order examine KN Kbase accurately Fig 16 compare similarity values 1296 benchmark problems corresponding case base objects renamed verify behaviour completely new problems provided OAKplan Each point corresponds similarity values produced KN Kbase If point solid diagonal KN performs better Kbase vice versa Here KN performs better Kbase 38 variants similμN 09 It important point experiments obtain similarity value equal test variants modiﬁcations respect initial goal facts correspond I0G0 instances In fact planning problems present case base OAKplan identiﬁes mapping correctly assigns objects selected planning case objects current planning problem Supplementary material additional results Figs A14A15 44 OAKplan vs state art planners In section analyse OAKplan behaviour respect stateoftheart planners showing effectiveness different benchmark domains particular consider metricff winner 2nd IPC lpg winner 3rd IPC downward 1st Prize Suboptimal Propositional Track 4th IPC SGPlanipc5 winner 5th IPC In Fig 17 graphically report number solutions average CPUtime solutions downward metricff SGPlanipc5 CPUtime ﬁrst solutions19 lpg OAKplan Then consider average plan difference values expressed number different actions respect solution produced corresponding planner problems generate variants average best plan quality solutions generated considering benchmark domains Here OAKplan solve greatest number variants followed SGPlanipc5 lpg Regarding CPUtime remark downward lpg OAKplan present similar computation time CPUtime signiﬁcant metricff SGPlanipc5 However average values computed considering problems solved single planner In case SGPlanipc5 planner solves 211 variants TPP domain requiring 942 seconds variants marginally inﬂuence results lpg Regarding difference values OAKplan clearly produces better results planners With respect plan quality 19 Considering median ones ﬁve runs 1396 I Serina Artiﬁcial Intelligence 174 2010 13691406 Fig 17 Summary results note metricff gives better results OAKplan produces worst results We like point OAKplan optimisation process tries balance good quality low distance values interested generating plan limited number differences respect target plan producing solutions good quality Moreover OAKplan able solve diﬃcult planning problems planners solutions weigh signiﬁcantly average plan quality produced In Table 8 report summary results OAKplanNns compared planners In second columns report number solutions planners columns report average speed problems solved milliseconds average plan qualities produced ﬁnally average plan stability average plan differences respect solutions set target plans produced single planner In brackets report percent errors respect OAKplanNns consider problems solved planners comparison column solutions Downward solve problem Rovers domain Globally solve 679 problems comparison 1232 solved OAKplanNns downward 141 slower OAKplanNns plan quality comparable The distance values plans generated downward respect solutions produced planner problems generate variants 411 greater OAKplanNns This high value particularly surprising downward planners know target plans comparison Moreover search processes solution plans produced planner signiﬁcantly different planning instances differ single initial fact These distance values interesting clear indicator good behaviour OAKplan generative approach feasible want preserve stability plans produced LPG solve 840 1296 variants requiring 32 CPUtime OAKplanNns average distance solutions target planning problems 354 actions corresponds 734 respect OAKplanNns It interesting remark CPUtime needed lpg solve Rovers variants 194 seconds signiﬁcantly lower OAKplan 624 seconds additional CPUtime required matching process OAKplanNns 537 seconds The distance plans generated lpg domain 4201 greater OAKplanNns I Serina Artiﬁcial Intelligence 174 2010 13691406 1397 Table 8 Summary Tables different planners examined comparison respect corresponding results produced OAKplanNns Domain Solutions Speed Quality Stability Differences Results DOVNWARD percent errors DOWNWARD vs OAKplanNns BlocksWorld Logistics DriverLog ZenoTravel TPP TOTAL 640 66 198 70 760 61 130 38 211 047 679 45 474335 437 93899 19 41738 381 54752 27 148591 444 133420 141 Results LPG percent errors LPG vs OAKplanNns TOTAL BlocksWorld Logistics DriverLog ZenoTravel Rovers TPP 730 61 211 09 122 38 216 24 216 093 200 99 840 32 94078 43 139416 58 108708 412 174570 95 19440 69 496110 41415 110054 52 Results MetricFF percent errors Metric vs OAKplanNns 307669 429 35598 345 219264 200 745702 1089 899049 7054 433941 737 171 20 650 67 164 22 198 75 770 63 675 45 Logistics DriverLog ZenoTravel Rovers TPP TOTAL Results SGPLANIPC5 percent errors SGPLANIPC5 vs OAKplanNns Logistics DriverLog ZenoTravel Rovers TPP TOTAL 216 14 106 46 180 15 216 093 211 047 929 25 462093 404 321346 2538 171353 126 163457 162 942278 3414 429328 644 572 155 353 48 788 14 128 23 293 51 281 59 238 12 451 16 127 68 202 23 335 11 393 69 291 38 304 80 722 16 123 29 299 19 246 39 229 15 414 46 119 31 142 23 343 84 314 16 288 24 060 32 066 24 045 46 058 29 045 53 055 38 071 19 060 31 032 63 025 70 018 82 040 60 037 58 069 20 019 77 057 30 016 84 051 47 044 51 068 22 018 79 053 36 015 84 041 57 041 55 375 634 242 217 916 447 857 72 315 1403 230 411 149 160 396 413 199 956 332 591 489 4201 468 46650 354 734 196 163 124 655 970 98 391 3366 240 1202 227 500 268 246 190 971 137 175 467 4011 354 1593 300 710 MetricFF solve variant BlocksWorld domain Globally solve 675 problems 757 slower OAKplanNns plan quality 15 better Finally distance plans generated metricff respect solutions produced planner target problems 500 greater OAKplanNns SGPlanipc5 planner solve 929 problems 644 slower OAKplanNns plan qualities similar considering distance plans generated SGPlanipc5 average 710 greater OAKplanNns Fig 18 gives graphical summary Wilcoxon results relative performance OAKplanNns downward lpg metricff SGPlanipc5 terms CPUtime plan quality difference values benchmark problems Supplementary material detailed results Figs A8A10 Here observe OAKplanNns statistically eﬃcient values planners terms CPUtime plan distance On contrary OAKplanNns lpg produce statistically worse plans quality point view planners metricff produces highest quality plans Globally note OAKplanNns able solve problems planners ﬁrst solution usually generated time In addition distance values signiﬁcantly lower respect target plans quality plans produced slightly worse plans produced planner related optimisation performed OAKplan try minimise plan quality distance respect solution plan planning case selected Supplementary material detailed results Figs A39A50 Finally Fig 19 observe cumulative distribution total number variants solved different planners vs time OAKplanNns able solve 1263 variants considering maximum CPUtime 1800 seconds solutions ﬁrst 800 seconds A similar behaviour observed considering lpg downward planners able solve lower number variants On contrary metricff SGPlanipc5 constant increment number variants solved case variants solved OAKplan The CPUtime limit 1800 seconds International Planning Competitions competitors evaluation think adequate evaluation planners practical applications Supplementary material additional results Figs A51A63 1398 I Serina Artiﬁcial Intelligence 174 2010 13691406 Fig 18 Partial order performance OAKplanNns downward lpg metricff SGPlanipc5 according Wilcoxon signed rank test benchmark problems Fig 19 Cumulative distribution total number variants solved different planners vs time 5 Related work casebased planning In following section examine relevant casebased planners considering retrieval adaptation storage capabilities Moreover present empirical comparison performance OAKplan vs faroff comments advantages OAKplan respect casebased planners Some CBP systems designed past consider generative planning structure ﬁnd solution cases stored case base These CBP systems called reuseonly systems As reuseonly systems ﬁnd planning solution scratch ﬁnd solution ﬁnd proper case case base I Serina Artiﬁcial Intelligence 174 2010 13691406 1399 adapted single rules An alternative approach reuseonly systems reuseoptional approach uses generative planning responsible adapt retrieved cases This feature allows CBP solve problems solved stored cases simple rules adaptation phase Empirically great number reuseoptional CBP systems shown use case base permit perform better processing time number planning solutions generative planning incorporate Obviously retrieval phase critically affects systems performance search space cases order choose good allow solve new problem easily In order improve eﬃciency retrieval phase necessary reduce search space design accurate similarity metric Reducing search space suitable subset cases available search process accurate similarity metric choose similar case decrease adaptation phase effort In literature different domain dependent domain independent plan adaptation casebased planning systems use search engine based space states 28296162 An alternative approach planning states planspace planning hierarchical systems 4 search space plans goals tasks achieved Since tasks semantically different goals similarity metric designed CBP systems different similarity rules designed statespace based CBP systems For detailed analysis casebased plan adaptation techniques papers Spalazzi 58 MunozAvila Cox 45 Three interesting works developed time adopt similar assumptions priar 34 spa 29 ProdigyAnalogy 6364 priar uses variant Nonlin 60 hierarchical planner spa uses constraint posting technique similar Chapmans Tweak 10 modiﬁed McAllester Rosenblitt 43 priars plan representation algorithms complicated spa There different types validations ﬁlter condition precondition phantom goal different reduction levels plan represents hierarchical decomposition structure ﬁve different strategies repairing validation failures In contrast representation plan representation spa consists causal links step order constraints The main idea spa separates systems mentioned process plan adaptation fairly simple extension process plan generation In spa view plan generation special case plan adaptation retrieved structure exploit With respect approach deﬁnes matching function μ Π Π cid9 maximises similarity function similμ noted priar spa conditions initial state match slightly complicated In priar number inconsistencies validation structure plan library minimised spa number violations preconditions plan library maximised Moreover problemindependent matching strategy implemented spa runs exponential time number objects simply evaluates possible mappings On contrary compute approximate matching function polynomial time use accurate plan evaluation function subset plans library The ProdigyAnalogy uses search oriented approach planning A library plan case transformational casebased planning framework stores solution prior problem summary new problems suitable solution contains little information process generates solution On hand derivational analogy stores substantial descriptions adaptation process decisions solution Velosos records information choice point spa like list failed alternatives An interesting similarity rule planspace approach presented caplancbc 46 extends similarity rule introduced ProdigyAnalogy 6364 feature weights order reduce errors retrieval phase There important differences approach similarity rules caplancbc designed statespace planning planspace planning Another difference retrieval function need learn knowledge present accurate estimate retrieval method needs knowledge extracted problem description actions planning cases mlr 47 casebased based proof While retrieving plan library adapted current world state makes effort employ retrieval plan proof set goal conditions start Should happen need iteration use plan outcome failed proof provide reﬁtting information On basis failed proof plan skeleton built modiﬁcation strategy makes use failed proof obtain parts plan useful removes useless parts After computation skeleton gaps ﬁlled reﬁnement strategy makes use proof Although object matching function inspired Nebel Koehlers formalisation approach signiﬁcantly differs theirs present effective domain independent matching function In fact experiments exhibit exponential run time behaviour matching algorithm use instead retrieval matching processes performed eﬃciently huge plan libraries The matching function formalisation proposed Nebel Koehler tries maximise ﬁrst cardinality common goal facts set second cardinality common initial facts set On contrary try identify matching function μ maximise similμ similarity value considers initial goal relevant facts accurate evaluation function based simulated execution candidate plans select best plan adapted Nebel Koehler 47 present interesting comparison mlr spa priar performance BlocksWorld domain considering planning instances 8 blocks They small sized instances single reuse candidate matching costs greater adaptation costs When modiﬁcation tasks diﬃcult reuse candidate new planning instance structurally similar savings plan 1400 I Serina Artiﬁcial Intelligence 174 2010 13691406 modiﬁcation predictable matching adaptation effort higher generation scratch On contrary OAKplan shows good performance respect plan generation tests BlocksWorld domain consider instances 140 blocks plan library thousands cases A interesting casebased planner faroff20 Fast Accurate Retrieval Fast Forward 61 It uses generative planning based FF planner 32 adapt similar cases similarity metric called ADG Action DistanceGuided like EvaluatePlan determines adaptation effort estimating number actions necessary transform case solution problem The ADG similarity metric calculates estimate values distance states The ﬁrst value called initial similarity value estimates distance current initial state I initial state case Iπ building relaxed plan having I initial state Iπ goal state Similarly second value called goal similarity value estimates distance ﬁnal state case goals current planning problem Our EvaluatePlan procedure evaluates instead single inconsistency case base solution plan determines current world state I The faroff uses new competencebased method called Footprintbased Retrieval 57 reduce space cases evaluated ADG The Footprintbased Retrieval competencebased method determining groups footprint cases represent smaller case base competence original Each footprint case set similar cases called Related Set 57 The union footprint cases Related Set original case base On contrary OAKplan uses simple procedure based similds function ﬁlter irrelevant cases The use Footprintbased Retrieval techniques case base maintenance policies OAKplan left future work It important point retrieval phase faroff use kind abstraction match cases problems The faroff retrieves similar case ordered k similar cases shifts adaptation phase Its adaptation process modify retrieved case completes ﬁnd plan begins current initial state goes initial state case plan begins state obtained applying actions case goes state satisﬁes current goals G Obviously completing cases leads faroff ﬁnd longer solution plans generative planners avoids wasting time manipulating case actions order ﬁnd shorter solutions length To complete cases faroff uses FFbased generative planning solution obtained merging plans FF based generative planning solution plan planning case selected On contrary OAKplan uses lpgadapt adaptation uses local search approach works input plan adapt ﬁnd solution current planning problem In Fig 20 observe behaviour OAKplan vs faroff considering different variants greater case bases provided faroff Logistics domain21 similar results obtained BlocksWorld Driver Log ZenoTravel domains Globally observe faroff faster OAKplan considering retrieval total adaptation time OAKplan CPUtime lower 06 seconds Considering OAKplan CPUtime devoted computation matching functions computed far simply considers identity matching function directly assigns objects case base current planning problem In fact consider objects present case base overcome limitation variants test directly obtained problems stored case bases Regarding plan qualities22 plan distances important point variant solved OAK plan consider ﬁrst solution produced faroff perform plan optimisation process However OAKplan able obtain better plans considering plan quality plan distance values Globally OAKplan able ﬁnd plans 20 better quality 24 better plan distances Moreover improvements plan qualities distance values OAKplan obtained performing optimisation process lpgadapt Finally note experiment case bases provided faroff contain 700 elements corresponding cases generated creating randomly planning problems conﬁguration objects trucks airplanes simply disposed different ways This kind experiment highly unfavourable OAKplan ﬁrst screening procedure ﬁlter signiﬁcant number cases structure On contrary experiments described previous sections case bases OAKplan standard conﬁguration small versions constrained particular planning problem generated considering different planning problems conﬁgurations International Planning Competitions This realistic situation cases added case base planning problems provided users resolved time goes 20 faroff available httpwwwfeiedubrﬂaviotfaroff 21 We case bases logistics160 logistics170 logistics180 Logistics IPC2 problems For problem considered faroff case base structure perform tests More 700 cases belong case base case base selected planning cases randomly generated 36 variants 22 In STRIPS domains plan quality obtained considering number actions solution plan I Serina Artiﬁcial Intelligence 174 2010 13691406 1401 Fig 20 CPUtime plan qualities number different actions Logistics variants Here examine OAKplan vs faroff 6 Summary future work CBP systems advantage plan reuse possible The success systems depends ability retrieve old cases similar target problem adapt cases appropriately In paper aim provide new effective casebased planner able retrieve planning cases huge plan libraries eﬃciently choose good candidate adapt order provide solution plan good plan quality similar plan retrieved case base We described novel casebased planning called OAKplan uses ideas different research areas showing excellent performance standard planning benchmark domains In paper analysed main components CBP presents signiﬁcant improvements state art especially ﬁltering retrieval phases Experimental results crucial importance accurate matching function global performance order obtain low distance values solve reasonable number planning problems To best knowledge ﬁrst casebased planner performs eﬃcient domain independent objects matching evaluation plan libraries thousands cases We examined OAKplan comparison state art plan generation systems showing extremely good performance terms number problems solved CPU time plan difference values plan quality Results encouraging casebased planning approach effective alternative plan generation suﬃciently similar reuse candidates chosen This happens different practical applications especially world regular types problems agents encounter tend recur Moreover kind approach extremely appealing situations stability plan produced fundamental This case example mission critical applications end users accept newly generated plans prefer use known plans successful analogous situations easily validated We believe signiﬁcant results come combining approach ideas methods developed planning casebased reasoning graph theory supervised learning research areas Speciﬁcally directions considering include 1402 I Serina Artiﬁcial Intelligence 174 2010 13691406 Case base maintenance eﬃciency retrieval phase improved case base maintenance policies thorough evaluation competence library proposed 5761 Graph representation current graph representation based initial goal states planning prob lem examined accurate representation try consider actions solution plans domain operators available importance relevant initial state facts It interesting extend graph representation afford temporal numeric planning problems effectively In fact OAKplan afford temporal metric domains numeric description planning problems examined actually deﬁnition Planning Encoding Graph corresponding kernel functions determining potential low performance Matching functions new effective matching functions obtained considering additional information derived domain analysis invariants 1726 symmetries 18 These functions deﬁned examining particular structures Planning Encoding Graphs like cliques linegraphs new approaches derived graph matching graph edit distance techniques 623484952 Learning techniques useful different planning methods kernel functions plugged kernelbased machine learning algorithm like SVMs 15 SVR Kernel PLS 53 better classify planning cases improve matching functions Adaptation retrievalevaluationupdate techniques independent adaptation mechanism adopted adaptation methods like adjustplan 2728 POPR 62 effectively Acknowledgements This research supported research project Study Design Prototype Intelligent Planning Sys tem Building Learning Paths Free University Bozen We thank Piergiorgio Bertoli Alfonso E Gerevini Alessandro Saetti especially anonymous referees helpful comments The authors like thank Flavio Tonidandel Márcio Rillo putting benchmark set faroff planning disposal Appendix B Proofs Theorem 3 obj_match NPhard Proof Similarly Nebel Koehlers analysis 47 NPhardness proved polynomial transformation subgraph isomorphism problem directed graphs NPComplete 22 p 202 obj_match The subgraph isomorphism problem deﬁned follows Instance Two directed Graphs G 1 V 1 E1 G 2 V 2 E2 Question Does G 2 contain subgraph isomorphic G 1 exist subsets V V 2 subset E E2 V V 1 E E1 exists onetoone function μ V 1 V satisfying u v E1 μu μv E Given instance subgraph isomorphism problem construct instance obj_match follows let Π1 cid9 PrO1 P1 I1 G1 O p1 cid10 cid9 Π2 PrO2 P2 I2 G2 O p2 cid10 planning instances O1 O2 V 1 V 2 G1 pu v cid13 cid17 cid17 u v E2 Now G 2 contains subgraph isomorphic G 1 iff exists mapping μ μG1 G2 E1 cid17 cid17 u v E1 O p2 pu v G2 O p1 cid14 P1 P2 p cid13 cid14 I1 I2 similμΠ1 Π2 μG1 G2 μI1 I2 G2 μI1 E1 E2 Note G 2 isomorphic G 1 iff exists mapping μ similμΠ1 Π2 1 cid2 μG1 G2 E1 E2 Theorem 4 R1 kernel function Proof We given set patterns x1 xn kernel matrix R R1xi x ji j positive semideﬁnite 56 symmetric Clearly R1 symmetric deﬁnition Let ζ denote permutation nsubset natural numbers 1 m permutation msubset natural numbers 1 n respectively ζ I Serina Artiﬁcial Intelligence 174 2010 13691406 kv cid23 ke cid12 cid12 cid11 cid11 eζ 1x e1x nζ 1x n1x cid12 cid11 cid2 1 n1x n1x kv 2 cid12 cid11 kv nnx nnx cid6 cid12 cid11 nix nix cid12 cid11 ke e1x e1x cid12 cid11 enx enx cid12 cid11 eix eix ke ke kv cid12 cid11 kv nζ nx nnx cid12 cid11 kv nζ 1x nζ 1x cid12 cid11 nζ nx nζ nx kv cid12 cid11 eζ nx enx ke cid12 cid11 eζ 1x eζ 1x cid12cid24 ke cid11 eζ nx eζ nx ke 1403 B2 B3 B4 2 kv cid11 cid12 nζ ix nix cid11 cid12 nix nix cid11 cid12 eζ ix eix ke cid11 cid12 ke eix eix kv cid2 kv cid11 cid12 nζ ix nζ ix cid11 cid12 eζ ix eζ ix ke kv ke positive semideﬁnite kernel functions product kernel functions kernel function Now maximum ζ R1x x B2 B3 B4 Similarly R1y y j kv n jy n jy kee jy e jy Without loss generality assume y cid3 x Further cid5 holds α β R j cid11 cid12 eix e jy cid11 cid12 nix n jy 2αβkv ke cid11 cid12 nix nix cid2 α2kv cid11 cid12 eix eix β 2kv cid11 cid12 n jy n jy cid11 cid12 e jy e jy ke ke kv ke positive semideﬁnite kernel functions It α2 R1x x 2αβ R1x y β 2 R1y y cid6 α2 cid11 cid12 nix nix cid11 cid12 eix eix ke cid11 cid12 n jy n jy cid11 cid12 e jy e jy ke kv β 2 kv cid6 j 2αβ max π cid11 cid12 nix nπ iy kv cid11 cid12 eix eπ iy ke cid6 By deﬁnition R1 second sum previous equation minx y x addends Using B5 xcid6 B6 cid3 cid11 cid12 nix nix cid11 cid12 eix eix ke α2kv 2αβkv cid11 cid12 nix nζ iy cid11 cid12 eix eζ iy ke i1 β 2kv cid11 cid12 nζ iy nζ iy cid11 cid12 eζ iy eζ iy ke cid3 0 This proves positive semideﬁniteness 2 2 kernel matrix From generalise result n n matrices induction assumption kv ke nonnegative Suppose know n n kernel matrix R R1xi x ji j set objects x1 xn positive semideﬁnite Now assume extend matrix size n 1 n 1 adding object xn1 It n1cid6 j1 viv jRi j ncid6 j1 viv jRi j 2 ncid6 j1 vn1v jRn1 j v2 n1Rn1n1 B8 By induction assumption know ﬁrst B8 nonnegative Furthermore deﬁnition kv ke n1Rn1n1 cid3 0 nonnegative R1 nonnegative Hence v2 cid5 Therefore order B8 0 suppose 2 n j1 vn1v jRn1 j 0 similarly B5 2 vn1v jRn1 j cid2 v2 n1Rn1n1 v2 j R j j This leads ncid6 2 j1 vn1v jRn1 j cid2 n1Rn1n1 v2 v2 j R j j cid12 0 ncid6 cid11 j1 contradiction nonnegativity R1 Hence B8 cid3 0 proofs theorem cid2 Theorem 5 Let γ l pl p 0 05 If exists C R e1 e2 Eq 10 converges L kv v 1 v 2 cid2 C v 1 v 2 kee1 e2 cid2 1 B5 B6 B7 1404 Proof It I Serina Artiﬁcial Intelligence 174 2010 13691406 R1u v cid2 1 maxEu Ev cid2 minEu Ev maxEu Ev minEuEvcid6 i1 C cid2 C max v1v2 kv v 1 v 2 max e1e2 kee1 e2 R2u v cid2 1 N iv N iu cid6 hhcid9 1 N ov N ou cid11 hv ni ni cid12 hcid9 u cid11 ehv ei cid12 hcid9 u ke cid9 u max ei hvei cid12 hcid9 u h max hveo eo h cid9 u cid11 hv cid11 hv eo eo cid12 hcid9 u ke R1 max hvni ni cid6 h cid9 u max hvno h cid9 u R1 hhcid9 N vcid6 N ucid6 cid2 1 N iv N iu C 1 N ov N ou N ovcid6 N oucid6 i1 j1 C 2 C i1 j1 Similarly Rlu v cid2 2l1C l 3 L Therefore Eq 10 cid2 C pC p22C p L2L1C cid2 C Lcid6 2plC l1 converges L p 0 05 cid2 Appendix C Variants As previously described p 1388 tests conducted series variants problems different standard benchmark domains 2nd 3rd 5th International Planning Competitions23 The variant problems generated taking problems benchmark test suite Logistics domain randomly modifying initial state goal states total 216 planning problems domain The problems considered probblocks400 probblocks600 probblocks800 probblocks1000 probblocks1201 probblocks1401 BlocksWorld Additionals randomly selected logistics160 logistics1001 Logistics Additionals Track2 pﬁle14 pﬁle17 pﬁle20 pﬁleHC03 pﬁleHC06 pﬁleHC09 DriverLog pﬁle14 pﬁle17 pﬁle20 pﬁleHC14 pﬁleHC17 pﬁleHC20 ZenoTravel pﬁle35 pﬁle36 pﬁle37 pﬁle38 pﬁle39 pﬁle40 RoversIPC5 pﬁle25 pﬁle26 pﬁle27 pﬁle28 pﬁle29 pﬁle30 TPP In following present brief description operators order modify initial goal states base problem In order modify initial state randomly choose completely instantiated noisy operator preconditions satisﬁed effects noisy operator determine new initial state With respect goals propagate effects actions solution plan base problem order deﬁne complete goal state randomly choose completely instantiated noisy operator preconditions satisﬁed goal base problem belongs The effects noisy operator change goal state particular negative effects delete corresponding goals positive effects added goal set BlocksWorld The NOISEfalldown noisy operator randomly split pile blocks piles contrary NOISEpileup operator randomly pile pile blocks DriverLog The NOISEmovepackage NOISEmovedriver noisy operators randomly change location package driver respectively Logistics The NOISEmovepackage NOISEflyairplane noisy operators change location package airplane respectively 23 The IPCs test problems available following websites IPC2 httpwwwcstorontoeduaips2000 IPC3 httpplanningcisstrathacukcompetition IPC5 httpipc5ingunibsit I Serina Artiﬁcial Intelligence 174 2010 13691406 1405 Rovers The NOISEcommunicate_soil_data NOISEcommunicate_rock_data NOISEcommuni cate_image_data noisy operators change status communicated communicated soil data rock data image data respectively waypoint x waypoint y The NOISE_drive NOISE_onsale noisy operators randomly change location truck randomly change sale conditions goods respectively TPP ZenoTravel For domain deﬁned ﬁve noisy operators NOISEfuel operator randomly change fuel level aircraft NOISEfly NOISEzoom operators randomly modify location aircraft different fuel NOISEmovepackage operator randomly change location package NOISEdebark operator randomly modify objects inside aircraft Supplementary data Supplementary data associated article online version doi101016jartint201007007 References 1 A Aamodt E Plaza Casebased reasoning foundational issues methodological variations approaches AI Commun 7 1 March 1994 3959 2 T Au H MuñozAvila DS Nau On complexity plan adaptation derivational analogy universal classical planning framework Proceed ings 6th European Conference Advances CaseBased Reasoning SpringerVerlag London UK 2002 pp 1327 3 F Bacchus F Kabanza Using temporal logic express search control knowledge planning Artiﬁcial Intelligence 116 12 2000 123191 4 R Bergmann W Wilke Building reﬁning abstract planning cases change representation language Journal Artiﬁcial Intelligence Research 3 1995 53118 5 WD Blizard Multiset theory Notre Dame Journal Formal Logic 30 1 1989 3666 6 H Bunke Recent developments graph matching 15th International Conference Pattern Recognition vol 2 2000 pp 117124 7 T Bylander An average case analysis planning Proceedings Eleventh National Conference American Association Artiﬁcial Intelligence AAAI93 AAAI PressMIT Press Washington DC 1993 pp 480485 8 T Bylander The computational complexity propositional STRIPS planning Artiﬁcial Intelligence 69 1994 165204 9 T Bylander A probabilistic analysis propositional STRIPS planning Artiﬁcial Intelligence 81 12 1996 241271 10 D Chapman Planning conjunctive goals Artiﬁcial Intelligence 32 3 1987 333377 11 M Chein M Mugnier Graphbased Knowledge Representation Computational Foundations Conceptual Graphs Springer 2008 12 YP Chien A Hudli M Palakal Using manysorted logic objectoriented data model fast robot task planning Journal Intelligent Robotic Systems 23 1 1998 125 13 AG Cohn Many sorted logic unsorted logic control Proceedings Expert Systems 86 6th Annual Technical Conference Research Development Expert Systems III Cambridge University Press New York NY USA 1987 pp 184194 14 LP Cordella P Foggia C Sansone M Vento A subgraph isomorphism algorithm matching large graphs Pattern Analysis Machine Intelligence IEEE Transactions 26 10 2004 13671372 15 N Cristianini J ShaweTaylor An Introduction Support Vector Machines Cambridge University Press Cambridge 2000 16 M Fox A Gerevini D Long I Serina Plan stability Replanning versus plan repair Proceedings International Conference AI Planning Scheduling ICAPS AAAI Press 2006 17 M Fox D Long The automatic inference state invariants TIM Journal Artiﬁcial Intelligence Research JAIR 9 1998 367421 18 M Fox D Long The detection exploitation symmetry planning problems Proceedings 16th International Joint Conference Artiﬁcial Intelligence IJCAI99 1999 pp 956961 19 H Fröhlich JK Wegner F Sieker A Zell Optimal assignment kernels attributed molecular graphs L De Raedt S Wrobel Eds ICML ACM International Conference Proceeding Series vol 119 ACM 2005 pp 225232 20 H Fröhlich JK Wegner F Sieker A Zell Kernel functions attributed molecular graphs new similarity based approach ADME prediction classiﬁcation regression QSAR Comb Sci 25 2006 317326 21 H Fröhlich JK Wegner A Zell Assignment kernels chemical compounds International Joint Conference Neural Networks 2005 IJCNN05 2005 pp 913918 22 MR Garey DS Johnson Computers Intractability A Guide Theory NPCompleteness Series Books Mathematical Sciences WH Freeman 1979 23 T Gärtner A survey kernels structured data SIGKDD Explor Newsl 5 1 2003 4958 24 D Gentner The mechanisms analogical learning BG Buchanan DC Wilkins Eds Readings Knowledge Acquisition Learning Automating Construction Improvement Expert Systems Kaufmann San Mateo CA 1993 pp 673694 25 A Gerevini A Saetti I Serina Planning stochastic local search temporal action graphs Journal Artiﬁcial Intelligence Research JAIR 20 2003 239290 26 A Gerevini L Schubert On pointbased temporal disjointness Artiﬁcial Intelligence 70 1994 347361 27 A Gerevini I Serina Plan adaptation planning graph analysis AIIA 99 Lecture Notes Artiﬁcial Intelligence SpringerVerlag 1999 pp 356367 28 A Gerevini I Serina Fast plan adaptation planning graphs Local systematic search techniques Proceedings 5th International Conference Artiﬁcial Intelligence Planning Scheduling AIPS00 AAAI PressMIT Press 2000 pp 112121 29 S Hanks DS Weld A domainindependent algorithm plan adaptation Journal Artiﬁcial Intelligence Research JAIR 2 1995 319360 30 P Hansen Upper bounds stability number graph Rev Roumaine Math Pures Appl 24 1979 11951199 31 D Haussler Convolution kernels discrete structures Technical Report UCSCRL9910 UC Santa Cruz 1999 32 J Hoffmann B Nebel The FF planning Fast plan generation heuristic search Journal Artiﬁcial Intelligence Research JAIR 14 2001 253302 33 M Johnson Relating Metrics Lines Variables Deﬁned Graphs Problems Medicinal Chemistry John Wiley Sons Inc New York NY USA 1985 34 S Kambhampati JA Hendler A validationstructurebased theory plan modiﬁcation reuse Artiﬁcial Intelligence 55 1992 193258 1406 I Serina Artiﬁcial Intelligence 174 2010 13691406 35 H Kashima K Tsuda A Inokuchi Marginalized kernels labeled graphs T Fawcett N Mishra Eds ICML AAAI Press 2003 pp 321328 36 V Kuchibatla H MuñozAvila An analysis transformational analogy General framework complexity ECCBR Lecture Notes Computer Science vol 4106 Springer 2006 pp 458473 37 HW Kuhn The Hungarian method assignment problem Naval Research Logistic Quarterly 2 1955 8397 38 DB Leake Ed CaseBased Reasoning MIT Press Cambridge MA 1996 39 P Liberatore On complexity casebased planning Journal Experimental Theoretical Artiﬁcial Intelligence 17 3 2005 283295 40 D Lin An informationtheoretic deﬁnition similarity JW Shavlik Ed ICML Morgan Kaufmann 1998 pp 296304 41 RY Liu An upper bound chromatic number graph J Xinjiang Univ Natur Sci 6 1989 2427 42 D Long M Fox The 3rd international planning competition Results analysis Journal Artiﬁcial Intelligence Research JAIR 10 2003 159 43 D McAllester D Rosenblitt Systematic nonlinear planning Proceedings Ninth National Conference Artiﬁcial Intelligence AAAI91 July 1991 pp 634639 44 J Mercer Functions positive negative type connection theory integral equations Philos Trans Roy Soc London 209 1909 415446 45 H MuñozAvila M Cox Casebased plan adaptation An analysis review IEEE Intelligent Systems 23 4 2008 7581 46 H MuñozAvila J Hüllen Feature weighting explaining casebased planning episodes EWCBR 96 Proceedings Third European Workshop Advances CaseBased Reasoning SpringerVerlag London UK 1996 pp 280294 47 B Nebel J Koehler Plan reuse versus plan generation A complexitytheoretic perspective Artiﬁcial Intelligence Special Issue Planning Schedul ing 76 1995 427454 48 M Neuhaus H Bunke A convolution edit kernel errortolerant graph matching 18th International Conference Pattern Recognition ICPR06 vol 4 IEEE Computer Society Washington DC 2006 pp 220223 49 M Neuhaus H Bunke Bridging Gap Between Graph Edit Distance Kernel Machines World Scientiﬁc 2007 50 AN Papadopoulos Y Manolopoulos Structurebased similarity search graph histograms Proceedings 10th International Workshop Database Expert Systems Applications IEEE Computer Society Press 1999 pp 174178 51 JW Raymond EJ Gardiner P Willett Rascal Calculation graph similarity maximum common edge subgraphs The Computer Journal 45 6 June 2002 631644 52 K Riesen H Bunke Approximate graph edit distance computation means bipartite graph matching Image Vision Comput 27 7 2009 950959 53 R Rosipal LJ Trejo Kernel partial squares regression reproducing kernel Hilbert space J Mach Learn Res 2 2002 97123 54 BH Ross Some psychological results casebased reasoning Proc Workshop CaseBased Reasoning Pensacola Beach FL 1989 pp 144 147 55 F Ruskey R Cohen P Eades A Scott Alley cats search good homes TwentyFifth Southeastern Conference Combinatorics Graph Theory Computing 102 1994 97110 56 B Scholkopf AJ Smola Learning Kernels Support Vector Machines Regularization Optimization Beyond MIT Press Cambridge MA USA 2001 57 B Smyth E McKenna Footprintbased retrieval KD Althoff R Bergmann K Branting Eds ICCBR Lecture Notes Computer Science vol 1650 Springer 1999 pp 343357 58 L Spalazzi A survey casebased planning Artiﬁcial Intelligence Review 16 1 2001 336 59 B Srivastava TA Nguyen A Gerevini S Kambhampati MB Do I Serina Domain independent approaches ﬁnding diverse plans MM Veloso Ed IJCAI 2007 pp 20162022 60 A Tate Generating project networks Proceedings Fifth International Joint Conference Artiﬁcial Intelligence IJCAI77 MIT Cambridge MA 1977 pp 888889 61 F Tonidandel M Rillo The FAROFF A heuristic search casebased planning M Ghallab J Hertzberg P Traverso Eds AIPS AAAI 2002 pp 302311 62 R van der Krogt M Weerdt Plan repair extension planning S Biundo KL Myers K Rajan Eds ICAPS AAAI 2005 pp 161170 63 M Veloso Learning analogical reasoning general problem solving Technical report CMUCS92174 Department Computer Science Carnegie Mellon University 1992 64 M Veloso Planning Learning Analogical Reasoning Lecture Notes Artiﬁcial Intelligence vol 886 SpringerVerlag Inc New York USA 1994 65 SVN Vishwanathan AJ Smola Fast kernels string tree matching S Becker S Thrun K Obermayer Eds NIPS MIT Press 2002 pp 569 576 66 S Vosniadou A Ortony Eds Similarity Analogical Reasoning Cambridge University Press New York NY USA 1989 67 C Walther A mechanical solution Schuberts steamroller manysorted resolution Artiﬁcial Intelligence 26 2 1985 217224 68 F Wilcoxon RA Wilcox Some Rapid Approximate Statistical Procedures American Cyanamid Co Pearl River NY USA 1964