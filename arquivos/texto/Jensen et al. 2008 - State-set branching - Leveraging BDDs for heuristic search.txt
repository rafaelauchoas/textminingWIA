Artiﬁcial Intelligence 172 2008 103139 wwwelseviercomlocateartint Stateset branching Leveraging BDDs heuristic search Rune M Jensen Manuela M Veloso Randal E Bryant Computer Science Department Carnegie Mellon University 5000 Forbes Ave Pittsburgh PA 152133891 USA Received 22 February 2006 received revised form 30 May 2007 accepted 30 May 2007 Available online 7 June 2007 Abstract In article present framework called stateset branching combines symbolic search based reduced ordered Binary Decision Diagrams BDDs bestﬁrst search A greedy bestﬁrst search The framework relies extension algorithms expanding single state iteration expanding set states We prove generally sound optimal A implementations new BDD technique called branching partitioning efﬁciently expand sets states The framework general It applies heuristic function evaluation function transition cost function deﬁned ﬁnite domain Moreover branching partitioning applies disjunctive conjunctive transition relation partitioning An extensive experimental evaluation A implementations proves stateset branching powerful framework The algorithms outperform ordinary A algorithm domains In addition improve complexity A exponentially dominate A blind BDDbased search orders magnitude Moreover substantially better performance BDDA currently efﬁcient BDDbased implementation A 2007 Elsevier BV All rights reserved Keywords Heuristic search BDDbased search Boolean representation 1 Introduction Informed heuristic bestﬁrst search BFS algorithms1 greedy bestﬁrst search A 27 considered important contributions AI The advantage algorithms compared uninformed blind search algorithms depthﬁrst search breadthﬁrst search use heuristics guide search goal way signiﬁcantly reduce number visited states The algorithms differ mainly way evaluate nodes search tree A probably widely known BFS algorithm Each search node A associated This work extended version paper presented AAAI02 RM Jensen RE Bryant MM Veloso SetA An efﬁcient BDDbased heuristic search algorithm Proceedings 18th National Conference Artiﬁcial Intelligence AAAI02 2002 pp 668673 The work supported Danish Research Agency United States Air Force Grants Nos F306020020549 F306029820135 The views conclusions contained document authors interpreted necessarily representing ofﬁcial policies endorsements expressed implied Defense Advanced Research Projects Agency DARPA Air Force US Government Corresponding author Email addresses runejcscmuedu RM Jensen mmvcscmuedu MM Veloso bryantcscmuedu RE Bryant URLs httpwwwcscmuedurunej RM Jensen httpwwwcscmuedummvMM Veloso httpwwwcscmuedubryant RE Bryant 1 In article BFS refers bestﬁrst search breadthﬁrst search 00043702 matter 2007 Elsevier BV All rights reserved doi101016jartint200705009 104 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 cost g reaching node heuristic estimate h remaining cost reaching goal In iteration A expands node minimum expected completion cost f g h A shown better performance uninformed search algorithms However unresolved problem algorithm number expanded search nodes grow exponentially heuristic small constant relative error 46 Such heuristic functions encountered practice heuristics derived relaxation search problem likely introduce relative error Furthermore order detect duplicate states construct solution A expanded nodes memory For reason limiting factor A space time In symbolic model checking 42 different approach taken verify systems large state spaces Instead representing manipulating sets states explicitly implicitly Boolean functions2 Given bit vector encoding states characteristic functions represent subsets states In similar way Boolean function represent transition relation domain ﬁnd successor states Boolean function manipulation The approach potentially reduces time space complexity exponentially Indeed decade remarkable results obtained reduced ordered Binary Decision Diagrams BDDs 9 Boolean function representation Systems 10100 states successfully veriﬁed BDDbased model checker SMV 42 For reasons limited work heuristics guide implicit search algorithms carried First solution techniques considered formal veriﬁcation require traversal reachable states making search guidance irrelevant Secondly nontrivial efﬁciently handle cost estimates g hcosts associated individual states representing states implicitly In article present new framework called stateset branching combines BDDbased search best ﬁrst search BFS efﬁciently solves problem representing cost estimates Stateset branching applies BFS algorithm transition cost function heuristic function nodeevaluation function deﬁned ﬁnite domain The stateset branching framework consists independent parts The ﬁrst extends general BFS algorithm algorithm called bestsetﬁrst search BSFS expands sets states iteration The second efﬁcient BDDbased implementation BSFS partitioning transition relation search domain called branching partitioning Branching partitioning allows sets states expanded implicitly sorted according associated cost estimates The approach applies disjunctive conjunctive partitioning 15 Two implementations A based stateset branching framework called FSETA anf GHSETA experimentally evaluated 10 search domains ranging VLSIdesign synchronous actions classical AI planning problems N 2 1puzzles problems international planning competitions 19982004 2293940 We apply different families heuristic functions ranging minimum Hamming distance sum Manhattan distances N 2 1puzzles HSPr 8 planning problems In experimental evaluation A implementations outperform implementations ordinary A algorithm domains efﬁcient Boolean state encoding challenging ﬁnd3 In addition results improve complexity A exponentially dominate ordinary A algorithm blind BDDbased search orders magnitude Moreover substantially better performance BDDA currently efﬁcient symbolic implementation A The main limitation stateset branching framework Boolean state encoding compact BDD representation target domain In cases easy general domain representation lan guages PDDL 24 challenging deﬁne automated encoding techniques Another issue branching partitionings easy obtain heuristics The experiments article additive heuris tics like sum Manhattan distances HSPr heuristic represented compactly A recent study 32 shows branching partitionings maxpair heuristic 28 prohibitively large It impression strong domain dependent heuristics combinatorial complex maxpair heuristic 2 By explicit representation mean enumerative representation uses space linear number represented elements By implicit representation mean nonenumerative representation Boolean expressions characterize elements 3 By ordinary A refer graphsearch version A maintains closed list duplicate elimination uses explicit state representation RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 105 The remainder article organized follows We ﬁrst related work Section 2 We deﬁne search problems Section 3 general BFS algorithm Section 4 In Section 5 extend algo rithm expand sets states study number example applications new bestsetﬁrst search algorithm In Section 6 introduce branching partitioning BDDbased techniques efﬁciently implement algorithms The experimental evaluation described Section 7 Finally conclude discuss directions future work Section 8 2 Related work Stateset branching ﬁrst general framework combining heuristic search BDDbased search All previ ous work restricted particular algorithms BDDbased heuristic search investigated independently symbolic model checking AI The pioneering work symbolic model checking heuristic search falsify design invariants ﬁnding error traces Yuan et al 60 study bidirectional greedy bestﬁrst search algorithm pruning frontier states according minimum Hamming distance4 error states BDDs rep resenting Hamming distance equivalence classes precomputed conjoined BDDs representing search frontier search Yang Dill 59 consider minimum Hamming distance heuristic function ordi nary greedy bestﬁrst search algorithm They develop specialized BDD operation sorting set states according minimum Hamming distance set error states The operation efﬁcient linear complexity size BDD representing error states However unclear operation generalized heuristic functions In addition approach ﬁnds states sorts according cost estimates separate phases Recent applications BDDbased heuristic search symbolic model checking include error directed search 51 symbolic pattern databases guided invariant model checking 49 In general heuristic BDDbased search received little attention symbolic model checking The reason main application BDDs ﬁeld veriﬁcation reachable states explored For Computation Tree Logic CTL checking 15 guiding techniques proposed avoid blowup intermediate BDDs reachability analysis 7 However techniques applicable search based deﬁning lower upper bounds ﬁxedpoint reachable states In AI Edelkamp Reffel 21 developed ﬁrst BDDbased implementation A called BDDA BDDA use heuristic function deﬁned ﬁnite domain applied planning model checking 51 Several extensions BDDA published including duplicate elimination weighted evaluation func tion pattern data bases disjunctive transition relation partitioning external storage 1819 BDDA currently efﬁcient symbolic implementation A It contributes combination A BDDs single BDD represent search queue A In iteration states minimum f costs extracted BDD The successor states associated f cost computed arithmetic BDD operations added BDD representing search queue There major differences BDDA SETA algorithms presented article 1 Our experimental evaluation BDDA shows successor state function scales poorly Section 76 A detailed analysis computation shows complexity mainly symbolic arithmetic opera tions For reason main philosophy stateset branching use BDDs represent state information Cost estimates like f cost state represented explicitly search tree 2 Stateset branching introduces novel approach called branching partitioning makes possible use transition relation partitioning propagate cost estimates efﬁciently sets states search In way bestﬁrst search algorithm called bestsetﬁrst search expands sets states iteration efﬁciently implemented BDDs As shown experimental evaluation Section 7 dramatic positive effect efﬁciency algorithms An ADDbased5 implementation A called ADDA developed 26 ADDs 3 generalize BDDs ﬁnite valued functions simplify representation numeric information like f cost states 58 4 The Hamming distance Boolean vectors number bits vectors different value 5 ADD stands Algebraic Decision Diagram 3 106 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 Similar BDDA ADDA performs arithmetic computations complex ADD operations It shown better performance BDDA 26 A recent comparison A symbolic implementation A called SA 500 random 8puzzle problems shows SA consistently uses memory A outperformed A heuristic strong 45 These results conﬁrmed experimental evaluation article GHSETA typically uses memory A ﬁnds solutions faster A We believe reasons observed differences First SA use stateset branching compute child nodes instead relies efﬁcient phase approach developed Yuan et al Second SA stores expanded nodes merging nodes gcost This GHSETA lead signiﬁcant space savings Third 8puzzle problems small 106 states compared benchmark problems considered evaluation It unclear extent symbolic approaches pay small problems Fourth statespace N 2 1 puzzle subspace permutation space consisting possible permutations n elements It easy BDD representation permutation space exponentially compact explicit representation It exponential number elements permutation For reason expect high memory consumption BDDbased search N 2 1puzzles Indeed fairly weak results FSETA GHSETA 24 35puzzle benchmarks Other related applications BDDs search include HTN planning 37 STRIPS planning 1012162333 56 universal planning 1334 adversarial planning 1735 fault tolerant planning 36 conformant planning 14 planning extended goals 47 planning partial observability 56 shortest path search 5253 3 Search problems A search domain ﬁnite graph vertices denote world states edges denote state transitions Transitions caused activity world changes world state deterministically Sets transitions deﬁned actions operator schemas guarded commands In article consider abstract transition descriptions If transition directed state s state scid3 state scid3 said successor s state s said predecessor scid3 The number successors emanating given state called branching factor state Since domain ﬁnite branching factor state ﬁnite Each transition assumed positive transition cost Deﬁnition 1 Search domain A search domain triple D cid4S T ccid5 S ﬁnite set states T S S transition relation c T R transition cost function A search problem search domain single initial state set goal states Deﬁnition 2 Search problem Let D cid4S T ccid5 search domain A search problem D triple P cid4D s0 Gcid5 s0 S G S A solution π search problem path initial state goal states The solution length number transitions π solution cost sum transition costs path Deﬁnition 3 Search problem solution Let D cid4S T ccid5 search domain P cid4D s0 Gcid5 search problem D A solution P sequence states π s0 sn sn G T sj sj 1 j 0 1 n 1 An optimal solution search problem solution minimum cost We use symbol C denote minimum cost Fig 1 shows search problem example optimal solution 4 Bestﬁrst search Bestﬁrst search algorithms characterized building search tree superimposed state space search process Each search node tree pair cid4s cid9ecid5 s single state cid9e Rd ddimensional real vector representing cost estimates associated node cid9e dimensional vector containing RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 107 Fig 1 An example search problem consisting states ﬁve transitions initial state s0 C single goal state G B The dashed path optimal solution The hcosts associated state deﬁne heuristic function Section 4 frontier MAKEQUEUEcid4s0 cid9e0cid5 loop function BFSs0 cid9e0 G 1 2 3 4 5 6 frontier 0 return failure cid4s cid9ecid5 REMOVETOPfrontier s G return EXTRACTSOLUTIONfrontier cid4s cid9ecid5 frontier ENQUEUEALLfrontier EXPANDcid4s cid9ecid5 Fig 2 The general bestﬁrst search algorithm Fig 3 Search tree example g hcost associated search node A Fig 2 shows general BFS algorithm We assume initial state associated cost estimate cid9e0 The solution extraction function line 5 simply obtains solution tracing transitions goal node root node EXPAND line 6 ﬁnds set child nodes single node ENQUEUEALL inserts child frontier queue A BFS algorithm6 sorts unexpanded nodes priority queue ascending order cost estimate given heuristic evaluation function f The evaluation function deﬁned f n gn hn gn cost path search tree leading root node n hn heuristic function estimating cost minimum cost path leading state n goal state7 Thus f n measures minimum cost solution paths constrained state n The search tree built A example problem heuristic function deﬁned Fig 1 shown Fig 3 6 However practical implementations A includes closed list detect duplicate states 7 For heuristic function valid require hn cid2 0 n hn 0 n containing goal state 108 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 A sound complete node expansion operation assumed correct inﬁnite cyclic paths unbounded cost A ﬁnds optimal solutions heuristic function hn admissible hn cid3 hn n hn minimum cost path going state n goal state The heuristic function called consistent hn cid3 cn ncid3 hncid3 successor node ncid3 n The complexity A directly tied accuracy estimates provided h When A employs perfectly informed heuristic hn hn f cost ties broken giving highest priority node lowest hcost guided directly closest goal At extreme heuristic available hn 0 search exhaustive normally yielding exponential complexity In general A duplicate elimination consistent heuristic linear complexity absolute error heuristic function constant exponential complexity relative error constant Subexponential complexity requires growth rate error logarithmically bounded 46 cid4 n cid2 cid2hn h cid2 cid2 O n cid3 log h The complexity results discouraging fact practical heuristic functions based relaxation search problem causes hn constant near constant relative error The results practical application A search intensive Often better performance A obtained weighting g hcomponent evaluation function 48 f n 1 wgn whn w 0 1 1 Weights w 00 05 10 correspond uniform cost search A greedy bestﬁrst search Weighted A optimal range 00 05 heuristic function admissible ﬁnds solutions faster range 05 1 5 Stateset branching The stateset branching framework independent parts modiﬁcation general BFS algorithm new algorithm called bestsetﬁrst search BSFS collection BDDbased techniques implementing new algorithm efﬁciently In section BSFS algorithm In section implemented BDDs 51 Bestsetﬁrst search Assume transition T s scid3 particular heuristic search algorithm changes cost estimates δcid9es scid3 Thus s associated cost estimates cid9e scid3 reached T s scid3 scid3 associated cost estimates cid9e δcid9es scid3 For A cost estimates dimensional f cost g hcost search node In ﬁrst case δcid9es scid3 f cost change caused transition The δf costs example problem shown Fig 4 The BSFS algorithm shown Fig 5 identical BSFS algorithm deﬁned Fig 2 However state set version traverses search tree search process search node contains set states associated cost estimates Multiple states node emerge child nodes having identical cost estimates coalesced STATESETEXPAND line 6 Fig 4 The example search problem δf costs RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 109 frontier MAKEQUEUEcid4s0 cid9e0cid5 loop function BSFSs0 cid9e0 G 1 2 3 4 5 6 frontier 0 return failure cid4S cid9ecid5 REMOVETOPfrontier S G cid12 return EXTRACTSOLUTIONfrontier cid4S G cid9ecid5 frontier ENQUEUEANDMERGEfrontier STATESETEXPANDcid4S cid9ecid5 Fig 5 The bestsetﬁrst search algorithm child emptyMap foreach state s S function STATESETEXPANDcid4S cid9ecid5 1 2 3 4 5 6 foreach transition T s scid3 cid9ec cid9e δcid9es scid3 childcid9ec childcid9ec scid3 return MAKENODESchild Fig 6 The state set expand function Fig 7 Stateset search tree example ENQUEUEANDMERGE merge child nodes nodes frontier queue having identical cost estimates The stateset expansion function deﬁned Fig 6 The states child associated cost estimates cid9e stored childcid9e The outgoing transitions state parent node ﬁnd successor states The function MAKENODES called line 6 constructs child nodes completed child map Each child node contains states having identical cost estimates However exist nodes cost estimates In addition MAKENODES prune child states implement duplicate elimination A As example Fig 7 shows search tree traversed BSFS algorithm A applied example problem In order reduce number search nodes ENQUEUEANDMERGE BSFS algorithm merge nodes search frontier having identical cost estimates This transforms search tree Directed Acyclic Graph DAG proven Appendix A affect soundness BSFS algorithm The EXTRACTSOLUTION function line 5 uses backward traversal described proof Lemma 7 extract solution It possible completeness BSFS algorithm covers incomplete algorithms greedy bestﬁrst search 52 The FSETA GHSETA algorithms The BSFS algorithm implement variants greedy bestﬁrst search A weighted A uniform cost search beam search To simplify presentation BSFS described treesearch version states repeated times search tree In concrete application BSFS closed 110 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 list expanded states maintained eliminate duplicates The elimination strategy depends application discussed independently algorithm below8 Greedy bestﬁrst search implemented values heuristic function cost estimates sorting nodes frontier ascending order node contains states hcost The cost estimate initial state cid9e0 hs0 transition T s scid3 associated change h δcid9es scid3 hscid3 hs In iteration greedy bestﬁrst search algorithm expand states hcost frontier A strategy eliminating duplicates compromise completeness subtract states closed list set states expand A implemented setting cid9e0 hs0 δcid9es scid3 cs scid3 hscid3 hs cost estimates equal f cost search nodes Again nodes frontier sorted ascending order node f cost expanded iteration If heuristic consistent strategy eliminating duplicates compromise optimality subtract states closed list set states expand However possible general admissible heuristics consider implementation duplicate elimination called FSETA The FSETA algorithm merges nodes frontier associated f cost9 An A implementation duplicate elimination require heuristic function admissible consistent track g hcost separately prune child states reached previously lower gcost To achieve deﬁne cid9e0 0 hs0 δcid9es scid3 cs scid3 hscid3 hs The frontier usual sorted according evaluation function f n gn hn An implementation uses strategy eliminating duplicates called GHSETA Compared FSETA GHSETA merges nodes identical g hcosts Thus nodes frontier f cost different g hcosts In iteration GHSETA expand subset states frontier minimum f cost A number improvements integrated GHSETA First applies usual tie breaking rule nodes identical f cost choosing node hcost Thus situations nodes frontier f n C algorithm focuses search DFS fashion The reason node depth level d situation greater hcost node level d 1 nonnegative transition costs In addition merges nodes frontier space resulting node upperbound u This help focus search situations abundance solutions space requirements frontier nodes grow fast search depth Both GHSETA FSETA easily extended weighted A algorithm described Section 4 Using approach similar Pearl 46 FSETA GHSETA shown optimal given admissible heuristic In particular true trivial admissible heuristic function hn 0 uniform cost search The proofs given Appendix A10 6 BDDbased implementation The motivation deﬁning BSFS algorithm efﬁciently implemented BDDs In section represent sets states implicitly BDDs develop technique called branching partitioning expanding search nodes efﬁciently 61 The BDD representation A BDD decision tree representation Boolean function set linearly ordered arguments The tree reduced removing redundant tests argument variables reusing structure This transforms tree rooted directed acyclic graph makes representation canonical BDDs advantages ﬁrst functions encountered practice symmetric functions polynomial size second graphs BDDs shared efﬁciently manipulated multirooted BDDs shared representation equivalence satisﬁability tests BDDs constant time ﬁnally fourth 16 Boolean operations BDDs x y time space complexity Oxy 9 A disadvantage BDDs exponential size 8 The graphsearch version BSFS reexpands state This strategy compromise optimality applications 9 Another reason studying algorithm expands set states BDDA 10 Notice follows optimality proof given Appendix A FSETA GHSETA complete RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 111 Fig 8 Boolean state encoding example search problem difference depending ordering variables However powerful heuristics exist ﬁnding good variable orderings 44 For detailed introduction BDDs refer reader Bryants original paper 9 books 4458 62 BDDbased state space exploration BDDs originally applied digital circuit veriﬁcation 1 More relevant work presented article later applied model checking range techniques collectively coined symbolic model checking 42 During decade BDDs successfully applied verify large transition systems The essential computation applied symbolic model checking efﬁcient reachability analysis BDDs represent sets states transition relation Search problems solved standard machinery developed symbolic model checking Let D cid4S T ccid5 search domain Since number states S ﬁnite vector n Boolean variables cid9v Bn represent state space In remainder let Z denote set variables cid9z The variables V cid9v called state variables A set states S represented characteristic function Scid9v cid9v Thus BDD represent set states The main efﬁciency BDD representation cardinality represented set directly related size BDD For instance BDD constant function True single node represent states domain matter In addition set operations union intersection complementation simply translate disjunction conjunction negation BDDs In similar way transition relation T represented characteristic function T cid9v cid9v cid3 We refer cid9v cid9v cid3 current state variables respectively To clear Boolean variables cid9v v0 v1 Fig 8 represent states example problem11 The initial state s0 goal state G represented BDDs expressions v0 v1 v0 v1 respectively The transition relation represented BDD equal Boolean function T cid9v cid9v cid3 v0 v1 vcid3 0 v0 v1 vcid3 0 v0 v1 vcid3 0 v0 v1 vcid3 vcid3 1 0 vcid3 v0 v1 vcid3 vcid3 1 1 0 vcid3 1 vcid3 1 The crucial idea BDDbased symbolic search stay BDD level ﬁnding states set states A set states computing image set states S encoded current state variables IMGS cid3 cid9v Scid9v T cid9v cid9v cid3 cid4 cid3 cid9v cid9v The previous states set states called preimage computed similar fashion The operation cid9vcid9v regular variable substitution Existential quantiﬁcation abstract variables expression Let vi variables expression ev0 vn vi ev0 vn ev0 vnviFalse ev0 vnviTrue 11 Readers interested studying structure BDD graphs representing sets states transition relations referred work Edelkamp Reffel 1621 In article consider BDDs abstract data type manipulating Boolean functions focus explaining implicit search performed manipulating functions 112 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 s0 0 reached forwardFrontier0 G forwardFrontieri function FORWARD BREADTHFIRST SEARCHs0cid9v 1 2 3 4 5 6 7 1 forwardFrontieri reached reached forwardFrontieri forwardFrontieri return EXTRACTSOLUTIONforwardFrontier False return failure IMGforwardFrontieri1 reached Existentially quantifying Boolean variable vector involves quantifying variable turn Fig 9 BDDbased forward breadthﬁrst search To illustrate image computation consider ﬁrst step search s0 example problem We Sv0 v1 v0 v1 Thus IMGS cid3 v0 v1 v0 v1 T v0 v1 v cid3 cid3 cid3 v v 0 0 1 v0 v1 v0 v1 v cid5 cid3 1 v cid3 1 cid6 cid3 1v0 v1 cid3 0 v cid3 0 v v cid4cid5 cid6 cid3 1v0 v1 cid3 0 v v expected corresponds state 1 0 0 1 It straightforward implement uninformed blind BDD based search algorithms image preimage computations The forward breadthﬁrst search algorithm shown Fig 9 computes set frontier states image computation The set reached contains explored states prune new frontier previously visited states A solution constructed traversing forward frontiers backward reached goal state initial state This computation lower complexity forward search preimage computation iteration restricted BDD representing single state Backward breadthﬁrst search implemented similar fashion preimage ﬁnd frontier states The algorithms easily combined bidirectional search algorithm In iteration algorithm computes frontier states forward backward direction If set frontier states algorithm returns failure If overlap frontier states reached states opposite direction algorithm extracts returns solution Otherwise search continues A good heuristic deciding direction search simply choose direction previous frontier took time compute When heuristic bidirectional search similar better performance forward backward search transform algorithms frontiers faster compute particular direction12 63 Partitioning A common problem computing image preimage intermediate BDDs tend large compared BDD representing result Another problem transition relation grow large represented single BDD monolithic transition relation In symbolic model checking successful approaches solve problems transition relation partitioning 11 The technique relies observation characterized asynchronous interleaved activity synchronous simultaneous activity Consider model shown Fig 10 During transition state variables V updated Assume subsystem determines value state variables Y cid3 given current value state variables Xi characterized transition relation Picid9xi cid9y cid3 If asynchronous single m subsystems active transition state variables subsystem change value Otherwise synchronous subsystem active transition In asynchronous case total transition relation given mcid7 cid9 cid8 T cid9v cid9v Picid9xi cid9y cid3 i1 v vcid3 Y cid3 cid10 cid3 v 12 Unless ﬁrst step inferior direction dominates total search time However experienced practice RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 113 To ease presentation assume Yi 1m synchronous case partitioning state variables13 The transition relation synchronous case given Fig 10 System model T cid9v cid9v mcid9 i1 Picid9xi cid9y cid3 Thus transition relation represented disjunctive partitioning conjunctive partitioning subre lations The main point partitioning complete transition relation needs computed image preimage computations carried directly subrelations The asynchronous model ﬁts search problems characterized changing small subset state variables transition The image computation asynchronous case IMGS mcid7 cid3 cid9yi Scid9v Picid9xi cid9y cid4 cid3 cid9y cid3 icid9yi i1 A similar approach simplify preimage computation Notice exploit variables ones modiﬁed active subsystem unchanged Thus quantiﬁcation variables necessary This substantial positive effect complexity computation The reason complexity quantiﬁcation BDDs exponential number quantiﬁed variables In practice advantage merge subrelations 50 combine quantiﬁcation disjunction operation single specialized BDD operation For domain shown Fig 8 merge transitions partitions P1 P2 disjunctive partitioning P1 modiﬁes v0 P2 modiﬁes v1 P1 consists transitions 0 0 1 0 0 1 1 1 1 0 0 0 P2 consists transitions 0 0 0 1 1 1 1 0 cid3 v0 v1 v cid3 v0 v1 v cid4 cid3 0 cid4 cid3 1 cid3 0 cid3 0 cid3 1 P1 P2 v0 v1 v v0 v1 v v0 v1 v v0 v1 v cid3 v0 v1 v 0 cid3 1 The synchronous model ﬁts search problems transition simultaneous activity centralized multiagent planning 34 The image computation complicated conjunctive case fact existential quantiﬁcation distribute conjunction However subrelation moved scope existential quantiﬁcation depend variables quantiﬁed This technique referred early quantiﬁcation We cid4 cid3 cid3 cid3 IMGS cid9z1 Scid9v P1cid9x1 cid9y 1 cid11 m m i1 Zi V Again similar approach simplify j i1 Xj 1 cid3 m Pmcid9xm cid9y cid3 cid9zm cid4 cid3 m cid9v cid9v cid11 cid4 cid3 Zi preimage computation 13 It easy extend approaches general case 114 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 As example consider state variables v0 v1 concurrent activities P1v0 vcid3 0 1 An image computation early quantiﬁcation state Scid9v v0 v1 0 P2v1 vcid3 1 v1 vcid3 v0 vcid3 IMGS cid3 cid4 cid3 cid3 cid9v1 cid9v0 Scid9v P1v0 v 0 cid3 cid3 0 P2v1 v cid9v1 cid9v0 v0 v1 v cid3 cid3 cid3 cid3 cid9v 0 v1 v cid9v1 v1 v 1 cid4 cid3 P2v1 v 1 cid4 cid3 cid9v 1 cid4 cid9v cid9v cid3 cid9v cid3 cid9v v0 v1 Thus expected image contains single state value state variables changed False True A large number heuristics developed choosing arranging partitions conjunctive case 4350 The main idea avoid blow intermediate BDDs image preimage computation reducing life span variables Assume variable introduced computation partition variable removed existential quantiﬁcation associated partition j The life span variable j 64 The BDDbased BSFS algorithm The BSFS algorithm represents states search node BDD This lead exponential space savings compared explicit state representation BFS algorithm In addition search nodes similar BDDs share structure multirooted BDD representation This reduce memory consumption substantially However want exponential space saving translate exponential time saving need implicit approach computing expand operation The image computation applied ﬁnd states set states implicitly need way partition states child nodes cost estimates The expand operation carried phases ﬁrst ﬁnds states image computation second splits set states child nodes 59 A direct approach split image computation phases combined We branching partitioning 641 Disjunctive branching partitioning For disjunctive partitioning approach straightforward We simply ensure partition contains transi tions cost estimate change The result called disjunctive branching partitioning Deﬁnition 4 Disjunctive branching partitioning A disjunctive branching partitioning disjunctive partitioning P1cid9x1 cid9ycid3 m subrelation represents set transitions cost estimate change 1 Pmcid9xm cid9ycid3 Notice exist partitions cost estimate change This makes possible optimize disjunctive branching partitionings partition modiﬁes small set states variables So far unresolved problem ﬁnd cost estimate change transition efﬁciently Since cost estimates based heuristic function h involves determining δh transition It intractable compute hs explicitly state number states grows exponentially number state variables domain In practice turns δh action independent state applied This coincidence Heuristics relaxations typically based ignoring interactions actions domain Thus effect action associated particular δh value In worst case necessary encode heuristic function symbolically BDD hcid9b cid9v vector Boolean variables cid9b encodes heuristic value binary state represented cid9v We compute δhs scid3 symbolically δhcid9v cid9v cid3 cid9d hcid9b cid9v hcid9b cid3 cid9v cid9d cid9b cid3 cid9b cid9d encodes value δhs scid3 binary This computation avoids iterating states In addition needs carried prior search For heuristics studied article including classical RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 115 function DISJUNCTIVESTATESETEXPANDcid4Scid9v cid9ecid5 1 2 4 5 6 child emptyMap 1 P cid9ec cid9e δcid9ei childcid9ec childcid9ec IMGi S return MAKENODESchild Fig 11 The state set expand function disjunctive branching partitioning heuristics necessary perform symbolic computation Instead δh value action independent close independent state action applied For domain shown Fig 8 valid disjunctive branching partitioning cid3 cid4 v0 v1 v0 cid3 cid4 v0 v1 v0 cid3 cid4 v0 v1 v1 cid3 cid4 v0 v1 v1 P1 P2 P3 P4 cid3 0 cid3 v0 v1 v v0 v1 v 0 cid3 v0 v1 v 0 cid3 v0 v1 v 1 cid3 v0 v1 v 1 δf1 0 δf2 2 δf3 0 δf4 3 Assume P disjunctive branching partitioning cost estimate change associated subrelation δcid9ei Let IMGiS denote image transitions subrelation IMGiS cid3 cid9yi Scid9v Picid9xi cid9y cid4 cid3 cid9y cid3 icid9yi The STATESETEXPAND function Fig 6 implemented BDDs shown Fig 11 We assume childcid9e False entry exists child key cid9e 642 Conjunctive branching partitioning An efﬁcient implicit node expansion computation possible deﬁne conjunctive partitioning Consider synchronous composition m subsystems Fig 10 Assume cost estimate change joint activity equals sum cost estimate changes activity We represent conjunctive branching partitioning m disjunctive branching partitionings disjunctive branching partitioning represents subrelations activities Deﬁnition 5 Conjunctive branching partitioning A conjunctive branching partitioning P1 Pm set dis junctive branching partitionings Picid9xi cid9ycid3 Rri 1 cid3 cid3 m cid9xi cid9ycid3 cid9xi cid9ycid3 R1 Since subsystems synchronous require sets variables cid9ycid3 cid9xi cid9ycid3 δcid9ej As example Rj 1 cid9ycid3 m form partitioning represent action state variables V cid3 Assume cost estimate change Rj transitions cost estimate change δcid9ej Further let agent multiagent consisting m synchronized agents cid3 j cid11 cid9xi cid9y SUBCOMP m j i1 Xi 1 cid3 m φ cid9zi φcid9v cid9v Rj φ represents intermediate computation result As ordinary conjunctive image computation require cid11 n Zi i1 Zi V The conjunctive stateset expansion function deﬁned shown Fig 12 The outer loop function performs m iterations In iteration value variables cid9yi computed In end map layeri contains sets states subsystem 1 identical cost estimates cid9e False entry exists layeri key cid9e In worst case number child nodes We assume layeri grow exponentially number activities However practice blowup child nodes avoided merging nodes identical cost estimates computation As example consider computing CONJUNCTIVESTATESETEXPANDcid4S 5cid5 set states S prob lem scalar cost estimate e concurrent subsystems transitions changing e 1 0 1 14 Fig 13 shows entries layer0 layer4 As depicted 1 Thus δe1 number entries ﬁnal layer 9 For kind activities considered example number child nodes grows linearly number concurrent activities 0 δe3 1 δe2 116 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 emptyMap layer0 cid9e S layer0 1 m layeri foreach entry cid4φ cid9ei1cid5 layeri1 function CONJUNCTIVESTATESETEXPANDcid4Scid9v cid9e cid5 1 2 3 4 5 6 7 cid9ei cid9ei1 δcid9ej layeri cid9ei layeri cid9ei SUBCOMP j 1 ri emptyMap j φ 8 9 10 child layermcid9vcid3cid9v return MAKENODESchild Fig 12 The STATESETEXPAND function conjunctive branching partitioning Fig 13 Entries layeri CONJUNCTIVESTATESETEXPANDcid4S 5cid5 problem concurrent subsystems transitions asso ciated cost estimate changes 1 0 1 Table 1 The search algorithms compared experimental evaluation GHSETA FSETA BIDIR A BDDA iBDDA The GHSETA algorithm evaluation function f n gn hn The FSETA algorithm evaluation function f n gn hn BDDbased blind breadthﬁrst bidirectional search heuristic choosing search direction described Section 62 Ordinary A duplicate elimination explicit state representation evaluation function f n gn hn15 The BDDA algorithm described 21 An improved version BDDA described 7 Experimental evaluation Even weighted A greedy bestﬁrst search subsumed stateset branching framework experimental evaluation article focuses algorithms performing search similar A There reasons First interested ﬁnding optimal near optimal solutions greedy bestﬁrst search emphasis quality heuristic function efﬁciency search approach Second behavior A extensively studied ﬁnally compare BDDA Readers interested performance stateset branching algorithms weighted A weight settings w 05 Eq 1 referred work Jensen et al 30 We implemented general search engine C BuDDy BDD package14 38 This package major parameters 1 number BDDnodes allocated represent shared BDD n 2 number BDD nodes allocated represent BDDs operator caches implement dynamic programming c The input search engine search problem deﬁned STRIPS PDDL 41 extended version NADL 34 action costs The output search engine solution search algorithms described Table 1 14 We experiments CUDD package 55 obtain signiﬁcantly better results BuDDy package 15 For planning problems state represented set true facts state Since set states ﬁxed number facts uses space linear size set consider explicit state representation RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 117 open cid9f cid9v h cid9f cid9v s0cid9v open cid12 function BDDAs0cid9v 1 2 3 4 5 6 7 fmin mincid9v opencid3 cid9f cid9v GOLEFTopen cid9v mincid9v Gcid9v return fmin opencid3cid3 cid9f cid3 cid9v cid9v mincid9v T cid9v cid9v cid9e hcid9e cid9v cid9ecid3 hcid9ecid3 cid9v cid9f cid3 fmin cid9ecid3 cid9e 1 open cid9f cid9v opencid3 cid9f cid9v opencid3cid3 cid9f cid3 cid9v cid9f cid3 cid9f cid9vcid3 cid9v Fig 14 The BDDA algorithm Table 2 The performance parameters search engine ttotal trel tsearch sol expand Qmax T The total elapsed CPU time search engine Time generate transition relation For BDDA iBDDA includes building symbolic representation heuristic function f formulas Time search extract solution Solution length For BIDIR average size BDDs representing search frontier For FSETA GHSETA average size BDDs search nodes expanded For BDDA iBDDA average size opencid3cid3 Maximal number nodes frontier queue Sum number nodes BDDs representing partitioned transition relation Number iterations algorithm The GHSETA FSETA BIDIR search algorithms implemented described article The ordinary A algorithm manipulates represents states explicitly For FGk DxV yM z N 2 1puzzles specialized algorithms customized state representations developed minimize space consumption For planning problems states encoded explicitly sets facts actions represented usual STRIPS fashion All ordinary A algorithms use strategy GHSETA eliminate duplicates Thus states visited previously lower equal gcosts eliminated The BDDA algorithm implemented described 21 The algorithm presented article shown Fig 14 It solve search problems domains unit transition costs The search frontier represented single BDD open cid9f cid9v This BDD characteristic function set states paired f cost The state encoded usual Boolean vector cid9v f cost encoded binary Boolean vector cid9f Similar FSETA BDDA expands states mincid9v minimum f cost fmin iteration The f cost child states computed arithmetic operations BDD level lines 5 6 The change hcost applying symbolic encoding heuristic function child parent state BDDA able ﬁnd optimal solutions algorithm returns path cost solutions In implementation added function tracing solution backward In domains investigated extraction function low complexity GHSETA FSETA Our implementation BDDA shows improved 1 deﬁning computation opencid3cid3 disjunctive partitioned transition relation instead monolithic transition relation lines 5 6 2 precomputing arithmetic operation end line 6 possible f cost 3 interleaving BDD variables cid9f cid9e cid9ecid3 improve arithmetic BDD operations 4 moving block variables middle BDD variable ordering reduce average distance dependent state variables All improvements considered degree later versions BDDA 16 The improvement actually antagonistic recommendation BDDA inventors locate cid9f variables beginning variable ordering simplify GOLEFT operation However factor speed modiﬁcation The improved algorithm called iBDDA In order factor differences state encodings BDD computations BDDbased algorithms use bit vector representation states variable ordering state variables similar space allocation cache sizes BDD package This necessary dissimilarity mentioned proper ties cause exponential performance difference All algorithms share subcomputations possible redundant unnecessary computations carried particular instantiation algorithm The perfor mance parameters search engine shown Table 2 Time measured seconds The time ttotal trel tsearch spent allocating memory BDD package parsing problem description case PDDL problems 118 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 analyzing problem order compact Boolean state encoding domain analysis method explained Section 74 For domains size state space given number possible assignments Boolean state variables represent domain All experiments ones Pipes World Free Cell main carried Linux 24 PC 500 MHz Pentium III CPU 512 KB L2 cache 512 MB RAM Experiments Pipes World Free Cell domain carried Linux 26 PC 320 GHz Intel Xeon CPU 1024 KB L2 cache 3 GB RAM Time memory indicated Time Mem Time changes experiments The algorithms considered memory start page faulting hard drive Our experiments cover wide range search domains heuristics The ﬁrst domain FGk uses minimum Hamming distance heuristic function It artiﬁcially designed demonstrate GHSETA ex ponentially better performance singlestate A Next consider artiﬁcial domain called DxV yM z puzzle minimum Hamming distance heuristic function The purpose domain scalability stateset branching function dependency objects domain In particular demonstrates u parameter GHSETA focus search subset optimal paths abundance We turn studying wellknown search domains including N 2 1 puzzles STRIPS 22 planning problems international planning competitions 19982004 We start examining 24 35puzzles usual sum Manhattan distances heuristic function The planning domains include Blocks World Logistics Gripper Zeno Travel Pipes World Free Cell The experiments planning domains interesting consider backward search guided approximation HSPr heuristic 8 In ﬁnal experiment example stateset branching conjunctive branching parti tioning We study range channel routing problems VLSI design produced circuits ISCAS85 benchmarks 57 specialized heuristic function 71 FGk This problem modiﬁcation Barret Welds D1S1 problem 4 The problem easiest STRIPS Thus state set facts actions fact triples deﬁning sets transitions In given state S action deﬁned cid4pre add delcid5 applicable pre S resulting state Scid3 S add del The actions A1 1 pre F add G1 del 2 n A1 pre F Gi1 add Gi del 1 n A2 pre add Fi del F Each action assumed unit cost The initial state F goal state Gi k cid3 n Action A1 produces Gi given Gi1 F belong current state In state actions A2 n applicable consume F Thus actions applied A1 actions applied n The purpose A2 This means solution A1 actions decision action apply state nontrivial Without guidance average number states visited order ﬁnd solution grows exponentially search depth 1 A1 1 A2 This domain artiﬁcially designed demonstrate advantage BDDs implicitly represent sets states GHSETA compared representing states explicitly ordinary singlestate A algorithm A state represented vector Boolean state variables G1 Gn F1 Fn F Hence initial state F true state variables false In goal state state variables Gk1 Gn true state variables arbitrary truth value The heuristic value hs state s minimum Hamming distance goal states That number goal state variables Gk1 Gn false state s Since heuristic function gives information guide search ﬁrst k steps expect complexity ordinary A algorithm grow exponentially k RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 119 Fig 15 Total CPU time FGk problems In experiment compare total CPU time number iterations GHSETA singlestate A The FGk problems deﬁned NADL A specialized polytime BDD operation splitting NADL actions transitions cost estimate change GHSETA preprocessing phase No upper bound u GHSETA upper limit branching partitions applied For FGk problems considered n equals 16 This corresponds 33 bits BDD encoding domain The parameters BDD package hand tuned experiment best performance Time 600 seconds The results shown Fig 15 The performance A degrades quickly number unguided steps A gets lost expanding exponentially growing set states The GHSETA algorithm hardly affected lack guidance An analysis unguided frontier layers shows form expressions represented symmetric functions Since functions represented polynomial sized BDDs GHSETA able perform ordinary BDDbased blind forward search unguided frontier layers polynomial time Thus performance difference A GHSETA grows exponentially 72 DxV yM z The DxV yM z domain artiﬁcial puzzle domain dependency objects domain adjusted changing number bits state encoding The domain minimum Hamming distance admissible heuristic It consists set sliding tokens moved corner positions hypercubes In state corner position occupied token Each action moves single token adjacent corner The dimension hypercubes y That hypercubes described y Boolean variables For y 3 hypercubes regular dimensional cubes 8 corners Each corner associated particular assignment y Boolean variables We enumerate corners according value encoded binary Boolean variables Hence action simply ﬂips value Boolean variables There z tokens x moving hypercube The remaining z x tokens moving individual hypercubes This means total z x 1 hypercubes Tokens individual hypercubes interact tokens Thus x parameter adjust dependency tokens changing number bits state encoding The tokens numbered Initially token located corner position number There 2y corners hypercube The goal token number n corner number 2y n 1 Each action assumed unit cost Fig 16 shows initial state D3V 3M 6 120 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 Fig 16 The initial state D3V 3M6 Fig 17 Total CPU time Dx V 4M15 problems When x z tokens moving cube If x 2y 1 corners cube occupied making permutation problem similar 8puzzle The key idea problem x parameter allows dependency tokens adjusted linearly changing number bits encode state In addition demonstrates u parameter GHSETA algorithm focus search abundance optimal paths explore For BDDbased algorithms DxV 4M 15 problems deﬁned NADL Again specialized polytime BDD operation splitting NADL actions transitions cost estimate change applied GHSETA FSETA For problems number bits BDD encoding 60 For GHSETA upper bound node merging 200 u 200 All BDDbased algorithms BDDA utilize disjunctive partitioning upper bound BDDs representing partition 5000 Time 500 seconds For problems BDDbased algorithms use 23 seconds initializing BDD package n 8000000 c 70000016 The results shown Table 3 Fig 17 shows graph total CPU time algorithms All solutions 34 steps long For BDDA iBDDA size BDD representing heuristic function 2014 1235 respectively Both size monolithic partitioned transition relation grows fast dependency tokens The problem efﬁcient way model position occupied The efﬁcient algorithm GHSETA The FSETA algorithm worse performance GHSETA expand states minimum f cost iteration GHSETA focus 16 Notice choose allocate large number nodes small problems The reason mainly care asymptotic performance algorithms Better results obtained small problems adjusting number nodes size problem doubling initially small number nodes time BDD package runs free nodes RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 Table 3 Results Dx V 4M15 problems Algorithm GHSETA FSETA BDDA iBDDA A BIDIR x 1 2 3 4 5 6 7 8 9 10 11 12 1 2 3 4 5 6 7 8 9 10 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 1 2 3 4 5 6 1 2 3 4 5 6 ttotal 27 28 31 32 31 33 39 49 81 295 469 Mem 27 28 31 33 51 96 375 634 4083 Time 36 39 46 55 102 564 2148 3121 Time 40 42 51 62 337 1176 Time 11 11 10 10 09 Time 27 27 32 52 2789 Time trel 03 03 04 05 04 06 10 19 50 143 438 03 03 04 04 05 06 10 20 49 05 05 06 08 13 34 108 527 04 04 05 04 04 05 02 02 03 02 02 tsearch 02 02 03 04 04 04 05 06 08 128 08 02 02 04 06 23 66 342 591 4011 04 06 13 20 62 504 2011 2561 08 11 19 30 304 1139 expand 3073 3073 6710 4417 1948 1399 1284 1159 1320 1461 1073 3073 3073 6710 6710 17786 29765 90467 90467 241754 3143 3143 6780 6780 17856 29835 90537 90537 3073 3073 6710 6710 17786 29765 01 02 07 26 2764 5685 6308 23051 31311 304450 Qmax 33 33 33 72 120 212 322 438 557 5103 336 1 1 1 1 1 1 1 1 1 1884 1882 1770 1750 1626 T 710 1472 4070 10292 20974 45978 104358 232278 705956 1970406 5537402 710 1472 4070 10292 20974 45978 104358 232278 705956 355 772 2128 6484 20050 64959 234757 998346 355 772 2128 6791 25298 84559 355 772 2128 5159 10610 121 34 34 34 34 34 34 34 34 34 373 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 122 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 Fig 18 Goal state 24puzzle subset having u 200 A subexperiment shows GHSETA similar performance FSETA setting u The impact u parameter signiﬁcant problem fairly large values x abundance optimal solutions As seen problem 10 low value u lead search BDDA worse performance FSETA expands exact set states iteration As Section 76 problem complexity computation opencid3cid3 grows fast size BDD representing states expand Surprisingly performance iBDDA worse BDDA This unusual remaining experiments The reason little space saved partitioning transition relation domain This cause computation opencid3cid3 iBDDA deteriorate iterate partitions A performs f n perfect near perfect discriminator soon gets lost keeping track fast growing number states optimal paths It times single step going second 500 seconds The problem BIDIR usual blind BDDbased search algorithms applied hard combinatorial problems BDDs representing search frontiers blow 73 The 24 35puzzle We analyzed nonartiﬁcial domains We aim domains embed search potential signiﬁcant large number search states We turned investigating N 2 1puzzles particular 24puzzle n 5 35puzzle n 6 The domain consists n n board n2 1 numbered tiles blank space A tile adjacent blank space slide space The task reach goal conﬁguration shown 24puzzle Fig 18 For experiments initial state generated performing r random moves goal state17 We assume unit cost transitions use wellknown sum Manhattan distances tiles goal position heuristic function This heuristic function admissible For GHSETA FSETA disjunctive branching partitioning easy compute δh action changing position single tile independent position tiles The algorithms upper bound size BDDs frontier nodes u For BDDbased algorithms problems deﬁned NADL best results obtained having limit partition size Thus BDDA iBDDA BIDIR use monolithic transition relation The number bits BDD encoding 24puzzle 125 The results experiment shown Table 4 For 24puzzle problems BDDbased algorithms spend 36 seconds initializing BDD package n 15000000 c 500000 Time 10000 seconds For BDDA iBDDA size BDD representing heuristic function 33522 18424 respectively For GHSETA FSETA size transition relations 70582 size transition relation BDDA iBDDA 66673 Thus small space saved monolithic transition relation representation However GHSETA FSETA better performance BDDA iBDDA efﬁcient node expansion computation Interestingly BDDA iBDDA spend signiﬁcant time computing heuristic function domain The GHSETA FSETA 17 In steps choosing previous state illegal RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 Table 4 Results 24puzzle problems Algorithm GHSETA FSETA BDDA iBDDA A BIDIR r 140 160 180 200 220 240 260 280 300 320 140 160 180 200 220 240 260 140 160 180 200 220 240 260 140 160 180 200 220 240 260 140 160 180 200 220 240 260 140 160 180 200 220 240 ttotal 288 300 314 437 363 1993 56737 Mem 47727 Mem 297 322 343 501 418 2052 Mem 985 1147 1298 4250 2677 41201 Time 798 853 936 3146 1569 21503 Mem 01 09 06 74 23 871 Mem 681 960 2147 12860 31688 Mem trel 221 222 222 219 222 220 239 209 210 209 210 210 210 210 830 832 829 831 828 831 667 657 657 658 656 659 366 368 368 368 368 tsearch 27 38 53 149 101 1732 56445 474397 47 74 95 253 170 1805 113 274 427 3371 1806 40328 59 118 200 2409 835 20766 279 556 1743 12456 31284 sol expand 26 28 32 36 36 50 56 60 26 28 32 36 36 50 26 28 32 36 36 50 26 28 32 36 36 50 26 28 32 36 36 50 26 28 32 36 36 1875 2132 2702 7862 4111 20555 106412 97613 6699 10516 12070 52760 31176 182433 6769 10586 12140 52830 31246 182503 6699 10516 12070 52760 31176 182433 343652 553884 1061660 3594880 4213070 Qmax 23 24 28 31 31 44 48 53 1 1 1 1 1 1 300 725 1470 15927 5228 159231 123 93 175 253 575 490 1543 2576 2705 42 57 69 93 88 156 42 57 69 93 88 156 42 57 69 93 88 156 221 546 1106 12539 4147 133418 26 28 32 36 36 algorithms scale better A BIDIR A good performance substantial overhead computing transition relation ﬁnding actions apply However explicit representation states runs memory solution depths approximately 50 For BIDIR problem usual BDDs representing search frontiers blow Fig 19 shows graph total CPU time 24 35puzzle Again time 10000 seconds 124 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 Fig 19 Total CPU time 24 35puzzle problems 74 Planning domains In section consider planning problems STRIPS track international planning compe titions 19982004 The problems deﬁned STRIPS PDDL An optimal solution solution minimal length assume unit cost actions A Boolean representation STRIPS domain trivial single Boolean state variable fact This encoding normally inefﬁcient redundant representation static facts facts mutually exclusive unreachable In order generate compact encoding analyze STRIPS problem step process 1 Find static facts subtracting facts mentioned add delete sets actions facts initial state RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 125 2 Approximate set reachable facts initial state performing relaxed reachability analysis ignoring delete set actions 3 Find sets singlevalued predicates 25 inductive proofs reachable facts If set predicates mutual exclusive restricting particular argument object set predicates said singlevalued Consider instance domain packages inside truck inP T locations atP L Then singlevalued respect ﬁrst argument The reachability analysis step 2 implemented based approach described work Edelkamp Helmert 20 It fast problems considered article problems 004 seconds The algorithm proceeds breadthﬁrst manner fact f assigned depth df reached Similar MIPS planning 16 use measure approximate HSPr heuristic 8 HSPr efﬁcient nonadmissible heuristic backward search For state given set facts S approximation HSPr given hS cid12 df f S A branching partitioning heuristic efﬁcient generate given action pre add del leading S Scid3 S add del satisﬁes del pre add pre These requirements natural satisﬁed planning domains considered article Due straints δh hS cid3 hS hadd S hdel cid12 df cid12 df f addS f del Thus action partitioned 2add sets transitions different δhcost The HSPr heuristic applied backward search regression search18 This affects computing hcost goal state Consider planning problem k facts f1 fk goal description G f1 In regression search G represents single state hG df1 In backward search hand G represents 2k1 states principle different hcost To avoid problem extended goal descriptions planning problems correspond single states This increase solution length problems In addition makes backward exploration similar forward exploration considers valid states Thus extending goal description avoid common deterioration BDDbased search applied backward exploration unstructured space consisting mixture valid invalid states Since HSPr heuristic states studied domains overestimates true distance initial state manually scaled accurate possible The reason comparison optimal BIDIR algorithm fair possible If heuristic overestimates A algorithms fast poor solutions If heuristic underestimates A algorithms optimal solutions overly slow However despite adjustments complexity difference suboptimal optimal search makes direct comparison BIDIR A algorithms impossible inadmissible heuristic like HSPr 741 Blocks world The Blocks World classical planning domain It consists set cubic blocks sitting table A robot arm stack unstack blocks initial conﬁguration goal conﬁguration The problems consider 18 Using BDDs regression search interesting direction future work 126 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 Table 5 Results Blocks World problems Algorithm GHSETA FSETA BDDA iBDDA A BIDIR p 4 5 6 7 8 9 10 11 12 13 14 15 4 5 6 7 8 9 10 11 12 13 14 15 4 5 6 7 8 9 10 4 5 6 7 8 9 10 4 5 6 7 8 9 10 4 5 6 7 8 9 10 ttotal 26 27 26 31 41 170 1162 1335 148 Time 1121 Time 25 27 27 32 39 300 2170 2598 392 Time 2743 Time 33 36 36 49 60 1008 Time 27 28 29 37 62 1137 Time 00 02 04 13 319 2339 Time 26 26 27 36 97 1468 Time trel 00 01 01 02 03 04 06 07 10 17 00 01 01 02 03 04 06 08 10 17 00 02 02 05 05 11 00 01 01 03 04 06 00 01 01 02 03 04 tsearch 00 01 01 04 13 141 1131 1302 112 1078 00 01 01 05 11 271 2138 2564 357 2700 01 02 02 12 22 965 00 01 01 07 32 1103 00 02 04 12 316 2329 00 00 01 08 68 1439 sol expand 6 12 12 20 18 32 38 32 34 38 6 12 12 20 18 32 38 32 34 38 6 12 12 20 18 32 6 12 12 20 18 32 6 12 12 20 18 32 6 12 12 20 18 30 195 334 577 538 5404 3318 7449 14049 4103 10678 298 687 1268 1219 13288 9355 25944 47560 8170 15551 378 767 1348 1299 13368 9435 298 687 1268 1219 13288 9355 1245 2283 4388 19313 111818 750409 Qmax 1 11 9 48 12 94 111 91 120 125 1 4 2 8 2 10 12 9 13 13 8 62 115 287 7787 38221 6 31 30 152 72 991 2309 1200 557 1061 6 23 20 92 35 610 1098 671 860 1462 6 23 20 92 35 610 6 23 20 92 35 610 15 70 102 287 5252 31831 6 12 12 20 18 30 T 706 1346 2608 4685 7475 8717 11392 16122 18734 30707 706 1346 2608 4685 7475 8717 11392 16122 18734 30707 706 1365 2334 4669 6959 9923 706 1365 2334 4669 7123 10361 706 1423 2567 5263 8157 11443 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 127 Fig 20 Total CPU time Blocks World Gripper problems untyped STRIPS track AIPS 2000 planning competition The number bits BDD encoding range 17 80 The HSPr heuristic scaled factor 04 The GHSETA FSETA algorithms upper bound size BDDs nodes frontier u For BDDbased algorithms partition limit 5000 For problem algorithms spend 25 seconds initializing BDD package n 8000000 c 800000 Time 500 seconds experiments The results shown Table 5 The graph Fig 20 shows total CPU time algorithms For BDDA iBDDA size BDD representing heuristic function range 8 1908 8 1000 respectively The GHSETA FSETA algorithms signiﬁcantly better performance algorithms As usual BDDA iBDDA suffer inefﬁcient expansion computation frontier BDDs blow BIDIR The general A algorithm STRIPS planning problems domaintuned previous A implementations In particular check 128 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 precondition actions iteration order ﬁnd ones applicable This addition explicit state representation explain poor performance A 742 Gripper The Gripper problems ﬁrst round STRIPS track AIPS 1998 planning competition The domain consists robot grippers rooms connected door Initially number balls located ﬁrst room goal room The number bits BDD encoding range 12 88 The GHSETA FSETA algorithms upper bound size BDDs frontier nodes u For BDDbased algorithms partition limit spend 08 seconds initializing BDD package n 2000000 c 400000 All algorithms generate optimal solutions The results shown Table 6 The graph Fig 20 shows total CPU time algorithms Interestingly BIDIR fastest algorithm domain BDDs representing search frontier grows moderately search The GHSETA FSETA algorithms good performance BDDA iBDDA particularly bad performance domain The problem BDDs frontier nodes grow large harder problems 743 Logistics The Logistics domain considers moving packages trucks locations city airplanes cities The problems considered STRIPS track AIPS 2000 planning competition The number bits BDD encoding range 21 86 The GHSETA FSETA algorithms upper bound size BDDs frontier nodes u For BDDbased algorithms partition limit 5000 spend 20 seconds initializing BDD package n 8000000 c 400000 Due systematic estimation HSPr heuristic scaled factor 15 The graph Fig 21 shows total CPU time algorithms Only GHSETA FSETA able solve large instances problem The BDD encoding based singlevalued predicates particularly efﬁcient domain Moreover HSPr heuristic strong gives A algorithms edge BIDIR 744 Zeno Travel Zeno Travel STRIPS track AIPS 2002 planning competition It involves transporting people planes different modes movement fuelefﬁcient wasteful The number bits BDD encoding range 9 165 The GHSETA FSETA algorithms upper bound size BDDs frontier nodes u For BDDbased algorithms partition limit 4000 About 27 seconds spent initializing BDD package n 10000000 c 700000 The graph Fig 21 shows total CPU time algorithms The results fairly similar results Logistics problems advantage GHSETA FSETA signiﬁcant 745 Pipes World The task Pipes World domain transport oil derivative products pipeline Since adding product pipeline affects products pipeline structure domain different structure Logistics Zeno Travel domain If pipe hold product actions model state change pipeline The ﬁrst adds product sender end pipe second removes product pushed receiver end pipe The problems consider typed STRIPS track International Planning Competition 2004 The problems changed manually untyped version The number bits BDD encoding range 62 118 The HSPr heuristic scaled factor 07 systematic estimation For GHSETA upper bound size BDDs nodes frontier u For BDDbased algorithms partition limit 10000 small problems 20000 large problems The number nodes allocated BDD package n range 2M 107M cache size c adjusted approximately 10 number nodes Time 3600 seconds experiments The results shown Table 719 The graph Fig 22 shows total CPU time algorithms For BDDA 19 The Qmax data gathered A Pipes World Free Cell domain Moreover time limitations investigated performance FSETA domains RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 Table 6 Results Gripper problems Algorithm GHSETA FSETA BDDA iBDDA A BIDIR p 2 4 6 8 10 12 14 16 18 20 2 4 6 8 10 12 14 16 18 20 2 4 6 8 10 12 14 16 18 20 2 4 6 8 10 12 14 16 18 20 2 4 6 2 4 6 8 10 12 14 16 18 20 ttotal 09 10 13 15 18 23 30 36 45 57 10 10 12 16 20 25 31 37 50 57 18 24 34 61 169 407 817 1493 2404 3911 12 16 23 36 62 122 235 448 761 1209 39 4229 Time 09 10 12 14 17 22 26 32 38 45 trel 01 01 02 03 04 05 07 09 11 14 01 01 02 03 04 06 08 09 12 15 01 02 03 06 09 12 16 22 31 39 01 01 03 04 06 09 11 16 22 27 01 01 02 03 04 05 07 09 12 15 tsearch 002 008 027 034 054 088 133 178 246 337 01 01 02 03 06 10 14 19 29 32 02 06 15 40 144 379 785 1454 2355 3855 01 04 10 22 45 92 213 421 724 1167 39 4223 00 01 01 03 05 08 10 13 17 21 expand 688 1689 3149 5048 7381 10147 13345 16975 21037 25531 954 2312 4239 6734 9799 13433 17635 22407 27747 33656 1034 2392 4319 6814 9879 13513 17715 22487 27827 33736 954 2312 4239 6734 9799 13433 17635 22407 27747 33656 1254 2909 5897 9582 14043 16110 20256 32656 40744 49449 Qmax 5 6 6 6 6 6 6 6 6 6 1 1 1 1 1 1 1 1 1 1 21 43 65 87 109 131 153 175 197 219 17 29 41 53 65 77 89 101 113 125 17 29 41 53 65 77 89 101 113 125 17 29 41 53 65 77 89 101 113 125 698 26434 1286 85468 17 29 41 53 65 77 89 101 113 125 129 T 594 1002 1410 1818 2226 2634 3042 3450 3858 4266 594 1002 1410 1818 2226 2634 3042 3450 3858 4266 323 539 755 971 1187 1403 1619 1835 2051 2267 323 539 755 971 1187 1403 1619 1835 2051 2267 323 539 755 971 1187 1403 1619 1835 2051 2267 130 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 Fig 21 Total CPU time Logistics Zeno Travel problems iBDDA size BDD representing heuristic function range 2244 18577 988 9743 respectively The performance GHSETA BIDIR fairly similar performance BDDA iBDDA A substantially lower Looking closer results GHSETA A BIDIR observe GHSETA A use considerably longer time problem 10 compared problem 9 opposite true BIDIR Since BIDIR GHSETA represent states way results indicate GHSETA traverse larger fraction state space BIDIR problem 10 Thus HSPr heuristic somewhat weak domain guiding exploration right direction problem 9 problem 10 Interestingly performance A better GHSETA problem 8 An inspection Table 7 shows algorithms spend little time search problem GHSETA spends considerable time constructing BDD representation transition relation Thus example situation search problem small BDDbased search pay RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 131 Fig 22 Total CPU time Pipes World Free Cell problems 746 Free Cell The Free Cell domain solitaire game shipped Windows The cards distributed face 8 columns The goal arrange cards order home cells In addition home cells free cells A legal action card column free cell home cell holding predecessor matching suit free cell column column holding successors opposite color The problems consider untyped STRIPS track International Planning Competition 2002 The number bits BDD encoding range 58 199 The HSPr heuristic scaled factor 06 systematic estimation The GHSETA algorithm upper bound size BDDs nodes frontier u For BDDbased algorithms partition limit 10000 small problems 20000 large problems The number nodes allocated BDD package n range 2M 107M cache size c adjusted approximately 10 number nodes Time 3600 seconds Qmax 31 61 60 56 54 111 127 132 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 Table 7 Results Pipes World problems Algorithm GHSETA BDDA iBDDA A BIDIR p 4 5 6 7 8 9 10 4 5 6 7 8 9 10 4 5 6 7 8 9 10 4 5 6 7 8 9 10 4 5 6 7 8 9 10 ttotal 20 45 48 79 147 799 1683 33 113 179 503 242 Time Time 24 73 75 138 175 11360 26968 03 60 178 137 11 2077 5555 20 70 47 70 148 1663 395 trel 12 22 16 28 48 90 35 17 31 29 53 90 11 19 17 31 48 82 37 10 18 15 26 37 65 31 tsearch 02 12 17 30 04 612 1611 05 66 132 426 54 03 34 38 75 12 11129 26878 02 38 17 22 16 1497 327 sol expand 8 13 20 16 14 21 30 8 13 20 16 14 8 13 20 16 14 21 30 8 13 20 16 14 21 30 8 13 20 16 14 21 30 1859 3891 3346 4579 1711 13563 7412 2043 5993 4142 6836 4537 1981 5933 4062 6756 4488 21058 9020 26469 121465 72364 108606 98416 2604280 486674 13 92 245 203 63 680 4427 14 65 457 394 54 14 65 457 394 54 4384 52010 69 1259 4278 2651 139 20881 104221 8 13 20 16 14 21 30 T 38123 57992 47297 74988 116758 195345 85022 21020 31406 25166 40395 60901 39536 62578 37335 61568 80153 164901 69929 39512 61000 37299 61001 71708 138504 68261 experiments The results shown Table 8 The graph Fig 22 shows total CPU time algorithms For BDDA iBDDA size BDD representing heuristic function range 553 4427 366 2060 respectively Again observe BDDA iBDDA substantially lower performance GHSETA In domain A outperforms GHSETA The reason Boolean encoding domain weak The domain contain singlevalued predicates forces grounded predicate represented Boolean variable Thus sophisticated planning domain analysis experimental evaluation necessary Whether efﬁcient Boolean encoding exists domain scope article It observed deleting home predicate card home cell moving new card cell predicates incell bottomcol home singlevalued ﬁrst argument The encoding predicate similar Blocks World The reduction efﬁcient Blocks World In Blocks World block block Free Cell card cards initially successors opposite color For problem 6 number bits BDD encoding reduced 199 125 performance BDDbased algorithms improved signiﬁcantly RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 133 Qmax 24 52 61 126 147 trel 07 38 85 129 348 12 59 156 07 36 57 07 36 56 77 tsearch 01 45 55 2821 1332 08 622 910 03 239 321 04 145 110 4229 2127 9269 01 28 311 4024 sol expand 8 14 18 29 30 8 14 18 8 14 18 8 14 18 29 30 35 8 14 18 26 2213 4185 4167 11165 10461 5188 30227 18719 5108 30147 18639 16871 222521 927944 3892760 19 210 193 1816 885 16 60 125 16 60 125 138 2193 1254 37655 12190 35920 8 14 18 26 T 13192 30048 62651 127854 215259 3735 8933 17153 3735 8933 26009 3735 8933 25136 58746 Table 8 Results Free Cell problems Algorithm GHSETA BDDA iBDDA A BIDIR p 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6 ttotal 11 95 167 3028 1769 Mem 28 701 1104 Mem Mem Mem 16 302 513 Mem Mem Mem 05 147 112 4313 2141 9392 11 77 397 4187 Mem Mem Fig 23 A solution channel routing problem 5 columns 3 tracks 2 nets labeled I II The pins numbered according net belong 75 Channel routing Channel routing fundamental subtask layout process VLSIdesign It NPcomplete problem makes exact solutions hard produce Channel routing considers connecting pins small gaps channels cells chip In classical formulation layers wires wires horizontal tracks wires vertical columns In order change direction connection layers These connections called vias Pins channel A set pins connected called net The problem connect pins optimally according cost function The 134 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 Table 9 Results ISCAS85 channel routing problems A problem ctn identiﬁed number columns c tracks t nets n Circuit Add C432 ctn 38310 47527 41312 46720 2546 83433 891158 101957 99858 971063 101753 95948 951048 84523 ttotal 02 08 02 50 01 04 Mem 2861 340 2950 157 2238 Time 32 trel 01 07 01 35 00 02 615 135 997 115 589 07 tsearch 02 01 01 15 01 02 2066 205 1953 42 1649 25 Qmax 1 24 1 56 1 0 135 59 129 90 59 0 40 46 42 89 30 93 113 448 109 101 399 92 cost function studied equals total number vias routing Fig 23 shows example optimal solution small channel routing problem The cost solution 4 One way apply search solve channel routing problem route nets left right A state search column paired routing nets left column A transition search routing live nets single column A usual way ﬁnd optimal solutions An admissible heuristic function cost function sum cost routing remaining nets optimally ignoring interactions nets We implemented specialized search engine solve channel routing problems GHSETA 31 The important point application GHSETA utilizes conjunctive branching partitioning instead disjunctive branching partitioning experiments reported article This possible transition regarded joint result routing net turn The performance GHSETA evaluated problems produced ISCAS85 circuits 57 For problems parameters BDD package hand tuned best performance There upper bound size BDDs frontier nodes u limit size partitions Time 600 seconds Table 9 shows results The performance GHSETA similar previous applications BDDs channel routing 54 57 However contrast previous approaches GHSETA able ﬁnd optimal solutions 76 Additional comparative experiments The major challenge BDDA arithmetic computations BDD level scales poorly size BDD representing set states expand lines 5 6 Fig 14 This hypothesis empirically veriﬁed measuring CPU time FSETA iBDDA expand set states Recall FSETA iBDDA expand exact set states iteration Any performance difference solely caused expansion techniques The results shown Fig 24 The reported CPU time average 15puzzle 50 100 200 random steps Logistics problem 4 9 Blocks World problem 4 9 Gripper problem 1 20 DxV 4M 15 x varying 1 6 For small frontier BDDs iBDDA slightly faster FSETA This probably small frontier BDDs mainly generated easy problems monolithic transition relation iBDDA efﬁcient partitioned transition relation FSETA However large frontier BDDs iBDDA needs expansion time FSETA 77 Stateset branching versus singlestate heuristic search Heuristic search trivial heuristic function informative In case stateset branching worse performance singlestate heuristic search overhead computing transition relation We seen example problem 8 Pipes World Moreover use inefﬁcient Boolean encoding domain performance stateset branching deteriorate worse singlestate heuristic search RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 135 Fig 24 Node expansion times FSETA BDDA seen Free Cell domain When issues present stateset branching outperformed singlestate heuristic search experiments In order control experimental setting particular use heuristics algorithms handcoded singlestate A implementations Thus stateoftheart implementations single state A experiments stateset branching outperform stateoftheart implementations singlestate A Only direct comparison verify On hand specialized versions singlestate A advantage domain structure developed FGk DxV yM z N 2 1puzzles The state representation singlestate A domains level sophistication node representation BuDDy package For reason consider comparison domains fair For planning domains hand general representation states sets facts improved representation techniques planning com munity aware This reduce memory consumption singlestate A factor However matter explicit state representation space consumption set states linear size set Another issue comparing stateset branching singlestate heuristic search heuristic function chosen freely stateset branching singlestate heuristic search As described earlier heuristics applied experimental evaluation represented compactly branching partitioning This probably case additive heuristics like sum Manhattan distances HSPr It clear compact branching partitionings exist sophisticated heuristics combinatorial nature cover special cases irregular way Indeed recent study disjunctive branching partitioning maxpair heuristic 28 turned prohibitively large domains 32 We believe reason artiﬁcial combinatorial nature maxpair heuristic The size branching partitioning dramatically reduced making function hcost search node expand Developing kind representation techniques complex heuristics interesting direction future work 78 Stateset branching versus blind BDDbased search Blind BDDbased search successfully applied symbolic model checking circuit veriﬁcation It shown problems encountered practice tractable BDDs 58 The classical search problems studied AI harder longer solutions problems considered formal veriﬁcation When applying blind BDDbased search problems BDDs represent search 136 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 frontier grow exponentially The experimental evaluation stateset branching shows problem substantially reduced efﬁciently splitting search frontier according heuristic evaluation states 79 Stateset branching versus BDDA Stateset branching implementations A GHSETA FSETA fundamentally different BDDA BDDA imitates usual explicit application heuristic function symbolic computation It reasonable expect symbolic representation practical heuristic functions large However seldom case heuristic functions studied article The major challenge BDDA arithmetic computations BDD level scales poorly size BDD representing set states expand lines 5 6 Fig 14 Another limitation BDDA inﬂexibility BDDbased arithmetic It makes hard extend BDDA efﬁciently general evaluation functions arbitrary transitions costs 8 Conclusion In article presented framework called stateset branching integrating symbolic heuristic search The key component framework new BDD technique called branching partitioning allows sets states expanded implicitly sorted according cost estimates step Stateset branching general framework It applies heuristic function search node evaluation function transition cost function deﬁned ﬁnite domain An extensive experimental evaluation stateset branching proves powerful approach Except case weak Boolean encoding stateset branching outperforms singlestate heuristic search In addition improve complexity singlestate search exponentially best known AI search problems orders magnitude faster singlestate heuristic search blind BDDbased search efﬁcient current BDDbased A implementation BDDA It important direction future work develop techniques representing branching partitionings com pactly sophisticated heuristics combinatorial nature cover special cases irregular way Other directions future work include applying stateset branching regression search linear space heuris tic search algorithms IDA Acknowledgements We thank Robert Punkunus initial work efﬁcient Boolean encoding PDDL domains We wish thank Kolja Sulimma providing channel routing benchmark problems Finally thank anonymous reviewers valuable comments suggestions Appendix A Lemma 6 The search structure build BSFS algorithm DAG node cid4Scid3 cid9ecid3cid5 different root node cid4s0 cid9e0cid5 set predecessor nodes For state scid3 Scid3 node exists predecessor cid4S cid9ecid5 state s S T s scid3 cid9ecid3 cid9e δcid9es scid3 Proof By induction number loop iterations We search structure ﬁrst iteration DAG consisting root node cid4s0 cid9e0cid5 For inductive step assume search structure DAG desired properties n iterations loop Fig 5 If algorithm iteration terminates line 3 5 search structure unchanged DAG required format Assume algorithm terminate cid4S cid9ecid5 node removed frontier The node expanded forming child nodes STATESETEXPAND function line 6 According deﬁnition function state scid3 Scid3 child node cid4Scid3 cid9ecid3cid5 state s S cid4S cid9ecid5 T s scid3 cid9ecid3 cid9e δcid9es scid3 Thus cid4S cid9ecid5 valid predecessor states child nodes Furthermore child nodes new nodes cycles created search structure remains DAG If child node merged old node enqueued frontier resulting search structure DAG nodes frontier unexpanded RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 137 successor nodes cause cycles In addition state resulting node obviously required predecessor nodes cid2 Lemma 7 For state scid3 Scid3 node cid4Scid3 cid9ecid3cid5 ﬁnite search structure BSFS algorithm exists cid13 path π s0 sn D sn scid3 cid9e cid9e0 n1 i0 δcid9esi si1 Proof We construct π tracing edges backwards search structure Let b0 scid3 According Lemma 6 exists predecessor cid4S cid9ecid5 cid4Scid3 cid9ecid3cid5 state b1 S T b1 b0 cid9ecid3 cid9e δcid9eb1 b0 Continuing backward traversal b1 eventually terminate search structure ﬁnite acyclic Moreover traversal terminate root node node predecessors Assume backward traversal terminates n iterations Then π bn b1 cid2 Theorem 8 The BSFS algorithm sound Proof Assume algorithm returns path π s0 sn cost estimates cid9e Since sn G follows Lemma 7 deﬁnition EXTRACTSOLUTION π solution search problem associated cost estimates cid9e cid2 Lemma 9 Assume FSETA GHSETA apply admissible heuristic π s0 sn optimal solution time FSETA GHSETA terminates exists frontier node cid4S cid9ecid5 state si S cid9e cid3 C s0 si search path associated si Proof A node cid4S cid9ecid5 containing si associated search path s0 si frontier node taining s0 initially inserted frontier FSETA GHSETA terminates node containing goal state sn removed frontier We cid9e costs0 si hsi The path s0 si preﬁx optimal solution costs0 si minimum cost reaching si Since heuristic function admissible hsi cid3 hsi gives cid9e cid3 C cid2 Theorem 10 Given admissible heuristic function FSETA GHSETA optimal Proof Suppose FSETA GHSETA terminates solution derived frontier node cid9e C Since node frontier queue C f n n frontier However contradicts Lemma 9 states optimal path node frontier time prior termination cid9e cid3 C cid2 References 1 SB Akers Binary decision diagrams IEEE Transactions Computers C27 6 1978 509516 2 F Bacchus AIPS00 Planning Competition The Fifth International Conference Artiﬁcial Intelligence Planning Scheduling Systems AI Magazine 22 3 2001 4756 3 R Bahar E Frohm C Gaona E Hachtel A Macii A Pardo F Somenzi Algebraic decision diagrams applications IEEEACM International Conference CAD 1993 pp 188191 4 A Barrett DS Weld Partialorder planning Evaluating possible efﬁciency gains Artiﬁcial Intelligence 67 1 1994 71112 5 P Bertoli A Cimatti M Roveri Conditional planning partial observability heuristicsymbolic search belief space Proceedings 6th European Conference Planning ECP01 2001 pp 379384 6 P Bertoli M Pistore Planning extended goals partial observability Proceedings 14th International Conference Auto mated Planning Scheduling ICAPS04 2004 pp 270278 7 R Bloem K Ravi F Somenzi Symbolic guided search CTL model checking Proceedings 37th Design Automation Conference DAC00 ACM 2000 pp 2934 8 B Bonet H Geffner Planning heuristic search New results Proceedings 5th European Conference Planning ECP99 Springer 1999 pp 360372 9 RE Bryant Graphbased algorithms boolean function manipulation IEEE Transactions Computers 8 1986 677691 10 D Bryce DE Smith Planning graph heuristics belief space search Journal Artiﬁcial Intelligence Research 26 2006 3599 138 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 11 JR Burch EM Clarke DE Long Symbolic model checking partitioned transition relations International Conference Very Large Scale Integration NorthHolland 1991 pp 4958 12 A Cimatti E Giunchiglia F Giunchiglia P Traverso Planning model checking A decision procedure AR Proceedings 4th European Conference Planning ECP97 Springer 1997 pp 130142 13 A Cimatti M Pistore M Roveri P Traverso Weak strong strong cyclic planning symbolic model checking Artiﬁcial Intelli gence 147 12 2003 14 A Cimatti M Roveri Conformant planning symbolic model checking Journal Artiﬁcial Intelligence Research 13 2000 305338 15 E Clarke O Grumberg D Peled Model Checking MIT Press 1999 16 S Edelkamp Directed symbolic exploration AIplanning AAAI Spring Symposium ModelBased Validation Intelligence 2001 pp 8492 17 S Edelkamp Symbolic exploration twoplayer games Preliminary results Proceedings Sixth International Conference AI Planning Scheduling AIPS02 Workshop Model Checking 2002 18 S Edelkamp Symbolic pattern databases heuristic search planning Proceedings Sixth International Conference AI Planning Scheduling AIPS02 2002 pp 274283 19 S Edelkamp External symbolic heuristic search pattern databases Proceedings 15th International Conference AI Planning Scheduling ICAPS05 2005 pp 5160 20 S Edelkamp M Helmert Exhibiting knowledge planning problems minimize state encoding length Proceedings 6th European Conference Planning ECP99 1999 pp 135147 21 S Edelkamp F Reffel OBDDs heuristic search Proceedings 22nd Annual German Conference Advances Artiﬁcial Intelligence KI98 Springer 1998 pp 8192 22 RE Fikes NJ Nilsson STRIPS A new approach application theorem proving problem solving Artiﬁcial Intelligence 2 1971 189208 23 MP Fourman Propositional planning Proceedings AIPS00 Workshop ModelTheoretic Approaches Planning 2000 pp 1017 24 M Fox D Long PDDL21 An extension PDDL expressing temporal planning domains Journal Artiﬁcial Intelligence Research JAIR 20 2003 61124 25 A Gerevini L Schubert Inferring state constraints domainindependent planning Proceedings 15th National Conference Artiﬁcial Intelligence AAAI98 1998 pp 905912 26 E Hansen R Zhou Z Feng Symbolic heuristic search decision diagrams Symposium Abstraction Reformulation Approx imation SARA02 2002 27 PE Hart NJ Nilsson B Raphael A formal basis heuristic determination minimum path cost IEEE Transactions SSC 100 4 1968 28 P Haslum H Geffner Admissible heuristics optimal planning Proceedings 5th International Conference Artiﬁcial Intelli gence Planning System AIPS00 AAAI Press 2000 pp 140149 29 J Hoffmann S Edelkamp The deterministic IPC4 An overview Journal Artiﬁcial Intelligence Research JAIR 24 2005 519 579 30 RM Jensen RE Bryant MM Veloso SetA An efﬁcient BDDbased heuristic search algorithm Proceedings 18th National Confer ence Artiﬁcial Intelligence AAAI02 2002 pp 668673 31 RM Jensen RE Bryant MM Veloso SetA applied channel routing Technical report Computer Science Department Carnegie Mellon University 2002 CMUCS02172 32 RM Jensen EA Hansen S Richards R Zhou Memoryefﬁcient symbolic heuristic search Proceedings 16th International Conference Automated Planning Scheduling ICAPS06 2006 pp 304313 33 RM Jensen MM Veloso OBDDbased deterministic planning UMOP planning framework Proceedings AIPS00 Workshop ModelTheoretic Approaches Planning 2000 pp 2631 34 RM Jensen MM Veloso OBDDbased universal planning synchronized agents nondeterministic domains Journal Artiﬁcial Intelligence Research 13 2000 189226 35 RM Jensen MM Veloso M Bowling Optimistic strong cyclic adversarial planning Proceedings 6th European Conference Planning ECP01 2001 pp 265276 36 RM Jensen MM Veloso RE Bryant Fault tolerant planning Toward probabilistic uncertainty models symbolic nondeterministic planning Proceedings 14th International Conference Automated Planning Scheduling ICAPS04 2004 pp 335344 37 U Kuter D Nau M Pistore P Traverso A hierarchical tasknetwork planner based symbolic model checking Proceedings 15th International Conference Automated Planning Scheduling ICAPS05 2005 pp 300309 38 J LindNielsen BuDDyA Binary Decision Diagram Package Technical Report ITTR 1999028 Institute Information Technology Technical University Denmark 1999 httpsourceforgenetprojectsbuddy 39 D Long M Fox The AIPS02 planning competition httpplanningcisstrathacukcompetition 2002 40 D Long HA Kautz B Selman B Bonet H Geffner J Koehler M Brenner J Hoffmann F Rittinger CR Anderson DS Weld DE Smith M Fox The AIPS98 planning competition AI Magazine 21 2 2000 1333 41 D McDermott M Ghallab A Howe C Knoblock A Ram M Veloso D Weld D Wilkins PDDLthe planning domain deﬁnition language Technical report Yale Center Computational Vision Control 1998 42 KL McMillan Symbolic Model Checking Kluwer Academic Publ 1993 43 C Meinel C Stangier A new partitioning scheme improvement image computation Proceedings ASPDAC2001 2001 pp 97 102 RM Jensen et al Artiﬁcial Intelligence 172 2008 103139 139 44 C Meinel T Theobald Algorithms Data Structures VLSI Design Springer 1998 45 A Nymeyer K Qian Heuristic search algorithms based symbolic data structures Proceedings 16th Australian Conference Artiﬁcial Intelligence Lecture Notes Computer Science vol 2903 Springer 2003 pp 966979 46 J Pearl Heuristics Intelligent Search Strategies Computer Problem Solving AddisonWesley 1984 47 M Pistore R Bettin P Traverso Symbolic techniques planning extended goals nondeterministic domains Proceedings 6th European Conference Planning ECP01 2001 pp 253264 48 I Pohl First results effect error heuristic search Machine Intelligence 5 1970 127140 49 K Qian A Nymeyer Guided invariant model checking based abstraction symbolic pattern databases Proceedings 10th International Conference Tools Algorithms Construction Analysis Systems TACAS04 2004 pp 497511 50 RK Ranjan A Aziz RK Brayton B Plessier C Pixley Efﬁcient BDD algorithms FSM synthesis veriﬁcation IEEEACM Proceedings International Workshop Logic Synthesis 1995 51 F Reffel S Edelkamp Error detection directed symbolic model checking Proceedings World Congress Formal Methods FM Springer 1999 pp 195211 52 D Sawitzki Experimental studies symbolic shortestpath algorithms Proceedings 3rd International Workshop Experimental Efﬁcient Algorithms WEA04 2004 pp 482498 53 D Sawitzki A symbolic approach allpairs shortestpaths problem Proceedings 30th International Workshop Graph Theoretic Concepts Computer Science WG04 2004 pp 154168 54 F Schmiedle R Drechsler B Becker Exact channel routing symbolic representation Proceedings IEEE International Symposium Circuits Systems ISCAS99 1999 55 F Somenzi CUDD Colorado University Decision Diagram Package ftpvlsicoloradoedupub 1996 56 HP Störr Planning ﬂuent calculus binary decision diagrams AI Magazine 2001 103105 57 K Sulimma W Kunz An exact algorithm solving difﬁcult detailed routing problems Proceedings 2001 International Symposium Physical Design 2001 pp 198203 58 I Wegener Branching Programs Binary Decision Diagrams Society Industrial Applied Mathematics SIAM 2000 59 CH Yang DL Dill Validation guided search state space Proceedings 35th Design Automation Conference DAC98 ACM 1998 pp 599604 60 J Yuan J Shen J Abraham A Aziz Formal informal veriﬁcation Conference Computer Aided Veriﬁcation CAV97 1997 pp 376387