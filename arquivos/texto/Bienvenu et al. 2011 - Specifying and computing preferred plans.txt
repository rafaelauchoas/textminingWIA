Artiﬁcial Intelligence 175 2011 13081345 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Specifying computing preferred plans Meghyn Bienvenu Christian Fritz b Sheila A McIlraith c CNRS Université ParisSud France b Palo Alto Research Center USA c Department Computer Science University Toronto Canada r t c l e n f o b s t r c t Article history Received 7 April 2009 Received revised form 30 July 2010 Accepted 30 July 2010 Available online 2 December 2010 Keywords Knowledge representation Preferences Planning preferences In paper address problem specifying computing preferred plans rich qualitative user preferences We propose logical language specifying preferences evolution states actions associated plan We provide semantics ﬁrstorder preference language situation calculus prove progression preference formulae preserves semantics This leads development PPlan bounded bestﬁrst search planner computes preferred plans Our preference language amenable integration existing planners planning support diversity dynamical reasoning tasks employ preferences 2011 Elsevier BV All rights reserved 1 Introduction Research automated planning historically focused classical planning generating sequence actions achieve userdeﬁned goal given speciﬁcation domain initial state However realworld settings satisﬁcing plans plentiful generation high quality plans meeting users preferences constraints presents greatest challenge 50 In paper examine problem preferencebased planning generating plan achieves user deﬁned goal conforms possible users preferences properties plan To address problem preferencebased planning require language specifying user preferences means gener ating plans capable optimizing deﬁned class preferences To end propose LPP ﬁrstorder language specifying domainspeciﬁc qualitative user preferences LPP expressive supporting deﬁnition tem porally extended preferences evolution actions states associated plan LPP harnesses expressive power ﬁrstorder linear temporal logic LTL 51 We deﬁne semantics ﬁrstorder preference language Reiters version situation calculus 4753 Leveraging semantics deﬁne extension LPP allows speciﬁcation preferences occurrence Golog complex actions 4453 Golog Algol inspired agent programming language supports construction complex actions programming languagelike constructs primitive complex actions Golog proven great utility diversity agent programming appli cations LPP s situation calculus semantics enables reason preferences situations corresponding trajectories partial plans language beneﬁcial diversity reasoning tasks distinguishing preferred situation trajectory relevant Such tasks include limited plan understanding diagnosis dynamical The majority work presented paper performed authors aﬃliated University Toronto Revisions paper carried ﬁrst author Université Paul Sabatier Universität Bremen second author Information Sciences Institute Corresponding author Email addresses meghynlrifr M Bienvenu cfritzparccom C Fritz sheilacstorontoedu SA McIlraith 00043702 matter 2011 Elsevier BV All rights reserved doi101016jartint201011021 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1309 systems requirements modeling software engineering LPP characterize ordered defaults norms default deontic reasoning Despite LPP s roots situation calculus planning LPP require use deductive plan synthesis theorem prover LPP amenable use stateoftheart planner LTLbased preferences input Indeed discuss later work Baier McIlraith 2 provides compilation algorithm enables preference based planners accept LTL formulae input plan LPP like LTL preferences In paper propose PPLAN bounded bestﬁrst search forwardchaining planner spirit TLPlan 1 TALPlanner 43 PPLAN exploits progression eﬃciently evaluate LTL preference satisfaction partial plans To guide search optimal plan propose admissible evaluation function concert A search results generation optimal plans There signiﬁcant body research preferences artiﬁcial intelligence AI related disciplines A recent special issue AI Magazine 36 provides highlevel overview latest AI research ﬁeld including research planning preferences 6 In years growing planning community preferencebased planning This includes study speciﬁcation preferences planning Son Pontelli 5960 Delgrande Schaub Tompits 23 particular extension Planning Domain Deﬁnition Language PDDL 48 Gerevini Long include preferences PDDL3 33 In 2006 biennial Interna tional Planning Competition IPC2006 included track planning preferences speciﬁed PDDL3 A number preferencebased planners developed time subsequently 24254161910293535 We discuss related work Section 7 This paper organized follows In Section 2 provide brief review situation calculus Then Section 3 introduce syntax semantics LPP preference language planning illustrating use moti vating example carried paper With semantics preference language hand return general problem planning preferences In Section 4 deﬁne notion progression LPP pref erence formulae prove preserves semantics preferences We deﬁne admissible evaluation function progression A search generate optimal plans Then Section 5 PPLAN algorithm bounded bestﬁrst forwardchaining planner plans preferences We prove correctness PPLAN algorithm present experimental results proofofconcept implementation algorithm Prolog Finally Section 6 extend LPP enable deﬁnition preferences Golog complex actions We correspondingly extend notion progression include new preference formulae We conclude paper discussion related work summary 2 Preliminaries The situation calculus sorted logical language equality designed specifying reasoning dynamical systems 53 The signature language speciﬁed terms sorts set action terms A consists constants functions mapping objects actions elements type action set situation terms consists constant S0 denoting initial state world terms form doa s action term s situation term ﬁnally object terms encompass action situation In situation calculus state world expressed terms functions relations called ﬂuents relativized particular situation s F cid3x s In paper consider relational ﬂuents distinguish set F ﬂuents isSnowings model dynamic properties world set R nonﬂuent relational formulae mealspaghetti properties world change time A situation s history primitive actions A performed initial distinguished situation S 0 The function maps situation s action new situation doa s The theory induces tree situations rooted S 0 states situation s precedes situation s A basic action theory D situation calculus comprises domainindependent foundational axioms set domaindependent axioms The foundational axioms Σ deﬁne situations branching structure situation predecessor relation cid2 s cid2 s situation tree Σ includes secondorder induction axiom The domaindependent axioms strictly ﬁrstorder general form described The reader directed Appendix A example axiomatization dinner domain use paper illustrate concepts Note follow notational convention established Reiter 53 assume free variables situation calculus formulae universally quantiﬁed outside noted In later sections discussing preferences Golog adopt convention referring ﬂuents situationsuppressed form athome athome s cid5 cid5 A set Dap action precondition axioms conditions possible execute action A situation s An action precondition axiom action A takes form cid2 Poss Acid3x s cid3 Π Acid3x s Π Acid3x s formula free variables cid3x s contains situation terms s For instance possible action precondition axiom action eat cid2 cid3 Poss eatx s mealx y cid2 cid3 y s readyToEatx y s 1310 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 A set DSS successor state axioms capture effects actions truth values ﬂuents A successor state axiom ﬂuent F form cid3 cid3x doa s ΦF cid3x s cid2 F ΦF cid3x s formula free variables cid3x s contains situation terms s For example successor state axiom ﬂuent kitchenClean kitchenClean cid2 cid3 doa s cleanDishes cid2 cid3 kitchenCleans y cid11 cook y A set axioms DS0 describing initial situation These consist formulae mention S 0 mention situation nonﬂuent predicates In paper assume complete information initial situation nary relation F ntuple constants cid3c DS0 cid12 F cid3c cid12 F cid3c DS0 A set Duna unique names axioms actions These forms cid3xcid3y Acid3x Acid3y cid3x cid3y A action cid3xcid3y Acid3x cid11 Bcid3y A B actions A cid11 B More details form axioms Reiter 53 Deﬁnition 21 Planning Problem A planning problem cid5 tuple cid14D Gcid15 D basic action theory G goal formula representing properties hold ﬁnal situation Here goal formula G denotes formula contains situation term suppressed We denote instantiation G situation s Gs In situation calculus planning characterized deductive plan synthesis 37 Given planning problem cid14D Gcid15 task determine situation s executable goal holds D cid12 s cid2 cid3 executables Gs cid5 Notice goal satisﬁed initial situation s executables def S0 s doan doan1 doa1 S01 case shown executing sequence actions a1a2 S0 enables reach goal state cid5 cid16 s Possa s cid5doa s We refer situation s plan trajectory possibly sequence actions a1a2 associated plan The length plan n The set plans denoted Π Π k denotes subset plans length cid2 k A planning problem cid14D Gcid15 solvable plan It ksolvable plan length k Note slightly abusing terminology refer executable sequences actions partial plans sequences actions extended plan 3 Preference speciﬁcation In section syntax semantics ﬁrstorder preference language We illustrate concepts paper terms compelling domain Dinner Domain An independent contribution paper creation planning domain serve benchmarking domain problems planning preferences In addition affording number natural compelling temporally extended preferences dinner domain easily scaled increasing number objects involved adding restaurants meals making events complex buying groceries cooking A complete axiomatization dinner domain example provided Appendix A Example 31 The Dinner Domain Its dinner time Claire tired hungry Her goal home hunger sated There possible ways Claire food cook home order takeout food restaurant To cook meal Claire needs know meal necessary ingredients require trip grocery store She needs clean kitchen prepare meal Ordering takeout simpler order eat meal Going restaurant requires getting restaurant ordering eating returning home 1 We frequently abbreviate doan doan1 doa1 S 0 doa1 S 0 docid3a S 0 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1311 This example easily encoded number planning systems given speciﬁcation Claires initial state planner generate numerous plans achieve Claires goal Nevertheless like Claire certain prefer ences concerning eats plans better It deﬁnition preferences generation preferred plans focus paper 31 A ﬁrstorder preference language In section present syntax ﬁrstorder language expressing preferences dynamical systems Our preference language modiﬁes extends preference language PP recently proposed Son Pontelli 59 We hierarchy basic desire formulae rename trajectory property formulae atomic preference formulae general preference formulae add new class aggregated preference formulae Subsequent references preference formulae refer aggregated preference formulae encompass trajectory property formulae atomic preference formulae general preference formulae It preference formula given input planner Deﬁnition 32 Trajectory Property Formula TPF A trajectory property formula sentence drawn smallest set B F B R B If f F ﬁnal f B If A occa B If ϕ1 ϕ2 B ϕ1 ϕ1 ϕ2 ϕ1 ϕ2 xϕ1 xϕ1 nextϕ1 alwaysϕ1 eventuallyϕ1 untilϕ1 ϕ2 TPFs properties trajectories sequences actions states The TPFs f r ﬁnal f static properties states belonging trajectory TPF occa allows types actions occur trajectory These basic TPFs serve building blocks creating complex TPFs standard Boolean connectives quantiﬁers temporal operators We illustrate kind properties expressed TPFs giving sample TPFs motivating example The formal semantics TPFs presented Section 32 hasIngredientsspaghetti knowsHowToMakespaghetti cid2 x cid3 hasIngredientsx knowsHowToMakex ﬁnalkitchenClean cid3 athome cid2 cid2 cid3cid3 cookx cid2 cid2 x eventually occ cid2 x y eventually occ cid2 x y eventually orderRestaurantx y occ cid2 cid2 cid2 cid3 x y occ isSnowing drivex y cid2 cid2 cid2 cid3cid3cid3 cid3 x eatx orderTakeoutx y chinesex occ cid3cid3 cid2 cid2 cid3cid3 cid3cid3 P1 P2 P3 P4 P5 P6 P7 P8 P9 The ﬁrst TPF P1 states initial situation Claire ingredients knowhow cook spaghetti P2 general expressing initial situation Claire ingredients knows Observe ﬂuents inside temporal connectives refer initial situation P3 states ﬁnal situation kitchen clean The TPF P4 states Claire remains home trajectory P5P7 state respectively point time Claire cooks orders takeout orders meal restaurant The TPF P8 states point Claire drive snowing Finally P9 tells Claire eats Chinese food TPFs express simple allornothing preferences For example TPF P7 indicate preference going restaurant TPF P4 express desire stay home However TPFs allow express complex preferences like fact Claire prefers cooking ordering takeout going restaurant Notice preferences type satisﬁed certain degree Claire happiest cooks happy orders takeout happy going restaurant Moreover Claire ﬁnd cooking slightly better takeout takeout appealing going This suggests need specify preferences alternatives user indicate level preference different alternatives These considerations motivate introduction atomic preference formulae 1312 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 Deﬁnition 33 Atomic Preference Formula APF Let V totally ordered set minimal element v min maximal element v max An atomic preference formula formula ϕ0v 0 cid18 ϕ1v 1 cid18 cid18 ϕnvn ϕi TPF v V v v j j v 0 v min When n 0 atomic preference formulae correspond TPFs Note requirement v v j j different values distinct loss generality set TPFs value replaced disjunction An atomic preference formula expresses preference alternatives Each alternatives APF annotated value totally ordered set V describes far alternative ideal The lower value closer ideal satisﬁed user In follows let V 0 1 parsimony easily choose strictly qualitative set like best good indifferent bad worst Returning example following APF expresses Claires preference eat spaghetti followed pizza followed crêpes2 cid2 cid5 occ cid3 eatspaghetti cid5 0 cid18 occ cid2 cid3 eatpizza 04 cid18 occ cid2 cid5 cid3 eatcrêpes 05 P10 From values Claire assigned options strong preference spaghetti ﬁnds pizza crêpes equally appealing If instead Claire hurry tired hungry concerned long wait meal giving rise following preference P60 cid18 P5 P402 cid18 P707 cid18 P5 P409 P11 This preference tells Claires ﬁrst choice takeout followed cooking doesnt involve going groceries followed going restaurant lastly cooking requires leaving home We Claire prefers options dont involve going To reiterate atomic preference formula represents preference alternatives ϕi We wish satisfy TPF ϕi lowest index Consequently Claire eats pizza crêpes better worse respect P10 situations Claire eats pizza strictly better situations eats crêpes Note implicitly option satisfy ϕi option preferred Atomic preference formulae contribute signiﬁcantly expressivity preference language lack way combine atomic preferences In order allow user specify complex preferences introduce class formulae extends language conditional conjunctive disjunctive preferences Deﬁnition 34 General Preference Formula GPF A formula Φ general preference formula following holds Φ atomic preference formula Φ γ Ψ γ TPF Ψ general preference formula Conditional Φ Ψ1 Ψn General And Ψ1 Ψn General Or n cid3 1 Ψi general preference formula Here example general preference formulae P2 P5 P4 P10 P11 P10 P11 P12 P13 P14 P12 states Claire initially ingredients prefers stay cook Preferences P13 P14 ways combine Claires food time preferences P13 maximizes satisfaction Claires food time preferences P14 says content satisﬁed Our ﬁnal class formulae allows combine general preferences number wellknown preference aggregation operators cf 26 Deﬁnition 35 Aggregated Preference Formula AgPF A formula Φ aggregated preference formula following holds 2 For legibility abbreviate eventuallyoccϕ occ cid5ϕ refer preference formulae labels M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1313 Φ general preference Φ lexΦ1 Φn leximinΦ1 Φn sumΦ1 Φn sum operation associated V n cid3 1 Φi general preference formula Note summing elements V operation exists possibly yield values outside V use standard arithmetic sum V 0 1 obtain numbers greater 1 All require sum operation deﬁned multiset elements V outputs elements totally ordered set possibly different V This concludes description syntax preference language Our language extends modiﬁes PP language recently proposed Son Pontelli 59 Quantiﬁers variables nonﬂuent relations conditional construct aggregation operators AgPF added language In PP impossible talk arbitrary action ﬂuent arguments properties diﬃcult impossible express kinds preferences given PPs APFs ordinal qualitative making relative differences ordered preferences impossible articulate Finally semantics present section gives different argue natural interpretation General And General Or Relative quantitative dynamical preferences argue language natural user 32 The semantics language We appeal situation calculus deﬁne semantics preference language TPFs interpreted situation calculus formulae evaluated relative action theory D In order deﬁne semantics complex pref erence formulae satisﬁed certain degree associate qualitative value weight situation term depending satisﬁes preference formula Weights elements V v min indicating complete sat isfaction v max complete dissatisfaction The motivation introducing values purely ordinal preferences atomic preference formulae 59 combined limited necessarily natural ways addition leading great incomparability outcomes Replacing ordinal preferences qualitative preferences allows nuanced representation users preferences cid5 Since TPFs refer properties hold situations situation history use notation ϕs s proposed Gabaldon 32 explicitly denote ϕ holds sequence situations originating s terminating cid5 doa1 s3 Recall ﬂuents represented situationsuppressed form F s denotes reinsertion s situation term s Deﬁnition 36 We deﬁne following set macros providing interpretation TPFs situation calculus 324 cid4 cid4 f r cid4 ﬁnal f cid4 occa cid4 ϕ ψ cid4 ϕ ψ cid4 ϕ cid4 xϕ cid4 xϕ cid4 eventuallyϕ cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 s s s s s s s s s s s s s s s s s s s s def f s f F def r cid4 def f cid5 s r R cid5 f F cid5 cid5 cid5 cid5 cid4 cid4 s s s s def doa s cid16 s cid5 cid5 cid5 cid5 cid5 ψ ψ cid5cid3 cid5 s s cid4 s s cid4 s s cid5cid3 cid5 cid5cid3 cid5 cid4 cid4 s s def ϕ def ϕ s s cid4 cid2 def ϕ cid2 def x ϕ cid2 def x cid2 ϕ def s1 s cid16 s1 cid16 s cid4 cid3 cid5 ϕ s1 s cid5 cid5 cid5 s cid5 s s 3 Actually 32 notation ϕs situation calculus convention s precedes s 4 We use following abbreviations cid5Φ def s1s cid16 s1 s1 cid16 s cid5Φ def s1s cid16 s1 s1 cid16 s s1 s cid16 s1 cid16 s s1 s cid16 s1 cid16 s cid5 Φ cid5 Φ cid5 cid5 start situation s end situation We chose invert roles s 1314 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 cid4 alwaysϕ cid4 nextϕ cid4 untilϕ ψ s s s s s s cid5 cid5 cid5 cid5 cid5 cid5 cid2 def def cid2 def s1 s cid16 s1 cid16 s cid2 doa s cid16 s cid4 cid3 cid5 ϕ cid5 ϕ cid3cid2 cid5 cid5 cid5 s1 s cid4 doa s s cid4 cid5 cid5cid3 cid5 s1 s cid16 s1 cid16 s cid5 ψ s1 s s2 s cid16 s2 cid2 s1ϕ cid5cid3 cid5 cid4 s2 s That ﬂuent embedded inside temporal connective holds sequence situations case holds ﬁrst situation sequence For r R r situation calculus formula A TPF ﬁnal f means ﬂuent f holds ﬁnal situation The TPF occa tells ﬁrst action executed The Boolean connectives quantiﬁers situation calculus require special translation Finally interpret temporal connectives exactly way 32 Since TPF shorthand situation calculus expression simple modeltheoretic semantics follows Deﬁnition 37 Trajectory Property Satisfaction Let D action theory A trajectory property formula ϕ satisﬁed situation s case D cid12 ϕS0 s We deﬁne w sϕ weight TPF ϕ respect situation s w sϕ v min ϕ satisﬁed s w sϕ v max We extend deﬁnition general case follows Deﬁnition 38 Let D action theory let s s ϕ satisﬁed sequence situations s s situations s cid16 s cid5 case cid5 cid5 A trajectory property formula D cid12 ϕ cid5 cid5 cid4 s s We deﬁne w sscid5 ϕ weight TPF ϕ respect situations s s ϕs s cid5 w sscid5 ϕ v max cid5 We deﬁne w sscid5 ϕ v min D cid12 Clearly Deﬁnition 37 special case Deﬁnition 38 w s simply shorthand w S0s In circum stances shorthand w s notation Deﬁnition 37 suﬃce advantage easier read understand Consequently use paper Nevertheless proving properties semantics relative progression revert twosituation notation Deﬁnition 38 Example 39 We evaluate example TPFs presented respect plan trajectory s1 docookcrêpes eatcrêpes cleanDishes S0 initial situation S0 Claire home clean kitchen ingredients crêpes knows spaghetti crêpes Recall examples assume V 0 1 v min 0 v max 1 See Appendix A detailed description S0 w s1 P1 1 w s1 P4 0 w s1 P7 1 w s1 P2 0 w s1 P5 0 w s1 P8 0 w s1 P3 0 w s1 P6 1 w s1 P9 0 The weight atomic preference formula simply deﬁned value associated ﬁrst satisﬁed compo nent TPF Deﬁnition 310 Atomic Preference Satisfaction Let s situation Φ ϕ0v 0 cid18 ϕ1v 1 cid18 cid18 ϕnvn atomic preference formula Then cid6 w sΦ v v max D cid12 ϕiS0 s D cid11cid12 ϕ jS0 s 0 cid2 j exists Example 311 We evaluate atomic preferences P10 P11 respect trajectory s1 initial situation S0 Example 39 w s1 P10 05 w s1 P11 02 For trajectory s2 dodrivehome store buyIngredientsspaghetti drivestore home cookspaghetti eatspaghetti S 0 obtain M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1315 w s2 P10 0 trajectory s3 dodrivehome italianRest orderRestaurantspaghetti italianRest eatspaghetti driveitalianRest w s2 P11 09 For home S0 instead w s3 P10 0 w s3 P11 07 Finally trajectory s4 doorderTakeoutpizza pizzaPlace eatpizza S0 w s4 P10 04 w s4 P11 0 Deﬁnition 312 General Preference Satisfaction Let s situation Φ general preference formula Then w sΦ deﬁned follows cid6 w sϕ0v 0 cid18 ϕ1v 1 cid18 cid18 ϕnvn deﬁned w sγ Ψ w sΨ1Ψ2 Ψn maxw sΨi 1 cid2 cid2 n w sΨ1 Ψ2 Ψn minw sΨi 1 cid2 cid2 n v min w sΨ w sγ v max Observe semantics generalized Boolean connectives extends semantics Boolean counterparts conjunction Ψ1 Ψn fully satisﬁed weight v min component preferences Ψi fully satisﬁed disjunction Ψ1 Ψn fully satisﬁed disjuncts Ψi fully satisﬁed conditional preference γ Ψ fully satisﬁed condition γ false weight v max component preference formula Ψ fully satisﬁed Returning example GPFs page 1312 Example 313 We evaluate general preference formulae respect trajectories s1 s2 s3 s4 initial situation S0 DS0 Appendix A P12 P2 P5 P4 P13 P10 P11 P14 P10 P11 s1 0 05 02 s2 1 09 0 s3 1 07 0 s4 1 04 0 We conclude section following deﬁnition shows compare situations respect aggregated preference formula Deﬁnition 314 Preferred Situations A situation s1 preferred situation s2 respect preference formula Φ written s1 cid4Φ s2 following holds Φ GPF w s1 Φ cid2 w s2 Φ Φ lexΦ1 Φn w s1 Φi w s2 Φi w s1 Φi w s2 Φi j w s1 Φ j w s2 Φ j Φ leximinΦ1 Φn w s1 Φi v w s2 Φi v v V v w s1 Φi v w s2 Φi v v cid5 v w s1 Φi v cid5 w s2 Φi v cid5 Φ sumΦ1 Φn i1 w s1 Φi cid2 cid7 n cid7 n i1 w s2 Φi Strict preference cid19 equivalence deﬁned standard way Thus comparing situations s1 s2 respect preference lexΦ1 Φn simply apply standard lexicographic ordering tuples weights w s1 Φ1 w s1 Φn w s2 Φ1 w s2 Φn For preference formula leximinΦ1 Φn check value value starting minimal value v min situations elements value privileging situations small good values In words ﬁrst sort weights tuples w s1 Φ1 w s1 Φn w s2 Φ1 w s2 Φn ascending order apply lexicographic ordering reordered tuples Finally preference sumΦ1 Φn simply sum weights tuples w s1 Φ1 w s1 Φn w s2 Φ1 w s2 Φn compare resulting values Example 315 We evaluate aggregated preference formulae respect trajectories s1 s2 s3 s4 initial situation S0 If Claire places greater importance satisfying food preference time preference AgPF Φ1 lexP10 P11 gives following order situations 1316 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 s3 cid19Φ1 s2 cid19Φ1 s4 cid19Φ1 s1 Suppose Claire wants satisfy food time preferences accords equal importance prefer ences This expressed AgPF Φ2 leximinP10 P11 yields following preference ordering s4 cid19Φ2 s3 cid19Φ1 s2 cid19Φ1 s1 Since numerical set values sum operator combine Claires preferences Φ3 sumP10 P11 allowing maximize average level satisfaction s4 cid19Φ3 s1 Φ3 s3 cid19Φ3 s2 Notice set V weights assumed totally ordered general preference formula Φ pair trajectories s1 s2 w s1 Φ w s2 Φ w s1 Φ w s2 Φ w s1 Φ w s2 Φ It follows s1 cid4Φ s2 s2 cid4Φ s1 cid4Φ deﬁnes complete preorder situations This continues hold replace Φ aggregated preference formula Remark 316 Given aggregated preference formula Φ relation cid4Φ deﬁnes complete preorder situations What interesting framework capable representing ordinal qualitative simple quantita tive preferences For example want avoid specifying values apply aggregation operators set TPFs If combine leximin generate preorder ranks plans based number satisﬁed preferences lexicographic operator lex classify plans according criteria vary ing importance By annotating APFs qualitative values focus paper user specify relative differences levels preference different alternatives allows combine preferences number natural ways Finally approach works equally case relative differences expressed numerically case user use sum aggregation operator allows compensation different preferences 4 Planning preferences With preference language hand return problem planning preferences Deﬁnition 41 PreferenceBased Planning Problem A preferencebased planning problem cid5P action theory G goal formula Φ preference formula tuple cid14D G Φcid15 D Deﬁnition 42 Preferred Plan Consider preferencebased planning problem cid5P cid14D G Φcid15 plan trajectories s1 s2 associated plans cid3a1 cid3a2 We plan cid3a1 preferred plan cid3a2 iff s1 cid19Φ s2 Following work planning domain control knowledge TALPlanner 43 TLPlan 1 interesting consider generalized problem planning hard constraints domain knowledge combined preference formulae This constrained planning problem preferences easily accommodated framework simply adding TPF φc representing control knowledge requiring plans satisfy φc Deﬁnition 43 Constrained Planning Problem Preferences A constrained planning problem preferences cid5P cid14D G φc Φcid15 φc TPF D G Φ A plan cid5P φcS0 docid3a S0 C plan cid3a cid14D Gcid15 C tuple D cid12 As example user dinner domain conjunction previously exempliﬁed preference formulae want rule plans involve leaving house She φc alwaysathome Deﬁnition 44 Ideal Plan Given constrained preferencebased planning problem associated preference formula Φ ideal plan plan cid3a w docid3aS0Φ v min Φ GPF w docid3aS0Φi v min 1 cid2 cid2 n Φ lexΦ1 Φn leximinΦ1 Φn sumΦ1 Φn Thus ideal plan plan fully satisﬁes users preferences Deﬁnition 45 Optimal Plan Given constrained preferencebased planning problem associated preference formula Φ optimal plan plan cid3a exist plan cid3b docid3b S0 cid19Φ docid3a S0 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1317 An optimal plan plan best satisﬁes users preferences possible plans Note optimality relative preferencebased planning problem plan exists optimal plan ideal plans exist impossible achieve goal fully satisfying agents preferences Deﬁnition 46 kOptimal Plan Given constrained preferencebased planning problem preference formula Φ length bound k koptimal plan plan cid3a Π k exist plan cid3b Π k docid3b S0 cid19Φ docid3a S0 Thus set koptimal plans consists plans best satisfy users preferences plans composed k actions For purposes paper restrict attention planning problems ﬁnite domains problems planning domain deﬁnitions representable propositional logic This restriction ﬁnite domains consistent state art automated classical planning Before elaborating approach generating preferencebased plans digress slightly discuss issues related complexity preferencebased planning 41 Complexity preferencebased planning While complete analysis computational complexity preferencebased planning scope paper subsection provide insight key issues related complexity preferencebased planning The computational complexity classical planning generally examined respect fundamental decision problems plan existence problem informally exist plan ii bounded plan existence problem exist plan length n A key factor determining complexity decision problems expressiveness planning domain description It established classical planning STRIPS ﬁrst order terms undecidable 28 numeric STRIPS 39 However STRIPS planning domain propositional plan existence PSPACEcomplete 19 It takes severe syntactic restrictions planning domain guarantee NP completeness drastic restrictions yield propositional STRIPS domains tractable The closely related complexity result problem examine van den Briel et al determining propositional partial satisfaction planning problem quality k PSPACEcomplete 62 However noted Section 7 partial satisfaction planning problems related notion preferencebased planning deﬁned notion quality preference deﬁned evaluated different way In order study computational complexity preferencebased planning deﬁned examine decision problems associated deﬁnitions provided In particular examine decision problems associated testing given plan ideal optimal koptimal The decision problem relating ideal plans necessitates testing sequence states induced action sequence satisﬁes component TPFs preference formula In contrast optimal koptimality problems involve evaluating preference formula respect given plan verifying exist preferred plan Note decided component TPFs satisﬁed given plan possible determine possible combinations TPFs rise preferred plans Example 47 Consider GPF Φ form cid2 cid3 ϕ10 cid18 ϕ202 cid18 ϕ307 cid2 cid3 ϕ40 cid18 ϕ505 cid18 ϕ609 ϕ1 ϕ6 TPFs Suppose identiﬁed plan trajectory s satisﬁes ϕ1 ϕ5 ϕ6 The weight s 05 preferred plan weight 05 There ways achieving satisfy ϕ1 ϕ4 weight 0 satisfy ϕ2 ϕ4 obtain weight 02 Thus key computational problems setting decide plan satisﬁes given TPF decide exists plan satisﬁes given TPF The problem seen generalization plan existence problem Existing complexity results related classical planning emphasize expressiveness planning domain description determining factor complexity plan existence With respect preferencebased planning preference language intended combination diversity action representations including limited situation calculus proper analysis require parameterize decision problems form action theory form preference formula In remainder subsection brieﬂy discuss complexity plan existence problem TPFs case propositional STRIPS action theories propositional preference formulae leaving investigation settings future work We begin noting complexity plan existence problem temporally extended goals expressed LTL studied previously Baral et al 7 They plan existence problem NPcomplete propositional action theories 1318 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 polynomial bound placed plan length As LTL goals similar TPFs result trivially extended setting Of greater case length bound provided length bound succinctly encoded minimallength plans exponentially long preventing applying guessandcheck method exploited Baral et al We know classical setting PSPACEcomplete determine instance propositional STRIPS planning problem solutions 19 The PSPACE lower bound clearly transfers setting The proof PSPACE membership based recursive computation reachability transition induced action theory Initially want test ﬁnal state s f s f reached initial state s0 2n steps n number propositional variables This test performed ﬁrst guessing intermediate state si testing si reached s0 2n1 steps ii s f reached si 2n1 steps The recursion stops allowed single step case states identical second state reachable single action ﬁrst state Since recursive calls processed independently recursion depth log 2n n obtain membership PSPACE A crucial point materialize transition path s0 s f exponentially large At ﬁrst glance appear obstacles extending PSPACE upper bound classical propositional planning setting In classical planning needs consider plans state visited assume paths length 2n Such restriction valid setting states need visited multiple times order satisfy TPF This means length shortest plan satisfying TPF larger number states The recursive reachability algorithm allow track satisfaction temporal properties Fortunately points addressed LTL modelchecking community Indeed key PSPACE membership proof model checking LTL formulae originally shown 54 construction enhanced tran sition precisely Büchi automaton states contain propositional atoms temporal formulae need satisﬁed state Reachability analysis performed modiﬁed tran sition system5 exponentially large constructed ontheﬂy The LTL approach directly applied setting standard LTL semantics treats inﬁnite ﬁnite state sequences TPFs contain nonstandard connectives occ ﬁnal However differences largely superﬁcial modifying deﬁnition ﬁnal state transition account ﬁniteness ﬁnal connective compiling away occ connective ﬂuents obtain membership PSPACE TPF plan existence purely propositional setting A result Baral et al shows verifying given plan satisﬁes TPF second key decision problem feasible polynomial time Thus combining results applying reduction gen eral preferences TPFs suggested PSPACEcompleteness optimality problem bounded variant 42 Progression We return question compute preferred plans Again recall restricting attention planning problems ﬁnite domains keeping state art classical planning In Section 5 present algorithm planning preferences based forwardchaining planning As control knowledge containing linear temporal logic formulae 143 evaluate preference formulae progressing construct plan Progression takes situation temporal logic formula TLF evaluates TLF respect state situation generates new formula representing aspects TLF remain satisﬁed subsequent situations In section deﬁne notion progression respect preference formulae prove semantics preference formulae preserved progression Our objective section develop method planning ﬁnite domain problems deﬁne progression preferences ranging ﬁnite domains This consistent previous deﬁnitions progression 143 We believe possible extend deﬁnition progression handle ﬁrstorder preference language syntactic restrictions investigation issue goes scope present paper left future work In order deﬁne progression operator add propositional constants TRUE FALSE situation calculus set TPFs D cid12 TRUE D cid2 FALSE action theory D To capture progression occa add TPF occLasta A semantics deﬁned occLastas s cid5cid5s doa s cid5 def s cid5cid5 5 More precisely need determine emptiness Büchi automaton This ﬁnding ﬁnal state s f reachable initial state reachable M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1319 Deﬁnition 48 Progression Trajectory Property Formula Let s situation The progression trajectory property formula ϕ s written ρsϕ given For f F ρs f def cid8 cid8 D cid12 f s TRUE FALSE D cid12 r cid8 cid5 cid5s doa s TRUE FALSE For r R ρsr def ρsocca def occLasta D cid12 s TRUE ρsoccLasta def FALSE ρsﬁnalψ def ﬁnalψ ρsψ def ρsψ ρsψ1 ψ2 def ρsψ1 ρsψ2 ρsψ1 ψ2 def ρsψ1 ρsψ2 ρsxψ def ρsxψ def ρsnextψ def ψ ρsalwaysψ def ρsψ alwaysψ ρseventuallyψ def ρsψ eventuallyψ ρsuntilψ1 ψ2 def ρsψ1 untilψ1 ψ2 ρsψ2 ρsTRUE def TRUE ρsFALSE def FALSE cC ρsψ cx cC ρsψ cx cid9 cid10 ψ cx denotes result substituting constant c instances variable x ϕ Example 49 With S0 deﬁned progress example TPFs ρS0 occcookcrêpes occLastcookcrêpes ρS0 eventuallykitchenClean ρS0 kitchenClean eventuallykitchenClean TRUE eventuallykitchenClean TRUE cid9 ρS0 xhasIngredientsx cC ρS0 hasIngredientsc ρS0 hasIngredientscrêpes ρS0 hasIngredientspizza TRUE FALSE TRUE Progression atomic general preference formulae deﬁned straightforward fashion progressing indi vidual TPFs comprise expressive formulae Deﬁnition 410 Progression Atomic General Aggregated Preference Formulae Let s situation let Φ atomic general preference formula The progression Φ s deﬁned ρsϕ0v 0 cid18 ϕ1v 1 cid18 cid18 ϕnvn def ρsϕ0v 0 cid18 cid18 ρsϕnvn ρsγ Ψ def ρsγ ρsΨ ρsΨ1 Ψn def ρsΨ1 ρsΨn ρsΨ1 Ψn def ρsΨ1 ρsΨn ρslexΦ1 Φn def lexρsΦ1 ρsΦn ρsleximinΦ1 Φn def leximinρsΦ1 ρsΦn ρssumΦ1 Φn def sumρsΦ1 ρsΦn Note progression lead potentially exponential increase size TPF In practice greatly reduce size progressed formulae use Boolean simpliﬁcation bounded quantiﬁcation cf 1 Deﬁnitions 48 410 progress preference formula step situation We extend notion iterated progression 1320 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 Deﬁnition 411 Iterated Progression The iterated progression preference formula Φ situation s docid3a S0 written ρ s Φ deﬁned ρ S0 Φ def ρS0 Φ cid2 ρ doasΦ def ρdoas cid3 ρ s Φ To prove progression theorem use general form iterated progression takes situation arguments Deﬁnition 412 General Iterated Progression The iterated progression preference formula Φ starting situation s1 situation s2 s1 cid16 s2 written ρ Φ deﬁned follows s1s2 ρ s1s1 Φ def ρs1 Φ ρ s1doas3Φ def ρdoas3 cid2 cid3 Φ ρ s1s3 Finally prove progression preference formulae preserves semantics action theory entails preference formula situation history s entails progressed formula including s state associated s We exploit proving correctness algorithm section follow Theorem 413 Correctness Progression Let s1 s2 doa1 s1 situations n cid3 1 let ϕ TPF Then D cid12 ϕs1 s2 s2 doan s3 iff D cid12 ρ s1s3 ϕs2 s2 Proof Refer Appendix B cid3 In context planning interested case s1 S0 Corollary 414 Let s doa1 S0 situation n cid3 1 let ϕ TPF Then D cid12 ϕS0 s cid5 s doan s iff D cid12 ρ scid5 ϕs s From Corollary 414 prove weight preference formula respect situation plan trajectory equal weight progressed preference formula respect ﬁnal situation disregarding history Corollary 415 Let s doa1 S0 situation n cid3 1 let Φ preference formula Then w sΦ w ss cid5 s doan s cid2 cid3 ρ scid5 Φ 43 An evaluation function bestﬁrst search In section propose admissible evaluation function bestﬁrst search To end introduce notion optimistic pessimistic weights situation relative GPF Φ These weights provide bound best worst weights successor situation respect Φ As result evaluation function nondecreasing overestimate actual weight enabling deﬁne optimal search algorithm Optimistic resp pessimistic weights deﬁned based optimistic resp pessimistic satisfaction TPFs Intuitively cid5opt assumes parts TPF falsiﬁed eventually satisﬁed optimistic satisfaction denoted ϕs s cid5 cid5cid5 entailed action theory ϕs s continuation s situation s cid5pess assumes opposite satisﬁed lookahead Pessimistic satisfaction denoted ϕs s eventually falsiﬁed The deﬁnition optimistic pessimistic satisfaction largely follows deﬁnition normal satisfaction TPFs given earlier The key difference deﬁnition nextϕ occa ﬁnalϕ cid5cid5 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1321 cid5 cid5 opt def TRUE s s cid4 ﬁnalϕ cid4 ﬁnalϕ s s cid4 occa cid4 occa s s cid4 nextϕ cid4 nextϕ s s s s s s cid5 cid5 cid5 pess def FALSE cid5 opt def doa s cid16 s cid5 cid5 pess def doa s cid16 s cid2 cid5 opt def cid5 cid5 cid5 pess def cid2 cid5 cid5 s s cid5 doa s cid16 s doa s cid16 s cid3 cid5 cid5 cid5 ϕ cid5 ϕ cid4 doa s s cid4 doa s s cid5pess FALSE nextϕs s cid5 opt s s cid3 cid5 pess cid5 cid5 It follows s s deﬁne occLastas s occas s cid5optpess def occLastas s cid5 cid4 eventuallyϕ cid4 alwaysϕ cid4 untilϕ ψ optpess def ϕ optpess def ϕ optpess def ψ s s cid4 s s s s s s s s s s cid5 cid4 cid4 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 We deﬁne temporal formulae terms cid3cid4 cid2 cid5 optpess optpess cid4 cid5 optpess cid2 cid2 ϕ s s eventuallyϕ cid5 optpess s s cid5 optpess cid5 cid3cid4 alwaysϕ s s cid5 optpess cid5 cid2 cid3cid4 untilϕ ψ cid5 cid5 optpess cid3 s s cid5pess FALSE For later use progression For purpose creating admissible evaluation function planning interested optimistic evaluation The reason need pessimistic evaluation simple TPF ϕ optimistically satisﬁed ϕ pessimistically satisﬁed That optimistic assume way falsify ϕ turn satisfy negation We deﬁne cid5 cid2 opt def cid5 cid2 pess def cid5 pess cid5 opt s s s s ϕ cid3 cid3 cid4 cid4 cid5 cid5 cid5 cid5 cid4 ϕ cid4 ϕ s s s s ϕ For elements language deﬁnitions normal TPF satisfaction We deﬁne optimistic pessimistic weights TPFs terms optimistic pessimistic TPF satisfaction cid6 w opt sscid5 ϕ D cid12 ϕs s v min v max cid5opt cid6 w pess sscid5 ϕ D cid12 ϕs s v min v max cid5pess For readability abbreviate w opt S0s w opt For APFs GPFs deﬁnitions optimistic pessimistic weights straightforward S0s w pess w pess respectively s s Deﬁnition 416 OptimisticPessimistic Atomic Preference Satisfaction Let s situation Φ ϕ0v 0 cid18 ϕ1v 1 cid18 cid18 ϕnvn atomic preference formula Then cid6 optpess s w Φ v v max D cid12 ϕiS0 soptpess D cid11cid12 ϕ jS0 soptpess 0 cid2 j exists Deﬁnition 417 General Preference Satisfaction Let s situation Φ general preference formula Then w opt respectively w pess Φ deﬁned follows s s Φ w optpess s w optpess s w w optpess s optpess s ϕ0v 0 cid18 ϕ1v 1 cid18 cid18 ϕnvn deﬁned γ Ψ γ v max pessopt s cid6 w Ψ v min w Ψ1 Ψn maxw Ψ1 Ψn minw optpess s optpess s optpess s Ψi 1 cid2 cid2 n Ψi 1 cid2 cid2 n The following theorem describes important properties optimistic pessimistic weight functions Theorem 418 Let s situation let a1 action sequence 0 cid2 cid2 n let si doa1 ai s Let ϕ TPF Φ general preference formula Then 0 cid2 cid2 j cid2 k cid2 n 1322 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1 If D cid12 ϕs sipess D cid12 ϕs s j D cid11cid12 ϕs siopt D cid11cid12 ϕs s j si Φ cid2 w opt 2 w opt s j Φ w opt s j Φ cid2 w sk Φ Φ cid3 w pess 3 w pess s j s j si Φ cid3 w sk Φ Φ w pess Proof Refer Appendix C cid3 Intuitively 1 states pessimistic satisfaction formula sequence situations implies continu ation sequence satisﬁes formula It states formula hold optimistically true continuation Correspondingly 2 states optimistic weight nondecreasing bounded real weight future situation Finally 3 gives analogue pessimistic weights nonincreasing bounded real weight future situation One immediate implication following Corollary 419 For situations s s cid5 s cid16 s cid5 If w opt s Φ wpess s Φ w scid5 Φ wopt s Φ wpess s Φ Since deﬁnitions compatible deﬁned progression following corollary Theo rem 418 Corollary 420 Let s doa1 an1 S0 s s ϕs ϕS0 s cid5optpess iff D cid12 ρ cid5optpess cid5 s cid5 doan s situations n cid3 1 let ϕ TPF Then D cid12 Proof Refer Appendix D cid3 This corollary states use progression computing optimistic pessimistic weights Intuitively optimistic pessimistic evaluation concerned future progression deals past Since past wont change room optimism pessimism We deﬁne evaluation function fΦ Deﬁnition 421 Evaluation function Let s docid3a S0 situation let Φ general preference formula Then fΦ s deﬁned follows fΦ s cid6 w sΦ w opt s cid3a plan Φ From Theorem 418 optimistic weight nondecreasing overestimates real weight Thus fΦ admissible bestﬁrst search search optimal 5 The PPLAN algorithm implementation In section PPLAN bounded bestﬁrst search forward chaining planner computing preferred plans PPLAN currently implemented Prolog optimized Rather Prolog implementation provides means experimenting different heuristics search techniques framework reasoning preferences situation calculus As result PPLANs subsequent integration Prolog interpreter agent programming language Golog straightforward 58 In follows PPLAN algorithm prove properties presenting experiments illustrate effectiveness heuristic guide search The PPLAN code test cases available online 12 The PPLAN algorithm outlined Algorithm 1 PPLAN takes input initial state init goal formula goal general preference formula pref 6 plan length bound maxLength The algorithm returns outputs plan weight respect pref The frontier list nodes form w 1 w 2 path state pref w 1 w 2 denote weights usually hold optimistic pessimistic weight respectively path considered partial plan state state reached pref denotes progressed preference formula Recall weights values drawn totally ordered set V qualitative concepts excellent good easily numeric values The frontier sorted w 1 w 2 length increasing order The frontier initialized partial plan optimistic pessimistic weights optW pessW respect initial situation preference formula pref In 6 For simplicity present algorithm general aggregated preference formulae We discuss extension aggregated preference formulae later section M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1323 Algorithm 1 PPLAND init goal pref maxLength 1 2 3 4 5 6 7 8 9 10 begin frontier optWpref init pessWpref init init pref D cid12 goalinit node1 realWpref init realWpref init init pref frontier sortNmergeByVal node1 frontier frontier cid11 node removeFirstfrontier D cid12 goalnodestate nodew1 nodew2 return nodepath nodew1 successors expandnodepath nodestate nodepref maxLength expandpath state pref maxLength returns list new nodes add frontier Each node form w 1 w 2 path state pref If path sequence actions far length equal maxLength expand returns list Otherwise expand determines executable actions given situation returns list contains executable actions node cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 path state optWpref pessWpref path action leading situation satisfies goal second node path state Here optW pessW realWdenote functions return optimistic pessimistic real weight given progressed preference formula action sequence state realWpref realWpref state state state state path path path pref pref cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 frontier sortNmergeByValsuccessors frontier return solution 11 12 13 end case initial situation satisﬁes goal addition node added frontier representing real weight plan Lines 35 On iteration loop PPLAN removes ﬁrst node frontier places node If partial plan node satisﬁes goal weights equal PPLAN returns nodes partial plan weight Otherwise function expand elements node input If path length equal maxLength new nodes added frontier Otherwise expand generates new set nodes cid5 form optW pessW path action executable state For actions leading goal states expand generates second node form optW pessW replaced actual weight achieved plan The reason need nodes hand need record actual weight associated plan hand ensure completeness need able reach nodes successors The new nodes generated expand sorted weights length merged remainder frontier If reach frontier exit loop return solution cid5 pref state cid5 A naive implementation planner require computing alternative plan trajectories evaluating relative weights This computationally explosive requiring computation numerous plan trajectories caching relevant trajectory state redundant evaluation preference formula weights Instead use Theorem 413 compute weights construct plans progressing preference formula Exploiting progression enables development bestﬁrst search strategy orders search weight evaluates preference formulae shared partial plans Progression commonly evaluate domain control knowledge forward chaining planners TLPlan 1 TALPlanner 43 progression hard constraints prunes search space In contrast unable prune preferred partial plans yield ﬁnal solution need bestﬁrst strategy Note length bound necessary prevent algorithm exploring long inﬁnite action sequences optimistic weight zero reach goal state This instance happen ﬁnalϕ TPF formula ϕ achieved available actions given initial state Since heuristic perform lookahead approximate able detect branches stuck inﬁnite loop The following theorem asserts completeness koptimality PPLAN Theorem 51 Correctness PPLAN algorithm Given input preferencebased planning problem P length bound k PPLAN turns koptimal plan P ksolvable returns solution Proof First prove algorithm terminates There ways PPLAN halts ﬁrst node frontier plan w 1 w 2 case PPLAN returns plan reach frontier case PPLAN returns solution Let suppose ﬁrst condition met In case stay loop expanding node iteration But successor nodes generated expand length greater parent expand returns list node partial plan length equal k ﬁnitely actions consider node eventually run nodes reach frontier Thus algorithm terminates 1324 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 Next prove output satisﬁes conditions theorem This obvious case P ksolvable case ﬁnd plan stay loop reach frontier ﬁnally returning solution We treat case P ksolvable By deﬁnition means exists plan length equal k As PPLAN systematically explores search space point expand create node partial plan satisﬁes goal set w 1 w 2 actual weight This means frontier contain node satisfying conditions ifstatement point enter ifstatement return nonempty plan It remains shown plan returned koptimal cid5 length equal k weight w Suppose contradiction return plan p weight w koptimal This means exists cid5 w There possibilities 1 plan p placed p frontier contradiction frontier generated node corresponding p sorted nondecreasing order nodew1 nodes corresponding plans equal real weights w w p frontier But possible cid5 w according Theorem 418 ancestor p p frontier We shown P ksolvable returned plan koptimal concluding proof cid3 optimistic weight equal w case 2 ancestor node p cid5 cid5 cid5 cid5 Note algorithm straightforwardly modiﬁed handle aggregated preference formulae It suﬃces associate tuple optimistic pessimistic weights node order track optimistic pessimistic weights component GPFs We sort frontier comparing tuples according Deﬁnition 314 So instance given AgPF Ψ lexΦ1 Φ2 Φ3 frontier contain nodes form w 1 w w 3 2 2 optimistic pessimistic weights associated GPF Φi 1 2 3 path state pref w When sorting frontier place node ﬁrst component 0 1 1 node ﬁrst component 1 0 0 0 1 1 precedes 1 0 0 lexicographic ordering It easy Theorem 51 continues hold modiﬁed algorithm takes aggregated preference formulae input 1 w 1 w 1 1 w 3 1 w 2 2 w 2 51 Experiments As noted previously PPLAN implemented Prolog testbed planning rich temporally extended pref erences optimized support largescale experimental evaluation As performance competitive recent stateoftheart preferencebased planners competed IPC2006 We discuss planners relationship PPLAN Section 7 We interested evaluating combination progression evaluate LTL satisfaction proposed admissible heuristic provided approach help guide planner ﬁnding optimal plan From outset concerns The ﬁrst progression blind search proven effective planners like TLPlan strength progression rooted ability prune states comply LTL domaincontrol knowledge vastly reducing search space With LTL preferences comparable pruning merit progression question Further objective ambitious generate optimal plan admissible evaluation function widely accepted admissible heuristics dont provide suﬃcient guidance relative inadmissible heuristics To assess behaviour planner ran 60 instances dinner domain7 Each instance run PPLAN PPLANC PPLAN augmented domain control knowledge depthﬁrst search DFS breadth ﬁrst search BFS algorithms In order facilitate comparison DFS BFS passed koptimal weight parameter run plan weight ran memory All algorithms implemented Prolog code base extent possible Each run compared respect length returned plan number nodes expanded Results reported Fig 1 instances numbered order increasing PPLAN running time Fig 2 plots test cases running time The 60 individual instances differed respect initial state goal size nature GPF length optimal plan In experiments agent initially home goal sated The initial state varies respect ingredients available home things agent knows cook Preferences reﬂect type food agent like eat agent obtains meal Most GPFs contained multiple TPFs APFs domain warrant LTL nesting Most GPFs contained eventuallyocc formulae GPFs differed respect formulae ground quantiﬁed contained conditionals Most optimal plans length 6 The preferences expressible GPFs diverse form complexity draw conclusions correspondence size GPF formula scalability planner Much depends speciﬁcs problem instance 12 7 We ran early version PPLAN simple school travel example presented 59 unable comparative statistics order compare approaches M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1325 PPLAN PPLANC BFS DFS PPLAN PPLANC BFS DFS Test 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 l 2 3 2 2 2 3 3 2 2 4 2 2 6 2 3 3 3 2 2 3 6 2 2 3 2 3 3 3 3 3 NE 7 55 7 8 9 52 55 61 51 29 2 3 171 3 54 51 64 8 10 55 108 7 8 585 9 55 15 15 16 15 l 2 3 2 2 2 3 3 2 2 4 2 2 6 2 3 3 3 2 2 3 6 2 2 3 2 3 3 3 3 3 NE 7 10 7 8 9 22 10 22 21 19 2 3 43 3 10 21 12 8 10 10 54 7 3 151 3 10 15 15 16 15 l 2 3 2 2 2 3 3 2 2 4 2 2 2 3 3 3 2 2 3 4 2 2 3 2 3 2 3 3 2 NE 61 426 51 61 71 432 426 61 51 1975 51 61 61 495 408 421 61 82 426 2479 51 51 408 61 426 71 408 495 61 l 6 7 6 6 7 7 7 7 6 7 6 7 7 7 6 7 7 7 6 6 3 6 7 7 7 7 7 NE 481 395 406 481 510 414 395 395 406 1113 406 461 389 377 481 590 395 1688 406 406 385 481 395 377 389 461 395 Test 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 l 3 2 3 3 3 5 5 5 4 4 5 5 2 4 3 4 4 5 3 7 2 7 2 3 3 4 7 6 6 3 NE 15 8 68 15 408 13 29 22 29 29 49 23 597 27 55 60 59 28 65 115 7 57 702 55 597 37 257 1254 51 753 16 878 l 3 2 3 3 3 6 6 5 4 4 5 5 2 5 3 4 4 6 3 5 2 7 2 3 3 4 6 6 6 3 NE 15 3 23 15 119 15 11 22 19 19 29 23 169 31 10 8 7 11 12 36 7 37 163 10 169 22 19 137 85 8157 340 l 3 2 3 3 3 2 4 2 4 4 2 2 3 4 4 4 3 2 4 2 2 3 4 4 3 NE 426 51 408 426 408 60 1975 61 1975 1975 71 51 432 2537 2088 2088 432 51 2417 61 61 505 2479 2599 432 l 7 6 3 7 7 7 7 6 6 6 7 7 2 7 7 7 7 7 7 6 7 2 7 3 7 7 NE 395 406 385 395 389 432 1113 481 11 767 11 767 15 049 510 402 414 1526 1015 1015 414 2540 406 1617 477 395 493 1688 1597 Fig 1 Plan length l nodes expanded NE PPLAN PPLAN augmented hard constraints PPLANC breadthﬁrst search BFS depthﬁrst search DFS The symbol indicates memory 1 GB limit Overall results positive In 55 60 test cases PPLAN expanded fewer nodes BFS DFS generally signiﬁcant margin order magnitude The cases BFS DFS outperformed PPLAN cases short koptimal nonideal plan In cases PPLAN quickly plan continue search order ensure better plan existed The poor performance PPLAN relative BFS DFS cases result experimental setup gave BFS DFS unfair advantage supplying koptimal weight If PPLAN received input resulted larger number expanded nodes In cases PPLAN expanded comparatively large number nodes 10000 This speaks diﬃculty task A good way cope problem add domaindependent control knowledge reduce search space TLPlan In order test idea reran PPLAN test suite time pruning nodes partial plans contained consecutive drive actions containing orderTakeout orderRestaurant cook actions immediately followed eat action As results adding simple pieces control knowledge allowed PPLAN ﬁnd plan expanding far fewer nodes process Taken feel results speak effectiveness evaluation function guiding search combining approach domaindependent control knowledge means pruning search space Regarding running times plotted Fig 2 rough correspondence numbers nodes expanded PPLAN instances running time Interestingly DFS generally expands nodes PPLAN comparatively fast This consequence knowing koptimal value If value incrementally long search horizons need explored exhaustively ﬁrst optimal planvalue It interesting note test cases 24 43 53 55 60 PPLAN demonstrates poorer performance BFS DFS Recall PPLANs bestﬁrst search explores plans based weight length As consequence PPLAN led astray investigating long plan low weight best plan end shorter plan higher weight However behaviour appears occur infrequently heuristic generally leads signiﬁcantly improved performance Also note BFS ﬁnds shorter plans PPLAN cases 31 33 34 36 37 39 48 49 52 54 PPLAN uses plan length sorting criterion length considered ﬁrst weights equal However goal second weight newly created tuple plan set real weight lower pessimistic weight Therefore plan returned plans weight shorter The comparison DFS shows reason PPLANs performance improvement BFS We conclude implemented heuristics provide valuable search guidance 1326 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 Fig 2 Runningtime PPLAN PPLAN augmented hard constraints PPLANC breadthﬁrst search BFS depthﬁrst search DFS Missing values indicate memory 1 GB limit 52 Beyond PPLAN Our original experimental results PPLAN encouraging realized experience IPC planners In particular stateoftheart planners use form heuristic search based relaxed plan graph RPG provides good estimate distance current state state goal reached 40 Of course goal case preference LTL formula diﬃcult form estimate Indeed analyzing earlier PPLAN results clear optimistic evaluation function lacking ways First certain cases distinguish partial plans progress satisfying preferences Second importantly evaluation function provided estimate number actions required satisfy TPFs eventuallyϕ way determining actions select progress satisfaction preferences To illustrate point consider PPLAN evaluates following GPF Φ taken 5 cid4 cid5 eventuallyϕ1 eventuallyϕ2 v 1 cid18 alwaysϕ3v 2 ϕ1 occcleankitchen ϕ2 occeatpizza ϕ3 athome Our PPLAN optimistic evaluation assumes optimistically component predicates TPF true new actions added proven false As TPF eventuallyϕ1 eventuallyϕ2 true ϕ1 ϕ2 actually satisﬁed eventuallyϕi falsiﬁed There hope ϕi achieved subsequent state plan Thus distinction partial plan ϕ1 ϕ2 achieved measure progress satisfaction TPF This lack ability distinguish progress satisfaction TPF dependent form TPF In contrast TPF alwaysϕ3 falsiﬁable soon ϕ3 false state To evaluate APFGPF assign weight equal smallest weight TPF optimistically satisﬁed Since TPF eventuallyϕ1 eventuallyϕ2 optimistically satisﬁed example Φ evaluated weight v 1 From observations shortcomings PPLAN evaluation function Baier McIlraith explored lookahead heuristics developed address deﬁciencies The results examination ported 5 First LPP GPF preferences decomposed smaller constituent pieces translated following 2 parameterized nondeterministic ﬁnitestate automata accepting conditions corresponded satisfaction component preference formulae For new planning instance planning domain description augmented description automata representing preference formulae state automaton governed transitions automaton states From set inadmissible admissible heuristics proposed guide search satisfaction goal preferences These heuristics exploited RPG automataenhanced domain able measure progress satisfaction LTL formulae Since use inadmissible heuristics caused lose guarantee ﬁrst plan returned optimal incremental approach search plan shown algorithm terminated plan optimal Leveraging insights PPLAN power pruning work developed sound pruning strategy allowed inferior partial plans identiﬁed pruned search space reducing search space signiﬁcantly M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1327 Experimental results comparing work PPLAN algorithm presented showed instances order magnitude reduction number nodes expanded optimal plan This attributed great heuristics ability guide search going forward turn result compiling LTL formulae form exploit lookahead heuristic RPG heuristic The optimistic evaluation function operates situations exploited IPC2006 planner great gain discussed Section 8 6 Specifying preferences complex actions In previous sections deﬁned LPP language specifying rich temporally extended preferences proposed algorithm computing optimal preferencebased plans In section return language proposing extension complex actions One notable features LPP occa statement allows speciﬁcation preferences partic ular actions We extend LPP additional constructs order allow expression preferences concerning occurrence complex actions actions capture orchestration multiple primitive complex actions wellknown programming constructs Dine restaurant complex action comprising actions agent current location restaurant orders eats meal ﬁnally returns agent original location In practical circumstances people think terms complex actions preferred ways achiev ing given goal It follows allowing users preferences directly terms complex actions instead requiring reformulate preferences terms atomic actions help simplify preference elicitation process Furthermore provision procedural complex actions effectively guide search goal complex actions form underconstrained prototypical plans For specifying reasoning complex actions use Golog language semantics 44 Golog pro gramming language deﬁned situation calculus allows user specify programs set legal executions speciﬁes subtree tree situations basic action theory Golog Algolinspired syntax extended ﬂexible nondeterministic constructs later transformed speciﬁc sequences actions planner This tegration planning programming proved useful variety diverse applications including museum tourguide robots 18 Web service composition 49 soccer playing robots 30 61 Golog The set Golog programs procedures inductively deﬁned following constructs appearing δs Golog programs procedures ϕs pseudoﬂuent expressions These represent situation calculus formulae situation terms suppressed The expression ϕs denotes instantiation ϕ occurring ﬂuents relativized situation s ϕ δ1 δ2 ϕ δ1 δ2 ϕ δcid5 δ1δ2 π vδ δ primitive action test condition ϕ sequence conditional loops nondeterministic choice nondeterministic choice argument nondeterministic iteration In addition introduce term denote action In order avoid ambiguity follows programs built constructs LPP programs As example following program preferred way going restaurant cid2 π r dineInRestr closehome r cid2 cid3 walkhome r π yorderRestaurantr y eat y walkr home cid3cid3 drivehome r π yorderRestaurantr y eat y driver home cid2 G1 The program begins picking dinein restaurant Then chosen place close home prescribes walk order eat return home Otherwise walking replaced driving The example shows nondeterminism achieve subgoal hasIngredientsm Using construct program leaves planner ﬁnd sequence actions satisfy subsequent condition The following program describes sensible procedure ﬁxing meal home cid2cid2 πm cid3 mealm knowsHowToMakem cid3 hasIngredientsm cookm eatm G2 1328 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 According program starts selecting meal knows ensuring necessary ingredients involve trip grocery store meal prepared ﬁnally eaten Originally semantics Golog programs deﬁned recursive macro expansion programs formulae situation calculus Such evaluation semantics requires evaluate entire program makes diﬃcult use context planning This reason paper adopt alternative semantics Golog programs socalled transition semantics introduced 21 shown equivalent evaluation semantics The transition semantics deﬁned terms possible transitions programsituation pairs called conﬁgurations Roughly speaking conﬁguration δ s lead conﬁguration δcid5 s cid5 executing single step program δ situation s reach situation s remaining program δcid5 A second predicate Final characterize conditions program executed completely The transition semantics wellsuited purposes permits stepbystep evaluation programs written Transδ s δcid5 s Formally aforementioned predicates Trans Final deﬁned following axioms 21 x denotes denotes action arguments evaluated s ϕs denotes truth value formula ϕ s δ v substitution occurrences v δ x cid5 cid5 cid2 s δ Trans cid2 Trans s δ cid2 Trans cid2 ϕ s δ cid5 δ1 δ2 s δ Trans cid5 cid5 cid5 cid5 s s cid5 s cid5 s cid2 Trans Trans ϕ δ1 δ2 s δ cid2 ϕ δ1 s δ cid2 δ1δ2 s δ π vδ s δ Trans cid2 Trans cid2 Trans δ s δ cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 s s s s s cid3 cid3 cid3 cid3 cid3 cid3 cid3 cid3 cid3 cid5 nil s cid3 cid2 cid5 s cid2 cid5 s cid3cid3 cid5 nil s cid2 Possa s δ ϕs δ Possa s δ cid5 nil Finalδ1 s Trans γ δ cid2 ϕs Trans cid2cid2 cid2 cid2 cid3cid3 cid5 cid5 s δ2 s δ cid2 cid5 γ δ2 Trans δ1 s γ s cid3cid3 δ1 s δ cid3 cid2 s cid2 cid2 cid2 cid5 cid5 cid3cid3cid3 cid5 Trans cid5 cid5 cid3 cid2 ϕs γ Trans xTrans cid2 γ Trans cid2 s cid5 δ1 s δ δ v x s δ cid2 δ s γ s s cid5 δ1 s γ s cid2 Trans cid3 cid5 cid3 cid5 cid3 δ cid5 γ δ cid2 cid3cid3 cid5 δ2 s δ ϕs Trans δ cid5 s cid3 cid5 γ ϕ δ1 cid5 s cid3 cid5 δ2 s δ Finalnil s Finalδ1 δ2 s Finalδ1 s Finalδ2 s cid2 Finalif ϕ δ1 δ2 s cid2 Final ϕ δ cid5 s cid2 cid3 ϕs Finalδ1 s cid3 s ϕs Final δ cid2 cid5 cid3 cid3 ϕs Finalδ2 s Finalδ1δ2 s Finalδ1 s Finalδ2 s Finalπ vδ s xFinal cid3 δ v x s cid3 cid2 cid2 Final δ s Trans Final enable reason satisfaction procedural constraints similar satisfaction temporal constraints expressed trajectory property formulae described earlier By transitive closure Trans deﬁne new predicate Do allows express fact program δ terminate denoted Trans situation s cid2 Do executed situation s cid3 Final def δ δ s δ δ s s Trans s s cid3cid3 cid3 cid2 cid2 cid2 cid5 cid5 cid5 cid5 cid5 cid5 cid5 cid5 satisfy δ alternatively s We s s describes complete execution δ s Since paper concerned ﬁnite situation terms equivalent saying sequence conﬁgurations 1 cid2 n D cid12 Transδi si δi1 si1 D cid12 Finalδn sn δ1 s1 δn sn δ1 δ s1 s sn s Given preference language Golog deﬁne semantics situation trajectories situation cal culus seamlessly integrated This enables speciﬁcation preferences occurrence complex actions deﬁned complete execution LPP programs describing actions cid5 δ cid5 62 Preferred programs We ready deﬁne preferences occurrence complex actions To end extend preference language LPP augmenting set trajectory property formulae follows Deﬁnition 61 Extended Trajectory Property Formula eTPF An extended trajectory property formula sentence drawn smallest set Bcid5 1 F Bcid5 2 R Bcid5 f F ﬁnal f Bcid5 3 4 If A occa Bcid5 ϕ2 5 If ϕ1 Bcid5 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1329 ϕ1 ϕ1 ϕ2 ϕ1 ϕ2 xϕ1 xϕ1 nextϕ1 alwaysϕ1 eventuallyϕ1 untilϕ1 ϕ2 6 If δ LPP program ϕ Bcid5 occCδ Bcid5 afterCδ ϕ Bcid5 Intuitively eTPF occCδ states program δ executed starting current state To express complex action δ executed point plan use eventually construct eventuallyoccCδ The eTPF afterCδ ϕ stipulates program δ executed ϕ holds situation δ terminates Note ϕ temporal formula For instance afterCcookx eventuallyocceatx describes set trajectories dish cooked eventually eaten Using possible state ϕ holds δ completes executing matter execution starts alwaysafterCδ ϕ Extending semantics TPFs eTPFs straightforward given deﬁnition program satisfaction cid4 occCδ cid4 afterCδ ϕ s s s s cid5 cid5 cid5 cid5 def def cid2 cid2 s1 s cid16 s1 cid16 s cid5 s1 s cid16 s1 cid16 s cid5 cid3 Doδ s s1 cid3cid2 Doδ s s1 ϕ cid5cid3 cid5 cid4 s1 s Note temporally extended properties coexist occurrence complex actions case prop erties applicable actions forming complex action For instance eTPF alwayscold eventuallyoccCG1 G1 denotes program speciﬁed states eventually program executed time execution agent feels cold Using afterC stipulate instance cooking home described procedure G2 dishes eventually cleaned cid2 cid2 G2 eventually afterC occcleanDishes cid3cid3 The remainder hierarchy preference formulae stays meaning change semantics TPF level require changes higher levels APFs GPFs AgPFs To refer preference formulae eTPFs instead TPFs use terms eAPFs eGPFs eAgPFs 63 Progressing programs The transition semantics presented Section 61 progression programs disguise To point clearer provide formal deﬁnition program progression In deﬁnition reference set cid2 cid5 cid3 δ doa s cid11 cid5 cid12 cid12 D cid12 Trans cid2 cid5 cid3cid13 cid5 δ s δ doa s δ consists possible remaining programs δcid5 having performed sequence program transitions primitive action given action starting given situation s The reason sequence program transitions single transition tests ψ change situation term Note cases set cid5cid5δ s possible transition contain single element unique possible transition One pathological example set contains element cid5cid5aa b doa S0 nil b Deﬁnition 62 Progression LPP program Let s situation let δ LPP program The progression occCδ afterCδ ψ s given cid6 If ϕ occCδ ρsϕ If ϕ occCtransδ ρsϕ If ϕ afterCδ ψ ρsϕ If ϕ afterCtransδ ψ ρsϕ D cid12 Finalδ s TRUE occCtransδ cid9 δcid5cid5cid5δs ρsoccCδcid5 cid6 ρsψ afterCtransδ ψ cid10 δcid5cid5cid5δs ρsafterCδcid5 ψ D cid12 Finalδ s Recall disjunction set false conjunction set true Hence situation term execution program δ occCδ fail afterCδ ψ trivially hold In deﬁnitions use auxiliary constructs similar occLast called occCtrans afterCtrans These like occLast required onestep bookkeeping statement occCa b states sequence actions 1330 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 b executed current situation regards future need track property evaluate partially step Thus occCtransa b requires action situation term describes transition sequence transitions program primitive action In occCtrans afterCtrans refer set possible partial program executions This mainly tech nical reasons In general given sequence primitive actions possible sequence conﬁgurations program contained sequence situations corresponds action sequence However pathological cases possible conﬁguration sequences possible remaining programs For instance case program aa b singleaction sequence cf Here program program b remains Ambiguities kind undesirable programs rewritten accordingly nilb example 64 Planning preferred programs In order planning algorithm able accept preference formulae involving complex actions need ﬁne optimisticpessimistic satisfaction extended trajectory property formulae providing optimistic pessimistic interpretations new constructs For occC construct optimistically assume incompletely executed program eventually com pleted cid4 occCδ s s cid5 opt def cid5 cid2 s1 s cid16 s1 cid16 s cid5 cid2 cid5 cid3cid2 δ Trans cid2 δ s δ cid5 s1 cid2 cid3 cid3 cid2 δ cid5 s1 Final s1 s cid3cid3cid3 cid5 On hand pessimistic assume incompletely executed programs com pleted Hence pessimistic evaluation coincides original semantics completed program execution cid4 occCδ s s cid5 pess def cid5 cid2 s1 s cid16 s1 cid16 s cid3 cid5 Doδ s s1 Regarding postconditions programs afterC optimistic assumption program execute completion evaluate condition optimistically cid4 afterCδ ψ s s cid5 opt def cid5 cid2 s1 s cid16 s1 cid16 s cid3cid2 cid5 Doδ s s1 ψ cid5 opt cid3 cid5 cid4 s1 s The pessimistic assumption completed execution condition hold Hence order condition pessimistically satisﬁed possible executions program termi nate given situation interval cid4 afterCδ ψ cid5 pess def cid5 pess s s cid3cid2 cid2 cid3 cid4 cid5 cid5 s1 s cid16 s1 cid16 s cid2 cid5cid5 cid3δ Trans s cid5 Doδ s s1 ψ cid3 cid5 cid2 s cid5cid5 δ s δ s s cid5 cid5 cid2 s1 s cid3 cid5cid5 Theorem 63 Theorem 418 continues hold ϕ eTPF Φ eGPF Proof Refer Appendix E cid3 Given theorem algorithm described Section 5 readily compute preferred plans case preferences refer complex actions preferences expressed extended general preference formula8 7 Related work There growing issue represent reason preferences AI In follows situate work presented paper respect related work representation preferences particular attention designed represent preferences planning We discuss literature generation preferred plans situating contributions context work 71 Preference languages The literature preference languages extensive originating ﬁeld economics AI In comparing work AI preference languages distinctions raise relate preference formalisms ordinal qualitative quantitative model temporal preferences solely static preferences 8 The algorithm easily extended treat aggregated preference formulae associating tuples weights situations explained Section 51 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1331 formalism propositional ﬁrst order induces complete preorder possible outcomes degree incomparability ordering In context language qualitative models temporal preferences ﬁrst order induces complete preorder As criteria comparison CosteMarquis et al 20 evaluate propositional logicbased preference languages respect expressiveness succinctness The issue expressiveness concerned nature preorders encoded preorders complete preorders As noted LPP design encode complete preorder atomic preference formula language represent complete preorders We express partial incomplete preorders We argue preferencebased planning restriction complete pre orders reasonable desirable First feel restriction great preference frameworks adopt restriction For example decision theory completeness agents preferences taken axiom 63 Second importantly feel disadvantages stemming restriction complete preorders compensated ease comparison different plans Indeed formalisms partial orders encoded problem deciding outcome preferred shown NPcomplete 13 Succinctness evaluates relative space eﬃciency languages succinctly preference relation ordering expressed language In 20 showing orderings expressible language trans lated language polynomially large increase size With respect LPP demonstrate following mapping preference language R pen 20 ranks outcomes sum penalties unsatisﬁed preferences polynomially translated equivalent AgPF language cid11 cid14αi G icid15 1 n cid13 cid4 sum cid2 cid3 G 10 cid18 G 1αi Gn0 cid18 Gnαi prio R Z This shows LPP succinct Rpen Moreover exists polynomial translations languages cond Rpen 20 follows LPP succinct languages Overall Rbo prio Rlexi positive results LPP expressive able generate complete preorders compact ﬁve preference languages 20 expressivity9 We point domaindependent approaches like comparisons based domainindependent criteria relevant real test language represent types preferences designed CPNets A widely adopted language studying user preferences AI propositional CPnets formalism 13 CPnets enable description conditional ceteris paribus statements user preferences user prefers red wine meat served white wine ﬁsh served things equal User preferences represented graphical notation compact reﬂects conditional independence dependence statements Unlike LPP CPnets restricted static ordinal statements preferences As CPnets express temporal preferences express relative importance different preferences The CPnets formalism simple elegant achieves expense expressiveness There high degree incomparability different states assumption ceteris paribus In 64 Wilson extends CPNets stronger statements enable statement preferences irrespective value variables Use preference statements supports determining complete preorder outcomes comes closer approach proposed LPP static ordinal QCL RKBs possibilistic logic Other noteworthy work includes Brewka qualitative choice logic QCL 17 This preference framework designed represent preferences alternatives induces complete preorder models QCL developed speciﬁcally planning provides subset expressive power preference language In 16 Brewka proposes ordinal preference language expresses complex preferences models terms ranked knowledge bases RKBs RKBs originally proposed default reasoning In 2006 Feldmann Brewka Wenzel applied work planning proposing extensions PDDL support deﬁnition preferences RKBs 29 In extensions preferences ﬁnal state plan There temporally extended preferences In related earlier work Brekwa uses variant QCL language perform preferencebased planning answer set optimization language called PLD 15 The basic elements PLD rules code contextdependent preferences answer sets More complex preference formulae formed different aggregation operators sum ranked set inclusion ranked cardinality pareto lexicographic order Finally possibilistic logic approach preferences 8 notable like LPP proposes qualitative preference framework allowing relative importance preferences speciﬁed The approaches discussed far consider temporal preferences unable express types preferences In follows review preference languages designed task preferencebased planning related tasks 9 We know relationship LPP ﬁfth language R H based Hamming distance models likely polynomial translation R H LPP R H involves weighted sums LPP designed handle arithmetic operations possibly simple sums 1332 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 Planningoriented preference languages In 2223 Delgrande Schaub Tompits developed useful framework expressing preferences causal reasoning planning To end proposed general query language histories sequences interleaved states actions This language unlike TPFs Building deﬁne second language supports expression preferences binary relation histories From base languages explored socalled choice temporal preferences extended language different aggregate features One argued beneﬁts base framework ability encode preference languages aside obvious distinction language ﬁrst order theirs propositional notions constructs language nicely expressed framework In particular TPFs limited ﬁnite domains encoded query language However APFs encoded second preference language capacity denote relative strength preferences Their framework capacity characterize diversity aggregation techniques similar More generally framework proposed papers fundamental differences LPP view underline merits situation calculus The histories employed framework ﬁnite sequences alternating states actions In contrast situation calculus foundational axioms induce tree situations conjoined domainspeciﬁc action theory characterize space possible situations follow domain axiomati zation As preferences situations entailed domain axiomatization comparison speciﬁc ﬁnite histories work PP Most noteworthy related work Son Pontelli 5960 developed propositional language PP planning preferences implementation answerset programming ASP The original PP language described 59 served starting point development language adopted idea deﬁning language terms hierarchy formulae adopted nomenclature BDF use TPF APF GPF augmenting AgPF Despite similarity names signiﬁcant differences preference languages terms syntax semantics In particular language ﬁrst order affords far compact simple expression preferences It enables expression preferences unnamed objects important online planning groundings known priori Planning Web services good example execution plan provide knowledge objects planner preferences speciﬁc ﬂights hotels case Web travel planning Furthermore language qualitative simply ordinal allowing express example TPF respectively BDF strongly preferred opposed providing preference ordering properties At GPF level language includes conditional preferences useful cf CPnets Like PP language notion General And Conjunction General Or Disjunction provide different semantics constructs According PP s semantics order trajectory t1 preferred trajectory t2 respect General And preference trajectory t1 strictly preferred t2 component preferences For General Or require t1 preferred t2 component preferences strictly preferred t2 component preference We feel natural ways interpreting conjunction disjunction For example expect fully satisfying component preferences ensure satisfaction disjunction follow PP semantics In contrast semantics keeping Boolean connectives constructs names Moreover semantics induces complete preorder semantics PP s general preferences leads great incomparability plans Finally AgPF level provide methods aggregating preferences reviewing work compelling useful claim usefulness veriﬁed usability study Son Pontelli implemented planner answerset programming variety blackbox ASP solvers In later paper overview encode preferences exploit answerset optimization engines PDDL3 Also comparison LPP PDDL3 34 Following description 36 PDDL3 developed Gerevini Long extension Planning Domain Deﬁnition Language PDDL 48 provides rich language deﬁning hard constraints user preferences planning PDDL3 designed 5th International Planning Competition IPC2006 ﬁrst international competition include tracks preferencebased planning There number commonalities PDDL3 LPP ultimately fundamental differences In particular PDDL3 quantitative qualitative preference language Plans evaluated respect maximization minimization numeric objective function composed weighted linear sum satisfac tion violation individual preferences Like LPP individual preferences PDDL3 described properties plan trajectories satisﬁed violated plan However preference formulae quantiﬁed way count taken number individuals violate preference This useful extension integrated LPP For example preference ingredients meal making fresh plan uses 5 fresh ingredients 2 frozen desirable plan uses 1 fresh 6 frozen M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1333 fully satisﬁes preference This example course uncovers problem occur counting If meals compared different numbers ingredients achieve intended interpretation counting count need normalized total number ingredients different meals PDDL3 Preferences plan trajectories PDDL3 temporally extended unlike LPP PDDL3 allow arbitrary nesting LTL formulae It allow expression preferences action occurrences important feature LPP However PDDL3 number features LPP In par ticular preferences related speciﬁc times I like eat dinner 8 PM 9 PM There precondition preferences state preferences desirable hold state action executed One use specify soft precondition record number times action executed preference satisﬁed Recently PDDL3 extended include preferences decompositions hierarchical task network HTN tasks 56 This work application web service composition motivates conceptually related extension LPP complex actions Other Finally variety work uses quantitative preferences planning temporal reasoning This includes Eiter et als work answer set planning respect plan length numeric action costs 27 work Rossi colleagues reasoning temporal soft constraints 65 Haddawy Hanks early work decisiontheoretic utility function guide planning 38 course extensive research decisiontheoretic planning MDPs 52 The quantitative nature frameworks makes preference elicitation diﬃcult This work decided focus qualitative preferences expressive ordinal preferences easier elicit quantitative preferences As useful middle ground Fritz McIlraith integrate qualitative quantitative preferences agent programming framework The authors express qualitative preferences restricted version LPP 31 72 Preferencebased planners The previous subsection noted efforts generate preferred plans related speciﬁc languages described Here provide broad overview noteworthy work development preferencebased planners Detailed descriptions planners provided survey article preferencebased planning Baier McIlraith 6 The interested reader directed Work decisiontheoretic planning notwithstanding ﬁrst pieces work generating preferred plans Myers colleagues SRI advisable planners Myers Lee 50 proposed means generating preferred plans biases guided planner plans certain attributes This followed 2004 work related problem partial satisfaction planning PSP called oversubscription planning 6255 9 Kambhampati colleagues developed number PSP planner including Sapa bboplp 10 In PSP planners planning problem cast task ﬁnding plan maximal beneﬁt given association utility facts costs actions The planners differ search solutions alternatively forwardchaining backwardchaining incremental branchandbound linear programming 62 Yochan 62 AltAlt PS PS PS As observed Section 1 2006 biennial International Planning Competition included track planning preferences speciﬁed PDDL3 This resulted development highly optimized preferencebased planners The planners differentiated respect complexity preferences handle starting ﬁnal state preferences adding temporally extended preferences ﬁnally extended include complex metric preferences Most planners form heuristic search order compute preferred plans The best comparators PPLAN planners plan temporally extended preferences HPlanP Baier et al 4 planner In HPlanP temporally extended preferences compiled ﬁnalstate preferences representing parameterized nondeterministic ﬁnite state automata Planning performed branch bound search incrementally generating plans increasing quality HPlanP uses portfolio admissible inadmissible heuristics guide search admissible heuristic soundly prune partial plans poorer quality plan previously computed By pruning search space HPlanP able cases search space exhaustively guarantee optimality Also note planners Edelkamp colleagues mipsbdd 24 mipsxxl 25 The optimal planner applies bidirectional breadthﬁrst search encoding states binary decision diagrams The heuristic planner based enforced hill climbing Both compile temporally extended preferences grounded Büchi automata treated ﬁnalstate preferences Finally SGPlan5 41 searchbased planner plan temporally extended preferences Unlike planners described SGPlan5 searches plan constraint partitioning decomposing original planning problem subproblems This technique stems treating preferencebased planning problem standard optimization problem objective function minimize makespan plan We remiss mention related efforts build preferencebased planners straint satisfaction problem CSP solver satisﬁability SAT solver Like PPLAN planners koptimal Similarly planners compete stateoftheart competitionoptimized planners 1334 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 However contrast PPLAN planners plan temporally extended preferences In 2005 Brafman Chernyavsky developed PrefPlan preferencebased planner CSP solver 14 Preferences speciﬁed possible goal states TCPnets A TCPnet tradeoffenhanced CPnet allows user express priorities variables The notable limitation TCPnets relative LPP express temporal prefer ences suffer incomparability states CPnets Their approach planning compile problem equivalent CSP problem imposing variable instantiation constraints CSP solver according TCPnet This promising method planning clear extend temporal preferences satplanP 35 Giunchiglia Maratea extension awardwinning Satplan planner 42 able plan ﬁnalstate preferences calling external SAT solver The approach similar PrefPlan sense variable ordering imposed propositional variables corresponding ﬁnalstate preferences way preferred plans explored ﬁrst SAT solver Preferences satplanP deﬁned qualitative quantitative language In qualitative language preference ordering plans induced partial order properties ﬁnal state In quantitative language hand preference ﬁnal state associated weight 8 Closing remarks In paper addressed problem preferencebased planning To end proposed LPP expressive ﬁrstorder language specifying domainspeciﬁc qualitative user preferences LPP supports expression temporally extended preferences states actions actions primitive complex form Golog complex actions In contrast ordinal qualitative preference formalisms yield signiﬁcant incomparability LPP provides complete ordering plans computationally advantageous preferencebased planning LPP supports speciﬁcation relative strength users preferences This acknowledged number practitioners desirable property preference languages realworld applications The semantics LPP described situation calculus In situation calculus executable situation corresponds possible partial plan executable situations described model domain theory means preference situation expressed language The situation calculus semantics facilitated extension LPP Golog complex actions The LPP language proposed 11 begun garner researchers For example Fritz McIlraith combined LPP quantitative preferences represented utility functions agent programming language 31 The resulting program searched quantitatively optimal plan space qualitatively best plans LPP exploited diverse applications including speciﬁcation user preferences customization web service composition integrated Golog interpreter Sohrabi et al 58 speciﬁcation goals software requirements engineering Liaskos et al 4546 Giunchiglia Maratea discuss use LPP order extend work preferencebased planning satplanP temporally extended preferences 35 Sohrabi McIlraith integrated LPP HTN planner 57 The extension LPP include preferences complex actions included works relevant enhance applications In addition LPP proposed approach computing preferred plans bounded bestﬁrst search forward chaining planner Key components approach exploitation progression eﬃciently evaluate levels preference satisfaction respect partial plans development admissible evaluation function guarantees optimality bestﬁrst search We implemented planner PPLAN evaluated experimentally PPLAN written Prolog intended stateoftheart preferencebased planner perform terms planning time Nevertheless experimental evaluation demonstrated admissible evaluation function informative generally expanding far fewer nodes breadth ﬁrst search Also contrast stateoftheart IPC planners PPLAN returns optimal plan While PPLAN highly optimized planner aspects PPLAN approach starting impact In particular heuristic evaluation function reported 11 exploited HPlanP state oftheart preferencebased planner received distinguished mention IPC2006 HPlanP heuristic portfolio different heuristics applied different IPC domains No heuristic strategy worked best domains heuristic best domains successfully combination inadmissible heuristics domains 4 Perhaps importantly cases HPlanP informative inadmissible heuristic guide search admissible heuristic soundly prune inferior partial plans branch bound search strategy This enabled HPlanP signiﬁcantly reduce search space cases search exhaustively plan provably optimal The work presented paper provides formal foundation specifying generating preferencebased plans Although work basis situation calculus language approach planning amenable integration existing planners planning support diversity reasoning tasks employ preferences M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1335 Acknowledgements We gratefully acknowledge support Natural Sciences Engineering Research Council Canada NSERC Discovery grant program Undergraduate Student Research Award USRA program We like thank anonymous referees detailed thorough comments Jérôme Lang helpful comments earlier paper describing work Finally gratefully acknowledge Shirin Sohrabi Araghi work implementation PPlan Appendix A Axiomatization dinner example Here provide formal axiomatization dinner domain basic action theory D situation calculus A STRIPSstyle speciﬁcation domain 12 Axioms marked presented exposition purposes experiments Recall basic action theory comprises sets domain dependent axioms action precondition axioms Dap successor state axioms DSS axioms describing initial situation S0 DS0 set unique axioms actions Duna The straightforward deﬁne shown Action precondition axioms Dap These form Poss Acid3x s Π Acid3x s Π Acid3x s formula free variables cid3x s Following notational convention established Reiter 53 free variables situation calculus axioms assumed universally quantiﬁed outside noted cid2 Poss Poss drivex y s cid2 walkx y s cid2 Poss cookx s cid2 Poss eatx s buyIngredientsx s cid2 Poss cid2 orderTakeoutx y s Poss cid2 orderRestaurantx y s Poss cid3 cid3 cid3 cid3 cid3 cid3 cid3 locationx location y x cid11 y atx s locationx location y x cid11 y atx s mealx knowsHowToMakex athome s hasIngredientsx s kitchenCleans cid2 cid2 cid3cid3 y mealx y s readyToEatx y s mealx hasIngredientsx atstore s mealx takeOutRest y onMenux y athome s mealx dineInRest y onMenux y y s PosscleanDishes s athome s Effect axioms translated successor state axioms DSS Reiters solution frame problem 53 pp 3032 We provide effect axioms successor state axioms tend easier understand human readers These positive form γ F cid3x s F cid3x doa s negative form γ F cid3x s F cid3x doa s γ state conditions action makes ﬂuent F true respectively false executed situation s γ cid3 doa s cid3 x home doa s cid3 x doa s cid2 cid3 y doa s cid2 cid2 cid3 x doa s cid3 y doa s cid2 cid3 x doa s cid2 drivex y drivex y walkx y walkx y cid2 isSnowings walkx y cold cookx readyToEat cookx hasIngredients cid2 cookx kitchenClean cid3 eatx sated doa s y s eatx readyToEat buyIngredientsx hasIngredients cid2 orderTakeoutx y readyToEat orderRestaurantx y readyToEat cleanDishes kitchenClean cid3 doa s cid2 cid2 cid2 cid2 cid2 cid3 x y doa s cid3 x doa s cid2 cid3 x home doa s cid3 x y doa s cid3 doa s 1336 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 Initial theory DS0 Unless stated text use following values ﬂuents initial state making closed world assumption athome S0 kitchenCleanS0 hasIngredientscrêpes S0 In addition include DS0 following axioms situationindependent relations Meals mealx x pizza x tacos x fajitas x spaghetti x sweetsourpork x crêpes x duck x salad Types meals vegetarianx x salad italianx x spaghetti x pizza mexicanx x tacos x fajitas frenchx x crêpes x duck chinesex x sweetsourpork Locations locationx x home x store x italianRest x frenchRest x chineseRest x pizzaPlace closex y x home y italianRest Types restaurants takeOutRestx x chineseRest x pizzaPlace dineInRestx x italianRest x frenchRest Restaurant offerings onMenux y y italianRest x spaghetti x pizza y frenchRest x crêpes x duck y pizzaPlace x pizza y chineseRest x sweetsourpork Knowledge recipes knowsHowToMakex x crêpes x spaghetti x tacos x fajitas x salad Appendix B Proof Theorem 413 Proof The proof proceeds induction structural complexity ϕ We assume stated given situations s1 s2 doa1 s1 n cid3 1 s2 doan s3 Case 1 ϕ f F D cid12 f s1 s2 iff D cid12 f s1 iff ρs1 f TRUE iff ρ s1s3 iff D cid12 ρ f TRUE s1s3 f s2 s2 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1337 The equivalence line 1 follows semantics TPFs For forward direction equivalence lines 1 2 use Deﬁnition 48 backwards direction use fact progressed ﬂuent equals TRUE ﬂuent satisﬁed situation The forwards directions equivalences lines 2 3 lines 3 4 obvious backwards directions use fact progressed ﬂuents TRUE FALSE plus fact TRUE FALSE unaffected progression Case 2 ϕ r R D cid12 rs1 s2 iff D cid12 r iff ρs1 r TRUE iff ρ s1s3 iff D cid12 ρ r TRUE s1s3 rs2 s2 For backwards direction use fact nonﬂuent relations progressed TRUE FALSE unaffected progression Case 3 ϕ occa We prove case steps ﬁrst case n 1 case n cid3 2 n 1 b n cid3 2 D cid12 occas1 s2 iff s2 doa s1 iff D cid12 occLastas2 s2 cid2 iff D cid12 ρ cid3 occa s2 s2 s1s1 D cid12 occas1 s2 iff D cid12 doa s1 cid16 s2 cid3 cid5 cid5 doa1 s1 s2 TRUE TRUE cid3cid3 cid5 cid2 iff doa1 s1 doa s1 cid2 doa1 s1 iff s s cid4 iff D cid12 occLasta iff ρdoa1s1 iff ρdoa1s1 iff ρ s1s3 iff D cid12 ρ cid3 occLasta ρs1 cid3 occa occa TRUE cid3 occa cid2 cid2 cid2 cid2 s1s3 s2 s2 For backwards direction use fact progression occa situations yields TRUE FALSE plus fact TRUE FALSE unchanged progression Case 4 ϕ occLasta D cid12 occLastas1 s2 iff D cid12 s cid2 cid5 cid5 cid3 s1 cid3 occLasta cid2 s TRUE cid3 occLasta cid2 TRUE cid3 occLasta cid2 iff ρs1 iff ρ s1s3 iff D cid12 ρ s1s3 s2 s2 For backwards direction utilize fact occLasta progresses Boolean constant TRUE FALSE stable progression Case 5 ϕ ﬁnal f TPF f F D cid12 ﬁnal f s1 s2 iff D cid12 f s2 iff D cid12 ﬁnal f s2 s2 cid3 iff D cid12 ρ s2 s2 ﬁnal f cid2 s1s3 1338 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 Case 6 ϕ ψ TPF ψ We assume result ψ result holds ψ D cid12 ψs1 s2 iff D cid11cid12 ψs1 s2 iff D cid11cid12 ρ s1s3 iff D cid12 ρ iff D cid12 ρ s1s3 ψs2 s2 s1s3 ψs2 s2 ψs2 s2 For equivalence line 1 use fact action theory D provides complete information initial situation means particular situation calculus formula γ D cid12 γ D cid12 γ Case 7 ϕ ψ1 ψ2 TPFs ψ1 ψ2 We assume result ψ1 ψ2 result holds ψ1 ψ2 D cid12 ψ1 ψ2s1 s2 iff D cid12 ψ1s1 s2 D cid12 ψ2s1 s2 ψ1s2 s2 D cid12 ρ cid3 ψ1 ρ ψ2 ψ1 ψ2s2 s2 iff D cid12 ρ s1s3 cid2 ρ iff D cid12 s1s3 iff D cid12 ρ s1s3 s1s3 s2 s2 s1s3 ψ2s2 s2 Case 8 ϕ ψ1 ψ2 As ψ1 ψ2 ψ1 ψ2 follows immediately cases 6 7 Case 9 ϕ xψ We assume result holds TPFs lower structural complexity ϕ In particular means assume result TPFs ψ cx D cid12 xψs1 s2 iff exists c C D cid12 ψ cxs1 s2 cid3 ψ cx iff exists c C D cid12 ρ cid2 ψ cx iff D cid12 cid14 s1s3 cid3 cid2 s2 s2 s2 s2 cid15 cid14 ρ s1s3 cid15 cC iff D cid12 ρs3 iff D cid12 ρs3 iff D cid12 ρ s1s3 ρdoa1s1 cid2 cid2 ρdoa1s1 xψs2 s2 cid16 cid3 cid2 ψ cx cid16 s2 s2 ρs1 cC cid3 ρs1 xψ cid3 s2 s2 Note backwards direction equivalence lines 2 3 uses fact D completely deﬁnes initial situation Case 10 ϕ xψ As xψ xψ follows directly Cases 6 9 Case 11 ϕ nextψ We proceed induction n difference length s1 s2 Our base case n 1 s2 doa1 s1 cid4 D cid12 nextψ cid5 s1 doa1 s1 cid5 cid4 doa1 s1 doa1 s1 iff D cid12 ψ iff D cid12 ρ cid2 nextψ s1s1 cid3cid4 cid5 doa1 s1 doa1 s1 Next assume result pairs situations s1 s2 doa1 s1 n k demonstrate result case n k D cid12 nextψs1 s2 iff D cid12 ψ iff D cid12 ρ iff D cid12 ρ iff D cid12 ρ cid4 doa1 s1 s2 cid5 doa1s1s3 doa1s1s3 cid2 ψs2 s2 cid2 cid2 ρs1 cid3 nextψ nextψ s2 s2 cid3cid3 s1s3 s2 s2 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1339 Case 12 ϕ alwaysψ We assume result ψ prove result holds alwaysψ The proof proceeds induction n difference length s1 s2 base case n 1 cid4 D cid12 alwaysψ cid5 s1 doa1 s1 cid4 cid5 s1 doa1 s1 cid4 ψ cid5 cid4 doa1 s1 doa1 s1 ψ cid5 doa1 s1 doa1 s1 cid5 cid4 doa1 s1 doa1 s1 ψ s1s1 ρs1 ψ alwaysψ alwaysψ We suppose theorem holds n k true s2 doa1 ak s1 cid5 doa1 s1 doa1 s1 cid5 doa1 s1 doa1 s1 s1s1 cid3cid4 cid3cid4 cid2 iff D cid12 ψ iff D cid12 ρ cid2 iff D cid12 iff D cid12 ρ cid4 D cid12 alwaysψs1 s2 iff D cid12 ψs1 s2 alwaysψ ψs2 s2 ρ cid3 ρs1 ψ alwaysψ ρdoa1s1 cid3 ρs1 ρdoa1s1 alwaysψ cid2 cid3 s2 s2 alwaysψ iff D cid12 ρ iff D cid12 ρs3 iff D cid12 ρs3 iff D cid12 ρ doa1 s1 s2 cid2 doa1s1s3 s1s3 cid2 cid3cid3 cid2 cid2 cid2 cid2 cid5 cid3 alwaysψ cid3 s2 s2 s1s3 s2 s2 s2 s2 Case 13 ϕ eventuallyψ Given eventuallyψ rewritten alwaysψ case follows immediately cases 6 12 Case 14 ϕ untilψ1 ψ2 We assume result ψ1 ψ2 prove result holds untilψ1 ψ2 We prove induction n difference length s1 s2 Our base case s2 doa1 s1 cid5 s1 doa1 s1 cid4 D cid12 untilψ1 ψ2 iff D cid12 s cid2 cid4 iff D cid12 ψ2 iff D cid12 ρ cid5 s doa s1 cid5 cid5cid3cid3 s cid3 cid2cid2 doa s1 s cid4 s1 cid16 s s cid16 doa s1 ψ2 cid4 cid5 cid2 s cid5 s cid5 ψ1 s1 cid16 s cid4 cid2 cid5 s1 doa1 s1 cid4 ψ2 s1s1 cid4 ψ2 cid2 ρs1 ψ2 doa1 s1 doa1 s1 cid5 s1 doa1 s1 cid5 ρ doa1 s1 doa1 s1 s1s1 cid3cid3cid4 ψ1 cid5cid3 cid2 cid2 iff D cid12 iff D cid12 ρs1 iff D cid12 ρ cid2 ρs1 ψ1 untilψ1 ψ2 cid5 doa1 s1 doa1 s1 cid5 doa1 s1 doa1 s1 cid3cid4 cid3cid4 untilψ1 ψ2 cid2 cid5 doa1 s1 doa1 s1 ψ2 cid4 doa1 s1 doa1 s1 cid5 cid4 doa1 s1 doa1 s1 ψ1 cid5cid3 untilψ1 ψ2 For equivalence lines 1 2 use fact s s1 s doa1 s1 In case ﬁrst line simpliﬁes ψ2s1 doa1 s1 case obtain ψ2doa1 s1 doa1 s1 ψ1s1 doa1 s1 s1s1 We prove result case n k assumption result holds case n k D cid12 untilψ1 ψ2s1 s2 iff D cid12 s cid2 cid5 s cid4 cid3 cid2cid2 cid5cid3cid3 s2 cid5 cid2 s s1 cid16 s s cid16 s2 ψ2s s2 cid5 s cid5 ψ1 s s1 cid16 s cid4 cid2 iff D cid12 ψ2s1 s2 ψ1s1 s2 untilψ1 ψ2 doa1 s1 s2 iff D cid12 ρ s1s3 cid2 ρ s1s3 cid2 ρdoa1s1 cid2 ρs1 cid2 cid3 untilψ1 ψ2 doa1s1s3 cid3 ρs1 ψ2 untilψ1 ψ2 cid3 ψ1s2 s2 ρ cid2cid2 cid3 untilψ1 ψ2 ψ2s2 s2 s2 s2 cid3 s2 s2 cid3 ρs1 ψ2 cid5cid3 cid2 cid2 cid3 untilψ1 ψ2 s2 s2 iff D cid12 ρs3 iff D cid12 ρs3 iff D cid12 ρ s1s3 cid3 s2 s2 Note equivalence lines 1 2 follows fact s s1 case line 1 simpliﬁes ψ2s1 s2 s cid11 s1 case line 1 gives cid5 cid5cid3cid3 cid2cid2 cid2 cid3 cid4 cid5 s doa1 s1 cid16 s s cid16 s2 ψ2s s2 s s1 cid16 s cid5 s cid5 cid2 s ψ1 s s2 way write ψ1s1 s2 untilψ1 ψ2doa1 s1 s2 1340 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 Case 15 ϕ TRUE ϕ FALSE Obvious D cid12 TRUE D cid11cid12 FALSE TRUE FALSE unaffected progression cid3 Appendix C Proof Theorem 418 Lemma C1 Let s situation sn doa1 s n cid3 0 collection situations ϕ TPF Then 0 cid2 cid2 j cid2 n D cid12 ϕs s jopt implies D cid12 ϕs siopt D cid11cid12 ϕs s jpess implies D cid11cid12 ϕs sipess Proof The proof proceeds induction structure trajectory property formulae Clearly ϕ F ϕ R ϕ ﬁnalψ assumption holds Also trivial case ϕ occa D cid12 occas s jopt j 0 entails 0 a1 In cases D cid12 occas siopt Similarly pessimistic case D cid11cid12 occas s jpess j 0 entails 0 cid11 a1 In cases D cid11cid12 occas sipess Now suppose assumption holds TPFs ϕ1 ϕ2 Then For conjunction D cid12 ψ1 ψ2s s jopt D cid12 ψ1s s jopt D cid12 ψ2s s jopt ih D cid12 ψ1s siopt D cid12 ψ2s siopt D cid12 ψ1 ψ2s siopt D cid11cid12 ψ1 ψ2s s jpess D cid11cid12 ψ1s s jpess D cid11cid12 ψ2s s jpess ih D cid11cid12 ψ1s sipess D cid11cid12 ψ2s sipess D cid11cid12 ψ1 ψ2s sipess For disjunctions D cid12 ψ1 ψ2s s jopt D cid12 ψ1s s jopt D cid12 ψ2s s jopt ih D cid12 ψ1s siopt D cid12 ψ2s siopt D cid12 ψ1 ψ2s siopt D cid11cid12 ψ1 ψ2s s jpess D cid11cid12 ψ1s s jpess D cid11cid12 ψ2s s jpess ih D cid11cid12 ψ1s sipess D cid11cid12 ψ2s sipess D cid11cid12 ψ1 ψ2s sipess We remark implication D cid12 ψ1 ψ2s s jopt D cid12 ψ1s s jopt D cid12 ψ2s s jopt line 1 follows fact D completely deﬁnes initial situation For negation D cid12 ϕ1s s jopt D cid11cid12 ϕ1s s jpess ih D cid11cid12 ϕ1s sipess D cid12 ϕ1s siopt D cid11cid12 ϕ1s s jpess D cid12 ϕ1s s jopt ih D cid12 ϕ1s siopt D cid11cid12 ϕ1s sipess Note D cid11cid12 ϕ1s sipess D cid12 ϕ1s siopt line 1 D cid11cid12 ϕ1s s jpess D cid12 ϕ1s s jopt line 2 leverage fact D contains complete information initial situation For D cid12 nextϕ1s s jopt D cid12 ϕ1s1 s jopt j 0 ih cid2 j D cid12 ϕ1s1 siopt 0 D cid12 nextϕ1s siopt D cid11cid12 nextϕ1s s jpess D cid11cid12 ϕ1s1 s jpess j 0 ih cid2 j D cid11cid12 ϕ1s1 sipess 0 D cid11cid12 nextϕ1s sipess The cases alwaysϕ eventuallyϕ untilϕ1 ϕ2 follow induction hypothesis cases nextϕ cid3 Lemma C2 Let s situation sn doa1 s n cid3 0 collection situations ϕ TPF Then 0 cid2 cid2 j cid2 n D cid12 ϕs s j implies D cid12 ϕs siopt D cid11cid12 ϕs s j implies D cid11cid12 ϕs sipess Proof The proof lemma proceeds analogously previous Again clear ϕ F ϕ R ϕ ﬁnalψ assumption holds Also trivial case ϕ occa D cid12 occas s j a1 D cid12 occas siopt And pessimistic case D cid11cid12 occas s j j 0 entails 0 cid11 a1 In cases D cid11cid12 occas sipess Now suppose assumption holds TPFs ϕ1 ϕ2 Then M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1341 For conjunction D cid12 ψ1 ψ2s s j D cid12 ψ1s s j D cid12 ψ2s s j ih D cid12 ψ1s siopt D cid12 ψ2s siopt D cid12 ψ1 ψ2s siopt D cid11cid12 ψ1 ψ2s s j D cid11cid12 ψ1s s j D cid11cid12 ψ2s s j ih D cid11cid12 ψ1s sipess D cid11cid12 ψ2s sipess D cid11cid12 ψ1 ψ2s sipess For disjunction D cid12 ψ1 ψ2s s j D cid12 ψ1s s j D cid12 ψ2s s j ih D cid12 ψ1s siopt D cid12 ψ2s siopt D cid12 ψ1 ψ2s siopt D cid11cid12 ψ1 ψ2s s j D cid11cid12 ψ1s s j D cid11cid12 ψ2s s j ih D cid11cid12 ψ1s sipess D cid11cid12 ψ2s sipess D cid11cid12 ψ1 ψ2s sipess For negation D cid12 ϕ1s s j D cid11cid12 ϕ1s s j ih D cid11cid12 ϕ1s sipess D cid12 ϕ1s siopt D cid11cid12 ϕ1s s j D cid12 ϕ1s s j ih D cid12 ϕ1s siopt D cid11cid12 ϕ1s sipess For D cid12 nextϕ1s s j D cid12 ϕ1s1 s j j cid3 1 ih D cid12 ϕ1s1 siopt D cid12 nextϕ1s siopt D cid11cid12 nextϕ1s s j D cid11cid12 ϕ1s1 s j j 0 ih D cid11cid12 ϕ1s1 sipess 0 D cid11cid12 nextϕ1s sipess As cases alwaysϕ eventuallyϕ untilϕ1 ϕ2 follow cases nextϕ cid3 With lemmas hand straightforward theorem Again proceed induction structure general preference formulae Proof Theorem 418 The ﬁrst item theorem follows directly Lemma C2 For second item theorem consider component inequalities separately Inequalities w opt si s j Φ cid3 w pess si Φ cid2 w opt s j Φ w pess Φ Assume w opt s j ϕ0v 0 cid18 ϕ1v 1 cid18 cid18 ϕmvm vr ϕl trajectory property formulae Then r cid2 m D cid12 ϕrS0 s jopt D cid11cid12 ϕlS0 s jopt l r Thus Lemma C1 D cid12 ϕrS0 siopt w opt si ϕ0v 0 cid18 ϕ1v 1 cid18 cid18 ϕmvm cid2 vr This trivially holds case ϕl holds optimistically vr v max For pessimistic case turn let w pess ϕ0v 0 cid18 ϕ1v 1 cid18 cid18 ϕmvm vr ϕl trajectory property formulae Then D cid11cid12 ϕlS0 s jpess l r Thus Lemma C1 D cid11cid12 ϕlS0 sipess l r w pess ϕ0v 0 cid18 ϕ1v 1 cid18 cid18 ϕmvm cid3 vr s j si Now induction step suppose assumption holds Ψ Ψi Then For Φ γ Ψ optimistic case possibilities D cid11cid12 γ s s jpess w opt s j Φ 0 Then Lemma C1 D cid11cid12 γ s sipess s j Ψ From induction hypothesis know w opt si Ψ cid2 w opt s j Ψ w opt si Φ 0 w opt D cid12 γ s s jpess w opt si Φ cid2 w opt s j Φ w opt s j Φ And pessimistic case possibilities D cid11cid12 γ s s jopt w pess D cid12 γ s s jopt w pess Φ w pess s j Φ w pess s j s j w pess si si Φ 0 immediately w pess Φ cid3 w pess Φ s j Ψ Using Lemma C1 follows D cid12 γ s siopt si Ψ induction hypothesis greater equal w pess Ψ s j 1342 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 For Φ Ψ1 Ψm w opt s j Ψ1 Ψm max 1cid2lcid2m w opt s j Ψl ih cid3 max 1cid2lcid2m w opt si Ψl w opt si Ψ1 Ψm w pess s j Ψ1 Ψm max 1cid2lcid2m w pess s j Ψl ih cid2 max 1cid2lcid2m w pess si Ψl w pess si Ψ1 Ψm For Φ Ψ1 Ψm w opt s j Ψ1 Ψm min 1cid2lcid2m w opt s j Ψl ih cid3 min 1cid2lcid2m w opt si Ψl w opt si Ψ1 Ψm w pess s j Ψ1 Ψm min 1cid2lcid2m w pess s j Ψl ih cid2 min 1cid2lcid2m w pess si Ψl w pess si Ψ1 Ψm Inequalities w opt s j Φ cid2 w sk Φ w pess s j Φ cid3 w sk Φ The proof inequalities proceeds direct analogy previous ones uses Lemma C2 instead Lemma C1 cid3 Appendix D Proof Corollary 420 Proof The proof proceeds induction structure ϕ Theorem 413 ϕ ﬁnalψ By deﬁnition ρ s ﬁnalψs cid5 s cid5 ﬁnalψs cid5 s cid5 ﬁnalψS0 s cid5optpess ﬁnalψs cid5 s cid5optpess thesis ϕ occa We cid5 opt cid5 cid4 D cid12 occa S0 s D cid12 doa S0 cid16 s D cid12 doa S0 cid16 s cid2 cid3cid4 D cid12 ρ occa s s iff cid5 s cid5 cid5 iff deﬁnition cid5 cid5 S0 s cid2 cid5 iff assumption n cid3 1 cid3 deﬁnition occa Theorem 413 Also deﬁnition occaS0 s Now cases consider ρ cid5 s cid5optpess ρ occLastas s follows trivially s occas cid5pess occaS0 s cid5 D cid12 occaS0 s cid5pess iff D cid12 ρ cid5 occLasta case thesis follows deﬁnition s occas cid5 equal Boolean constant TRUEFALSE case thesis s occas cid5 s cid5 s cid5 ϕ nextψ Again assuming n cid3 1 nextψS0 s cid5optpess nextψS0 s cid5 Hence thesis For remaining temporal formulae thesis follows induction hypothesis deﬁnition terms follows Theorem 413 cid3 Appendix E Proof Theorem 63 Proof The theorem easily proven extending Lemmas C1 C2 handle new constructs eTPFs follows With respect Lemma C1 observe M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1343 If D cid12 occCδs s jopt deﬁnition D cid12 s1 s cid16 s1 cid16 s jδ cid2 cid5 Trans cid2 δ s δ cid5 s1 cid3 cid2 s1 cid11 s j Final cid3cid3cid3 cid2 cid5 δ s1 The chosen s1 s1 cid16 si way round si cid16 s1 In case follows cid2 D cid12 s cid5 1 s cid16 s cid5 1 cid16 si cid2 cid3 cid5 δ Trans cid2 δ s δ cid5 s cid5 1 cid3 Final cid3cid3 cid2 cid5 δ s cid5 1 In case follows cid3 cid2 D cid12 δ cid5 Trans cid5 δ s δ si Hence obtain D cid12 s1 s cid16 s1 cid16 siδ cid2 cid5 Trans cid2 δ s δ cid5 s1 cid2 cid3 s1 cid11 si Final cid3cid3cid3 cid2 cid5 δ s1 D cid12 occCδs siopt Furthermore D cid11cid12 occCδs s jpess deﬁnition D cid11cid12 s1 s cid16 s1 cid16 s jDoδ s s1 Since si precedes s j obvi ous D cid11cid12 s1 s cid16 s1 cid16 siDoδ s s1 deﬁnition D cid11cid12 occCδs sipess If D cid12 afterCδ ϕs s jopt deﬁnition D cid12 s1 s cid16 s1 cid16 s jDoδ s s1 ϕs1 s jopt Since si precedes s j follows D cid12 s1s1 cid16 si s1 cid16 s j derive D cid12 s1 s cid16 s1 cid16 siDoδ s s1 ϕs1 siopt D cid12 afterCδ ϕs siopt Furthermore If D cid11cid12 afterCδ ϕs s jpess deﬁnition cid2 cid3cid2 cid2 cid3 cid3 D cid11cid12 s1 s cid16 s1 cid16 s jDoδ s s1 ϕs1 s jpess cid5 cid3δ s cid5cid5 Trans cid5 cid5cid5 δ s δ s s j cid2 s cid5cid5 Hence 1 D cid12 s1 s cid16 s1 cid16 s jDoδ s s1 ϕs1 s jpess 2 D cid12 δcid5 s In case cases distinguish chosen s1 si cid2 s1 cid16 s j b s1 cid16 si In case follows cid5cid5 s j cid2 s δ s δcid5 s cid5cid5Trans cid5cid5 D cid12 δ cid5cid5 cid5s cid2 cid2 δ s δ cid5 s cid3 cid5cid5 Trans cid3 cid5cid5 si cid2 s case b follows cid2 D cid12 s1 s cid16 s1 cid16 si Doδ s s1 ϕs1 sipess cid3 induction hypothesis wrt ϕ In case enumeration 2 follows immediately deﬁnition Trans fact si cid2 s j D cid12 δ cid5cid5 cid5s cid2 cid2 δ s δ cid5 s cid3 cid5cid5 Trans cid3 cid5cid5 si cid2 s Hence taking cases D cid11cid12 s1 s cid16 s1 cid16 siDoδ s s1 ϕs1 sipess cid3cid2 cid2 cid5 cid3δ s cid5cid5 Trans cid2 δ s δ cid5 s cid3 cid5cid5 cid3 cid5cid5 si cid2 s deﬁnition D cid11cid12 afterCδ ϕs sipess With respect Lemma C2 observe If D cid12 occCδs s j deﬁnition cid2 cid2 D cid12 s1 s cid16 s1 cid16 s jδ cid5 Trans δ s δ cid5 s1 cid3 Final cid3cid3 cid2 cid5 δ s1 It follows deﬁnition Trans D cid12 s1 s cid16 s1 cid16 siδ cid2 cid5 Trans cid2 δ s δ cid5 s1 cid2 cid3 s1 cid11 si Final cid3cid3cid3 cid2 cid5 δ s1 deﬁnition D cid12 occCδs siopt Furthermore D cid11cid12 occCδs s j deﬁnition D cid11cid12 s1 s cid16 s1 cid16 s jDoδ s s1 Since si precedes s j obvious D cid11cid12 s1 s cid16 s1 cid16 siDoδ s s1 deﬁnition D cid11cid12 occCδs sipess 1344 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 If D cid12 afterCδ ϕs s j deﬁnition D cid12 s1 s cid16 s1 cid16 s jDoδ s s1 ϕs1 s j Since si precedes s j follows D cid12 s1s1 cid16 si s1 cid16 s j induction hypothesis wrt ϕ D cid12 s1 s cid16 s1 cid16 siDoδ s s Furthermore If D cid11cid12 afterCδ ϕs s j D cid11cid12 s1 s cid16 s1 cid16 s jDoδ s s1 ϕs1 s j Hence D cid12 s1 s cid16 s1 cid16 s jDoδ s s1 ϕs1 s j There cases distinguish chosen s1 si cid2 s1 cid16 s j b s1 cid16 si In case follows cid2 cid5 1 ϕs1 siopt D cid12 afterCδ ϕs siopt cid3 cid3 D cid12 δ cid5cid5 cid5s cid2 Trans cid5 cid5cid5 δ s δ s s1 cid2 s cid5cid5 case b follows cid2 D cid12 s1 s cid16 s1 cid16 si Doδ s s1 ϕs1 sipess cid3 induction hypothesis wrt ϕ Hence taken cid3cid2 cid3 cid2 Doδ s s1 ϕs1 sipess cid5 cid3δ s cid5cid5 cid2 D cid11cid12 s1 s cid16 s1 cid16 si cid2 δ s δ cid5 s cid3 cid5cid5 Trans cid3 cid5cid5 si cid2 s deﬁnition D cid11cid12 afterCδ ϕs sipess With extensions place proof proceeds analogously proof Theorem 418 cid3 References 1 F Bacchus F Kabanza Using temporal logics express search control knowledge planning Artiﬁcial Intelligence 16 2000 123191 2 J Baier S McIlraith Planning ﬁrstorder temporally extended goals heuristic search Proceedings 21st National Conference Artiﬁcial Intelligence AAAI06 2006 pp 788795 3 JA Baier F Bacchus SA McIlraith A heuristic search approach planning temporally extended preferences Proceedings 20th Inter national Joint Conference Artiﬁcial Intelligence IJCAI07 2007 pp 18081815 4 JA Baier F Bacchus SA McIlraith A heuristic search approach planning temporally extended preferences Artiﬁcial Intelligence 173 56 2009 593618 5 JA Baier SA McIlraith On domainindependent heuristics planning qualitative preferences Proceedings 7th Workshop Non monotonic Reasoning Action Change NRAC07 2007 6 JA Baier SA McIlraith Planning preferences AI Magazine 29 4 2008 2536 7 C Baral V Kreinovich R Trejo Computational complexity planning temporal goals Proceedings 17th International Joint Conference Artiﬁcial Intelligence IJCAI01 2001 pp 509514 8 S Benferhat D Dubois H Prade Towards possibilistic logic handling preferences Applied Intelligence vol 14 Kluwer 2001 pp 303317 9 J Benton S Kambhampati MB Do YochanPS PDDL3 simple preferences partial satisfaction planning Proceedings 5th International Planning Competition Booklet IPC06 2006 pp 5457 10 J Benton M van den Briel S Kambhampati A hybrid linear programming relaxed plan heuristic partial satisfaction problems Proceedings 17th International Conference Automated Planning Scheduling ICAPS07 2007 pp 3441 11 M Bienvenu C Fritz S McIlraith Planning qualitative temporal preferences Proceedings 10th International Conference Knowledge Representation Reasoning KR06 2006 pp 134144 12 M Bienvenu C Fritz S Sohrabi S McIlraith PPLAN Code experiments httpwwwcstorontoedusheilaPPLAN 2006 13 C Boutilier R Brafman C Domshlak H Hoos D Poole CPnets A tool representing reasoning conditional ceteris paribus preference statements Journal Artiﬁcial Intelligence Research 21 2004 135191 14 RI Brafman Y Chernyavsky Planning goal preferences constraints Proceedings 15th International Conference Automated Planning Scheduling ICAPS05 2005 pp 182191 15 G Brewka Complex preferences answer set optimization Proceedings 9th International Conference Knowledge Representation Reasoning KR04 2004 pp 213223 16 G Brewka A rank based description language qualitative preferences Proceedings 16th European Conference Artiﬁcial Intelligence ECAI04 2004 pp 303307 17 G Brewka S Benferhat DL Berre Qualitative choice logic Artiﬁcial Intelligence 157 12 2004 Special Issue Nonmonotonic Reasoning 18 W Burgard AB Cremers D Fox D Hähnel G Lakemeyer D Schulz W Steiner S Thrun Experiences interactive museum tourguide robot Artiﬁcial Intelligence 114 12 1999 355 19 T Bylander The computational complexity propositional STRIPS planning Artiﬁcial Intelligence 69 12 1994 165204 20 S CosteMarquis J Lang P Liberatore P Marquis Expressive power succinctness propositional languages preference representation Proceedings 9th International Conference Knowledge Representation Reasoning KR04 2004 pp 203212 21 G De Giacomo Y Lespérance H Levesque ConGolog concurrent programming language based situation calculus Artiﬁcial Intelli gence 121 12 2000 109169 22 J Delgrande T Schaub H Tompits Domainspeciﬁc preferences causual reasoning planning Proceedings 9th International Conference Knowledge Representation Reasoning KR04 2004 pp 673682 23 JP Delgrande T Schaub H Tompits A general framework expressing preferences causal reasoning planning Journal Logic Computa tion 17 2007 871907 24 S Edelkamp Optimal symbolic PDDL3 planning MIPSBDD Proceedings 5th International Planning Competition Booklet IPC06 2006 pp 3133 25 S Edelkamp S Jabbar M Naizih Largescale optimal PDDL3 planning MIPSXXL Proceedings 5th International Planning Competition Booklet IPC06 2006 pp 2830 26 M Ehrgott Multicriteria Optimization Springer Berlin 2000 27 T Eiter W Faber N Leone G Pfeifer A Polleres Answer set planning action costs Journal Artiﬁcial Intelligence Research 19 2003 2571 28 K Erol DS Nau VS Subrahmanian Complexity decidability undecidability results domainindependent planning Artiﬁcial Intelligence 76 1 2 1995 7588 M Bienvenu et al Artiﬁcial Intelligence 175 2011 13081345 1345 29 R Feldmann G Brewka S Wenzel Planning prioritized goals Proceedings 10th International Conference Knowledge Representation Reasoning KR06 2006 pp 503514 30 A Ferrein C Fritz G Lakemeyer Online decisiontheoretic Golog unpredictable domains Proceedings 27th German Conference AI KI04 2004 pp 322336 31 C Fritz S McIlraith Decisiontheoretic GOLOG qualitative preferences Proceedings 10th International Conference Principles Knowledge Representation Reasoning KR06 2006 pp 153163 32 A Gabaldon Precondition control progression algorithm Proceedings 9th International Conference Knowledge Representation Reasoning KR04 2004 pp 634643 33 A Gerevini P Haslum D Long A Saetti Y Dimopoulos Deterministic planning ﬁfth international planning competition PDDL3 experi mental evaluation planners Artiﬁcial Intelligence 173 56 2009 619668 34 A Gerevini D Long Plan constraints preferences PDDL3 The language ﬁfth international planning competition Tech Rep University Brescia 2005 35 E Giunchiglia M Maratea Planning satisﬁability preferences Proceedings 22nd Conference Artiﬁcial Intelligence AAAI07 2007 pp 987992 36 J Goldsmith J Ulrich Eds AI Magazine 29 4 2008 Winter 2008 Special Issue Preferences 37 CC Green Application theorem proving problem solving Proceedings 1st International Joint Conference Artiﬁcial Intelligence 1969 pp 219240 38 P Haddawy S Hanks Representations decisiontheoretic planning Utility functions deadline goals Proceedings 3rd International Conference Knowledge Representation Reasoning KR96 1992 pp 7182 39 M Helmert Decidability undecidability results planning numerical state variables Proceedings Sixth International Conference Artiﬁcial Intelligence Planning Systems AIPS02 2002 pp 4453 40 J Hoffmann B Nebel The FF planning Fast plan generation heuristic search Journal Artiﬁcial Intelligence Research 14 2001 253302 41 CW Hsu B Wah R Huang Y Chen Constraint partitioning solving planning problems trajectory constraints goal preferences Proceedings 20th International Joint Conference Artiﬁcial Intelligence IJCAI07 2007 pp 19241929 42 HA Kautz B Selman Unifying SATbased graphbased planning Proceedings 16th International Joint Conference Artiﬁcial Intelligence IJCAI99 1999 pp 318325 43 J Kvarnström P Doherty TALplanner A temporal logic based forward chaining planner Annals Mathematics Artiﬁcial Intelligence 30 2000 119169 44 HJ Levesque R Reiter Y Lesperance F Lin RB Scherl GOLOG A logic programming language dynamic domains Journal Logic Program ming 31 13 1997 5983 45 S Liaskos Acquiring reasoning variability goal models PhD Computer Science Department Computer Science University Toronto Toronto Canada 2008 46 S Liaskos SA McIlraith J Mylopoulos Towards augmenting requirements models preferences Proceedings 24th IEEEACM International Conference Automated Software Engineering ASE09 2009 pp 565569 47 J McCarthy Situations actions causal laws Tech Rep Stanford University 1963 48 DV McDermott PDDLThe Planning Domain Deﬁnition Language Tech Rep TR98003DCS TR1165 Yale Center Computational Vision Control 1998 49 S McIlraith T Son Adapting Golog composition semantic web services Proceedings 8th International Conference Knowledge Representation Reasoning 2002 pp 482493 50 K Myers T Lee Generating qualitatively different plans metatheoretic biases Proceedings 16th National Conference Artiﬁcial Intelligence AAAI99 1999 pp 570576 51 A Pnueli The temporal logic programs Proceedings 18th IEEE Symposium Foundations Computer Science FOCS77 1977 pp 46 57 52 M Puterman Markov Decision Processes Discrete Dynamic Programming Wiley New York 1994 53 R Reiter Knowledge Action Logical Foundations Specifying Implementing Dynamical Systems MIT Press Cambridge MA 2001 54 AP Sistla EM Clarke The complexity propositional linear temporal logics Journal ACM 32 3 1985 733749 55 DE Smith Choosing objectives oversubscription planning Proceedings 14th International Conference Automated Planning Scheduling ICAPS04 2004 pp 393401 56 S Sohrabi JA Baier SA McIlraith HTN planning preferences Proceedings 21st International Joint Conference Artiﬁcial Intelligence IJCAI09 2009 pp 17901797 57 S Sohrabi SA McIlraith On planning preferences HTN Proceedings 4th Multidisciplinary Workshop Advances Preference Handling MPref08 AAAI08 2008 pp 103109 58 S Sohrabi N Prokoshyna S McIlraith Web service composition generic procedures customizing user preferences Proceedings 5th International Semantic Web Conference ISWC06 2006 pp 597611 59 TC Son E Pontelli Planning preferences logic programming Proceedings 7th International Conference Logic Programming Nonmonotonic Reasoning LPNMR04 2004 pp 247260 60 TC Son E Pontelli Planning preferences logic programming Theory Practice Logic Programming 6 5 2006 559607 61 PH Tu TC Son E Pontelli CPP A constraint logic programming based planner preferences Proceedings 9th International Conference Logic Programming Nonmonotonic Reasoning LPNMR07 2007 pp 290296 62 M van den Briel RS Nigenda MB Do S Kambhambati Effective approaches partial satisfaction oversubscription planning Proceedings 19th National Conference Artiﬁcial Intelligence AAAI04 2004 pp 562569 63 J von Neumann O Morgenstern Theory Games Economic Behavior Princeton University Press 1994 64 N Wilson Extending CPNets stronger conditional preference statements Proceedings 19th National Conference Artiﬁcial Intelligence AAAI04 2004 pp 735741 65 N YorkeSmith KB Venable F Rossi Temporal reasoning preferences uncertainty Proceedings 18th International Joint Conference Artiﬁcial Intelligence IJCAI03 2003 pp 13851390