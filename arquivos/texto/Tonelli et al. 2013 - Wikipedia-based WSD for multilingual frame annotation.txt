Artiﬁcial Intelligence 194 2013 203221 Contents lists available SciVerse ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Wikipediabased WSD multilingual frame annotation Sara Tonelli Claudio Giuliano Kateryna Tymoshenko Fondazione Bruno Kessler Sommarive 18 I38100 Trento Italy r t c l e n f o b s t r c t Article history Received 11 November 2010 Received revised form 9 May 2012 Accepted 16 June 2012 Available online 18 June 2012 Keywords Frame annotation Multilingual FrameNets Word sense disambiguation FrameNetWikipedia mapping 1 Introduction Many applications context natural language processing proven achieve signiﬁcant performance exploiting semantic information extracted highquality annotated resources However practical use resources biased limited coverage Furthermore generally available English languages We propose novel methodology starting mapping FrameNet lexical units Wikipedia pages automatically leverages Wikipedia new lexical units example sentences The goal build reference data set semiautomatic development new FrameNets In addition methodology adapted perform frame identiﬁcation language available Wikipedia Our approach relies stateoftheart word sense disambiguation ﬁrst trained English Wikipedia assign page lexical units frame Then mapping exploited perform frame identiﬁcation English language available Wikipedia Our approach shows high potential multilingual settings applied languages lexical resources WordNet thesauri available 2012 Elsevier BV All rights reserved The FrameNet database 12 English lexical resource based description prototypical situations frames frameevoking words expressions associated lexical units Every frame corresponds scenario involving set participants frame elements typically semantic arguments shared lexical units frame Given rich semantic information provided frames attempts exploit knowledge improve diverse natural language processing NLP tasks question answering 3 relation extraction 4 entailment rules generation 5 The integration semantic paradigm existing NLP tools hindered diﬃculties creating systems frame semantic parsing Some attempts FrameNet data training 68 Since large amounts data highquality annotation currently available English 1 German 9 applicability supervised approaches limited languages Alternative approaches based systems trained directly FrameNet partially explored investigating integration FrameNet WordNet 1012 use distributional approaches 1314 In article Wikipedia extensive multilingual repository frame information order achieve main goals ﬁrst devise novel approach multilingual frame identiﬁcation subtask frame semantic parsing training directly FrameNet Then retrieve large frame example sentences different languages Corresponding author Tel 39 0461 314 542 fax 39 0461 314 591 Email addresses satonellifbkeu S Tonelli giulianofbkeu C Giuliano tymoshenkofbkeu K Tymoshenko 00043702 matter 2012 Elsevier BV All rights reserved httpdxdoiorg101016jartint201206002 204 S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 We rely Wikipedia reasons First largest existing repository encyclopedic knowledge freely available 282 languages It combines freeform natural language content structural informa tion represented intra interlanguage links Furthermore generally shows high editorial quality especially Wikipedia versions widely languages In order exploit Wikipedia perform frame annotation strategy link resource FrameNet pro posed However aware interoperability FrameNet Wikipedia hindered different structure granularity extension resources Therefore main research questions addressed article Is possible link FrameNet Wikipedia exploit outcome mapping frame identiﬁca tion ii Which strategy chosen devise frame identiﬁcation directly trained FrameNet examples And compare stateoftheart systems iii Can strategy employed support development nonEnglish FrameNets To extent The ﬁrst question partially addressed preliminary work Tonelli Giuliano 15 idea use Wikipedia multilingual repository frame information ﬁrst presented The second problem instead tackled We address comparing approach stateoftheart frame semantic parser English As multilingual frame annotation acquisition frame example sentences Italian Wikipedia introduced 15 marginally evaluated On contrary methodology use frame identiﬁca tion approach different languages presented ﬁrst time article evaluated comparing WordNetbased strategies 11 This article structured follows We introduce FrameNet Wikipedia Section 2 We present past research work related approach Section 3 A general description methodology provided Section 4 The Wikipedia based disambiguation described compared state art Section 5 The methodology mapping framelexical unit pairs Wikipedia pages described evaluated Section 6 ﬁrst research questions addressed items Then Section 7 new frame identiﬁcation approach described applied English lexical units A thorough evaluation comparison stateoftheart SEMAFOR 8 reported addressing second research topic Section 8 devoted research question details twofold strategy creation multilingual FrameNets ﬁrst example sentences lexical units new language extracted Wikipedia word sense disambiguation WSD multilingual frame identiﬁcation Finally draw conclusions discuss future work Section 9 2 FrameNet Wikipedia description terminology FrameNet 12 lexical resource English based frame semantics 16 created context Berkeley FrameNet project1 Its aim collect range semantic syntactic combinatorial possibilities word senses annotation example sentences The conceptual model based main elements Semantic frames Cognitive schemata scenarios necessary understand meaning words They situa tions objects events participants involved Lexical units LUs Words multiwords idiomatic expressions evoking frame Frame elements FEs Semantic roles involved situation event expressed frame They apply LUs frame FrameNet 13 released 2006 comprised 10195 lexical units 6000 fully annotated nearly 800 semantic frames hierarchical relations An essential element FrameNet database corpusbased evidence lexical instantiated example sentence In FrameNet 13 135000 sentences manually annotated frame information As example report Table 1 FrameNet entry Wearing frame In ﬁrst row frame deﬁnition natural language reported second includes list core frame elements The row contains LU list including frameevoking predicates fourth example sentences reported All LUs printed bold phrases bearing FE label reported square brackets followed role label In remainder article frame semantic annotation annotation sentences frame FE role information performed framesemantic parsers 6 8 The subtask assigning frame label lexical unit sentence called frame identiﬁcation This concerns lexical units listed FrameNet socalled seen LUs present resource unseen LUs When frame identiﬁcation applied unseen LUs leads acquisition new LUs known LU induction 13 The second resource account work Wikipedia largest online repository encyclopedic knowl edge At moment writing 20 million articles 282 languages 382 million English written 1 httpframeneticsiberkeleyeduindexphp S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 205 Table 1 Wearing frame Frame Wearing Def FEs LUs Ex The words frame refer clothing wearer speciﬁc body_part wearer body_part clothing wearer The body wearer covered clothing This FE identiﬁes clothing wearer wears The person clothing discussion attireda barearmeda barebreasteda barea bralessa clotheda coatlessa costumeda decked outa dresseda got onv sportv swaddleda swatheda wearv The leaderWearer wore golden helmetClothing She saw herWearer left handBody_part bare SheWearer apronClothing collaboratively approximately 100000 regularly active contributors world This makes Wikipedia reliable source knowledge Internet users researchers The article page basic entry Wikipedia Each article uniquely identiﬁed URL For exam ple Ball_dance identiﬁes page describes types ball intended formal dance Dance_ musical_form describes dance musical genre Every Wikipedia article linked body page links anchors connect relevant terms pages Such connections manually added Wikipedia contributors following available Manual Style2 increase readers understanding topic ﬁnd related information 3 Related work Frames 17 primarily cognitive structures determined social environment personal experiences individual language This assumption ﬁrst analyzed lexical level Boas 18 considered semantic frames interlingual representations multilingual lexical databases The languageindependence hypothesis great extent conﬁrmed projects aimed development FrameNet different languages starting common repository Englishbased frames 1923 These projects showed cases Englishbased model capture relevant semantic distinctions speciﬁc language 24 Therefore article crucial assumption frames constant languages FrameNet mapped WordNet 25 mainly LU induction aim improving FrameNet data sparseness Different approaches proposed aim ﬁrst assigning WordNet synset LU WSD step linking given synset frame exploiting synonym hypernym information WordNet example rulebased approach Burchardt et al 10 SVMbased techniques presented 26271311 Other authors proposed exploit semiautomatic mappings WordNet FrameNet resources example VerbNet 12 LDOCE 28 The ﬁrst task address work frame identiﬁcation English documents focus unseen lexical units Current systems frame annotation 768 usually trained FrameNet examples order assign probable frame candidate lexical unit In case lexical unit present FrameNet WordNet usually exploited detour assess similarity seen unseen lexical units 10 Supervised systems integrate WordNetbased features tackle problem 826 Some attempts integrate WordNetbased distributional models 13 We address problem completely new perspective propose base disambiguation step Wikipedia sense repository FrameNet frames In contrast previous works approach applicable different languages As induction LUs example sentences new languages issue tackled Section 8 present work previous attempts different lexical resources In cases WordNet ﬁrst mapped FrameNet multilingual extensions LU induction different languages For example works Cao et al 27 Tonelli Pighin 11 based MultiWordNet 29 acquisition Italian LUs Crespo Buitelaar 30 exploiting EuroWordNet 31 retrieving Spanish LUs Other approaches rely WordNet proposed French 32 Chinese 33 German 34 In ﬁrst case new French LUs acquired translating English lexical units Wiktionary EuRADic dictionary As Chinese LUs Berkeley FrameNet ﬁrst mapped entries listed HowNet Chinese ontology Then sentences containing mapped predicates extracted Chinese corpus ﬁltered according speciﬁc PoSsequences The methodology presented German instead use bilingual dictionaries relies automatically aligned parallel corpora set ﬁlters translation inconsistencies 2 httpenwikipediaorgwikiWikipediaManual_of_Style 206 S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 In contrast approach acquisition LUs example sentences new languages relies bilingual dictionaries aligned parallel corpora Also carry linguistic analysis sentences extract ing The general framework resembles WordNetbased approaches start mapping FrameNet English resource case Wikipedia exploit multilingual potential resource acquire data languages The advantage Wikipedia instead WordNetrelated resources languages represented continuously updated semistructured information coupled freeform natural language texts With regard Wikipedia research directions closely related work The ﬁrst aims Wikipedia content order extend existing resources limited coverage create new ones The second concerns task automatically enriching plain text links Wikipedia With respect ﬁrst research ﬁeld Wikipedia combined mapped resources WordNet widely RuizCasado et al 35 example propose methodology map WordNet synsets articles Simple Wikipedia SW version Wikipedia simple English words grammar3 Medelyan Legg 36 integrate Cyc 37 knowledge base Wikipedia mapping Wikipedia articles Cyc cepts purpose extending Cyc Wikipedia knowledge new synonyms translations Given Cyc concept set potential Wikipedia mappings exploiting synonymy information resources If set contains possible mapping best Wikipedia page chosen based commonness seman tic relatedness context Cyc concept Such context created categories surround concept Cyc taxonomy direct hypernyms hyponyms More recently mapping algorithm improved Sarjant et al 38 Wikipedia create new child concepts Cyc categories Suchanek et al 39 use Wikipedia WordNet automatically construct knowledge base called YAGO4 YAGO classes derived WordNet taxonomy Wikipedia category extend YAGO class taxonomy The extension algorithm based parsing category names mapping constituents WordNet frequent sense strategy Wikipedia pages populate classes individuals Other resources built use Wikipedia include DBpedia5 Freebase6 Navigli Ponzetto 40 create largescale multilingual resource BabelNet combining Wikipedia WordNet The authors perform disambiguation necessary resource multilingual Wikipedia crosslanguage links machine translation techniques The line research Wikipedia related work automatic annotation terms plain text links Wikipedia pages This WSD task goal link term sentence Wikipedia concept best expresses sense Some wellknown approaches task include works Csomai Mihalcea 41 Milne Witten 42 They perform wikiﬁcation document identify main concepts text annotate links Wikipedia pages Csomai Mihalcea 41 divide task steps extraction relevant concepts WSD step Wikipedia pages sense repository The second step closely related work In step authors experiment knowledgebased WSD algorithm datadriven The second approach integrates local topical features naiveBayes classiﬁer achieves better results The methodology proposing paper similar spirit uses sophisticated features machine learning techniques Milne Witten 42 decompose task steps reversed order First terms document possibly linked appropriate Wikipedia pages relevant links selected The pages terms text linked unambiguously form context Then disambiguation speciﬁc term performed machinelearning approach commonness sense Wikipedia relatedness context context coherence features The approach achieves competitive results compared 41 However limitation relies presence nonambiguous terms document case Kulkarni et al 43 address general task aiming exhaustive annotation document links Wikipedia Based assumption entities document tend topically related cast task collective optimization problem They annotate document links Wikipedia maximizing function encodes joint annotation probability It incorporates compatibility terms contexts candidate Wikipedia pages topical coherence Wikipedia pages terms document linked 4 General workﬂow multilingual frame annotation The core component methodology multilingual frame identiﬁcation acquisition frame example sentences word sense disambiguation based Wikipedia It relies supervised approach given training examples extracted Wikipedia assigns correct sense Wikipedia article speciﬁc term text The workﬂow based ﬁve steps The ﬁrst creation sensetagged training set based English Wikipedia training WSD Section 5 3 httpsimplewikipediaorg 4 httpwwwmpiinfmpgdeyagonagayago 5 httpdbpediaorg 6 httpwwwfreebasecom S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 207 Fig 1 Creation WSD model based Wikipedia mapping FrameNet Fig 2 Frame identiﬁcation English documents Fig 3 Frame identiﬁcation language Ln In second step English WSD create mapping English Wikipedia articles l F pairs l lexical unit frame F deﬁned FrameNet Section 6 The ﬁrst steps presented Fig 1 In step English WSD mapping FrameNet Wikipedia exploited frame identiﬁcation seen unseen lexical units English texts The WSD ﬁrst disambiguate words text mapping associate frame label Section 7 This step portrayed Fig 2 In fourth step WSD trained Wikipedia nonEnglish language Ln It disambiguate texts Ln linking term Wikipedia article Ln Next crosslanguage links articles Ln English exploited retrieve English version linked article Finally mapping English Wikipedia FrameNet applied annotate texts Ln frame labels Section 82 This step depicted Fig 3 In addition frame example sentences acquired language Ln corresponding Wikipedia version We English Wikipage previously mapped frame f extract version wn language Ln Then retrieve Wikipedia sentences pointing wn acquire example sentences frame f new language Ln All terms sentences point wn retrieved lexical units f Section 81 5 The WSD In proposed framework problems mapping LUs Wikipedia articles identifying frames multilin gual documents cast WSD exercise WSD task selecting appropriate sense word text according 208 S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 sense inventory containing list possible senses word 4445 Our WSD called The Wiki Machine7 ensemble wordexpert classiﬁers trained labeled data extracted Wikipedia annotations The following sections present machine learning approach evaluation 51 Learning algorithm We extended kernelbased approach described Giuliano et al 46 basic kernel functions em ployed integrate syntactic semantic pragmatic knowledge sources typically WSD literature 4445 Kernel methods theoretically founded statistical learning theory good empirical results applications 47 The strategy adopted consists splitting learning problem parts First input data embedded suitable feature space linear algorithm case support vector machines discover nonlinear pat terns input space The kernel function taskspeciﬁc component learning algorithm By exploiting properties kernels basic kernels combined deﬁne WSD kernel Speciﬁcally linear combination local global kernels deﬁned following sections 511 Local kernels The local kernel extends gapweighted subsequence kernel capture syntagmatic relations words Typi cally ngrams words partofspeech tags extracted local context target word represent syntagmatic relations 48 However ngrams fail represent noncontiguous shifted collocations consider lexi cal variability For example suppose disambiguate verb score context Maradona scored Argentinas goal given labeled example Ronaldo scored goals second half training A traditional approach considers contiguous ngrams clues conclude occurrences verb sense contexts features common Instead gapweighted subsequence kernel extract non contiguous bigram score goal shared examples Sequence kernels family kernel functions developed compute inner product images strings highdimensional feature space dynamic programming techniques 4951 The gapweighted subsequence kernel general types kernel functions based sequences aka string kernels Roughly speaking compares strings means number contiguous non contiguous substrings given length common Noncontiguous occurrences penalized according number gaps contain Formally let V vocabulary feature space associated sequence kernel length n indexed set I subsequences V length n The explicit mapping function deﬁned φn cid2 usi λli u V n 1 u si subsequence s positions given tuple li length spanned u λ 0 1 decay factor penalize noncontiguous subsequences The associated kernel function deﬁned Kns1 s2 cid3 us1 φn φn cid4 us2 cid2 uV n us1φn φn us2 Furthermore kernel deﬁned Eq 2 extended compare subsequences length p Formally K ps1 s2 pcid2 n1 Kns1 s2 2 3 The local kernel obtained combination extended gapweighted subsequence kernels deﬁned sequences word stems partofspeech tags orthographic features extracted ﬁxedsize window centered target word This implementation differs original removal softmatching criteria introduction orthographic features The ﬁrst change signiﬁcant increase computational cost compared formance improvement obtain Giuliano et al 46 report 08 English lexical sample task SemEval 2007 The introduction orthographic features typically employed named entity recognition helps distinguishing nouns senses present sense inventory derived Wikipedia appreciably affecting computational effort The integration orthographic features straightforward simply deﬁne function takes input word returns CAP UPPER LOWER ALPHANUM PUNCT NUM SYMB word capitalized uppercase lowercase sequence alphanumeric characters punctuation numeral symbol respectively Formally local kernel deﬁned K Ls1 s2 S ps1 s2 P ps1 s2 O ps1 s2 7 httpthewikimachinefbkeu 4 S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 209 S p P p O p extended gapweighted subsequences Eq 3 deﬁned sequences word stems partof speech tags orthographic features deﬁned respectively It follows directly closure properties kernels valid kernel 512 Global kernels The global kernel combines bagofwords latent semantic kernels capture semantic domain topical information This composite kernel takes input wide context window target word Speciﬁcally bagofwords kernel deﬁnes Ndimensional feature space context c represented row vector φc cid6 cid5 t f t1 c t f t2 c t f tN c RN ith component frequency word ti c The bagofwords kernel deﬁned KBOW c1 c2 Ncid2 j1 t f t j c1t f t j c2 5 6 The main drawback approach need large training data reliably generalize unseen data For example despite fact examples People affected AIDS HIV virus express related cepts similarity zero bagofwords model words common represented orthogonal vectors vector space model On hand ambiguity word virus similarity contexts laptop infected virus HIV virus greater zero convey different messages To overcome drawback bagofwords incorporate semantic information means latent semantic kernel 52 The contexts implicitly mapped semantic space documents share words close words semantically related The semantic similarity model obtained cooccurrence analysis large corpus words cooccur documents considered related The technique extract cooccurrence statistics relies singular value decomposition SVD term document matrix corpus The contextual features projected subspace spanned ﬁrst k singular vectors feature space Thus dimension feature space reduced k dimension controlled varying k For example similarity latent semantic space examples People affected AIDS HIV virus higher bagofwords representation terms AIDS HIV virus cooccur medical domain Formally matrix D deﬁne function D RN Rk maps vector φc represented standard bagofwords space vector φcid5c latent semantic space D deﬁned cid5 cid6 φc cid5 φc IIDFD cid6 D cid5 φ c IIDF N N diagonal matrix iIDF ii IDFti IDFti inverse document frequency ti 7 SVD obtain matrix D corpus represented termbydocument matrix T SVD decomposes matrix T matrices T cid6 Vcid2kUT V U orthogonal matrices VT V I UT U I columns eigenvectors TTT TT T respectively cid2k diagonal N N matrix containing highest k cid7 N eigenvalues T remaining elements set 0 The parameter k dimensionality latent semantic space ﬁxed advance Under setting matrix D deﬁned cid7 D INV cid2k IN diagonal matrix iN ii 1 cid5 cid10w cid9 cid10w cid5 cid11 cid10w cid5 ith row matrix V explicitly deﬁned KLSc1 c2 cid3 cid4 Dc1 Dc2 D mapping deﬁned Eq 7 513 Composite kernel cid2k The latent semantic kernel 8 9 Finally combine local global information composite kernel deﬁned KWSDt1 t2 ˆK Lt1 t2 ˆKBOW t1 t2 ˆKLSt1 t2 10 ˆK L ˆKBOW ˆKLS normalized kernels deﬁned Eqs 4 6 9 respectively8 It follows directly explicit construction feature space closure properties kernels valid kernel 8 ˆK x1 x2 K x1x2 K x1x1K x2x2 210 S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 514 Training set The labeled examples extracted Wikipedia annotations ﬁrst proposed Mihalcea 53 Speciﬁcally parse Wikipedia internal link extract anchor term target article surrounding context The target article regarded sense annotation corresponding term context example Examples grouped according anchor term create training sets wordexpert classiﬁers For instance context Lie theory frequently built study classical linear algebraic groups Special branches include Weyl groups Coxeter groups buildingsBuilding_mathematics extracted Wikipedia article Lie_theory assume word building meaning deﬁned article Building_mathematics Overall word building link 42 different articles 708 different contexts This constitutes sense inventory training set train buildingexpert classiﬁer Note links cases accurate manually created Wikipedia contributors We extracted English Italian training sets May 2010 English Wikipedia dump9 June 2010 Italian Wikipedia dump10 respectively dictionaries 12321704 2369918 different entries correspond 101105787 14429138 labeled examples Links disambiguation pages considered links redirection pages replaced redirected page 52 Implementation details We following open source tools implementation algorithm Java Wikipedia Library parse Wikipedia dumps 54 The Apache OpenNLP library sentence detection tokenization partofspeech tagging11 The Snowball library stemming12 The LIBSVM library support vector machines 55 The SVDLIBC package compute SVD13 The following set experiments The English Italian latent semantic models derived 200000 visited Wikipedia articles language14 After removing terms occur 5 times resulting dictionaries contain 300000 terms The decomposed matrix D truncated 100 dimensions parameter k No task speciﬁc parameter optimization performed experiments We default LIBSVM parameter settings The global context corresponds paragraph local context window words target word The local kernel parameter p set 3 53 System evaluation The original algorithm 46 achieved stateoftheart results wide range languages Senseval3 56 SemEval 2007 57 evaluation exercises In addition provide uptodate evaluation assessed ACE05 WIKI Extension 58 This benchmark extends English Automatic Content Extraction ACE 2005 data set ground truth links Wikipedia15 It speciﬁcally designed evaluate disambiguation systems based Wikipedia ACE 2005 composed 599 articles assembled variety sources selected broadcast news programs newspapers newswire reports Internet sources transcribed audio It contains annotation entity mentions different types person location organization In extension NAM nominal NOM mention total 29300 entity mentions manually assigned zero Wikipedia articles If assigned ordered speciﬁc generic We compared approach stateoftheart Wikipedia Miner 42 Since requires Wikipedia preprocessed speciﬁc way preprocessed version July 2008 available authors Table 2 shows results obtained ACE05WIKI Extension The evaluation performed considering speciﬁc Wikipedia articles assigned human annotators gold standard annotations We report evaluation task consisting linking nominal mentions NAM NOM partial tasks linking mentions NAM nominal mentions NOM The evaluation interesting purposes lexical units include proper names The Wiki Machine signiﬁcantly outperforms Wikipedia Miner NAM NOM NOM tasks The difference systems smaller number knowledge sources exploited Wikipedia Miner Speciﬁcally Wikipedia Miner use Wikipedia internal links consequently information provided local global contexts This difference stressed disambiguation nominal mentions use information extracted local context important disambiguation mentions For example phrase opening goal fact word goal preceded opening suggests sense successful 9 httpdownloadwikimediaorgenwiki20100312 10 httpdumpswikimediaorgitwiki20100624 11 httpincubatorapacheorgopennlp 12 httpsnowballtartarusorg 13 httptedlabmitedudrsvdlibc 14 Wikipedia article traﬃc statistics available httpstatsgrokse 15 httpwwwitlnistgoviadmigtestsaceace05indexhtml S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 211 Table 2 Comparative evaluation disambiguation methods ACE05WIKI microaverage Symbol indicates signiﬁcant differences relative corresponding mention type p 001 Signiﬁcance tests computed approximate randomization procedure Approach Wikipedia Miner The Wiki Machine Mention type NAM NOM NAM NOM NAM NOM NAM NOM Precision 078 086 066 072 078 062 Recall 048 069 028 071 074 065 F 1 059 076 040 071 076 063 Table 3 Comparative evaluation basic composite kernels ACE05WIKI The use orthographic features denoted Symbols indicate signiﬁcant difference respect preceding entry row p 001 p 005 respectively scores indicate signiﬁcant differences relative preceding entry row p 001 p 005 respectively Signiﬁcance tests computed approximate randomization procedure Basic kernels K L 623 K L 632 KBOW 646 Composite kernels KBOWLS 661 KWSD 697 K WSD 710 F 1 attempt scoring In contrast local context provides clues disambiguate entity example phrase Mr Johnson fact word Johnson preceded title Mr suggest mention type number gender global context provides decisive clues identify corresponding Wikipedia article Finally twoyear difference training data systems partly affect performance To alleviate problem updated output Wikipedia Miner taking account changes occurred redirection pages led improvement 1 point On contrary varying Wikipedia Miner free parameters produce statistically signiﬁcant improvement Table 3 shows comparison basic composite kernels The results substantially conﬁrm previous conclusions 46 composite WSD kernel signiﬁcantly outperform basic ones In addition signiﬁcant differences kernels orthographic features usefulness additional information Finally Mendes et al 59 compared The Wiki Machine ensemble academic commercial systems DBpedia Spotlight Zemanta Open Calais Alchemy API Ontos showing highest F score 6 FrameNetWikipedia mapping We apply WSD model learned described Section 5 assign Wikipedia articles lexical units We creating pseudocontext l F pair frame deﬁnition lexical units associated F build left right context lexical unit disambiguated As example report pseudocontext created lexical unit cablev Communication_means frame This frame concerns Communicators communicating aid Means communication telephone cable wire phone semaphore telegraph telex radio telephone fax The disambiguation algorithm assigns sense Wikipedia article lexical unit pseudocontext sense uniquely deﬁnes mapping 61 Mapping lexical units Wikipedia We restrict mapping nominal lexical units Wikipedia basically resource organized concepts usually expressed nouns Verbs adjectives generally linked articles describing nominal concepts We ﬁrst extract FrameNet l F pairs nominal l obtaining set 4154 lexical units Then dis ambiguation step performed based pseudocontext Table 4 shows mapping statistics We compare disambiguation step informed baseline assigns l page frequently linked Wikipedia For example baseline sense pair bonnetn Accoutrements Wikipedia article Hood_vehicle cause bonnet frequently linked page Wikipedia In setting average number senses available Wikipedia lexical unit corresponding linked pages 11 62 Mapping analysis We manually inspected sample 500 mappings l F pairs Wikipedia pages The pairs selected order maximize frame variability pair contains different frame Table 5 shows results analysis 212 S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 Table 4 Output Wikipedia mapping N l F pairs N mapped lexical units N frames mapping Different mappings wrt baseline Table 5 Mapping analysis sample 500 mappings N exact matches N exact matches baseline Wikipage generic l Wikipage speciﬁc l N wrong matches N wrong matches missing sense 4154 3800 492 277 309 280 10 35 71 75 We compare result mostfrequent baseline deﬁned Section 61 Wrong mappings cases WSD assigns l F wrong sense right possible senses listed Wikipedia Also report separate row number wrong assignments fact correct sense missing Wikipedia This measure estimate upperbound accuracy mapping Our analysis cludes mappings l F W semantically related Wikipedia concept general speciﬁc l F For example beliefn Awareness mapped Belief page describes belief concept broader sense includes meaning l F pair beliefn Opinion In cases relation l F W reversed For example enlargementn Expansion mapped Enlargement_of_the_European_Union 63 Discussion Table 5 shows 15 evaluated lexical units mapped page corresponding concept present Wikipedia This conﬁrms hypothesis FrameNet Wikipedia linkable resources far nominal lexical units concerned Overall mapping covers 37 FrameNet lexical units 68 frames Table 4 As Section 8 result relevant coverage achieved single lexical units methodology acquire new FrameNets multilingual settings performed frame basis If Wikipedia page associated frame lexical unit lexical units linked page acquired regardless speech In general terms inherent differences FrameNet Wikipedia affect mapping resources The evident distinction large number concepts encoded Wikipedia 382 million concepts compared smaller set lexical units 10195 FrameNet 13 Another relevant difference FrameNet built semantic classes concepts frames Wikipedia pages structured Although set words point Wikipedia page seen semantically related words design priori characteristics classes implicitly deﬁned different editors links For example professionals linked corresponding profession activity Wikipedia distinct frames created Medical_specialties Medical_professions FrameNet However FrameNet distinction consistently performed frames contain LUs denoting persons activities example assassinn assassinationn assassinatev Killing Another main difference way transitive intransitive use verb treated FrameNet usually modeled frame alternation Cause_to_make_noise Make_noise distinction generally Wikipedia editors With regard disambiguation strategy approaches investigated relying pseudocontexts For instance lexical units disambiguated context FrameNet sentences occur similar contexts training However approach account lexical units instantiated example sentence FrameNet A comparison strategies shows approach based pseudocontexts disambiguate 3800 lexical units examplebased approach covers 2505 lexical units A comparison showed 10 assignments approaches match achieved signiﬁcant improvement terms precision Therefore account mapping obtained pseudocontexts The examplebased approach beneﬁt availability large number sentences lexical unit In order acquire additional examples lexical unit context replaced lexical units belonging frame However partly lead creation ungrammatical sentences given LUs frame different parts speech Also antonymous lexical units affect quality sentences created substitution S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 213 Table 6 Frame identiﬁcation seen lexical units Symbols indicate signiﬁcant differences relative SEMAFOR p 001 p 005 respectively Signiﬁcance tests computed approximate randomization procedure SEMAFOR WIKIBASED WIKIBASEDWLM Precision 076 081 074 Recall 073 025 027 F 1 075 038 039 7 English frame identiﬁcation The WSD mapping l F pairs Wikipedia pages straightforwardly automatic frame identiﬁcation Given English sentence containing lexical unit ﬁrst disambiguate assigning Wikipedia page exploit mapping ﬁnd appropriate frame The potential approach greater languages FrameNet available performs frame identiﬁcation Wikipedia training For English supervised systems Shalmaneser 7 SEMAFOR 8 trained directly FrameNet achieved good performances However ﬁrst test approach English want assess difference methodology standard supervised approaches available English ii want assess performance approach decreases moving English languages 71 Frame identiﬁcation seen lexical units As ﬁrst step compare methodology performance SEMAFOR1 8 stateofthe art frame semantic parser applies conditional loglinear model prospected lexical units frame identiﬁcation We choose signiﬁcantly outperforms systems participating SemEval 2007 task frame semantic parsing 8 freely available16 711 Experimental setup In order compare approaches use test set SemEval 2010 task Linking events participants discourse 60 Although task concerned argument labeling given lexical units use test set gold standard frame identiﬁcation In particular account subset LUs listed FrameNet 13 training set SEMAFOR1 source data set mapping This subset SemEval test set contains 1432 lexical units divided nouns 38 verbs 51 adjectives 9 PoS including prepositions adverbs determiners 2 Note selection strategy adopted lexical unit identiﬁcation different SEMAFOR set rules applied ﬁlter bad candidates example support predicates prepositions In approach term multiword disambiguated potentially seen LU candidate However include gold standard lexical units appear FrameNet 13 We test methodology based mapping process described Section 6 Then compare second setting exploit Wikipediabased similarity library improve coverage The basic intuition link lexical unit li Wikipedia page w included original mapping M retrieve M page wn similar w assign li frame fn originally mapped wn To end compute similarity score w w M select best match page wn M highest similarity score We apply Wikipedia linkbased measure WLM 61 available Wikipedia Miner Toolkit17 Given pages relatedness measure takes account incoming outgoing links page assumes pages sharing links similar containing different links The measure similarity w wn ranges 0 1 majority cases comprised 0 05 The evaluation performed different cutoff values produce slightly different signiﬁcant results The values reported Table 6 obtained threshold set zero 712 Evaluation As shown Table 6 methodology affected recall problems lexical units linked Wikipedia page appears mapping identiﬁed In addition approach evenly cover parts speech 3 verbal LUs correctly annotated In English documents Wikipediabased approach frame identiﬁcation compete supervised systems classiﬁcation seen lexical units A frame identiﬁcation model trained directly FrameNet database covers smaller set possible senses guarantees better performance disambiguation 16 httpwwwarkcscmueduSEMAFOR 17 httpwikipediaminersourceforgenetindexhtm 214 S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 Table 7 Evaluation frame annotation unseen LUs Symbols indicate signiﬁcant differences relative SEMAFOR p 001 p 005 respectively Signiﬁcance tests computed approximate randomization procedure Precision Recall All frames LUs AFAL SEMAFOR WIKIBASED WIKIBASEDWLM All frames nominal LUs AFNL SEMAFOR WIKIBASED WIKIBASEDWLM Restricted frame set LUs RFAL SEMAFOR WIKIBASED WIKIBASEDWLM Restricted frame set nominal LUs RFNL SEMAFOR WIKIBASED WIKIBASEDWLM 028 034 020 052 038 038 025 039 027 049 042 040 014 009 015 021 017 035 012 013 021 018 018 037 F 1 019 014 017 030 024 036 016 019 023 026 025 038 model trained Wikipedia Nevertheless analysis suggests applying Wikipediabased methodology languages good annotation precision expected direct supervision possible 72 Frame identiﬁcation unseen lexical units The annotation unseen lexical units open problem generally tackled current frame semantic parsers 67 partially solved relying WordNet 1026 distributional models 13 Our approach frame identiﬁcation require speciﬁc strategies unseen lexical units underlying disambiguation model remains seen lexical units Compared approaches additional resources large corpora required word expression occurring training set WSD treated potential lexical unit need included FrameNet We evaluate approach speciﬁc task comparing SEMAFOR relies lexicosemantic features partly extracted WordNet relate unseen seen lexical units 62 We choose SEMAFOR available handles seen unseen lexical units similar approach 721 Experimental setup Approaches dealing annotation unseen lexical units evaluated leaveoneout fashion FrameNet 13 gold standard 1310 We introduce realistic setting classifying lexical units completely missing FrameNet 13 We extract sentences added FrameNet 15 database respect previous release version 13 The sentences introducing new LUs belong frames present FrameNet 13 included test set We discard lexical units belonging frames present version 13 task frame discovery scope article The test set includes 2736 sentences containing 179 l F pairs In order evaluate impact mapping coverage approach consider smaller test set including frames represented mapping Wikipedia pages 1976 sentences 132 l F pairs We evaluate nominal lexical units separately setting including frames 880 sentences 57 l F pairs setting including frames mapping 828 sentences 56 l F pairs 722 Evaluation In Table 7 report evaluation frame assignment task unseen lexical units test set frames LUs AFAL We account subsets mentioned Section 721 set comprising frames nominal LUs AFNL set including restricted set frames occurring mapping LUs RFAL including restricted frame set nominal LUs RFNL The evaluation test set conﬁrms ﬁndings shown Table 6 basic setting outperforms SEMAFOR regard classiﬁcation precision recall major issue The fact frames included mapping relevant impact results WIKIBASED outperforms SEMAFOR RFAL test set In general small mappings acquired Wikipedia pages l F pairs main reason low recall 90 missing assignments AFAL test set low mapping coverage 10 disambiguated WSD The strategy improve recall WLM proves effective achieves best recall test set With nominal lexical units implies limited drop precision RFNL reduction S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 215 AFNL compared WIKIBASED However drop dramatic similarity measure applied lexical units 73 Discussion A major shortcoming recognizes labels mainly nominal LUs This depends set l F pairs originally mapped Wikipedia contains nominal LUs Besides Wikipedia structure based concepts typically expressed nominal expressions However analysis correct assignments test set Table 7 AFAL shows 58 correct assignments concern nominal LUs 26 verbs 16 adjectives In words preference given nominal lexical units parts speech handled The results obtained SEMAFOR suggest suffers lower performance handling unseen verbal adjectival LUs shows remarkable drop precision recall allLUs setting In order generalize seen unseen lexical units main approaches presented past works relies WordNet 102613 distributional similarity 13 A shortcoming ﬁrst approach applied unseen lexical units having WordNet entry limited languages WordNet available Burchardt et al 10 evaluate methodology leaveoneout strategy FrameNet 12 report 87 coverage 39 precision recall computed way experiments 34 However authors deﬁne precision weak measure overlap gold standard corresponds number times list suggested frames given LU contains gold standard frame These measures likely decrease evaluation setting based standard precision recall Furthermore WordNetbased detour evaluated FrameNet 12 containing 600 frames FrameNet 13 experiments contains 725 frames makes assignment task diﬃcult Distributional approaches hand require large corpora available representing existing frames unknown LUs semantic space Using BNC reference corpus combined WordNet Pennacchiotti et al 13 new lexical units added existing frames achieving 043 accuracy 095 coverage bestﬁrst model However approach comparable reasons ﬁrst experimental setting different lexical unit reassigned frame removed original frames 10 The assignment considered correct original frames matched performed lemma basis This means LU ambiguity possibility lemma corresponds LUs different frames accounted evaluation As result methodology 13 applied perform frame identiﬁcation running text account different senses equal frames LU bear depending context occurs Furthermore evaluation performed reduced test set including frames 2 LUs candidate LUs frequency higher 5 BNC 67 FrameNet LUs As preliminary conclusion experiments English approach rival SEMAFOR dealing unseen LUs However possibility train WSD model directly FrameNet data guarantees better performance classifying seen LUs Also methodology evenly cover parts speech SEMAFOR better balanced respect Our approach shows WordNet large reference corpora necessary frame identiﬁcation Wikipedia sense repository represents valuable alternative resources Therefore greatest potential methodology expressed multilingual settings languagespeciﬁc versions WordNet FrameNet available 8 Creation multilingual FrameNets Many research projects recently devoted development FrameNet languages English However collection large handcrafted annotation expensive timeconsuming process slows growth initiatives German FrameNet18 FrameNetlike resource released coverage comparable English version To overcome bottleneck semi automatic techniques developed collect FrameNetlike data languages exploiting external resources WordNet 1163 parallel corpora 64346566 bilingual dictionaries 32 However nonavailability resources limited development languages strong motivation investigate use Wikipedia Wikipedia includes multilingual information aligned concept level similar bilingual dictionaries ii textual data 282 languages organized comparable corpus addition links documents iii internal structure allows computation similarity measures concepts similar WordNet Even organized rigorous coherent way Wikipedia combines aspects mentioned particularly suitable NLP applications multilingual settings resources scarcely available For development new FrameNets ﬁrst use Wikipedia acquire set preclassiﬁed sentences LUs second perform frame identiﬁcation multilingual documents The basic assumption approach frames capture languageindependent situations events frame repository English FrameNet represent 18 httpwwwcoliunisaarlanddeprojectssalsacorpus 216 S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 Table 8 Statistics data extracted Italian Wikipedia English Wikipedia articles mapping Linked articles Italian Wikipedia N extracted sentences Frames 1 sentence LU candidates Table 9 Sentence LU evaluation Italian Accuracy sentence extraction Accuracy LU induction N new LU candidates N correct candidates 3818 1866 610397 404 14415 069 062 635 396 backbone FrameNets languages major changes This assumption conﬁrmed different projects aimed automatically acquiring data languages 203267 81 Acquisition lexical units example sentences The goal phase automatic acquisition LUs example sentences nonEnglish language Ln For English Wikipedia article W mapped l F pair Section 6 retrieve Wikipedia article W n Ln following crosslanguage link W W n In Ln W n supposed translation W alternative description concept If W n exists extract sentences Sn contain link W n Wikipedia Ln We assume Sn example sentences F Ln In addition terms linked W n acquired LUs The approach exploited principle languages represented Wikipedia 811 Experimental setup Experiments performed Italian Wikipedia dump June 201019 In order increase mapping coverage disambiguate nominal LUs FrameNet pseudocontexts See Section 61 case instanti ated example sentence apply examplebased disambiguation Section 63 The ﬁnal mapping contains 3818 links 18 mapping based deﬁnitions We ﬁlter sentences shorter 40 characters ones extracted People_by_origin frame The ﬁrst ﬁlter applied discard examples likely incomplete need create ﬁrst set examples possibly contain textual material future annotation semantic roles The second ﬁlter introduced tackle problem involves links nationalities nations Wikipedia The mapping algorithm usually connects LU belonging People_by_origin frame contains list nationalities Wikipedia article corresponding nation For example Britn LU mapped United_Kingdom article turn linked Italian Regno_Unito article Even considered conceptually correct represents relevant problem task nationalities nations belong different frames Many sentences extracted Wikipedia articles describing nations linked articles Therefore rule necessary reduce negative impact annotation practice extraction task Table 8 shows statistics extracted data 812 Evaluation We manually evaluate 2000 examples consisting 5 sentences randomly extracted 400 linked Wikipedia articles turn randomly drawn The evaluation focused performance sentence extraction algorithm aims assessing given sentences included Italian version F We check candidate LUs occurring evaluated sentences appropriately included F The results shown Table 9 We computed Cohens kappa statistic 68 random sample 200 sentences Agreement judges achieves 082 rule thumb seen good agreement represents solid basis evaluation A manual inspection evaluation set shows 34 wrong sentences extracted disambiguation errors Around 44 mistakes depend frames structured compared Wikipedia pages frames built speciﬁc parts speech distinction Wikipedia For instance Toxic_substance lists harmful substances poisonn venomn Cause_harm groups verbs describing harmful actions poisonv In Wikipedia terms linked Poison page regardless speech In remain ing cases 22 mistakes depend cross intralanguage links Wikipedia Speciﬁcally ﬁnegrained sense distinctions English missing Italian extension Italian Wikipedia 23 English 19 httpdownloadwikimediaorgitwiki20100624 S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 217 Table 10 N correct LUs acquired frame grouped speech Attempt_suasion Change_pos_on_a_scale Death Departing Self_motion 2 n 4 n 1 v 3 17 n 8 v 6 6 n 3 v 2 9 n 3 v 2 Table 11 Frame annotated data MultiSemCor N annotated LU occurrences N acquired Italian l F pairs nominal LU verbal LU adjectival LU adverbial LU Frames 1 acquired LU WIKIBASED 17714 1708 1097 272 307 32 269 WNBASED 23872 3380 1341 1525 512 2 530 Wrong sentences extracted wrong internal links For example sentences dealing newspaper La Nazione linked Nazione Nation page As shown Section 7 approach nouncentered constrained design Wikipedia based concepts This holds LU induction multilingual setting acquired LUs nouns Nevertheless 396 LUs evaluated correct data set include 2 adverbs 15 verbs 30 adjectives In order investigate impact nouncentered approach LU acquisition randomly select 5 frames FrameNet characterized verbal lexical units proportion verbal lexical units wrt nominal ones 2 We extract data set reported Table 8 sentences acquired frames Then analyze speech correct LUs acquired sentences induction process The statistics reported Table 10 conﬁrm nominal LUs predominant acquisition phase methodology induce LU types Attempt_suasion This line analysis behavior reported annotation unseen LUs English Section 72 82 Development multilingual frame assignment systems The backbone methodology exploited perform multilingual frame identiﬁcation The components needed English supervised WSD Wikipedia WikipediaFrameNet mapping We combination potentially lead development frame annotation language available Wikipedia The methodology similar applied English Fig 3 ﬁrst train WSD Wikipedia language Ln following procedure described Section 5 Second disambiguate terms document d language Ln For Wikipedia page W n linked term tn d retrieve English article W e crosslanguage link W n W e Finally retrieve WikipediaFrameNet mapping frame f e mapped article W e assign term tn 821 Experimental setup We test methodology Italian MultiSemCor corpus 69 This data set contains 12843 sentences enriched synset labels automatically transferred English counterpart precision 086 Tonelli Pighin 11 employ corpus test procedure maps WordNet synset corresponding frame based set lexicosemantic features Since attempt acquire evaluate lexical units example sentences real corpus Italian evaluate frame assignment approach data However 11 gold English synsets given Italian ones automatically acquired word alignment On contrary methodology includes disambiguation Therefore classiﬁcation accuracy reported 11 represents sort upper bound approach Statistics Italian data annotated methodology reported Table 11 WIKIBASED We report statistics related data extracted 11 WNBASED Most acquired LUs nouns PoS included The Wikipediabased approach covers smaller range LUs frames examples acquired average LU WordNet 10 vs 7 sentences l F pair 218 S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 Table 12 Evaluation frame assignment MultiSemCor Nominal LUs evaluation set correctly classiﬁed Verbal LUs evaluation set correctly classiﬁed Adjectival LUs evaluation set correctly classiﬁed Adverbial LUs evaluation set correctly classiﬁed Classiﬁcation accuracy 674 492 217 47 91 36 18 5 058 Table 13 Comparison 10 populated WordNets Wikipedia Language English Polish German Spanish Japanese Dutch Italian French Hindi Romanian N WordNet synsets 155287 73839 69594 57424 57238 44015 38658 32351 26208 20191 Project Princeton WN plWordNet GermaNet MultiWordNet Japanese WN EuroWordNet MultiWordNet WOLF HindiWordNet MultiWordNet N Wikipedia articles 3817361 848759 1324259 849263 781433 908386 867277 1181260 100549 169472 822 Evaluation In order compare approach 11 evaluation applied data set However 11 200 instances manually evaluated After running data set noticed 42 instances annotated approaches This number small allow accurate evaluation comparison systems Therefore decided manually evaluate corpus 1000 sentences annotated instance This data set built order include sentences documents MultiSemCor cover topics For labeled instance annotator asked assign positive judgment frame label given correct negative judgment Since reference frames Italian annotator allowed look frame descriptions example sentences English FrameNet More details frame assignment methodology given 70 Evaluation results reported Table 12 Classiﬁcation accuracy reported 11 070 based smaller evaluation set Given synsets deﬁned methodology includes disambiguation conclude approach promising In order apply methodology 11 document unsupervised WSD based WordNet needed Given performance existing systems integration lead signiﬁcant drop accuracy20 Also coverage statistics reported Table 11 WordNetbased approach considerably different real application scenario recall best unsupervised WSD systems 60 Precision seen LUs English 081 Section 7 Although results different languages directly comparable difference accuracy reﬂects impact errors introduced Italianspeciﬁc setting mistakes WSD trained Italian quality links English Italian Wikipages 83 Discussion Other presented approaches aimed acquiring initial set preclassiﬁed sentences LUs new language However shortcoming strongly languagedependent require speciﬁc NLP com ponents resources Both Tonelli Pighin 11 Cao et al 27 acquire Italian LUs based MultiWordNet procedure applied limited number languages EuroWordNet 31 includes languages MultiWordNet English synsets strictly aligned languages makes WordNetbased methodology applicable 20 Agirre et al 71 report SemEval2010 task WordNetbased unsupervised WSD speciﬁc domain best performing English achieved P 057 R 055 topranked Italian scored P 053 R 053 Although accuracy best supervised systems higher 75 57 applicable practical applications high cost creating maintaining training data S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 219 Wikipedia covers 282 languages21 60 available WordNet22 This represents clear advantage methodology compared WordNetbased approaches Also coverage languagespeciﬁc versions Wikipedia clearly exceeds WordNet conﬁrmed data Table 13 comparing 10 populated WordNets corresponding Wikipedia version We report speciﬁc WordNet project different projects developing WordNets language MultiWordNet EuroWordNet Italian Spanish In absolute terms extraction frame example sentences Italian Wikipedia leads creation data set comprising 610397 sentences 14415 candidate LUs Through MultiSemCor Section 821 mapping tween frames MultiWordNet synsets 11 extract 23872 Italian sentences 6429 candidate LUs Note 3049 LUs acquired 11 directly synsets instantiated examples This conﬁrms Wikipedia allows acquisition remarkably data WordNet supporting lexicographers annotators develop ment new FrameNets As frame identiﬁcation new languages unexplored task given existing frame semantic parsers require large set training data Our methodology ﬁrst attempt handle task framespeciﬁc su pervision extended languages Wikipedia To knowledge available handling nonEnglish documents Shalmaneser 7 trained German SALSA corpus 9 The labels mainly verbs SALSA 97 LUs verbs Our methodology complement German FrameNet enriching existing frames nominal lexical units example sentences It integrate Shalmaneser output assigning frame label unseen LUs German documents 9 Conclusions Our goal article present approach frame identiﬁcation frame example acquisition languages Wikipedia In cases training data highquality frame annotation available Therefore developed methodology avoiding direct supervision FrameNet data Research direction crucial alleviate performance degradation dealing different domains languages Furthermore FrameNet paradigm frame annotation paramount importance prerequisite semantic role labeling quality impacts annotation task Experiments English showed compared supervised approaches methodology achieves good precision low recall Section 7 A ﬁrst attempt alleviate problem basic Wikipediabased similarity showed promising improvement In future plan improve recall exploiting Wikipediabased similarity metrics 72 The quality acquired data Italian showed method particularly promising multilingual settings It exploited editors lexicographers develop new FrameNets semiautomatic way especially lexical resources available Yet room improvement In particular recall boosted increasing number interlanguage links Past works showed possible retrieve Wikipedia pages expressing concept different languages explicitly connected link 73 Experiments direction increase number interlanguage links FrameNetWikipedia mapping accessed Finally research lexical units beneﬁt deeper understanding semantics arguments vice versa Therefore developing uniﬁed methodology order perform frame identiﬁcation semantic role annotation WSD In framework FrameNet Wikipedia WordNet integrated A preliminary study semantics role ﬁllers based resources conﬁrmed approach promising 74 In near future investigate best strategy combine LU semantic role information evaluate frame semantic parser based Wikipedia stateoftheart systems Acknowledgements We like thank anonymous reviewers comments suggestions We thankful Ryan Bohler proofreading ﬁnal article version References 1 CF Baker CJ Fillmore JB Lowe The Berkeley FrameNet project Proceedings 17th International Conference Computational Linguistics COLING98 Montreal Quebec Canada 1998 pp 8690 2 C Fillmore C Johnson MRL Petruck Background FrameNet International Journal Lexicography 16 2003 235250 3 D Shen M Lapata Using semantic roles improve question answering Proceedings Joint Conference Empirical Methods Natural Language Processing Computational Natural Language Learning EMNLPCONLL07 Prague CZ 2007 pp 1221 4 B Rink S Harabagiu UTD Classifying semantic relations combining lexical semantic resources Proceedings 5th International Work shop Semantic Evaluation SemEval3 Uppsala Sweden 2010 pp 252255 5 RB Aharon I Szpektor I Dagan Generating entailment rules FrameNet Proceedings 48th Annual Meeting Association Computational Linguistics ACL10 Stroudsburg PA USA 2010 pp 241246 21 httpmetawikimediaorgwikiList_of_Wikipedias 22 httpwwwglobalwordnetorggwawordnet_tablehtml 220 S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 6 B Coppola A Moschitti A general purpose FrameNetbased shallow semantic parser Proceedings 7th Language Resources Evaluation Conference LREC10 La Valletta Malta 2010 pp 1921 7 K Erk S Padó Shalmaneser toolchain shallow semantic parsing Proceedings 5th Language Resources Evaluation Conference LREC06 Genoa Italy 2006 pp 527532 8 D Das N Schneider D Chen NA Smith Probabilistic framesemantic parsing Proceedings 11th Annual Conference North American Chapter Association Computational Linguistics NAACL10 Stroudsburg PA USA 2010 pp 948956 9 A Burchardt A Frank S Padó M Pinkal The SALSA corpus German corpus resource lexical semantics Proceedings 5th Language Resources Evaluation Conference LREC06 Genoa Italy 2006 pp 969974 10 A Burchardt K Erk A Frank A WordNet detour FrameNet B Fisseni H Schmitz B Schröder P Wagner Eds Sprachtechnologie mobile Kommunikation und linguistische Resourcen Peter Lang Frankfurt Main Germany 2005 pp 408421 11 S Tonelli D Pighin New features FrameNetWordNet mapping Proceedings Thirteenth Conference Computational Natural Language Learning CONLL09 Boulder CO USA 2009 pp 219227 12 L Shi R Mihalcea Putting pieces Combining FrameNet VerbNet WordNet robust semantic parsing Proceedings 6th International Conference Intelligent Text Processing Computational Linguistics CICLing05 Springer Mexico City Mexico 2005 pp 100111 13 M Pennacchiotti D Cao R Basili D Croce M Roth Automatic induction FrameNet lexical units Proceedings Conference Empirical Methods Natural Language Processing EMNLP08 Waikiki Honolulu Hawaii 2008 pp 457465 14 M Pennacchiotti D Cao P Marocco R Basili Towards vector space model FrameNetlike resources Proceedings 6th Language Resources Evaluation Conference LREC08 Marrakech Morocco 2008 pp 790796 15 S Tonelli C Giuliano Wikipedia frame information repository Proceedings Conference Empirical Methods Natural Language Pro cessing EMNLP09 Singapore 2009 pp 276285 16 CJ Fillmore Frames semantics understanding Quaderni di Semantica IV 2 1985 222254 17 CJ Fillmore Frame semantics nature language Annals New York Academy Sciences Conference Origin Development Language Blackwell Publishing 1976 pp 2032 18 HC Boas Semantic frames interlingual representations multilingual lexical databases International Journal Lexicography 18 4 2005 445 478 19 A Burchardt M Pennacchiotti S Thater M Pinkal Assessing impact frame semantics textual entailment Natural Language Engineering 15 4 2009 527550 Special Issue Textual Entailment 20 C Subirats Spanish FrameNet A framesemantic analysis Spanish lexicon HC Boas Ed Multilingual FrameNets Computational Lexicog raphy Methods Applications Trends Linguistics Mouton Gruyter 2009 pp 135162 21 S Tonelli Semiautomatic techniques extending FrameNet lexical database new languages PhD thesis Dept Language Sciences Università Ca Foscari Venezia Italy 2010 22 MR Petruck Typological considerations constructing Hebrew FrameNet HC Boas Ed Multilingual FrameNets Computational Lexicography Methods Applications Trends Linguistics Mouton Gruyter 2009 pp 183205 23 KH Ohara Lexicon grammar multilinguality Japanese FrameNet Proceedings 6th Language Resources Evaluation Conference LREC08 Marrakech Morocco 2008 pp 32643268 24 KH Ohara Framebased contrastive lexical semantics Japanese FrameNet case risk kakeru HC Boas Ed Multilingual FrameNets Computational Lexicography Methods Applications Trends Linguistics Mouton Gruyter 2009 pp 163182 25 C Fellbaum WordNet An Electronic Lexical Database MIT Press 1998 26 R Johansson P Nugues Using WordNet extend FrameNet coverage Proceedings Workshop Building FrameSemantic Resources Scandinavian Baltic Languages NODALIDA Tartu Estonia 2007 pp 2730 27 D Cao D Croce M Pennacchiotti R Basili Combining word sense usage modeling frame semantics Proceedings Symposium Semantics Systems Text Processing STEP08 Venice Italy 2008 pp 85101 28 R Green BJ Dorr P Resnik Inducing frame semantic verb classes WordNet LDOCE Proceedings 42nd Annual Meeting Association Computational Linguistics ACL04 Barcelona Spain 2004 pp 375382 29 E Pianta L Bentivogli C Girardi MultiWordNet Developing aligned multilingual database First International Conference Global WordNet Mysore India 2002 pp 292302 30 M Crespo P Buitelaar Domainspeciﬁc EnglishtoSpanish translation FrameNet Proceedings 6th Language Resources Evaluation Conference LREC08 Marrakech Morocco 2008 pp 14701473 31 P Vossen Ed EuroWordNet A Multilingual Database Lexical Semantic Networks Springer 1998 32 C Mouton G Chalendar B Richert FrameNet translation bilingual dictionaries evaluation EnglishFrench pair Proceedings 7th Language Resources Evaluation Conference LREC10 La Valletta Malta 2010 pp 2027 33 B Chen P Fung Automatic construction EnglishChinese bilingual FrameNet Proceedings Human Language Technology Conference North American Chapter Association Computational Linguistics HLTNAACL04 Boston USA 2004 pp 2932 34 S Padó M Lapata Crosslingual bootstrapping semantic lexicons The case FrameNet Proceedings 20th National Conference Artiﬁcial Intelligence AAAI05 vol 3 AAAI Press 2005 pp 10871092 35 M RuizCasado E Alfonseca P Castells Automatic assignment Wikipedia encyclopedic entries WordNet synsets Advances Web Intelli gence 3528 2005 380386 36 O Medelyan C Legg Integrating Cyc Wikipedia Folksonomy meets rigorously deﬁned commonsense Proceedings AAAI 2008 Workshop Wikipedia Artiﬁcial Intelligence An Evolving Synergy vol 8 2008 pp 1318 37 D Lenat CYC A largescale investment knowledge infrastructure Communications ACM 38 11 1995 3338 38 S Sarjant C Legg M Robinson O Medelyan All eat ontologybuilding Feeding Wikipedia Cyc Proceedings IEEEWICACM International Joint Conferences Web Intelligence Intelligent Agent Technologies WIIAT09 2009 pp 341348 39 F Suchanek G Kasneci G Weikum Yago A core semantic knowledge Proceedings 16th International World Wide Web Conference ACM Banff Alberta Canada 2007 pp 697706 40 R Navigli S Ponzetto BabelNet Building large multilingual semantic network Proceedings 48th Annual Meeting Association Computational Linguistics Association Computational Linguistics Uppsala Sweden 2010 pp 216225 41 A Csomai R Mihalcea Linking documents encyclopedic knowledge IEEE Intelligent Systems 23 5 2008 3441 Special Issue Natural Language Processing Web 42 D Milne IH Witten Learning link Wikipedia Proceedings 17th ACM Conference Information Knowledge Management CIKM08 ACM New York NY USA 2008 pp 509518 43 S Kulkarni A Singh G Ramakrishnan S Chakrabarti Collective annotation Wikipedia entities web text Proceedings 15th ACM SIGKDD International Conference Knowledge Discovery Data Mining KDD09 ACM New York NY USA 2009 pp 457466 44 E Agirre PG Edmonds Word Sense Disambiguation Algorithms Applications Springer 2006 45 R Navigli Word sense disambiguation survey ACM Computing Surveys 41 2 2009 169 S Tonelli et al Artiﬁcial Intelligence 194 2013 203221 221 46 C Giuliano AM Gliozzo C Strapparava Kernel methods minimally supervised WSD Computational Linguistics 35 4 2009 513528 47 J ShaweTaylor N Cristianini Kernel Methods Pattern Analysis Cambridge University Press 2004 48 D Yarowsky Decision lists lexical ambiguity resolution Application accent restoration Spanish French Proceedings 32nd Annual Meeting Association Computational Linguistics Las Cruces New Mexico 1994 pp 8895 49 H Lodhi J ShaweTaylor N Cristianini C Watkins Text classiﬁcation string kernels Journal Machine Learning Research 2 3 2002 419444 50 C Saunders H Tschach J ShaweTaylor Syllables string kernel extensions Proceedings 19th International Conference Machine Learning ICML02 2002 pp 530537 51 N Cancedda E Gaussier C Goutte J Renders Wordsequence kernels Journal Machine Learning Research 32 6 2003 10591082 52 N Cristianini H Lodhi J ShaweTaylor Latent semantic kernels Journal Intelligent Information Systems 18 2 2002 127 53 R Mihalcea Using Wikipedia automatic word sense disambiguation Proceedings Human Language Technologies The Annual Conference North American Chapter Association Computational Linguistics NAACLHLT07 Rochester New York USA 2007 pp 196203 54 T Zesch C Müller I Gurevych Extracting lexical semantic knowledge Wikipedia Wiktionary Proceedings 6th Language Resources Evaluation Conference LREC08 Marrakech Morocco 2008 pp 16461652 55 CC Chang CJ Lin LIBSVM library support vector machines 2001 Software available httpwwwcsientuedutwcjlinlibsvm 56 R Mihalcea P Edmonds Eds Proceedings SENSEVAL5 Third International Workshop Evaluation Systems Semantic Analysis Texts Association Computational Linguistics Barcelona Spain 2004 57 S Pradhan E Loper D Dligach M Palmer SemEval2007 Task17 English lexical sample SRL words Proceedings 4th International Workshop Semantic Evaluations SemEval2007 Association Computational Linguistics Prague Czech Republic 2007 pp 8792 58 L Bentivogli P Forner C Giuliano A Marchetti E Pianta K Tymoshenko Extending English ACE 2005 corpus annotation groundtruth links Wikipedia Proceedings COLING 2010 Workshop The Peoples Web Meets NLP Collaboratively Constructed Semantic Resources Beijing China 2010 pp 1926 59 PN Mendes M Jakob A GarcíaSilva C Bizer DBpedia spotlight Shedding light web documents Proceedings 7th International Conference Semantic Systems ISemantics Graz Austria 2011 pp 18 60 J Ruppenhofer C Sporleder R Morante CF Baker M Palmer SemEval2010 Task 10 Linking events participants discourse Proceed ings NAACLHLT Workshop Semantic Evaluations Recent Achievements Future Directions Boulder CO USA 2009 pp 106111 61 I Witten D Milne An effective lowcost measure semantic relatedness obtained Wikipedia links Proceeding AAAI Workshop Wikipedia Artiﬁcial Intelligence Evolving Synergy AAAI Press Chicago USA 2008 pp 2530 62 D Das N Schneider D Chen NA Smith SEMAFOR 10 A probabilistic framesemantic parser Tech Rep CMULTI10001 Carnegie Mellon University 2010 63 P Annesi R Basili Crosslingual alignment FrameNet annotations hidden Markov models Proceedings 11th International Confer ence Computational Linguistics Intelligent Text Processing CICLing10 Iasi Romania 2010 pp 1225 64 S Padó M Lapata Crosslingual annotation projection semantic roles Journal Artiﬁcial Intelligence Research 36 2009 307340 65 S Padó G Pitel Annotation précise du français en sémantique roles par projection crosslinguistique Actes la 14e conférence sur le Traite ment Automatique des Langues Naturelles TALN07 Toulouse France 2007 pp 271280 66 S Tonelli E Pianta Frame information transfer English Italian Proceedings 6th Language Resources Evaluation Conference LREC08 Marrakech Morocco 2008 pp 22522256 67 KH Ohara S Fujii H Saito S Ishizaki T Ohori R Suzuki The Japanese FrameNet project A preliminary report Proceedings Conference Paciﬁc Association Computational Linguistics PACLING03 Halifax Canada 2003 pp 249254 68 J Carletta Assessing agreement classiﬁcation tasks The kappa statistic Computational Linguistics 22 2 1996 249254 69 L Bentivogli E Pianta Exploiting parallel texts creation multilingual semantically annotated resources The MultiSemCor corpus Natural Language Engineering 11 3 2005 247261 Special Issue Parallel Texts 70 S Tonelli G Riccardi Guidelines annotating LUNA corpus frame information Tech Rep DISI10017 Department Information Engineer ing Computer Science University Trento 2010 71 E Agirre O López Lacalle C Fellbaum SK Hsieh M Tesconi M Monachini et al SemEval2010 Task 17 Allwords word sense disambiguation speciﬁc domain Proceedings 5th International Workshop Semantic Evaluation Association Computational Linguistics Uppsala Sweden 2010 pp 7580 72 M Strube SP Ponzetto WikiRelate Computing semantic relatedness Wikipedia Proceedings 21st National Conference Artiﬁcial Intelligence AAAI06 Boston USA 2006 pp 14191424 73 P Sorg P Cimiano Enriching crosslingual structure Wikipedia classiﬁcationbased approach Proceedings AAAI 2008 Workshop Wikipedia Artiﬁcial Intelligence WikiAI08 2008 pp 16 74 V Bryl S Tonelli C Giuliano L Seraﬁni A novel FrameNetbased resource semantic web Proceedings 27th ACM Symposium Applied Computing Association Computing Machinery Riva del Garda Italy 2012 pp 360365