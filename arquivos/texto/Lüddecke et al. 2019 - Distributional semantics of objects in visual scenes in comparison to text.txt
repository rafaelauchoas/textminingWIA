Artiﬁcial Intelligence 274 2019 4465 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Distributional semantics objects visual scenes comparison text Timo Lüddecke Minija Tamosiunaite ab Florentin Wörgötter GeorgAugustUniversity Göttingen Third Institute Physics Germany b Vytautas Magnus University Faculty Informatics Lithuania Alejandro Agostini Michael Fauth r t c l e n f o b s t r c t Article history Received 24 July 2017 Received revised form 31 May 2018 Accepted 4 December 2018 Available online 7 February 2019 Keywords Object semantics Vision language Semantics Distributional hypothesis Computer vision The distributional hypothesis states meaning concept deﬁned contexts occurs In practice word cooccurrence proximity analyzed text corpora given word obtain realvalued semantic word vector taken partially encode meaning word Here transfer idea text images preassigned labels objects activations convolutional neural networks serve context We propose simple algorithm extracts processes object contexts image database yields semantic vectors objects We empirically representations exhibit par performance stateoftheart distributional models set conventional objects For employ wellknown word benchmarks addition newly proposed objectcentric benchmark 2019 The Authors Published Elsevier BV This open access article CC BYNCND license httpcreativecommonsorglicensesbyncnd40 1 Introduction It remains matter debate aspects constitute meaning word object scene term meaning heavily discussed different ﬁelds Here speciﬁcally concerned distributional representation hypothesis Harris 17 states company word determines meaning distributional semantics This study sets test hypothesis images For deﬁnition meaning sense natural language processing NLP uses semantic vectors repre sent wordneighborhoods sentence This approach proven useful different applications text translation different languages 27 determining sentiment sentence 33 question answering 39 Thesaurus generation spelling correction query expansion count applications discussed Turney Pantel 37 Analogously context visual scenes important deﬁning meaning objects It serve basis variety approaches image understanding involve interactions multiple objects determining useful robotic actions ﬁnding taskrelevant objects scene Thus work inspired NLP approaches develop methods obtain semantic vector representations objects considering respective contexts real world scenes composed multiple objects Corresponding author Email address timolueddeckephysunigoettingende T Lüddecke httpsdoiorg101016jartint201812009 00043702 2019 The Authors Published Elsevier BV This open access article CC BYNCND license httpcreativecommonsorglicensesbyncnd40 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 45 Fig 1 By assessing object cooccurrences visual features obtain semantic vectors objects right actual output Texts scenes akin structures composed individual interrelated constituents words objects The location word sentence object scene subject constraints On hand constraints fundamental imposed grammar physics The violation constrains render sentence wrong scene impossible nonsensical Eg grammar forbids subsequent articles chair stand ceiling gravity On hand obeying grammatical constraints guarantee sentence sense laws physics guarantee room useful structure For making sense respective neighbor hoods need appropriate context words arrangement items room Furthermore context help disentangle multiple meanings words objects For example natural language meaning polyseme depends context similarly multifunctional objects employed differently depending situation In way word board acquires particular sense contextual words objects surrounding coffee cup scene constrain set useful actions involving cup coffee klatsch vs cup sink dirty dishes However text analysis long history approaches address question distribu tional semantics derive meaning word degree context Interest approaches recently revived success largescale methods 2829 exhibiting remarkable performance judging similarity analogy concepts By contrast little work obtaining meanings objects considering scene contexts This possible particular largescale datasets recently published vision community allow investigation distributed semantics domain objects Therefore justiﬁed investigate learning semantic vectors words objects In work study hypothesis spatial context contributes meaning object scene anal ogously surrounding words deﬁning meaning word To gather evidence design algorithm extracts semantic vectors scenes visualized Fig 1 We aim analyzing big set images arrive represen tation semantic vectors similar objects group Fig 1 schematically shows cake spoon fork knife group schema object names remain separate bicycle motorcycle car form different group Just common sense hope obtain clustering results obvious differences sentences scenes In contrast scene text linear structure word predeces sor successor Thus straightforward assumption distributional hypothesis hold images remains question complex 3D layout visual world 2D image projections render context relations spread Hence ask Will scenes provide equally strong context relations text In paper address question comparing large set different NLP imagebased methods 11 Overview approach A schematic introduction approach comparison linguistic approaches presented Fig 2 Common distri butional models natural language text corpora determine word sequences generate context vectors word cooccurrence A context vector describes surrounding individual entities words array real numbers Different methods combine vectors ﬁnally semantic vector representations emerge different cepts compared In essence approach middle similar considers concepts objects We scene datasets extract different image descriptors numbering ﬁgure 1 Humanassigned object labels 2 object labels automatically obtained applying RCNN 14 detect objects 3 CNN activations features generated pretrained convolutional neural networks From approaches extract context vectors object scene Context vectors merged create unique semantic vector speciﬁc object class This allows directly comparing types descriptors benchmarking results automatic NLPbased methods human raterbased methods This measuring semantic distances objects inverse semantic similarity respective semantic vector spaces 46 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 Fig 2 Flow diagrams analyzes performed standard natural language processing new approach based human labeling In red abbreviation different analysis methods descriptions Methods For interpretation colors ﬁgures reader referred web version article 12 Contributions We propose simple algorithm compute semantic vectors object classes segmented images extensively compare existing textbased methods This paper knowledge ﬁrst speciﬁcally focus objects scenes In addition analysis existing data collected dataset similarity relatedness judgments 250 object pairs 20 raters speciﬁcally slanted everyday objects Our analysis shows obtained imagebased representations par existing textbased representation methods Quality improved concatenating different context models These ﬁndings indicate text serve basis distributional semantics visual scenes fundamentally different text The remainder paper structured following way Literature originating natural language processing community reviewed Section 2 Section 3 introduces theoretical background approach section 4 experimental methods In order assess validity approach experiments investigating semantic similarity carried Section 5 Discussion outlook provided Section 6 2 Related work There approaches originating diverse ﬁelds related work They discussed section ordered according ﬁeld come Most similar idea paper approaches link distributed semantics natural language processing images However ﬁeld natural language processing arguably largest impact work consequently discussed Image labeling discussed links visual textual data Natural language processing The idea representing entities distributional representations origins linguis tics The distributional hypothesis introduced Harris 17 established ﬁeld distributional semantics The idea distributional semantics statistically analyze distribution words linguistic entities order derive meaning simply You shall know word company keeps 1237 Several methods represent contextual concepts real numbered vectors intermediate representation NLP tasks 482 work ﬁnal output assessed respect semantic similarity 36 An elaborate survey conducted Turney Pantel 37 The work Lund Burgess 26 particularly relevant cooccurrencebased method closely related approach differs respect derivation data underlying methods A direction research laterally addressed Turney Pantel 37 based parameterizing complex statistical models optimizing random initializations Bengio et al 4 proposed condition probability word context cooccurring words neural architecture This learns represent words vectors employ representations order infer word probability Recently starting word2vec algorithms 28 large scale models gained lot attention ability extract synonyms analogies remarkable quality numerous words unsupervised way text collections Subsequent papers discussed ways obtaining word vectors exhibiting properties 29 related traditional approaches 23 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 47 Image labeling Vector representations employed natural language processing vision Some image labeling methods learn map images labels text joint space One approaches WARP model Weston et al 38 Images mapped space multiplying bagofvisualword representation image obtained quantization features 9 Learning carried optimization procedure starting random initializations mappings minimizing hinge rank loss given ground truth data Having learned mappings unknown images mapped vector space determining nearest neighbors labels predicted Instead training scratch recent approach 13 makes use transfer learning They learn mapping images word vector space obtained skipgram model proposed Mikolov et al 28 The mapping carried pretrained convolutional neural network ﬁnetuned adapt task hinge rank loss At test time image mapped joint vector space nearest neighbors evaluated order predict category Both approaches differ methods aim attributing labels images based visual content obtaining general vector representations objects They focus images presenting single salient object common ImageNet work interested constellations multiple objects Distributed semantics images Linking distributed semantics natural language processing images new idea There work employing labels tags images order link textual meaning visual features extracted images Feng Lapata 11 propose method works documents associated image experiments ducted news articles For modalities bagofword representation images representation obtained extracting visual words SIFT descriptors 25 capture local edge orientations extracted images matched visual words learned previously kmeans clustering feature descriptors images In way visual words treated like actual words text semantic vectors assigned words A topic model based Latent Dirichlet Allocation 5 trained documents involving textual visual words In experiments model measure similarity words Bruni et al 6 employ visual words descriptions images However visual features computed differently SIFT extracted densely keypoints spatial binning channel HSV encoded image making algorithm sensitive color Also simple count model employed topic model Visual words conjunction multiple textual labels tags obtain cooccurrence counts certain terms Finally transformed Local Mutual Information association scores Multiple models fusing representations modalities discussed Kádár et al 22 propose model learn meanings words images caption text relating words visual features Similarly work use pretrained Deep Convolutional Neural Networks DCNNs extract visual features A similar approach pursued Kiela Bottou 21 Rather relying captions concatenate visual features multiple object classes ImageNet 10 extracted pretrained DCNNs wellknown word semantic vectors Mikolov et al 28 Both assess models common word similarity bench marks Another example DCNNbased approach Peterson et al 30 They extract features 120 photographs animals observe pairwise dot similarity features correlate weakly human similarity judgments Consequently transformation visual features learned strongly increases correlation human judgments All discussed approaches differ work aspect labels text refer entire image regions In setting availability segmentations able directly access object location image class object enables explicitly focus context objects features object evaluate validity distributional hypothesis images 3 Determining imagebased context One central assumptions approaches discussed context strongly determines meaning In section ﬁrst deﬁne object context image integrate contexts extracted separate images obtain context representations image database We context obtained object image context instance context instance vector context representation object integrated instances semantic vector As main approach integration context averaging provide mathematical justiﬁcation For comparison use standard skipgram method median integration Finally explain concatenate different features create fused context representations 31 Context instance deﬁnition Given dataset scenes containing multiple objects context extraction applied object scene obtain set context instances object In study main approaches deﬁne object instance context image labelbased context described subsection 311 visual featurebased context described subsection 312 48 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 Fig 3 The context averaging method considers object illustrated shapes image determines context Subsequently averaged context calculated objects semantic vector Contextual instances counted cocount indexed cooccurrence reference object counted context self noself Table 1 Comparison employed pretrained CNNs The layer features extracted number features top5 accuracy achieved ImageNet classiﬁcation challenge provided Network architecture Feature Vector Layer Feature Vector Size reported top5accuracy InceptionV1 InceptionV4 ResNet50 VGG16 AvgPool_1a_7x7 global_pool global_pool fc7 1024 1536 4096 2048 896 952 898 928 311 Labelbased Labelbased contexts fully rely image annotations image pixels taken consideration An illustration context description case provided Fig 3 Three schematic images shown left objects represented abstract shapes Two ways determining context deﬁned For object scene neighboring objects object classes counted The resulting counts components vector taken instantiation objects context We model cocount CC column called Counted Instances left box Fig 3 Alternatively neglect number objects scene tickmark existing object creating binary vs notthere vector This model referred cooccurrence CO column called Binary Instances right box Fig 3 The reference object object currently consider counted context s n self noself Fig 3 right vs left Hence labelbased vector v holds v NN N number object classes dataset case cooccurrence v 0 1N 312 Visual featurebased An alternative imagebased way describing object context visual features While multiple ap proaches extract visual features image possible bagofvisual words 9 recent years dominated success convolutional neural networks CNNs activations speciﬁc layers consid ered abstract representation features image fed CNN Here constrained analysis CNNs trained ImageNet 10 InceptionV1 GoogLeNet 34 InceptionV4 35 VGG16 32 ResNet50 18 In contrast labelbased vectors visual featurebased vectors general If o object associ ated image visual featurebased context f o deﬁned result sequence interleaved matrix multiplications nonlinearities pooling operations performed CNN layer f extracted Visualfeaturebased context described vector real numbers opposed vector natural numbers labelbased context Technical details employed CNNs shown Table 1 Feature Size indicates number features actually Following distributional hypothesis 17 constrained analysis image region pertains context object exclude object In visual featurebased case means extract CNN features covering reference object black box mask shape object visible In case multiple objects considered From theoretical perspective expect black box image inhibit features masked area way emphasizing features extracted unmasked area context If convolution window contains mask contents inference However bias affects context object T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 49 wrong features introduced canceled analyzing differences distances object representations Actually experimented objectshaped instead rectangular black mask yielded similar results 32 Context integration Context integration obtain semantic vectors Three methods compared context averaging skip gram based context integration use median instead average 321 Context averaging One way obtain semantic vector object calculate elementwise average context vectors obtained individual object instances This overly simple fact maximum likelihood estimator underlying distributions objects images shown Let set Ok denote object instances class k dataset f context extraction function considers objects context returns realvalued vector representing context Examples functions described subsection 311 312 The vector representation ˆcid2k concept k obtained formula ˆcid2k 1 Ok cid2 oOk f o 1 The averaging method illustrated Fig 3 blackdiskobject Each highlighted row corresponds context vector black disk corresponding schematic image left vector fo equation 1 In depicted case k semantic vector ˆcid2 obtained averaging individual context vectors For obtaining semantic vectors visualfeaturebased analysis realnumbered context instance vectors averaged way obtain object class representations Justiﬁcation context averagingThe averaging context justiﬁed imagining scenario scene scanned perspective object o considering time object seen event dependent object class o In cocount model CC number events object class described integer random variables cooccurrence model CO random variables refer probability event Consequently underlying distributions cocount Poisson cooccurrence Bernoulli For distributions averaging observations equivalent maximum likelihood estimation distributions parameters Hence implicitly deﬁne meaning objects optimal parameters random distributions visual features object labels given observations large scale dataset The theoretical motivation averaging rests following arguments ﬁrst discussed cocount model As stated scanning scene cocount model implies number contextual objects type given object class k Poisson distributed ci k Poissoncid2ki ci N0 Hence corresponding likelihood function Lλki c 0 ki c n ki Ncid3 j1 c λ j ki e j c ki λ j ki c estimator λki sample mean j 1 Nk observed counts object context object class k Then maximum likelihood An alternative model cooccurrence model Here mark object existence Hence assume en context class k certain success probability This leads countering objects class P ci o k Bernoullipik ci 0 1 likelihood function Lpki c 0 ki c n ki c j ki 1 p1c j ki p Ncid3 j1 Also maximum likelihood estimation parameters pki represented sample mean In Appendix provide additional derivations concerning aspects 322 Skipgrambased context integration In addition countingbased averaging described implemented skipgrambased context integration method originates natural language processing considered stateoftheart Its goal generate representations words given word corpus allow prediction contextual surrounding words This algorithm serves basis word2vec 28 programs shown yield good semantic word representations 50 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 We implemented skipgram negative sampling algorithm 28 approximates skipgram target com putationally eﬃcient way ﬁxed number negativesamplepairs This method compatible occurrence CO context In case positive samples obtained pairs objects image Training carried 50 epochs learning rate 1 For positive sample 25 negative samples presented dimension concept vectors 64 A detailed exploration hyperparameters leading values reported provided section A6 Appendix 323 Medianbased context integration In general integration methods possible limit common ones median appears possible natural choice Results impressive Appendix overburden main text 33 Fusion contexts Labelbased visual featurebased contexts encode different information The tells occurring object classes highlevel symbolic description addresses visual appearance features contextobjects Hence appears natural combine semantic quality improves While exist possible methods emphasize concatenation The advantage method require strong assumptions structure context vectors combine number realvalued vectors case different length Concatenation applied levels Given scene object scene apply context extraction methods labelbased context visualfeaturebased context concatenate context vectors This procedure early fusion Alternatively integrate contexts semantic vectors methods inde pendently concatenate obtained vectors ﬁrst average visual featurebased contexts car average labelbased contexts car concatenate resulting vectors This late fusion Let f g context extraction methods O k set object instances class k dataset φ denote context integration function averaging Then formally deﬁne early fusion cid4early k φfo o O k concatenation operation involves normalization mean standard deviation vector b b μb σb Late fusion deﬁned μa σa cid4late k φfo o O k φgo o O k concatenation operation normalization different way Let semantic vectors obtained ﬁrst tobefused context extraction methods object included study Then arrange semantic vectors matrix A rowwise vector row Analogously matrix B semantic vectors obtained second context extraction method arranged From matrices obtain vectors means μ A μB standard deviations σ A σ B columnwise semantic vector zerocentered normalized Then concatenation operation uses normalization b μ A σ A b μB σ B subtraction division operations performed elementwise In section A2 Appendix introduce analyze fusion techniques 4 Standard methods NLP One major goal study compare new imagebased methods stateoftheart textbased methods extraction semantic vectors NLP Fig 2 For Glove 29 50 dimensions 6 billion tokens skipgram negativesampling method Word2Vec toolkit 300 dimensions 100 billion words Google News dataset 28 In cases downloaded precomputed semantic vectors provided authors Internet As standard methods extend explanations instead refer reader respective references 2829 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 51 Table 2 Overview image datasets obtain vector representations LabelMe dataset abbreviated LM Image Training datasets Text Training datasets Dataset Classes Scenes Instances Method Dataset Words COCO LM RCNN 80 3288 79 82081 28072 111974 604907 325288 286835 W2VNeg Glove GoogleNews Wikipedia Gigaword 5 100B 6B Humanrater datasets Name Scene250 Simlex999 MEN Words 80 1028 751 Pairs 250 999 3000 5 Datasets 51 Image datasets Since method requires annotated image data started experiments datasets offering object bounding boxes object labels box However method case raw images available took additional dataset initially annotated advanced offtheshelf object detectionandlabeling algorithm perform automatic labeling Speciﬁcally COCO 24 LabelMe 31 annotated source datasets We created additional automatically labeled dataset RCNN paper combination images COCO ImageNet 10 datasets Dataset statistics presented Table 2 511 Manually annotated datasets Both COCO LabelMe provide annotations form object segments corresponding object names The COCO dataset 74 object labels scene average LabelMe 116 object labels The object labels COCO reliable dataset contains 80 object classes LabelMe provides diverse set classes tendency contain wrong nonsensical labels crowdsourced Because consider object labels occur times LabelMe yields 3288 object classes 512 Automatically annotated dataset RCNN We created RCNN dataset applying Mask RCNN object detector 19 unannotated images Mask RCNN takes raw image input automatically generates labeled bounding boxes objects detected scene This way annotated dataset created analogous manually labeled datasets introduced subsection 511 We purpose initial dataset COCO create RCNN allow direct comparison results humanlabeled data We forced use smaller testing set COCO pretrained MaskRCNN model employ trained COCOtraining set Thus increase resulting RCNN dataset added subset ImageNet images With processed 160000 images total Mask RCNN objects 111974 images high threshold applied reliable object detection By procedure 79 object classes discovered possible 80 COCO objects classes Mask RCNN pretrained The average number discovered objects scene 25 52 Human raterbased datasets Ground Truth Benchmarks To compare scenebased analysis corresponding results obtained natural language analysis conducted extensive experiments common human raterbased benchmarks NLP including newly introduced benchmark speciﬁcally targeting everyday objects All benchmarks rely wordpair comparisons assessed human raters In general relations measured similarity relatedness 20 Similarity refers shared properties words concepts pair train car wheels host passengers On hand general aspect relatedness incorporates additional relationships 7 like function meronymy remote control turn TV related similar 521 Existing word pairbased benchmarks Here MEN 6 3000 word pairs SimLex999 20 999 word pairs benchmarks Naturally restrict analyses intersection words benchmark image datasets small quantiﬁcation intersection section A3 appendix 52 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 522 Novel object namebased benchmark Due small intersection common benchmarks decided create benchmark dataset called Scene250 consists randomly sampled subset 250 pairs possible 3160 pairs 80 COCO objects This way Scene250 fully intersects COCO large degree LabelMe section A3 We asked 20 adult raters 10 male 10 female indicate degree object similarity relatedness pairs scale zero The concepts similarity relatedness explained participants based deﬁnitions examples For obtaining ﬁnal score averaged scores 20 participants The average pairwise Spearman correlation coeﬃcient raters 0544 similarity 0659 relatedness The Scene250 dataset available download httpcns physik3 uni goettingen cns group datasets scene250 6 Means quantiﬁcation We introduced quality measures evaluate obtained semantic vectors 1 clustering consistency 2 tohuman correlation 61 Clustering consistency This measure based organization 80 object classes contained COCO dataset super categories like animal vehicle kitchenware 24 In ideal case closest neighbors given semantic vector belong supercategory We measure proportion satisﬁed Speciﬁcally object o supercategory consider semantic vector ﬁnd k nearest neighbor semantic vectors Of k vectors count number objects fall supercategory o normalize count k Then average results o supercategory super categories ﬁnally average scores k 1 k 5 5 size smallest supercategory COCO obtain single scalar score For COCO 80 object classes 80dim semantic vector space To remain comparable evaluating LabelMe compatible subset 60 classes occurring LabelMe 80 COCO classes semantic vectors 3288 instead 80 dimensions The clustering consistency measure based similar grounds common standard classiﬁcation accuracy met rics knn classiﬁer like precision recall To main text concise discuss relation subsection A4 Appendix 62 Systemtohuman correlation For compared similarity relatedness scores wordpairs determined human raters benchmarks MEN Simlex Scene250 ratings pairs calculated different automatic procedures This best understood simple example Let assume benchmark dataset consists ﬁve wordpairs listed descending order accord ing humandetermined similarity rankorder list motorcyclebicycle trainmotorcycle cartrain trainorange orangeairplane From vector representations concepts calculated VGG16 compute semantic vector distance word pairs Semantic distances cartrain d 02 orangeairplane d 08 motorcyclebicycle d 01 trainorange d 09 trainmotorcycle d 03 For comparison use inverse distance following rankordered list motorcyclebicycle cartrain trainmotorcycle orangeairplane trainorange Both lists identical clearly correlated quantify Spearman rank correlation coeﬃcient example value 08 This Spearman rank correlation calculation performed COn CCn COs CCs InceptionV1 InceptionV4 VGG16 ResNet50 SkipGram Random vectors MEN Simlex Scene250 wordpairs existing datasets section A3 quantiﬁcation wordpair intersections Note automatic procedures calculate distance value given pair Thus compared resulting inverse distance rank list similarity relatedness rank lists human raters 7 Experiments This section reports quantitative results experiments Regarding measure semantic distance consistent differences results obtained Euclidean versus cosine distance Both measures T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 53 Fig 4 Experimental evaluation different context models given different colors legend ﬁgure COCO LabelMe middle RCNN On left clustering consistency shown On right systemtohuman correlation Scene250 data measuring similarity sim relatedness rel shown render results usually 10 differences Therefore results cosine distance commonly relevant literature In following visualfeature based semantic vectors match quality stateoftheart textbased methods everyday objects despite extracted different data smaller number samples 71 Comparison context models The ﬁrst experiment Fig 4 compare different context models ﬁrst foremost labelbased context vs visual featurebased context Performance analyzed semantic vectors obtained scene datasets COCO LabelMe RCNN Number classes scenes contexts datasets provided Table 2 section 51 Labelbased contexts annotated CO CC corresponding Co Occurrence CoCount discussed section 31 With subscripts s n indicate reference objects excluded context description s means selfincluded n means nonselfincluded Visualfeaturebased contexts obtained CNNs VGG16 InceptionV1 InceptionV4 ResNet50 All mentioned contexts obtained averag ing context integration Skipgram performance context COn provided baseline comparison averagingbased methods Chance performance indicated case label Random For skipgram chance columns Fig 4 samples average obtained shown horizontal lines corresponding column The remaining columns rely randomized sampling All plots left clustering consistency measure different methods ones center right systemtohuman correlation described For clustering consistency neighbors semantic vector space analyzed based existing division 80 COCO object classes 11 supercategories given 54 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 Fig 5 Plot Spearman correlation coeﬃcient similarity ratings relation number instances training developers dataset Systemtohuman correlation based newly introduced Scene250 benchmark One observe measures contexts clear abovechance performance Different measures similar rankorder analyzed contexts holds COCO LabelMe datasets RCNN shows bit lower scores measuring systemtohuman correlation labelbased contexts However RCNN dataset sparsest labels 25 labels image average reported method section Apparently object density support visualfeaturebased context analysis low reliably analyzing label cooccurrences Furthermore ﬁnd skipgram negative sampling baseline based COn 9th column plot performing worse corresponding COn context obtained simple averaging 7th column The exception RCNN dataset sparsity labels evaluation labelbased contexts stable discussed paragraph Relatively low skipgram performance reasons In contrast text corpora skipgrams employed big datasets dataset fairly small labels Also negative sampling requires hyperparameter choices number negative samples sampling strategy negatives chance better conﬁgurations ﬁnd despite fairly extensive search subsection A6 Appendix Surprisingly visual featurebased contexts speciﬁcally look ResNet50 exhibit better performance labelbased ones Hence appears CNNgenerated visual features stronger association meaning objects manually assigned class labels addition expensive obtain In general best performance context model COs n featurebased model ResNet50 VGG16 Thus evaluations emphasis methods Concerning systemtohuman correlation central right column ﬁnd times produces slightly bigger systemtohuman correlations similarity relatedness We maximal correlation 0616 similarity 0550 relatedness Correlation humans 0544 similarity 0659 relatedness This degree remarkable shows performs close human level An additional important observation RCCN dataset automatically labeled neural net methods visualfeaturebased approaches VGG16 InceptionV1 ResNet50 left bars lead scores higher COCO dataset This remarkable automatic labeling Mask RCNN reliable humanlabeling These ﬁndings demonstrate impressive progress object detection recent years suggest applying object detector preprocessing step viable solution handles huge number scenes quantity annotated humans In future performance improved simply pluggingin advanced object detection algorithm In particular interesting larger set objects covered 72 Scale dependency size dataset Under assumption quality increases number data points valid question ask quality reached ceiling hereused number scenes expect increase given larger dataset Since number considered object classes crucial factor determine scaling behavior COCO dataset diverse LabelMe dataset Fig 5 suggests different answer datasets results obtained COCO dataset 80 different objects 604907 context instances subsection 31 reach ceiling 1000 analyzed contexts T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 55 Table 3 Fusion contexts extracted COCO RCNN Clustering consistency Scene250 sim rel MSCOCO 80 concepts COn VGG16 ResNet50 Late Norm VGG16COn Early Norm VGG16COn Late Norm ResNet50COn Early Norm ResNet50COn RCNN 79 concepts COn VGG16 ResNet50 Late Norm VGG16COn Early Norm VGG16COn Late Norm ResNet50COn Early Norm ResNet50COn 0533 0648 0698 0680 0656 0738 0702 0472 0662 0691 0717 0690 0726 0713 0467 0513 0460 0643 0579 0663 0522 0317 0547 0494 0653 0614 0686 0554 0489 0593 0533 0685 0645 0696 0587 0312 0616 0559 0704 0681 0715 0614 scenes LabelMe 3288 different objects clear saturation visible 325288 analyzed instances instances available dataset This expected number context vector dimensions LabelMe larger higher number possible contextual objects allows conﬁgurations context requiring examples convergence 73 Fusion contexts Table 3 reports fusion results supervised COCO dataset automatically annotated RCNN dataset We apply fusion context COn best label based contexts shown Fig 4 visualfeature based contexts VGG16 ResNet50 It seen fusing types contexts improves clustering consistency systemtohuman correlation similarity relatedness datasets Hence fusion turns inexpensive powerful method increase quality Late fusion provides consistently better scores early fusion Thus late fusion comparing methods stateoftheart 74 Comparison stateoftheart How imagebased method compare automatic textbased methods NLP Word2Vec Glove This comparison ways 1 We determine compare clustering consistency different methods 2 ask methods behave relative humanrater based groundtruth data MEN Sim lex999 Scene250 datasets Hence ask speciﬁcally Spearman correlation coeﬃcient imagebased vs human rater based bigger smaller NLPbased vs human raterbased For comparison use purely textbased approaches Word2Vec skipgram negative sampling trained Google news 28 W2VNeg Glove 6B 29 trained Wikipedia Gigaword 5 Glove We use multimodal text imagebased methods proposed Kiela Bottou 21 KielaMax KielaMean This compared methods use basis ResNet50 VGG16 best performing methods according previous experiments extend comparisons different combinations basemethods Late Fusion cooccurrence context selfcounting COn addition Late Fusion NLPmethod skipgram negative sampling vectors computed Google News W2VNeg Note considered comparison smallest common subset concepts word pairs corresponds respective intersection datasets comparison This intersection sets example COCO Scene250 data Glove In section A3 Appendix explain intersection subsets look like Due fact RCCN descendent COCO intersections Table 4 shows results 741 Clustering consistency We evaluate clustering consistency intersection categories scene datasets COCO LabelMe RCNN stateoftheart implementations Glove W2VNeg Kiela As use supercategories deﬁned 56 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 Table 4 Comparison representation stateoftheart methods benchmarks left right Clustering sistency Spearman correlation relatedness rel similarity sim ratings Scene250 benchmark Spearman correlation similarity SimLex999 relatedness MEN Clustering Consistency Scene250 SimLex999 MEN sim rel COCO 64 concepts 165 pairs 9 pairs 3 pairs ResNet50 LateFusionNorm ResNet50COn LateFusionNorm ResNet50COnW2VNeg VGG16 LateFusionNorm VGG16COn LateFusionNorm VGG16COnW2VNeg Glove W2VNeg KielaMax KielaMean LabelMe ResNet50 LateFusionNorm ResNet50COn LateFusionNorm ResNet50COnW2VNeg VGG16 LateFusionNorm VGG16COn LateFusionNorm VGG16COnW2VNeg Glove W2VNeg KielaMax KielaMean RCNN 0682 0670 0693 0631 0654 0678 0590 0716 0580 0592 0459 0702 0726 0537 0689 0703 0666 0707 0435 0520 0548 0744 0766 0626 0740 0754 0744 0742 0494 0574 60 concepts 151 pairs 166 pairs 626 pairs 0641 0647 0663 0606 0614 0622 0587 0715 0589 0599 0588 0681 0711 0567 0666 0687 0704 0727 0462 0549 0617 0727 0755 0606 0716 0737 0752 0751 0506 0598 0271 0230 0290 0297 0241 0268 0289 0463 0430 0366 0343 0431 0545 0354 0404 0461 0679 0776 0573 0608 64 concepts 165 pairs 9 pairs 3 pairs ResNet50 LateFusionNorm ResNet50COn LateFusionNorm ResNet50COnW2VNeg VGG16 LateFusionNorm VGG16COn LateFusionNorm VGG16COnW2VNeg Glove W2VNeg KielaMax KielaMean 0631 0677 0719 0605 0677 0703 0590 0716 0580 0592 0521 0724 0743 0591 0708 0718 0666 0707 0435 0520 0590 0754 0772 0661 0751 0763 0744 0742 0494 0574 COCO Under assumptions ﬁnd intersection 60 64 concepts respectively datasets cases Fusing labelbased featurebased contexts VGG16COn improves results Adding textbased context VGG16 COnW2VNeg increases performance improvement small This conﬁrms ﬁndings usefulness context fusion including fusion textbased contexts Concerning pure NLPbased methods ﬁnd W2VNeg shows strong performance methods achieve But far beat NLPbased methods 742 Systemtohuman correlation Systemtohumancorrelation measured relative Scene250 SimLex999 MEN datasets The table shows considering COCO RCNN essentially intersection data 9 3 pairs respectively Scene250 purposefully created useful overlap 165 151 pairs Findings Scene250 benchmark closely following results obtained clustering consistency However fusion visual contexts W2Vneg twice outperforming pure W2Vneg happened scene datasets strictly controlled object labels COCO RCNN The overlap LabelMe SimLex999 166 pairs MEN 625 pairs big This intersection contains big proportion general objects straightforward visual representation ex amples art bedroom construction game image reﬂection shoulder smile subway sunlight water Also includes supercategories animal cloth container food furniture vehicle usage introduces ambiguities image T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 57 Fig 6 Qualitative results Plot 80 object vectors labels COCO projected 2D multidimensional scaling color corresponding supercategory Bottom Plot belonging word labels notations bus vehicle Some pairs benchmarks include words multiple meanings homonyms speciﬁcally nonobject meaning makes words related like guitar rock card bridge As consequence imagebased methods worse NLPbased ones Another reason based statistics LabelMe 28072 scenes robustness reasons considered objects labeled scenes times Thus objects included analysis fairly infrequent appeared contexts infrequently This likely led data gain statistically solid scenebased knowledge abstract objects mentioned Furthermore SimLex999 MEN collected assess general concepts best judge object concepts Scene250 instead created speciﬁcally judge everyday object pairs Pairs rated informed subjects treated wordpairs thoughtfully It rigorous condition differences image based word pairbased assessments vanish Summary Summed methods compare textbased semantic vectors outperform multi modal semantic algorithms long evaluation run set proper objects W2VNeg turns exhibit good scores note text corpora W2VNeg trained magnitudes larger terms vocabulary size similar context number words object instances datasets employ 75 Qualitative results Results visualized reducing dimensions preserving distances multidimensional scal ing This way qualitative insights obtained Here present different types visualization Super classes Fig 6 Top A plot vectors corresponding COCO classes visualized dots supercategories animal determining color Ideally object vectors pertaining supercategory form groups Local space Fig 6 Bottom On ﬁnegrained scale object vectors preselected set names plotted Instead dot respective object plotted Functional Fig 7 Instead grouping based supercategories split set concepts according functional trait Concepts trait visualized color concepts trait visualized gray dots We deﬁned traits larger_than_human sharp round has_wheels can_fly We observe concepts cluster according supercategory reasonable groups objects local space Furthermore ﬁnd concepts grouped functional groups share supercategory Thus ﬁgures provide visual conﬁrmation reported clustering results 58 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 Fig 7 Qualitative analysis functional concepts represented Top VGG16 middle COn W2VNeg Positive examples cate gories highlighted red concepts gray points 8 Discussion 81 Main contribution In study asking distributional hypothesis linguistics 17 hold images Text linear structure images 2Dprojections 3D scenes higher dimensionality lead dilution information Thus speciﬁcally wanted quantify powerful semantic vector representation obtained scene information Here presented simple effective method approach problem understanding objects scene context extracting semantic vectors The main result study experiments methods data text images appear equally powerful sources context analysis This degree astonishing textbased methods like W2VNeg GloVe use 1011 words order 105 images 106 labels Taken shows visual context contributes cognitive concepts objects considered building semantic vectors Our evaluations suggests simple integration methods like presented paper suﬃce capture kind semantics The data critical text imagebased context method 82 Pros Cons Why analyze images instead text One aspect mentioned density information Different expectations small set images carry substantial amounts certain context information This holds speciﬁcally context information aspects texts dont talk like layout utensils kitchen drawer way workshop arranged Arguably texts provide type information cases context extraction easier images text Action understanding execution robotics encountered situation While easy obtain massive higher level action information text sources types information vital household robot missing For example Hardly ﬁnds text handle knife spatula cooking Videos images hand abundant In addition important beneﬁcial aspect imagebased context extraction results performance RCNNlabeled CNN activationdetermined object context indicate possible perform automatic semantic assessment objects scenes human labeling accuracy similar humansupervised methods T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 59 Furthermore small pilot experiment shown Fig 7 functional groupings extracted Other visual featurebased grouping possibly detailed analysis currently possible mainly object categories broad category knife tell metallic For quantitative analysis interesting train classiﬁer regressor capture speciﬁc aspects semantic vectors However currently possible set objects small number features large Eg training like eatable maybe tens positive samples hundreds negative samples having thousands features likely overﬁt simple classiﬁers At moment prevents rigorous quantitative analyses kind results Fig 7 look promising future work addressing mentioned problems possible direction Imagebased context analysis clear disadvantages For example abstract concepts extracted Also longer textnarratives contain aspects reasoning Images Hence artiﬁcial narrative generation images far remains relatively shallow compared creativity example child describes image This achieved humans able extract generative way complex context image Modern image analysis methods including ones presented stop short However practical perspective conﬁdent existing methods extract word vectors Glove Word2Vec serve basis numerous methods NLP beneﬁt addition visual scenic context This require large dataset object detector capable handling thousands classes considering recent progress vision matter time available 83 Other aspects future work It interesting discuss ﬁndings different perspective Meaning obtained sidering text This issue commonly known symbol grounding problem 16 artiﬁcial intelligence Glenberg Robertson 15 argue possible assign meaning abstract symbol like word long expressed respect abstract symbols This case text labels image annotations However authors suggest overcoming problem linking different modalities considered text images Evidently humans perform cocontext analyses text image information example text remains abstract opaque image A good example industrial instruction sheets small product assembly human workers Textonly instructions nontransparent One example worked context European funded ACAT Action Categories project Place rotor cap magnet holder This instruction meaningful seeing actual objects assembly step Object class vectors conjunction text afford degree obtained complementary modalities This way objects spatial context linked textual context Hence process acquiring meaning stand legs While directly results support notion context strengthened combinations Several additional aspects addressed future work Currently knowledge captured model expressed linear translations high dimensional feature space It useful investigate complex rep resentations reduce size feature space As starting point hyperbolic geometry considered Additionally performed early experiments concerning combination vectors spaces obtained different modalities The performance gain experiments indicates direction promising fairly cheap way improving results relative single modal semantic vectors All example lead improved identiﬁcation taskrelevant objects suggest tasks generate planning problem deﬁnitions automatically depending objects scene This great use robotic execu tions humanlike tasks 1 instance automatic generation task descriptions signiﬁcantly ease humanrobot interaction Acknowledgements This research received funding European Commission Horizon 2020 Program H2020ICT20161 grant agreement 731761 IMAGINE Appendix A A1 Derivation cocount context This derivation explains cocount context Cooccurrence context seen special case frequency object class limited Hence argument following modiﬁed accordingly transferred cases 60 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 A11 Probabilistic derivation A common way events knowing number trials Poisson distribution 3 The choice Poisson distribution justiﬁed occurrence objects considered events spatial domain Furthermore Poisson distributed random variable takes positive integer values true cooccurring objects Hence assume frequency object m occurring context object k follows Poisson probability distribution rate λm k This means generate context vector object draw samples Poisson distribution speciﬁc parameters component Following idea distributional hypothesis parameters context represent object classes Subsequently obtain parameters Having observed Nk instances object class k variable 1 Nk refers context vector ˆcki ith instance class k We assume probabilistic model P c o object class determines context The goal k m 1 K maximize likelihood L observations ﬁnd parameters cid2 λm k Lcid2 P c o cid2 Kcid3 Nkcid3 k1 i1 P c ˆcki o k cid2 Due monotonicity logarithm applied This facilitates steps retains maximum log Lcid2 Kcid2 Nkcid2 k1 i1 log P c ˆcki o k cid2 2 3 The Poisson distributions mass function inserted Due assumption cooccurring objects independent occurrence probabilities context objects follow multiplication P c ˆcki o k cid2 Kcid3 m1 ˆcm ki e λm k ˆcm ki λm k In order ﬁnd maximum likelihood derivative respect λλλk calculated Kcid2 Nkcid2 Kcid2 log Lcid2 ˆcm ki log λm k λm k log ˆcm ki log Lcid2 λm k m1 1 k1 Nkcid2 i1 i1 ˆcm ki λm k 4 5 6 Since c refers positive cooccurring object counts λm k describes rate positive second derivative negative indicating maximum Hence setting ﬁrst derivative zero obtain optimal parameterization λ k Simpliﬁed λ k average context vectors cid4 cid5 ˆcki 7 λ k arg max cid2 Lcid2 k A12 Geometric perspective 1 Nk Nkcid2 i1 Rather considering observations objects events problem permits geometric perspective ob servations context vectors involving cooccurrence frequencies spread highdimensional K dimensions vector space Every observed context associated class goal ﬁnd representative context class We interpret problem optimization cost function If cost deﬁned sum mean quadratic Euclidean distances class minimum analytically derived mean context λ k arg min ck 1 Nk Nkcid2 i1 ck ˆci2 1 Nk Nkcid2 i1 ˆci 8 A2 Alternative context integration methods In main text compared average context Skip Gram context integration Many integration methods possible For example median appears possible natural choice Thus look based COCO dataset Fig 8 compare performance averaging Fig 8 In plot ﬁrst columns obtained averaging columns 5 8 obtained median The results T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 61 Fig 8 Comparison averaging diagonal hatching median square hatching context integration median leads improvement decreases performance In particular case VGG16 median yielded fairly strong improvement However median stable performance decrease performance substantial C O n C Cn context methods ﬁgure averaging remains better method A3 Comparison fusion methods There multiple ways combining different types context vectors concept In main text analyzed type early fusion concatenating context instances type late fusion concatenating semantic vectors We applied speciﬁc type normalization early fusion type late fusion Here analyze methods The investigated methods concatenationbased sum vary way normalization carried prior concatenation Let b stand vectors concatenation operation We deﬁne following fusion methods vectors 1 Simple concatenation cata b b 2 Simple averaging averagea b b 2 Note method fairly limited requires context vectors length 3 Concatenation lengthbased normalization eqa b dima b dimb dim denotes length vectors 9 4 Early fusion weight normalization main text b μb σb normearlya b μa σa μa μb σa σb scalar mean standard deviation vectors b respectively 5 Late fusion weight normalization main text b μB σ B normlatea b μ A σ A considers vectors respective embedding A B computes mean standard deviation independently dimension μ σ vectors 62 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 Table 5 Comparison fusion methods COCO Clustering Scene250 CCn COn 1 Early Concat CCnCOn 2 Early Average CCnCOn 1 Early Concat InceptionV1COn 3 Early Equal InceptionV1COn 4 Early Norm InceptionV1COn 5 Late Norm InceptionV1COn 3 Late Equal InceptionV1COn 7 Late NormToOne InceptionV1COn 6 Late NormStdOnly InceptionV1COn 1 Early Concat VGG16COn 3 Early Equal VGG16COn 4 Early Norm VGG16COn 5 Late Norm VGG16COn 3 Late Equal VGG16COn 7 Late NormToOne VGG16COn 6 Late NormStdOnly VGG16COn 0520 0533 0529 0530 0670 0627 0682 0693 0627 0535 0677 0649 0639 0656 0680 0639 0535 0645 sim 0375 0467 0385 0395 0466 0573 0573 0643 0573 0467 0419 0513 0563 0579 0643 0563 0468 0473 rel 0362 0489 0377 0391 0550 0611 0637 0674 0611 0490 0499 0593 0615 0645 0685 0615 0490 0556 6 A simpliﬁed version weight normalization considers standard deviation Fig 9 Intersections different data sets normstda b σ A b σ B 7 Late fusion norm concatenates vectors normalized length normonea b b b Note context averaging integration method early fusion late fusion equivalent concatenation average length normalization order operations commutative In Table 5 results obtained different fusion methods shown First compare results simple concatenation averaging contexts C Cn C O n Note use averaging potentially interesting context combinations vectors shall equal length Here indicated context fusion methods substantial advantage We experimented fusion methods different types context vectors labelbased visualfeaturebased In summary shows fusion usually improve result Late Norm method best Note fusion methods possible exhaustive analysis performed A4 Intersections different datasets When evaluating method stateoftheart methods given groundtruth benchmarks needed consider tripartite intersection different datasets 1 2 3 numbering Fig 9 left Here explain reasoning specify coverage intersections Concerning similarity ratings Fig 9 A compared 3 conventional NLP textbased methods 2 imagebased methods grounding comparisons 1 humanrated datasets Scene250 Simplex999 MEN These datasets T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 63 Fig 10 Sketch precisionrecall evaluation Left concepts supercategory middle square centered view twonearestneighbors concepts indicated right error categories based true labels classiﬁcation based nearest neighbors Fig 11 kNN scores context extraction methods named row Fig 9 red The human rated datasets collection pairs concepts similarity relatedness pair indicated The number pairs included dataset given ﬁgure beneath datasets names In order evaluate performance methods NLP textbased methods consider pairs conjointly contained datasets levels 13 The row ﬁgure blue shows number pairs conjointly contained humanrater image datasets row black shows ﬁnal minimal resulting intersection NLP datasets These ones W2VNeg Glove Clearly large intersections given row study Intersection 3 9 pairs ruled The procedure performed right Fig 9 B time concepts supercategories evaluate clustering consistency As ground truth evaluation division 80 COCO concepts 11 supercategories humans RCNN 2nd row contains 79 Mask RCNN able ﬁnd hair dryer LabelMe overlaps 76 concepts The ﬁnal overlap NLP datasets given row panel B concepts perform comparison A5 Precision recall As alternative clustering consistency quality clustering assessed k nearest neighbor classiﬁer First explain create classiﬁer Consider semantic vectors Fig 10 involving 12 concepts supercategories Square circle triangle We iterate supercategories Fig 10 mid square differentiate element square nonelement X Using binarization decide truepositive falsepositive falsenegative truenegative precision recall computed precision recall T P T P F P T P T P F N Since involved supercategory procedure repeated supercategory precision recall scores averaged yielding numbers reported Fig 11 Results remain consistent comparison ones obtained clustering consistency compare Fig 4 main text 64 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 Table 6 Scores hyperparameter search skipgram The number bracket indicates standard deviation runs negative samples epochs dimension clustering consistency similarity relatedness 10 25 50 25 25 25 25 50 50 50 10 100 50 50 128 128 128 128 128 64 256 0423 0015 0413 0016 0404 0013 0228 0044 0468 0015 0478 0020 0372 0018 0438 0031 0455 0026 0452 0017 0265 0029 0474 0027 0472 0021 0403 0021 0397 0030 0433 0019 0441 0014 0258 0030 0441 0016 0451 0019 0386 0016 A6 Skipgram hyperparameter search The SkipGram negative sampling training multiple hyperparameters To enable fair comparison meth ods investigate different choices number negative samples presented positive sample number training epochs dimension concept vectors Table 6 Regarding number negative sam ples ﬁnd algorithm fairly stable choose 25 The scores suggest epochs 50 epochs training converged cases 64 dimensions exhibit good performance Hence decided run training 50 epochs 64dimensional concept vectors References 1 Alejandro Agostini Carme Torras Florentin Wörgötter Eﬃcient interactive decisionmaking framework robotic applications Artif Intell 247 2017 187212 2 Mohit Bansal Kevin Gimpel Karen Livescu Tailoring continuous word representations dependency parsing Proceedings 52th Annual Meeting Association Computational Linguistics Association Computational Linguistics 2014 pp 809815 3 Roger J Barlow Statistics A Guide Use Statistical Methods Physical Sciences vol 29 John Wiley Sons 1989 4 Yoshua Bengio Réjean Ducharme Pascal Vincent Christian Janvin A neural probabilistic language model J Mach Learn Res 3 2003 11371155 5 David M Blei Andrew Y Ng Michael I Jordan Latent Dirichlet allocation J Mach Learn Res 3 2003 9931022 6 Elia Bruni NamKhanh Tran Marco Baroni Multimodal distributional semantics J Artif Intell Res 49 2014 147 7 Alexander Budanitsky Graeme Hirst Evaluating wordnetbased measures lexical semantic relatedness Comput Linguist 32 1 2006 1347 8 Ronan Collobert Jason Weston Léon Bottou Michael Karlen Koray Kavukcuoglu Pavel Kuksa Natural language processing scratch 9 Gabriella Csurka Christopher Dance Lixin Fan Jutta Willamowski Cédric Bray Visual categorization bags keypoints Workshop Statistical J Mach Learn Res 12 Aug 2011 24932537 Learning Computer Vision ECCV Prague 2004 Vision Pattern Recognition CVPR 2009 pp 248255 ACL Association Computational Linguistics 2010 pp 9199 10 Jia Deng Wei Dong Richard Socher LiJia Li Kai Li Li FeiFei Imagenet largescale hierarchical image database IEEE Conference Computer 11 Yansong Feng Mirella Lapata Visual information semantic representation The 2010 Annual Conference North American Chapter 12 John R Firth A synopsis linguistic theory 19301955 Studies Linguistic Analysis 1957 pp 132 13 Andrea Frome Greg S Corrado Jon Shlens Samy Bengio Jeff Dean Tomas Mikolov et al Devise deep visualsemantic embedding model Advances Neural Information Processing Systems NIPS 2013 pp 21212129 14 Ross Girshick Jeff Donahue Trevor Darrell Jitendra Malik Rich feature hierarchies accurate object detection semantic segmentation IEEE Conference Computer Vision Pattern Recognition CVPR 2014 pp 580587 15 Arthur M Glenberg David A Robertson Symbol grounding meaning comparison highdimensional embodied theories meaning J Mem Lang 43 3 2000 379401 ISSN 0749596X httplinkinghub elseviercom retrieve pii S0749596X00927141 16 Stevan Harnad The symbol grounding problem Phys D Nonlinear Phenom 42 13 1990 335346 17 Zellig S Harris Distributional structure Word 10 23 1954 146162 18 Kaiming He Xiangyu Zhang Shaoqing Ren Jian Sun Deep residual learning image recognition IEEE Conference Computer Vision Pattern Recognition CVPR 2016 665695 19 Kaiming He Georgia Gkioxari Piotr Dollár Ross Girshick Mask rcnn IEEE international Conference Computer Vision ICCV 2017 20 Felix Hill Roi Reichart Anna Korhonen Simlex999 evaluating semantic models genuine similarity estimation Comput Linguist 41 4 2015 21 Douwe Kiela Léon Bottou Learning image embeddings convolutional neural networks improved multimodal semantics Conference 22 Ákos Kádár Afra Alishahi Grzegorz Chrupała Learning word meanings images natural scenes Trait Autom Lang Nat Sci Cognitives Natural Empirical Methods Natural Language Processing EMNLP 2015 Language Processing Cognitive Sciences TAL 55 3 2014 23 Levy Omer Yoav Goldberg Neural word embedding implicit matrix factorization Advances Neural Information Processing Systems NIPS 2014 pp 21772185 24 TsungYi Lin Michael Maire Serge Belongie James Hays Pietro Perona Deva Ramanan Piotr Dollár C Lawrence Zitnick Microsoft coco common objects context European Conference Computer Vision vol 8693 ECCV Springer International Publishing ISBN 9783319106014 2014 pp 740755 25 David G Lowe Object recognition local scaleinvariant features IEEE International Conference Computer Vision ICCV 1999 pp 11501157 26 Kevin Lund Curt Burgess Producing highdimensional semantic spaces lexical cooccurrence Behav Res Methods Instrum Comput 28 2 1996 203208 27 Tomas Mikolov Quoc V Le Ilya Sutskever Exploiting similarities languages machine translation arXiv preprint arXiv1309 4168 2013 28 Tomas Mikolov Ilya Sutskever Kai Chen Greg S Corrado Jeff Dean Distributed representations words phrases compositionality Advances Neural Information Processing Systems NIPS 2013 pp 31113119 29 Jeffrey Pennington Richard Socher Christopher D Manning Glove global vectors word representation Conference Empirical Methods Natural Language Processing EMNLP 2014 pp 15321543 T Lüddecke et al Artiﬁcial Intelligence 274 2019 4465 65 30 Joshua C Peterson Joshua T Abbott Thomas L Griﬃths Adapting deep network features capture psychological representations Proceedings 38th Annual Conference Cognitive Science Society 2016 31 Bryan C Russell Antonio Torralba Kevin P Murphy William T Freeman LabelMe database webbased tool image annotation Int J Comput Vis 77 13 2008 157173 32 Karen Simonyan Andrew Zisserman Very deep convolutional networks largescale image recognition arXiv preprint arXiv1409 1556 2014 33 Richard Socher Alex Perelygin Jean Y Wu Jason Chuang Christopher D Manning Andrew Y Ng Christopher Potts Recursive deep models semantic compositionality sentiment treebank Conference Empirical Methods Natural Language Processing EMNLP 2013 pp 16311642 34 Christian Szegedy Wei Liu Yangqing Jia Pierre Sermanet Scott Reed Dragomir Anguelov Dumitru Erhan Vincent Vanhoucke Andrew Rabinovich Going deeper convolutions Proceedings IEEE Conference Computer Vision Pattern Recognition CVPR 2015 pp 19 35 Christian Szegedy Sergey Ioffe Vincent Vanhoucke Alexander A Alemi Inceptionv4 inceptionresnet impact residual connections learning AAAI Conference Artiﬁcial Intelligence 2017 p 12 36 Joseph Turian Lev Ratinov Yoshua Bengio Word representations simple general method semisupervised learning Proceedings 48th Annual Meeting Association Computational Linguistics Association Computational Linguistics 2010 pp 384394 37 Peter D Turney Patrick Pantel From frequency meaning vector space models semantics J Artif Intell Res 37 1 2010 141188 38 Jason Weston Samy Bengio Nicolas Usunier Large scale image annotation learning rank joint wordimage embeddings Mach Learn 39 Caiming Xiong Victor Zhong Richard Socher Dynamic coattention networks question answering International Conference Learning Repre ISSN 15730565 81 1 Oct 2010 2135 sentations ICLR 2017