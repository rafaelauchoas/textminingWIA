Artiﬁcial Intelligence 194 2013 130150 Contents lists available SciVerse ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Evaluating Entity Linking Wikipedia Ben Hachey Will Radford bc Joel Nothman bc Matthew Honnibal d James R Curran bc Research Development Thomson Reuters Corporation St Paul MN 55123 USA b School Information Technologies University Sydney NSW 2006 Australia c Capital Markets CRC 55 Harrington Street NSW 2000 Australia d Department Computing Macquarie University NSW 2109 Australia r t c l e n f o b s t r c t Article history Available online 23 April 2012 Keywords Named Entity Linking Disambiguation Information extraction Wikipedia Semistructured resources 1 Introduction Named Entity Linking nel grounds entity mentions corresponding node Knowledge Base kb Recently number systems proposed linking entity mentions text Wikipedia pages Such systems typically search candidate entities disambiguate returning best candidate nil However comparison focused disambiguation accuracy making diﬃcult determine search impacts performance Furthermore important approaches literature systematically compared standard data sets We reimplement seminal nel systems present detailed evaluation search strategies Our experiments ﬁnd coreference acronym handling lead substantial improvement search strategies account variation systems This interesting ﬁnding aspects problem neglected literature focused largely complex candidate ranking algorithms 2012 Elsevier BV All rights reserved References entities people places organisations diﬃcult track text entities referred mention strings mention string refer multiple entities For instance David Murray refer jazz saxophonist Iron Maiden guitarist known aliases Mad Murray These synonymy ambiguity problems diﬃcult language processing systems collect exploit information entities documents ﬁrst linking mentions knowledge base Named Entity Linking nel task resolving named entity mentions entries structured Knowledge Base kb nel useful necessary compute direct reference people places organisations potentially ambiguous redundant character strings In ﬁnance domain nel link textual information companies ﬁnancial data example news share prices 34 nel search results named entity queries include facts entity addition pages talk 8 nel similar widelystudied problem word sense disambiguation wsd 36 Wikipedia articles playing role WordNet synsets 20 At core tasks address problems synonymy ambiguity natural language The tasks differ terms candidate search nil detection Search wsd assumes WordNet complete lexical resource consists lexical lookup ﬁnd possible synsets given word The approach taken wikiﬁcation arbitrary phrases including names general terms matched Wikipedia pages 32332715 Corresponding author Email address benhacheygmailcom B Hachey 00043702 matter 2012 Elsevier BV All rights reserved httpdxdoiorg101016jartint201204005 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 131 However provide mechanism dealing objects present database nel hand assume kb complete requiring entity mentions kb entries marked nil 831 Furthermore named entity mentions vary lexical mentions wsd Therefore search nel requires noisier candidate generation process fuzzy matching improve recall 4828 Until recently widecoverage nel possible general purpose publicly available collection information entities However Wikipedia emerged important repository semistructured collective knowledge notable entities Accordingly widely knowledge modelling 4663742 It nlp tasks like automatic summarisation 4550 And exploited number information extrac tion tasks ranging ner learnt Wikipedia link structure 40 relation extraction learnt nearly structured information encoded Wikipedia Infoboxes 51 The popular data sets nel distributed recent Knowledge Base Population tasks nist Text Analysis Conference tac The thirteen participants 2009 task developed systems linked set 3904 entity mentions news web text knowledge base extracted Wikipedia infoboxes The highest accuracy achieved 822 48 subsequent publications reporting results high 86 21 The popularity tac shared tasks led wide range innovative entity linking systems literature However participants individually striving highest accuracy achieve systems differ multiple dimensions currently unclear aspects systems necessary good performance aspects improved In paper reimplement prominent entity linking systems literature obtain better understand ing named entity linking task Our primary question concerns relative importance search disambiguation nel ﬁrst search set candidate entities mention string refer selecting sin gle candidate given document These phases evaluated isolation systems literature tend differ dimensions We ﬁnd search phase far important previously acknowledged System descriptions usually focused complicated ranking methods However search accounts variation systems Furthermore relatively unremarked search features query expansion based coreference resolution acronym detection larger impact performance candidate ranking 2 Review named entity disambiguation tasks data sets Several research communities addressed named entity ambiguity problem It framed different ways Within computational linguistics problem ﬁrst conceptualised Bagga Baldwin 4 extension coreference resolution problem Mihalcea Csomai 32 later Wikipedia word sense disambiguation data set attempting reproduce links pages link text ambiguous Finally Bunescu Pa sca 8 Wikipedia similar way include ner preprocessing step require link nil identiﬁed mentions We follow terminology papers refer tasks respectively crossdocument coreference resolution cdcr wikiﬁcation named entity linking nel We use general term named entity disambiguation avoid referring speciﬁcally single task The cdcr wikiﬁcation nel tasks different assumptions problem lead different evalu ation measures slightly different techniques The cdcr task assumes documents provided batch clustered according entities mention Systems evaluated clustering evaluation measures B3 measure 3 The wikiﬁcation task assumes existence knowledge base high coverage entities entities covered knowledge base relatively unimportant And nel requires knowledge base assume complete Systems usually evaluated microaccuracy percentage mentions linked correctly macroaccuracy percentage entities linked correctly In section review main data sets cdcr nel research Although reference approaches reserve main description named entity disambiguation techniques Section 3 21 Early crossdocument coreference datasets The seminal work crossdocument coreference resolution cdcr performed Bagga Baldwin 4 They performed experiments set 197 documents New York Times text matched expression JohnSmithwhere nongreedy wildcard match ﬁrst instance Smith John Donnel Smith matched John Donnell Smith bequeathed herbarium Smithsonian The documents manually grouped according John Smith entities mentioned None articles mentioned multiple John Smiths annotations document level The John Smith dataset approaches problem people entities referred ambiguous John Smith However problem person names An entity known John Smith known Jack Smith Mr Smith In words synonymy ambiguity issues named entities 132 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 Most cdcr datasets similarly collected searching set canonical names ignoring noncanonical coreferent forms For instance Mann Yarowsky 29 collected data set web pages returned 32 search engine queries person names sampled US census data This data later included WePS data described Section 23 While ensuring document contains canonical form ambiguous entity produces unrealistic sample distribution In contrast Day et al 11 identify coreferent entity chains documents ACE 2005 corpus 38 marks indocument coreference proper nominal pronominal entity mentions Marking document crossdocument coreference entities corpus addresses synonymy ambiguity issues 22 Generating data pseudonames Because manually annotating data costly adopting pseudowords strategy gen erating artiﬁcial word sense disambiguation data ﬁrst described Gale et al 16 For word sense disambiguation data generated taking words sense ambiguous replacing instances ambiguous key For instance instances words banana door replaced ambiguous key bananadoor The original unambiguous version reserved gold standard training evaluation Crossdocument coreference resolved data generated way taking instances names conﬂating anonymisation key Person X The task group documents according original mentions This strategy ﬁrst explored Mann Yarowsky 29 subsequently Niu et al 39 Gooi Allan 17 Pseudodata generation problematic word sense named entity disambiguation different reasons For words ambiguities related senses For instance tennis mathematical meanings word set linked common concept Few sense ambiguities unrelated concepts banana door diﬃcult select word pairs reﬂect meaningful relationships word senses For named entity disambiguation little reason believe people named John Smith share properties entity named Paul Simonell named Hugh Diamoni criticism pseudodata word sense disambiguation apply On hand named entities interesting internal structures named entity disambiguation want exploit For instance use title Mr Dr critical clue This makes named entities diﬃcult anonymise effectively key Person X losing important information 23 Web People Search The ﬁrst large data set cdcr distributed Web People Search shared task 1 The data set consisted 100 web search results 49 personal names total data set 3489 documents manually sorted 527 clusters The task repeated following year new evaluation set consisting 3432 documents sorted 559 clusters 2 The recent task WePSIII provided 57956 documents new evaluation data drawnthe 200 search results 300 person names Only subset documents received gold standard annotations WePSIII added additional entity disambiguation task targeted Online Reputation Management The organisers searched Twitter messaging service posts 100 companies selected according ambiguity namescompanies names ambiguous unambiguous excluded Mechanical Turk cheaply determine 100 tweets company actually referred company Participants supplied tweets company url companys homepage This task closer named entity linking crossdocument coreference resolution shares common weakness cdcr data data collected searching company task address named entity synonymy 24 Wikiﬁcation The development Wikipedia offered new way approach problem entity ambiguity Instead clustering entities cdcr mentions resolved encyclopedia pages This ﬁrst described Mihalcea Csomai 32 The task refer wikiﬁcation add links important concept mentions text corresponding Wikipedia article The task differs Named Entity Linking concepts necessarily named en tities knowledge base assumed complete presence encyclopedia minimum requirement identiﬁed linked In order encourage research wikiﬁcation inex workshops ran Link Wiki task 2007 2009 25 The task designed improve Information Retrieval places emphasis Wiki creation maintenance evaluation tools methodologies The 2009 task introduces second wiki Te Ara1 expertedited encyclo pedia New Zealand Te Ara contain interarticle links ﬁrst subtask discover The second task link Te Ara articles Wikipedia articles 1 httpwwwtearagovtnz B Hachey et al Artiﬁcial Intelligence 194 2013 130150 133 25 Named Entity Linking The ﬁrst attempts term Named Entity Linking nel taskthe task linking entity mentions knowl edge basepredicted target links Wikipedia This resembles pseudoname generation task described Section 22 makes large volume data immediately available data entirely representa tive Cucerzan 9 pointed ambiguity Wikipedia link anchor texts lower named entity mentions news data This MediaWiki mark requires editors retrieve article title order link actively decide use mention string anchor text This encourage refer entities consistent terminology writers types text Bunescu Pa sca 8 ﬁrst use Wikipedia link data train evaluate grounding text knowledge base However evaluate systems manually linked mentions text sources Wikipedia The ﬁrst Cucerzan 9 evaluated Wikipedia manually linked set 20 news articles described Section 27 26 The Text Analysis Conference Knowledge Base Population challenge The ﬁrst large set manually annotated named entity linking data prepared National Institute Standards Technologies nist Knowledge Base Population kbp shared task 2009 Text Analysis Conference tac 31 The 2009 tackbp distributed knowledge base extracted 2008 dump Wikipedia test set 3904 queries Each query consisted ID identiﬁed document set Reuters news articles mention string occurred document node ID knowledge base Little training data provided Each knowledge base node contained Wikipedia article title Wikipedia article text predicted entity type org loc misc keyvalue list information extracted articles infobox Only articles infoboxes predicted correspond named entity included knowledge base The annotators select mentions randomly Instead favoured mentions likely ambiguous order provide challenging evaluation If entity referred occur knowledge base labelled nil A high percentage queries 2009 test set map nodes knowledge basethat gold standard answer 2229 3904 queries nil The 2010 challenge conﬁguration 2009 challenge kept knowledge base A training set 1500 queries provided test set 2250 queries In 2010 training set 284 queries nil compared 571 2009 test data 546 2010 test data details Section 4 This mismatch training test data harmed performance systems Systems sensitive number nil queries diﬃcult determine candidate weakly match query discarded favour guessing nil A high percentage nil queries favours conservative systems stay close nil baseline conﬁdent match The successful participants 2009 challenge addressed issue augmenting knowledge base articles recent Wikipedia dump This allowed consider strong matches articles corresponding node knowledge base return nil matches This turned preferable assigning general threshold match strength nil returned We use 30th July 2010 snapshot English Wikipedia proxy kb nel Since larger provide information disambiguate candidate entities mentions After disambiguation check linked entity exists kb returning nil entities link supplied kb 27 Other nel evaluation data In addition data tac challenge individual researchers test sets available Cucerzan 9 manually linked entities 20 MSNBC news articles 2006 Wikipedia dump total 756 links 127 resolving nil This data set particularly interesting mentions linked exhaustively articles unlike tac data mentions selected annotation annotators regarded interesting The Cucerzan dataset gives better indication realworld perform Fader et al 13 evaluate 500 predicateargument relations extracted TextRunner corpus 500 million Web pages covering topics genres Considering relations argument proper noun au thors manually identiﬁed Wikipedia page corresponding ﬁrst argument assigning nil corresponding page 160 500 mentions resolved nil Dredze et al 12 performed manual annotation similar methodology tac challenges order generate additional training data They linked 1496 mentions news text tac knowledge base 270 resolved nila substantially lower percentage nillinked queries 2009 2010 tac data There work integrating linking annotation existing ner datasets including CoNLL03 English data 24 ACE 2005 English data 5 This important allows evaluation different steps pipeline nerecognition coreference goldstandard case linking 134 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 Table 1 Summary named entity disambiguation data sets Task cdcr cdcr cdcr cdcr cdcr wikify wikify wikify nel nel nel nel nel nel nel Name John Smith WePS 1 Day et al WePS 2 WePS 3 Mihalcea Kulkarni Milne Cucerzan tac 09 Fader tac 10 Dredze Bentivogli Hoffart Year 1998 2007 2008 2008 2009 2007 2009 2010 2007 2009 2009 2010 2010 2010 2011 Source News Web News Web Web Wiki Web Wiki News News News News Blogs News News Web Transcripts News 28 The BioCreative challenge Gene Normalisation task All mentions Instances 197 3489 3660 3432 31950 7286 17200 11000 797 3904 500 3750 1496 16851 34956 The 2008 BioCreative workshop ran entity linking challenge biomedical text termed Gene Normal isation gn 2335 Participants provided raw text abstracts scientiﬁc papers asked extract Entrez Gene identiﬁers human genes proteins mentioned abstract The gn task motivated genomics database curation scientiﬁc articles linked genesproteins The gn task differs real curation task use text articles annotates human geneprotein mentioned described new scientiﬁc results The version Entrez Gene database task consists list 32975 human geneprotein identiﬁers including average 55 synonyms Evaluation data created human experts trained molecular biology included 281 abstracts training 262 testing These sets 684 785 total identiﬁer annotations respectively corresponding averages 24 3 abstract Interannotator agreement reported 90 29 Database Record Linkage Record Linkage 49 aims merge entries different databases commonly names addresses individual This framed database cleaning canonical versions names addresses produced du plicates removed process Initial research Fellegi Sunter 14 presented probabilistic description linkage problem subsequent work extends use multiple sources information treats graph mentions partitioned entity clusters While similar nel Record Linkage tends consider structured data names addresses cleanly separated database ﬁelds This allow exploration large datasets personrelated data census medical records motivating work eﬃciency privacy 210 Summary Evaluation Sets Table 1 shows data sets evaluate named entity disambiguation work Named entity disambiguation addressed multiple tasks including crossdocument coreference resolution cdcr wikiﬁcation wikify named entity linking nel The cdcr data usually assumes document mentions person usually canonical form The task cluster documents refer person In recent years task focused Web Person Search challenge datasets Named entity disambiguation addressed wikiﬁcation tasks In tasks concepts identiﬁed linked best Wikipedia page Concepts named entities need This evaluated Wikipedia links directly Kulkarni et al 27 point leads inaccurate performance estimates canonicalisation collected dataset 17200 terms mentions web text popular domains variety genres Finally nel resembles wikiﬁcation seeks link named entity mentions requiring mechanism handling mentions corresponding node knowledge base Much work problem tac data sets One weakness datasets collected cherrypicking interesting mentions systematically annotating mentions document One dataset corrects described Cucerzan 9 However Cucerzan data collected correcting output bias data approach This data unsuitable comparison systems B Hachey et al Artiﬁcial Intelligence 194 2013 130150 135 Table 2 Comparative summary seminal linkers System Extractor Searcher Condition Title Redirect Link Truncated Bold DABTitle Filter Bunescu Pa sca 8 NER NA Cucerzan 9 NER coreference expansion Varma et al 48 NER acronym expansion 3 Approaches NA acronym expandable search 1 candidates NA NA kb NA kb NA Disambiguator svm rank cosine mention context word category features Scalar product candi date category term vector documentlevel vector Cosine candidate article term vector mention context vector To date literature named entity linking largely consisted detailed descriptions novel complex systems However nel systems commonly described terms separate search disambiguation components2 little analysis performed looks individual effect components In section implementations complex systems literature 8948 order provide ﬁrst detailed analysis named entity linking task These systems selected seminal work task highly novel reporting high performance None systems compared 31 A framework Named Entity Linking We suggest Named Entity Linking nel framework allows replication comparison different approaches The core task nel link query mention given document context Knowledge Base kb entity node nil This separated main components extractors searchers disambiguators Extractor Extraction detection preparation named entity mentions Most nel datasets supply mention strings queries Some additional mention detection preparation desirable information entities text useful disambiguation The extraction phase include preprocessing tokeni sation sentence boundary detection indocument coreference Indocument coreference particular important ﬁnd speciﬁc search terms ABC cid3 Australian Broadcasting Corporation Searcher Search process generating set candidate kb entities mention Titles Wikipediaderived aliases leveraged stage capture synonyms Section 5 An ideal searcher balance precision recall capture correct entity maintaining small set candidates This reduces computation required disambiguation Disambiguator In disambiguation best entity selected mention We frame ranking problem candidate set We hold nildetection strategy ﬁxed disambiguators This uses Wikipedia snapshot 30th July 2010 larger proxy kb linking entities exist small tackb returned nil Table 2 contains summary extraction search disambiguation components linker implementations described remainder section Rows correspond implementations seminal ap proaches literature The ﬁrst column searcher components contains conditions need met given search performed The following columns correspond alias sources Section 5 And column speciﬁes ﬁlters applied narrow resulting candidate set 2 McCallum et al 30 similar decomposition motivated eﬃciency related task clustering citation references 136 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 32 Bunescu Pa sca Bunescu Pa sca 8 ﬁrst explore nel task Support Vector Machines svm rank disam biguation However performance compared subsequent approaches Extractor Bunescu Pa sca use data derived Wikipedia evaluation goal return correct target given link anchor reintroduce link targets Wikipedia articles given anchor text They perform coreference additional preprocessing Searcher The search component Bunescu Pa sca exact match lookup article redirect disambigua tion title aliases It returns matching articles candidates Disambiguator The Bunescu Pa sca disambiguator uses Support Vector Machine svm ranking model svmlight toolkit 26 Two types features The ﬁrst feature type realvalued cosine similarity query context text candidate entity page Eq 1 The second feature type generated creating 2tuple combination candidate categoriesWikipedia classiﬁcations group pages similar subjectsand context words The categories ancestors assigned candidate entity page words occurred 55token context window entity mention Based results Bunescu Pa sca implementation uses categories occur 200 times However Bunescu Pa sca fo cused Person occupation pages Wikipedia tac data experiments includes organisation geopolitical entity types general person type Section 4 Thus explored general strategies disambiguating arbitrary entity types The union great greatgreat grandparent categories performed best prelim inary experiments implementation Bunescu Pa sca include nil pseudocandidate candidate list allowing svm algorithm learn return nil topranked option good candidate exists We include nil pseudocandidates decreased performance development experiments 05 accu racy As mentioned allows hold nildetection strategy constant disambiguation approaches The learner trained development data provided tac 2010 shared task It important note Bunescu Pa sca approach relies supervised learning The original paper derived training sets 12288 38726 ambiguous person mentions Wikipedia Here use tac 2010 training data 1500 total handannotated person organisation geopolitical entity mentions The small size training set limits performance machine learning approach experiments However reﬂects challenges porting supervised approaches different variations task 33 Cucerzan Cucerzan 9 describes nel approach focuses interesting documentlevel disambiguation approach He introduces preprocessing module identiﬁes chains coreferring entity mentions order use speciﬁc strings querying However effect coreference handling search disambiguation explored Extractor Cucerzan report evaluation goal link entity mentions news article corresponding Wikipedia page Therefore necessary split text sentences detect corefer named entity mentions Cucerzan uses hybrid ner tagger based capitalisation rules web CoNLL03 ner shared task data 47 statistics In implementation ﬁrst use CC ner tagger 10 extract named entity mentions text Next naïve indocument coreference performed taking mention trying match longer canonical mention document These expected longer speciﬁc easier disambiguate Mentions examined turn longest shortest forms preﬁx suﬃx previous mention tokens shorter Uppercase mentions considered acronyms mapped canonical mention acronym letters match order initial characters mentions tokens Our coreference implementation differs described Cucerzan require canonical mention entity type mention coreferred view identity stronger evidence predicted type Searcher For candidate generation canonical mentions ﬁrst casenormalised comply Wikipedia conventions These searched exactmatch lookup article titles redirect titles apposition stripped articleredirect titles disambiguation titles In contrast Cucerzan use link anchor texts search aliases caused substantial drop performance 52 kb accuracy Cucerzan news data approximately 10 worse runtime Disambiguator Cucerzan disambiguated query mention respect documentlevel vectors derived entity mentions Vectors constructed document global set entity candidates candidate canon ical mention A candidate vector indicator variables created global candidates based presence articles categories contexts Contexts anchor texts ﬁrst paragraph linked article B Hachey et al Artiﬁcial Intelligence 194 2013 130150 137 The extended document vector populated represent union indicator variables entity vectors The category values number entity vectors containing category context values count context document Each candidate list mention reranked separately respect document level vector Speciﬁcally candidates ranked scalar product candidate vector extended document vector penalty avoid doublecounting Following Cucerzan exclude categories contains following words plurals article page date year birth death living century acronym stub fourdigit number year We exclude Exclude print category mark content included printed output We shrink source document context clear entity candidate identiﬁed Benchmarking We compared performance reimplementation Cucerzan evaluation data Section 27 consists news articles msnbc This data includes 629 entity mentions automatically linked manually veriﬁed Cucerzan linkable Wikipedia articles We achieved accuracy 883 Cucerzan reports accuracy 914 There possible differences implementation First certain ﬁlter lists categories exactly heuristics Cucerzan We performing coreference resolu tion acronym detection casenormalisation slightly differently Changes Wikipedia especially changes gold standard factor We observed evaluation sensitive small variations tended score poorly document global disambiguation model 34 Varma et al Finally Varma et al 48 uses carefully constructed backoff approach candidate generation simple text similarity approach disambiguation Despite fact eschewed complex disambiguation approaches submissions achieved best result 822 accuracy tac 2009 shared task Extractor The ﬁrst determines query acronym ABC This based simple heuristic test checked query consists entirely uppercase alphabetical characters If query document searched expanded form This scans sequence words starting letters acronym ignoring stop words Australian Broadcasting Corporation Agricultural Bank China No preprocessing query query document performed Searcher Different candidate generation strategies followed acronym nonacronym queries For acronym queries expanded form query query document matched kb titles Otherwise original query string exactmatch lookup articleredirectdisambiguation titles bold terms ﬁrst paragraph article For nonacronym queries query string ﬁrst matched kb titles If match query string searched aliases described The Varma et al tac 2009 metaphone search kb titles nonacronym queries We omitted feature implementation Varma et al reported degraded performance experiments conducted tac data released personal communication Disambiguator The Varma et al approach ranks candidates based textual similarity query context text candidate page cosine measure Here query context paragraph surrounding query mention paragraphs easily identiﬁed doublenewline delimiters tac source documents The cosine score ranks candidates default formulation Lucene Cosineq d Tq Td maxmM Tq Tm cid2 tTq cid3 t f t d cid4 1 log cid5 D df t 1 Td 1 q text query context d document text Ti set terms M set documents match query q t f t d frequency term t document d D document set df t count documents D include term t 4 Data We report results tac data sets tac queries consist mention string Abbot source document containing Also DVD Oct 28 Abbot Costello The Complete Universal Pictures Collection The gold standard reference tac kb node E0064214 Bud Abbott nil corresponding node kb tac source documents drawn newswire blog collections We extract store body text discarding markup nonvisible content formatted markup language After tokenising defer processing speciﬁc extractors 138 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 Table 3 Comparison tac data sets queries Q unique entities E Q kb nil org gpe News Web Acronym E kb nil org gpe tac 2009 test tac 2010 train tac 2010 test 3904 1675 2229 627 2710 567 3904 0 827 560 182 378 136 364 60 43 57 16 69 15 100 0 21 33 67 24 65 11 1500 1074 426 500 500 500 783 717 173 462 72 28 33 33 33 52 48 12 2250 1020 1230 751 750 749 1500 750 347 871 402 469 334 332 205 45 55 33 33 33 67 33 15 46 54 38 38 24 The tac kb derived pages October 2008 Wikipedia dump3 infoboxes It includes approximately 200000 nodes 200000 gpe nodes 60000 org nodes 300000 miscellaneousnonentity nodes We exploit recent English Wikipedia dump 30th July 2010 This consumes 118 GB disk bzip2 compression including markup 33 M articles We use mwlib4 Python package extract article text categories links disambiguation redirect information store Tokyo Tyrant5 fast database server Tokyo Cabinet keyvalue stores This provides fast access article data structures title ability stream articles We use tac 2009 test data main development set benchmark large set published results We use tac 2010 training data training Bunescu Pa sca 8 disambiguator And reserve tac 2010 test data ﬁnal heldout test set These summarised queries Table 3 The ﬁrst thing note difference proportion nil queries data sets In tac 2009 tac 2010 test sets approximately 55 However tac 2010 training set considerably lower 28 The second difference distribution entity types The tac 2009 test data highly skewed org entities tac 2010 training test data sets uniformly distributed org gpe entities Finally tac 2009 consisted solely newswire documents tac 2010 included blogs The tac 2010 training data roughly evenly divided news web documents blogs test data skewed news 67 The Table 3 contains corresponding numbers deﬁned unique entities Note analysis possible tac 2010 training data nil queries clustered The main difference data sets terms average number queries entity QE7 tac 2009 compared 26 tac 2010 test The proportion nil queries querylevel analysis approximately 55 tac 2009 2010 test sets The distribution entity types similarly skewed tac 2009 data Where querylevel analysis tac 2010 test data showed uniform distribution entity types entitylevel analysis shows substantial drop proportion gpe entities 41 Evaluation measures We use following evaluation measures deﬁned notation Table 4 The ﬁrst accuracy A oﬃcial tac measure evaluation endtoend systems tac reports kb accuracy AC nil accuracy A equivalent candidate recall nil recall maximum candidate set size The remaining measures introduced analyse candidate sets generated different search strategies accuracy A percentage correctly linked queries A Ci0Ci0 G N 3 httpdownloadwikimediaorg 4 httpcodepediapresscomwikiwikimwlib 5 httpfallabscomtokyotyrant 2 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 139 Table 4 Notation searcher analysis measures N G Gi C Ci Ci j Number queries data set Gold standard annotations data set G N Gold standard query kb ID nil Candidate sets output C N Candidate set query Candidate rank j query Ci cid9 candidate count cid10Ccid11 mean cardinality candidate sets Fewer candidates mean reduced disambiguation workload cid10Ccid11 cid6 Ci N 3 4 5 6 candidate precision P C percentage nonempty candidate sets containing correct entity P C CiCi cid9 Gi Ci CiCi cid9 candidate recall RC percentage nonnil queries candidate set includes correct candidate RC CiGi cid9 nil Gi Ci GiGi cid9 nil nil precision P percentage candidate sets correct correspond nil queries P CiCi Gi nil CiCi nil recall R percentage nil queries candidate set A high R rate valuable diﬃcult disambiguators determine queries nillinked candidates returned R CiGi nil Ci GiGi nil 5 Wikipedia alias extraction 7 We extract set aliasespotential mention strings refer entityfor Wikipedia article By querying index aliases able ﬁnd candidate referents entity mention We consider following attributes article candidate aliases Article titles Title The canonical title article While ﬁrst character Wikipedia titles caseinsensitive canonically given uppercase form articles containing special lowercase title template gzip iPod extract alias ﬁrst character lowercased Redirect titles Redirect Wikipedia provides redirect mechanism automatically forward user noncanonical titlessuch variant erroneous spellings abbreviations foreign language titles closelyrelated topics etcto relevant article For articles lowercase title redirect title begins ﬁrst word canonical title ﬁrst character lowercased IPods iPods Bold ﬁrst paragraph terms Bold Common canonical names topic conventionally listed bold articles ﬁrst paragraph Link anchor texts Link Links Wikipedia articles use arbitrary anchor text Link anchors offer variety forms refer mention running text varied reasons authors linking makes noisy We extract anchor texts link article twice Disambiguation page titles DABTitle Disambiguation pages intended list articles referred ambiguous title The title disambiguation page surname abbreviation taken alias pages disambiguates Disambiguation pages usually consist lists list item linking candidate referent disambiguated term However links conﬁned exclusively candidates based observations consider links appear beginning list item following single token determiner All descendants Disambiguation pages category considered disambiguation pages Disambiguation redirects bold text DABRedirect One page disambiguate multiple termsfor instance disambiguation page Amp AMP In addition page title consider bold terms page titles redirects point disambiguation pages aliases articles disambiguate 140 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 Table 5 Sources aliases including number articles excluding disambiguation pages aliases source Support indicates average number sources support alias Source Articles Aliases Support truncation truncation Article title Redirect title Bold terms Link anchor Disamb title Disamb redirect Disamb bold Disamb hatnote Any 3 198 290 1 493 931 2 984 381 2 728 066 933 308 907 330 536 438 90 564 3 198 290 Table 6 Search individual alias ﬁelds tac 2009 3 198 290 3 960 765 3 601 296 5 320 423 1 126 714 1 312 327 1 563 650 96 649 3 777 818 4 393 709 3 601 296 5 320 423 1 203 648 1 312 327 1 650 858 115 524 17 156 466 Alias source Title Redirect Link Bold Hatnote Truncated DABTitle DABRedirect cid10Ccid11 02 01 42 16 00 12 35 27 C P 835 746 557 451 426 378 342 340 C R 372 200 801 488 12 245 293 189 P 681 621 886 717 577 622 587 579 34 18 28 25 37 33 23 28 16 R 965 962 595 672 999 786 651 773 Disambiguation hatnotes Hatnote Even term highly ambiguous referents far frequently intended For instance notable people named John Williams composer far famous At article link known hatnote tem plate points disambiguation pages alternative referents term We extract disambiguation information hatnote templates English Wikipedia use referring articles title alias disambiguated redirect title speciﬁed template Truncated titles Truncated Wikipedia conventionally appends disambiguating phrases form unique article title John Howard Australian actor Sydney Nova Scotia For alias sources titles redirects strip expressions parenthesis following comma title use truncated title additional alias We store alias sources features articlealias pair use discriminate aliases terms reliability Titles redirects unique references article considered reliable link texts require context understood reference particular entity Table 5 indicates aliases derived link texts numerous frequently supported alias sources disambiguation page titles The extracted aliases indexed Lucene6 search engine Aliases stored Lucene keyword ﬁelds support exact match lookup We index Wikipedia text Article text stored Lucene text ﬁelds scoring matches based terms entity mention contexts source documents The entire index occupies 12 gb disk space includes ﬁelds required experiments Note experiments reported set Lucene query limit return maximum 1000 candidates 51 Coverage alias sources Table 6 shows candidate count candidate recall candidate precision nil recall nil precision different alias sources development set tac 2009 The ﬁrst thing note performance Title alias source Title queries return 0 1 entities depending article title directly matched query The candidate count 02 indicates 20 query mentions matched Wikipedia titles These matches return correct entity 372 nonnil queries Precision titlematched nonnil queries 835 This means systems beneﬁt simple heuristic trusts direct title matches simply returns entity match 6 httpluceneapacheorg B Hachey et al Artiﬁcial Intelligence 194 2013 130150 141 Table 7 Search multiple alias ﬁelds tac 2009 Alias source Title Redirect Link Bold Hatnote Truncated DABTitle DABRedirect Table 8 Backoff search alias ﬁelds tac 2009 Alias source Title Redirect Link Bold Hatnote Truncated DABTitle DABRedirect cid10Ccid11 02 03 42 47 47 50 69 72 cid10Ccid11 02 03 24 24 24 24 24 24 C P 835 794 562 557 557 557 565 563 C P 835 794 562 558 558 558 558 554 C R 372 546 817 848 848 854 876 878 C R 372 546 765 771 771 771 771 771 P 681 750 902 906 906 906 908 907 P 681 750 876 882 882 882 882 881 R 965 926 594 551 551 542 533 525 R 965 926 638 629 629 629 629 622 It rare direct title match returned answer actually nil occurred 35 queries It common title match failures occur nonnil queries This seen nil precision ﬁgure 681 A titlematch returns entity title matches query nil achieves 710 accuracy endtoend linking task tac 2009 This fairly strong baselinehalf 35 runs submitted tac 2009 scored Expanding consult redirect titles improves baseline 763 linking accuracy Only 5 14 tac 2009 teams achieved higher accuracy The alias sources potentially return multiple candidates utility depends strength disambiguation component Table 7 shows number candidates proposed increases extra alias sources considered candidate recall improves The addition link anchor texts increases candidate recall 817 greatly increases number candidates suggested The nil recall drops 926 594 means candidate proposed 40 nillinked queries This makes form nil detection necessary similarity threshold supervised model Zheng et al 54 Using alias sources produces candidate recall 878 mean 72 candidates returned query The candidate recall constitutes upper bound linking kb accuracy That 122 kblinked queries perfect disambiguator able answer correctly Many queries acronyms short forms retrieved expanding query appropriate fullform source document experiments analysis Sections 62 7 82 9 One way reduce number candidates proposed use backoff strategy candidate generation Using strategy reliable alias sources considered ﬁrst consults alias sources 0 candidates returned Table 8 shows performance backoff strategy alias source considered ordered according candidate precision A maximum 24 candidates returned candidate recall 771 This good strategy simple disambiguation employed cosine similarity 6 Analysis searcher performance Having described reimplementations named entity linking systems examine performance beginning accuracy searchersthat accurately systems propose candidates mention strings 61 Comparison implemented searchers Table 9 contains analysis results searcher reimplementations The ﬁrst row describes performance Bunescu Pa sca searcher uses exact match article redirect disambiguation title aliases The second row describes Cucerzan searcher includes coreference acronym handling As described Section 33 mentions replaced fullforms determined coreference acronym detection heuristics The query terms searched exact match article redirect disambiguation titles appositionstripped article redirect titles Finally row describes Varma et al searcher replaces acronyms fullforms possible employs backoff search strategy favours highprecision matching article titles map kb alias 142 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 Table 9 Performance searchers literature tac 2009 Searcher Bunescu Pa sca Cucerzan Varma et al cid10Ccid11 36 32 30 C P 563 586 598 Table 10 Effect coreferenceacronym handling searcher performance tac 2009 Searcher Cucerzan coreference handling Varma et al acronym handling cid10Ccid11 32 41 30 38 C P 586 534 598 540 C R 770 793 812 C R 793 793 812 794 P 866 888 909 P 888 890 909 896 R 627 651 664 R 651 566 664 579 Fig 1 Effect query limit searcher candidate recall search Alias search includes exact match article redirect disambiguation titles bold terms ﬁrst paragraph article The implemented Cucerzan Varma et al perform best They achieve candidate precision close 60 candidate recall near 80 This suggests coreference acronym handling important preference highprecision matching beneﬁcial The Varma et al searcher slightly better terms candidate precision 12 candidate recall 19 It returns candidate set size average contains 02 fewer items This corresponds reduction ambiguity 63 respect Cucerzan searcher 62 Effect extractors search Table 10 contains subtractive analysis coreference acronym handling searchers literature The spective components result ambiguity 09 Cucerzan 08 Varma et al simultaneous increase candidate precision 52 58 respectively For Varma et al increase candidate recall 18 This highlights importance speciﬁc mention forms possible likely match canonical names occur Wikipedia 63 Effect query limit searcher candidate recall One way improve disambiguation eﬃciency reduce number candidates considered However correct candidate ﬁrst returned searcher Fig 1 plots candidate recall searcher implementations query limitthe maximum number results returned lucene alias index All linkers start candidate recall 60 climb maximum query limit 1000 Interestingly appears knee 100 searchers suggests possibility eﬃciency gain However going query limit 100 10 results substantial drop candidate recall especially Bunescu Pa sca searcher Despite possible eﬃciency gain remaining experiments query limit 1000 implementations close possible literature B Hachey et al Artiﬁcial Intelligence 194 2013 130150 143 Table 11 Number kb accuracy errors search tac 2009 System Bunescu Pa sca Cucerzan Varma et al Systems agree Search errors Total errors 386 384 316 287 899 847 776 301 Table 12 Distribution searcher errors tac 2009 queries Error type Ambiguous Name variation Annotation Organisation Typographic Total Examples Type Token Health Department Garden City Air Macao Cheli ABC Mainland China Michael Kennedy New Caledonia Blufton 20 26 6 5 4 61 118 109 38 14 8 287 Table 13 Coreference analysis 100 queries sampled tac 2009 queries Coreferrable Acronym Count 12 12 4 72 7 Searcher errors In section investigate types errors systems implemented The ﬁrst question asked systems making errors searchers failing ﬁnd candidates Table 11 shows number search errors It shows total number linking kb accuracy errors searchers disambiguators column The row shows number queries systems returned incorrect result On average 43 kb accuracy errors search recall problems It interesting note large proportion searcher error queries common systems Table 12 shows distribution common search errors classiﬁed broad categories The Type column contains error totals unique query mention strings Token column contains error totals individual queries The common type search error occurs mention underspeciﬁed ambiguous Health Department Name variationsincluding nicknames Cheli Chris Chelios acronyms ABC transliterations Air Macao instead Air Macau inserted deleted tokens Ali Akbar Khamenei instead Ali Khameneiare problematic There cases indicate annotation errors For example gold standard articles disambiguation pages existed dataset prepared Other errors targeting mention incorrect point organisational structure The distinction general university sports teams teams baseball example subtle proved diﬃcult systems draw There legitimate typographic errors Blufton Bluffton We investigated impact coreference linking performance sample 100 queries drawn random tac 2009 data Table 13 contains counts queries coreferred speciﬁc mention count acronyms Among 24 coreferrable queries Cucerzan coreference module correctly resolves 5 Varma et al acronym expansion module correctly resolves 6three common Both systems correctly corefer acronyms including DCR cid3 Danish Council Refugees DMC cid3 DeLorean Motor Co The Varma et al coreference addition ally corefers acronym cases CPNUML cid3 Communist Party Nepal Uniﬁed MarxistLeninist TSX cid3 Tokyo Stock Exchange Since Cucerzan implementation corefers nes ne boundary detection error rule corefer ring acronyms correctly handles Cowboys cid3 Dallas Cowboys Detroit cid3 Detroit Pistons Note acronyms coreferrable half coreferrable queries acronyms indicating coreference advantageous risks introducing complexity potentially error 8 Analysis disambiguator performance Next examine disambiguator performance beginning endtoend accuracy implemented linkers 144 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 Table 14 Comparison systems literature tac 2009 System nil baseline Title baseline Redirect baseline Bunescu Pa sca Cucerzan Varma et al replicated tac 09 Median tac 09 Max Varma A 571 710 763 770 783 801 711 822 AC 00 372 546 678 713 723 635 765 Table 15 Effect coreferenceacronym handling endtoend linking performance tac 2009 System Cucerzan coreference handling Varma et al acronym handling A 783 749 801 773 AC 713 694 723 697 A 1000 965 926 838 835 860 789 864 A 835 790 860 830 81 Comparison implemented linkers Table 14 summarises performances different systems tac 2009 test data In addition systems described report nil baseline returns nil query Thus overall accuracy 571 reﬂects number nil queries data set We report baselines based exact matching Wikipedia article titles exact matching article titles redirect titles Section 51 The Title Redirect baseline particular strong baseline task achieving score 52 points median 59 points maximum score achieved submissions shared task The rows correspond median maximum results tac 2009 proceedings maximum corresponds reported results Varma et al Of systems implemented Varma et al approach performs best data followed Cucerzan The Cucerzan Bunescu Pa sca systems perform slightly better Title Redirect baseline use disambiguation simply queries exact matches mention string title redirect ﬁelds However systems placed outside 5 tac 2009 While Varma et al best submitted tac 2009 recent papers reported higher scores data Zheng et al 54 report accuracy 849 highest literature approach based learnt ranking ListNet separate svm classiﬁer nil detection diverse feature set Zhang et al 53 report accuracy 838 classiﬁer nil detection built large training set derived Wikipedia Nevertheless competitiveness Varma et al approach suggests good search strategy critical nel different disambiguators impact 82 Effect extractors disambiguation Table 15 contains subtractive analysis coreference acronym handling disambiguators literature In Table 10 effect extractors search saw resulted lower ambiguity signiﬁcantly affecting precision recall Here results substantial improvements accuracy A approximately 3 points For Cucerzan implementation difference mainly terms nil accuracy sees 45 point increase use speciﬁc variants search Our Varma et al implementation sees balanced increase kb accuracy nil accuracy approximately 3 points The relatively large increase kb accuracy Varma et al search entire document acronym expansions entity mentions case Cucerzan coreference handling This makes acronym expansion vulnerable Named Entity Recognition errors We evaluated linker performance 100 query sample mentioned Section 7 On sample adding coreferenceacronym handling allowed Cucerzan Varma et al implementations correctly link query 83 Effect searchers disambiguation Table 16 contains results versions Bunescu Pa sca Cucerzan implementations use described candidate search strategies replace disambiguation approach simple cosine disambiguator described Section 34 The results relate directly search results Table 9 comparison implemented searchers high accuracy achieved searchers high candidate recall low candidate count In Table 9 Varma et al B Hachey et al Artiﬁcial Intelligence 194 2013 130150 145 Table 16 Effect searchers cosine disambiguation tac 2009 Searcher Bunescu Pa sca Cucerzan Varma et al A 777 788 801 AC 696 697 723 Table 17 Combinations searchers implemented disambiguators tac 2009 Searcher Bunescu Pa sca Varma et al Cucerzan Varma et al Disambiguator Bunescu Pa sca Bunescu Pa sca Cucerzan Cucerzan A 770 781 783 794 AC 696 679 713 733 A 838 856 860 A 838 858 835 839 Table 18 Number kb accuracy errors disambiguation System Bunescu Pa sca Cucerzan Varma et al Systems agree Disambiguator errors Total errors 513 463 460 14 899 847 776 301 searcher outperforms Bunescu Cucerzan searchers terms candidate recall 19 42 points respectively terms candidate countby 02 06 Here performs best terms accuracy 80124 points better Bunescu 13 point better Cucerzan Note Bunescu Pa sca Cucerzan disambiguators Table 14 perform worse cosine disambiguators reported This attributed differences training development testing data For example distributions nil kb queries changes described Table 3 Also tac 2010 training data includes web documents tac 2009 evaluation data development testing For Bunescu Pa sca difference fact training data fairly small The heldout evaluation data Section 10 similar training data Results data Table 21 suggest Bunescu Pa sca learningtorank disambiguator obtains higher accuracy corresponding cosine disambiguator 07 15 point increase candidate recall 84 Effect swapping searchers Table 17 contains comparison Bunescu Pa sca Cucerzan disambiguators search strategy search strategy Varma et al7 For Cucerzan use Varma et al search tac query Cucerzan search named entity mentions document The results suggest high precision Varma et al search generally beneﬁcial resulting increase accuracy 11 Bunescu Pa sca Cucerzan disambiguators Both results suggest selecting good search strategy crucial 9 Disambiguator errors Table 18 shows number disambiguator errorsqueries tac 2009 data correct link returned disambiguator unable choose correct candidate search results It shows total number kb accuracy errors searchers disambiguators The row shows number queries systems return incorrect result The errors account remaining errors approximately 47 attributed searchers Table 11 Interestingly search errors largely common systems disambiguation errors shared Given variation performance diversity errors systems compared tempting explore voting However approaches described require substantial resources largescale applications linking mentions news archive containing decades worth articles We believe important explore eﬃciency improvements future work Therefore report voting experiments 7 Note Varma et al disambiguator corresponds cosine disambiguator Therefore cosine disambiguation rows Tables 14 21 correspond Bunescu Pa sca Cucerzan systems Varma et al disambiguation Note swap Bunescu Pa sca searcher competitive discussed Section 61 146 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 Table 19 Distribution disambiguator errors tac 2009 queries Error type Name variation Ambiguous Total Examples ABC UT Garden City Type 2 4 6 Token 14 10 24 Table 20 Characteristic errors tac 2009 queries System Type Token Acronym Not acronym Acronym Not acronym Bunescu Pa sca Cucerzan Varma et al 21 30 17 16 33 21 138 81 30 43 115 68 Table 21 Comparison systems literature tac 2010 test data System nil baseline Title baseline Redirect baseline Bunescu Pa sca CosDAB Cucerzan CosDAB Bunescu Pa sca Cucerzan Varma et al tac 2010 Median tac 2010 Maximum Lehmann A 547 696 794 801 810 808 845 816 684 868 AC 00 350 606 671 711 684 784 705 806 A 1000 984 950 909 893 911 895 907 920 Table 19 shows breakdown common errors The types errors varied search errors dominated cases entities similar names similar domains Name variation makes reasonable proportion errors stage exclusively acronyms nicknames transliter ations insertionsdeletions search errors Finally Table 20 summarises counts queries returned incorrect entity The errors categorised according mention acronym counts aggregated type token granularity The relative proportion acronym nonacronym errors differs slightly systems Bunescu Pa sca making acronym errors Cucerzan balances Varma et al makes errors nonacronyms This trend reﬂects level acronym processing Bunescu Pa sca Varma et al uses ﬁnely tuned acronym search Cucerzan uses coreference The counts tokens broadly follow trend skewed bursty distribution types tokens 10 Final results As ﬁnal comparison evaluate implementations seminal systems tac 2010 test data set aside development The results shown Table 21 Results columns correspond oﬃcial tac evaluation measures include accuracy A kb accuracy AC nil accuracy A Rows correspond systems The nil baseline returns nil query The overall accuracy 547 reﬂects percentage queries nil gold answer The Title baseline performs exact match lookup Wikipedia titles The Title Redirect baseline performs exact match union article redirect titles The rows correspond implementations Bunescu Pa sca Cucerzan Varma et al systems Finally rows contain median maximum scores tac 2010 The maximum obtained Lehmann et al 28 searcher differs explored tokenbased exactmatch search coreference ﬁltering Google search The Lehmann et al disambiguator uses features based alias trustworthi ness mentioncandidate similarity mentioncandidate entity type matching Wikipedia citation overlap candidates unambiguous entities mention context A heuristic features candidate ranking And supervised binary logistic classiﬁer nil detection The Cucerzan accurate systems evaluation data achieving accuracy 2 maximum performance reported tac 2010 challenge The strong performance Cucerzan data surprising given results development data On tac 2009 data Varma et al outperforms Cucerzan 2 Table 14 There number differences data sets detailed Table 3 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 147 Table 22 Overall accuracy genre entity type tac 2010 test System nil baseline Title baseline Redirect baseline Bunescu Pa sca CosDAB Cucerzan CosDAB Bunescu Pa sca Cucerzan Varma et al News org 726 728 748 776 808 770 772 784 gpe 210 512 656 656 684 644 830 682 910 910 970 972 982 972 982 974 Web org 332 496 804 876 864 884 836 900 gpe 566 751 767 655 602 723 719 687 331 721 829 869 876 896 880 873 The 2009 data queries entity skewed org queries contains web text The 2010 test data varied balanced containing entities overall evenly balanced kb nil distribution queries entity type Acronyms comprise 15 2010 test queries versus 21 2009 queries account performance loss Varma et al 48 linker specialised acronym processing 101 Performance genre entity type Table 22 contains accuracy scores broken genre news web entity type org gpe Rows corre spond systems reported Table 21 The best scores column bold The ﬁrst thing note approach consistently best genres entity types This suggests combination voting entityspeciﬁc models worth investigating Next percentage nil queries reﬂected nil baseline scores varies hugely genre entity types In particular nil percentage web text lower news text org entities higher gpe entities There striking results behaviour Title Redirect baseline First performs near perfectly entities news text 970 In probably attributable editorial standards associated news results entities mentioned news generally referred canonical forms However queries evaluation data set randomly sampled possible quantify observation The second striking result fact Title Redirect baseline outperforms implemented systems gpe entities web text This suggests candidate generation noisy entities results especially diﬃcult disambiguation problem For org entities systems cosine disambiguators including Varma et al best news web text It interesting note little variation scores entities especially news text Overall Cucerzan implementation best newswire worse web text This holds cosine disambiguators disambiguators literature This suggests Cucerzan search strategy tuned formal text This attributed searchers reliance coreference acronym handling accurate text follows journalistic conventions introducing new entities discourse fairly unambiguously For Cucerzan disambiguator poorer performance named entity recognition web text likely effect introducing noise documentlevel vector representations 11 Discussion Wikipedia rich source data natural language processing Recently exploited number information extraction tasks ranging named entity recognition relation extraction This article explored problem entity linking disambiguates entity mentions linking Wikipedia page This exciting new task moves conventional named entity recognition output list unnormalised entity mention strings It shifts information extraction actionable semantic interpretation objects text grounded node underlying knowledge base The task opens range applications aggregation information given entity diverse structured semistructured unstructured knowledge sources automated reasoning extracted information The named entity linking task ﬁrst explored Bunescu Pa sca 8 Cucerzan 9 focus shared tasks organised US National Institute Standards Technology Text Analysis Conferences tac 2009 2010 2011 Previous approaches largely focused devising elaborate approaches ranking set candidates goal promoting true candidate list These assume search strategy generating list candidate entities previous work investigated candidate generation A notable exception topscoring entry tac 2009 shared task includes highly tuned candidate generation strategy relies simple cosine similarity query context candidate Wikipedia page ranking This suggests worthwhile consider candidate generation strategies carefully 148 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 A key theme results baseline systems diﬃcult beat Speciﬁcally exact match lookup page redirect titles results accuracy scores 763 tac 2009 test data 794 tac 2010 test data This highly curated nature Wikipedia commonly searched variations names likely redirect disambiguation pages On hand Wikipedia dynamic resource redirect disambiguation pages likely reﬂect changes popularity search terms time This important implications evaluationthe version Wikipedia strong effect performance especially recall candidate generation Another theme results search strategies extremely important Analysis alias sources shows page titles redirect titles high precision Title Redirect baseline able correctly return 50 links tac 2009 2010 data sets maintaining nil recall near 95 Additionally comparison searcher implementations highlighted importance coreference acronym handling Subtractive analysis components showed lead small improvements candidate recall 18 Varma et al More importantly lead increase approximately 55 percentage candidate sets include correct answer candidate precision simultaneous decrease approximately 08 ambiguity measured average candidate set size Detailed evaluation measures candidate generation proved useful predicting subsequent performance endtoend linking task A searchers candidate recall example sets upper bound disambiguator performance That maximum kb accuracy obtainable disambiguator equal candidate recall searcher proceeding Recent work reports dramatically higher candidate recall 969 28 This promising led improved linker accuracy warrants investigation determine relative effect novel components token based exact match search coreference ﬁltering based character overlap use Google search However comparison search linking results suggests improvements candidate recall come cost candidate precision search ambiguity needs carefully managed This supported personal communication Varma et al reported detailed analysis metaphone search employed tac 2009 actually reduced ﬁnal accuracy linker Our results highlight interesting similarities differences named entity word sense disam biguation tasks Both tasks strong baselines related ﬁrst sense heuristics referent word entity common possibilities number candidates large Wikipedia editors adapted phenomenon tuning article titles redirects capture likely intended meanings common queries Title Redirect baseline present competitive In disambiguation tasks document contents important clues disambiguation simple methods based bagofwords models fairly competitive Early work linking Wikipedia 32 disambiguated arbitrary terminology relating task word sense disambiguation However important difference named entity linking conventional word sense dis ambiguation WordNet candidate senses word sense disambiguation provided directly candidate generation critical successful named entity linking The importance aspect problem properly appreciated 111 Recent literature The implementation work present start larger effort perform detailed comparison entity linking approaches framework A key development recent literature use learningtorank approaches In addition Bunescu Pa sca 8 approach explored Dredze et al 12 Zheng et al 54 use svmrank ListNet respectively incorporate variety features Zheng et al report 849 overall accuracy tac 2010 test data Another key development use instance selection generate training data Wikipedia 53 Zhang et al 52 leverage achieving current stateoftheart performance 861 tac 2010 data Wikipedia structure continued drive new approaches including eschew supervised machine learning Han et al 22 propose generative probabilistic model based entity mention context statistics performs 86 accuracy tac 2009 data Gottipati Jiang 18 use language modelbased information retrieval nemention candidate context This particularly competitive variant tac task Wikipedia text allowed It obtains 852 topranking score 779 oﬃcial tac 2010 results Wikipedias link structure particular driven new approaches incorporating graphbased methods nel This motivation citation overlap measures candidates unambiguous context entities 33284344 More recent systems build graph vertices correspond mentions andor entities edges correspond candidate entities given mentions andor entityentity links Wikipedia Intuitively highly connected regions represent topic document correct candidates lie regions Ploch 41 demonstrates PageRank 7 values candidate entities useful feature supervised ranking nil detection systems leading overall accuracy 842 tac 2009 data Hachey et al 20 degree centrality better PageRank leading performance 855 tac 2010 test data And Guo et al 19 degree centrality better baseline similar cosine CosDAB baselines reported leading performance 824 tac 2010 test data Recent experiments data sets explored evidence propagation 22 community detection 24 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 149 12 Conclusion Entity linking allows applications compute direct references people places organisations potentially ambiguous redundant character strings As world knowledge problems important question task information access order achieve satisfactory accuracy This question diﬃcult answer building single Instead range approaches evaluated single framework ability plug different components analyse We presented ﬁrst systematic investigation entity linking problem implementing canoni cal systems literature We performed ﬁrst direct comparison systems analysed errors come surprising conclusions nature entity linking task We useful divide entity linking task phases search disambiguation During search phase proposes set candidates named entity mention linked ranked disambiguator To surprise variation systems considered explained perfor mance searchers This surprising literature named entity linking focused exclusively disambiguation The disambiguation task arguably conceptually interesting lends algorithmic solutions related longstudied problem word sense disambiguation However simple vector space model performed surprisingly compared interesting disambiguation strategies imple mented Until impossible compare search disambiguation strategies entity linking directly ﬁnal accuracy ﬁgures available Task accuracy informative unclear ambitiously searcher proposing candidates disambiguator rank A conservative disambiguation perform surprisingly offering way improve accuracy task future We shown stateoftheart entity linking systems pushing past local maximum results suggest long way diﬃcult problem determining given set candidates likely referent named entity mention References 1 J Artiles J Gonzalo S Sekine The SemEval 2007 WePS evaluation Establishing benchmark Web People Search task Proceedings 4th International Workshop Semantic Evaluations 2007 pp 6469 2 J Artiles J Gonzalo S Sekine WePS 2 evaluation campaign Overview Web People Search clustering task Proceedings WWW Web People Search Evaluation Workshop 2009 3 A Bagga B Baldwin Algorithms scoring coreference chains Proceedings LREC Linguistic Coreference Workshop 1998 pp 560567 4 A Bagga B Baldwin Entitybased crossdocument coreferencing vector space model Proceedings 17th International Conference Computational Linguistics 1998 pp 7985 5 L Bentivogli P Forner C Giuliano A Marchetti E Pianta K Tymoshenko Extending English ACE 2005 corpus annotation groundtruth links Wikipedia Proceedings Coling Workshop Peoples Web Meets NLP Collaboratively Constructed Semantic Resources 2010 pp 1927 6 C Bizer J Lehmann G Kobilarov S Auer C Becker R Cyganiak S Hellmann DBpediaa crystallization point web data Journal Web Semantics 7 2009 154165 7 S Brin L Page The anatomy largescale hypertextual web search engine Proceedings 7th International World Wide Web Conference 1998 pp 107117 8 R Bunescu M Pa sca Using encyclopedic knowledge named entity disambiguation Proceedings 11th Conference European Chapter Association Computational Linguistics 2006 pp 916 9 S Cucerzan Largescale named entity disambiguation based Wikipedia data Proceedings Joint Conference Empirical Methods Natural Language Processing Computational Natural Language Learning 2007 pp 708716 10 JR Curran S Clark J Bos Linguistically motivated largescale NLP CC Boxer Proceedings 45th Annual Meeting Association Computational Linguistics demo 2007 pp 3336 11 D Day J Hitzeman M Wick K Crouch M Poesio A corpus crossdocument coreference Proceedings 6th International Conference Language Resources Evaluation 2008 pp 2331 12 M Dredze P McNamee D Rao A Gerber T Finin Entity disambiguation knowledge base population Proceedings 23rd International Conference Computational Linguistics 2010 pp 277285 13 A Fader S Soderland O Etzioni Scaling Wikipediabased named entity disambiguation arbitrary web text Proceedings IJCAI Workshop UserContributed Knowledge Artiﬁcial Intelligence 2009 pp 2126 14 IP Fellegi AB Sunter A theory record linkage Journal American Statistical Association 64 1969 11831210 15 P Ferragina U Scaiella TAGME ontheﬂy annotation short text fragments Wikipedia entities Proceedings 19th International Con ference Information Knowledge Management 2010 pp 16251628 16 W Gale K Church D Yarowsky Work statistical methods word sense disambiguation Proceedings AAAI Fall Symposium Intelligent Probabilistic Approaches Natural Language 1992 pp 5460 17 CH Gooi J Allan Crossdocument coreference largescale corpus Proceedings 7th Annual Conference North American Chapter Association Computational Linguistics 2004 pp 916 18 S Gottipati J Jiang Linking entities knowledge base query expansion Proceedings Conference Empirical Methods Natural Language Processing 2011 pp 804813 19 Y Guo W Che T Liu S Li A graphbased method entity linking Proceedings 5th International Joint Conference Natural Language Processing 2011 pp 10101018 20 B Hachey W Radford JR Curran Graphbased named entity linking Wikipedia Proceedings 12th International Conference Web Information System Engineering 2011 pp 213226 21 X Han L Sun A generative entitymention model linking entities knowledge base Proceedings 49th Annual Meeting Association Computational Linguistics 2011 pp 945954 150 B Hachey et al Artiﬁcial Intelligence 194 2013 130150 22 X Han L Sun J Zhao Collective entity linking web text A graphbased method Proceedings 34th International Conference Research Development Information Retrieval 2011 pp 765774 23 L Hirschman M Colosimo A Morgan A Yeh Overview BioCreAtIvE task 1B Normalized gene lists BMC Bioinformatics 6 2005 S11 24 J Hoffart MA Yosef I Bordino H Fürstenau M Pinkal M Spaniol B Taneva S Thater G Weikum Robust disambiguation named entities text Proceedings Conference Empirical Methods Natural Language Processing 2011 pp 782792 25 WC Huang S Geva A Trotman Overview INEX 2009 link wiki track Lecture Notes Computer Science vol 6203 SpringerVerlag BerlinHeidelberg 2010 pp 312323 26 T Joachims Training linear SVMs linear time Proceedings 12th International Conference Knowledge Discovery Data Mining 2006 pp 217226 27 S Kulkarni A Singh G Ramakrishnan S Chakrabarti Collective annotation Wikipedia entities web text Proceedings 15th International Conference Knowledge Discovery Data Mining 2009 pp 457466 28 J Lehmann S Monahan L Nezda A Jung Y Shi LCC approaches knowledge base population TAC 2010 Proceedings Text Analysis Conference 2010 29 GS Mann D Yarowsky Unsupervised personal disambiguation Proceedings 7th Conference Computational Natural Language Learning 2003 pp 3340 30 A McCallum K Nigam LH Ungar Eﬃcient clustering highdimensional data sets application reference matching Proceedings 6th International Conference Knowledge Discovery Data Mining 2000 pp 169178 31 P McNamee HT Dang H Simpson P Schone SM Strassel An evaluation technologies knowledge base population Proceedings 7th International Conference Language Resources Evaluation 2010 pp 369372 32 R Mihalcea A Csomai Wikify Linking documents encyclopedic knowledge Proceedings 16th Conference Information Knowledge Management 2007 pp 233242 33 D Milne IH Witten Learning link Wikipedia Proceedings 17th Conference Information Knowledge Management 2008 pp 509518 34 M Milosavljevic JY Delort B Hachey B Arunasalam W Radford JR Curran Automating ﬁnancial surveillance User Centric Media Lec ture Notes Institute Computer Sciences Social Informatics Telecommunications Engineering vol 40 Springer BerlinHeidelberg 2010 pp 305311 35 AA Morgan Z Lu X Wang AM Cohen J Fluck P Ruch A Divoli K Fundel R Leaman J Hakenberg C Sun H Liu R Torres M Krauthammer WW Lau H Liu C Hsu M Schuemie KB Cohen L Hirschman Overview BioCreative II gene normalization Genome Biology 9 2008 S3 36 R Navigli Word sense disambiguation A survey ACM Computing Surveys 41 2009 1011069 37 R Navigli SP Ponzetto Babelnet Building large multilingual semantic network Proceedings 48th Annual Meeting Association Computational Linguistics 2010 pp 216225 38 NIST The ACE 2005 ACE05 evaluation plan httpwwwitlnistgoviadmigtestsace2005docace05evalplanv3pdf 2005 39 C Niu W Li RK Srihari Weakly supervised learning crossdocument person disambiguation supported information extraction Proceedings 42nd Annual Meeting Association Computational Linguistics 2004 pp 597604 40 J Nothman T Murphy JR Curran Analysing Wikipedia goldstandard corpora NER training Proceedings 12th Conference European Chapter Association Computational Linguistics 2009 pp 612620 41 D Ploch Exploring entity relations named entity disambiguation Proceedings ACL Student Session 2011 pp 1823 42 SP Ponzetto M Strube Taxonomy induction based collaboratively built knowledge repository Artiﬁcial Intelligence 175 2011 17371756 43 W Radford B Hachey J Nothman M Honnibal JR Curran CMCRC TAC10 Documentlevel entity linking graphbased reranking Proceed ings Text Analysis Conference 2010 44 L Ratinov D Roth D Downey M Anderson Local global algorithms disambiguation Wikipedia Proceedings 49th Annual Meeting Association Computational Linguistics 2011 pp 13751384 45 C Sauper R Barzilay Automatically generating Wikipedia articles A structureaware approach Proceedings Joint 47th Annual Meeting Association Computational Linguistics 4th International Joint Conference Natural Language Processing 2009 pp 208216 46 FM Suchanek G Kasneci G Weikum Yago A large ontology Wikipedia WordNet Journal Web Semantics 6 2008 203217 47 EF Tjong Kim Sang F De Meulder Introduction CoNLL2003 shared task Languageindependent named entity recognition Proceedings 7th Conference Natural Language Learning 2003 pp 142147 48 V Varma P Bysani K Reddy V Bharat Santosh GSK K Kumar S Kovelamudi Kiran Kumar N N Maganti IIIT Hyderabad TAC 2009 Proceed ings Text Analysis Conference 2009 49 WE Winkler Overview record linkage current research directions Technical Report Bureau Census 2006 50 K Woodsend M Lapata Learning simplify sentences quasisynchronous grammar integer programming Proceedings Conference Empirical Methods Natural Language Processing 2011 pp 409420 51 F Wu DS Weld Autonomously semantifying Wikipedia Proceedings 16th Conference Information Knowledge Management 2007 pp 4150 52 W Zhang CS Sim J Su CL Tan Entity linking effective acronym expansion instance selection topic modelling Proceedings 22nd International Joint Conference Artiﬁcial Intelligence 2011 pp 19091914 53 W Zhang J Su CL Tan WT Wang Entity linking leveraging automatically generated annotation Proceedings 23rd International Conference Computational Linguistics 2010 pp 12901298 54 Z Zheng F Li M Huang X Zhu Learning link entities knowledge base Proceedings 11th Annual Conference North American Chapter Association Computational Linguistics 2010 pp 483491