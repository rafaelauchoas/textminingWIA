Artiﬁcial Intelligence 165 2005 137163 wwwelseviercomlocateartint Decision making sole basis statistical likelihood Phan H Giang Prakash P Shenoy b Computer Aided Diagnosis Therapy Solutions CAD Siemens Medical Solutions 51 Valley Stream Pkwy Malvern PA 19355 USA b University Kansas School Business 1300 Sunnyside Ave Summerﬁeld Hall Lawrence KS 660457585 USA Received 10 May 2004 accepted 16 March 2005 Available online 10 May 2005 Abstract This paper presents new axiomatic decision theory choice uncertainty Unlike Bayesian decision theory uncertainty represented probability function theory uncertainty given form likelihood function extracted statistical evidence The likelihood prin ciple statistics stipulates likelihood functions encode relevant information obtainable experimental data In particular assume knowledge prior probabilities Conse quently Bayesian conversion likelihoods posterior probabilities possible setting We assumption deﬁnes likelihood set hypotheses maximum likelihood elements set We justify axiomatic similar von Neumann Morgenstern choice risk Our main result representation theorem new concept binary utility We discuss ambiguity attitudes handled Applied sta tistical inference problem theory suggests novel solution The results paper useful probabilistic model selection 2005 Elsevier BV All rights reserved Keywords Decision theory Likelihood Statistical inference Ambiguity attitude Corresponding author Email addresses phangiangsiemenscom PH Giang pshenoykuedu PP Shenoy 00043702 matter 2005 Elsevier BV All rights reserved doi101016jartint200503004 138 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 1 Introduction Various formal decision theories choice risk uncertainty studied seminal work von Neumann Morgenstern vNM 38 expected utility maximization principle formally established With exceptions common feature theories use probability express uncertainty decision situ ations An axiomatic model good axioms debate axioms vNM theory started immediately publication 2 As result ongoing debate axiomatic systems weaker vNM possess expected utility representation investigated 173233 There recognition uncer tainty usually associates words ambiguity vagueness fuzziness kind associated risk The captured standard nu merical probability In paper1 consider class choice problems uncertainty character ized likelihood functions This class includes typical statistical inference problem formulated follows Suppose analyze statistical experiment random variable Y given Y follows distributions F Pθ θ Ω parameter ized θ ii outcome experiment Y y The question conclude true value parameter θ There consensus statisticians information sample y brings unknown parameter According likelihood principle fundamental princi ples statistics 458 relevant information sample encoded likelihood function parameter space And consensus ends point The statistical inference problem treated differently different approaches 3 According decisiontheoretic approach advocated Wald 39 inference problem viewed choice problem For example context hypothesis testing problem choice accept reject hypothesis Within decisiontheoretic approach variations Walds maximin decision rule selects action delivers favorable worstcase outcome A Bayesian treatment problem sug gests calculation posterior probability function Ω Bayess theorem likelihood function assuming prior distribution Given posteriors actions com pared basis expected utility In paper proposes alternative We construct decision theory works directly likelihood information We choose treat likelihood uncertainty right simple reason priors known situations The problem probabilistic model selection areas AI machine learning pat tern recognition data mining example statistical inference problem Given training data set y researchers construct probabilistic model P Bayesian net generatesﬁts data use model inference future observations Because models emerge plausible candi dates model selection essential model construction 1 A preliminary version work appeared Proceedings 18th Conference Uncertainty Artiﬁcial Intelligence UAI 2002 21 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 139 From decision theoretic point view prevailing practice select model simple criteria maximum likelihood ML maximum posteriori probability MAP equivalent assuming equal utilities costs models consideration This assumption explain following example Given models approximately likelihoods researchers simpler jus tify choice invoking Occams razor principle In statistics literature models selected Akaike Information Criterion AIC 1 Schwarzs criterion aka Bayesian Information Criterion BIC 34 The idea underlying AIC BIC penalize models likelihood depending number parameters Poland Shachter 31 suggest effectiveness ratio criterion penalty ex plicit computational interpretation Clearly concern complexity viewed cost associated model In broader terms implication works different models associated different costs taken account model selection process This paper organized follows In section discuss extending likelihood function function set subsets possible worlds In main Section 3 develop decision theory likelihood uncertainty We begin proposing set ﬁve axioms justiﬁed intuition stochastic dominance principle Next introduce concept binary utility prove representation theorem likeli hood lotteries That followed comments related works In Section 4 decision theory applied statistical inference problem Section 5 contains concluding remarks 2 Likelihood uncertainty measure Let consider statistical inference problem described earlier Although phe nomenon study described probabilistically set probability functions F uncertainty pertaining choice problem It likelihood function The term likelihood modern statistics coined RA Fisher mentioned early 1922 18 Fisher likelihoods measure mental conﬁdence competing sci entiﬁc hypotheses result statistical experiment 14 detailed account Likelihood puzzling nature For θ Ω likelihood quantity magnitude equals Pθ ythe probability probability density case inﬁnite Ω2 observing y θ fact true value parameter However view set likelihood quantities function parameter space likelihood function A likelihood function probability function For simple reason sum likelihood values parameter space add unity Moreover likelihood functions equivalent proportional constant To emphasize fact likelihood function tied data y θ variable notation likyθ instead Pθ y Technically probability likelihood 2 One write Pθ0 y form conditional probability P Y y θ θ0 The notation implies probability measure parameter space Ω This case Bayesian approach In paper assume probability measure So stick notation 140 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 kinds animals close mule donkey This proximity reason intertwining relationship Obviously posterior probability derived likelihood priors Bayes theorem Since priors supposed summarize information parameter experiment conducted assumption existence realm science statisticians contend Although certain situations prior probability comes naturally compelling argument known experimenter situations Another path likelihood probability bypasses issue priors started Fisher He suggested compute called ﬁducial probabilities malizing likelihoods dividing sum likelihoods Fishers idea shown work isolated examples faces difﬁculty applied general cases Some statisticians believe ﬁducial probability mistake 3 Belief function theory proposed Dempster 9 attempt overcome difﬁculty ﬁducial argument Shafer 35 mainly responsible turning Dempsters idea fullﬂedged theory evidence A basic construct DempsterShafer theory basic probability assignment BPA m 2Ω 0 1 m 0 cid1 AΩ mA 1 1 Value mA A Ω called probability mass A If mA 0 A called focus A standard probability function belief function foci singletons From BPA derive plausibility function PlA def cid1 BAcid7 mB cid7 A Ω 2 BPA plausibility information content original m recov ered Pl Shafer 35 proposes represent statistical evidence belief function nested foci consonant belief function CBF plausibilities singletons propor tional likelihood values Given likelihood function likx corresponding CBF constructed follows Suppose likx partitions Ω Ωi according values Ωi ω likxω ai a1 a2 ak Then k foci Ai k masses Ai icid2 j 1 Ωi mAi ai ai1 a1 3 ak1 def 0 A consequence nestedfocus structure plausibility function union decom posable A B Ω cid4 cid3 PlA B max PlA PlB 4 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 141 A crucial argument favor Shafers original3 proposal likelihood treatment CBF agreement maximum likelihood method ML statistics In ML likelihood assigned set hypotheses taken maximum likelihoods individual hypothesis set The idea taking maximum individual likelihood likelihood set standard practice publication seminal papers 30 Neyman Pearson 1928 ML intuitively appealing backed asymptotic optimality properties 2627 We use different notation 35 We want emphasize nature likelihood avoid belief function connotations While Shafer mainly interested representing reasoning evidence goal decision making Let deﬁne extended likelihood function ELF Liky 2Ω 0 1 follows Likyθ def likyθ supωΩ likyω ˆθ maximum likelihood estimate θ likyθ liky ˆθ θ Ω LikyA def sup ωA Likyω A Ω 5 6 After learning true value parameter subset parameter space B Ω LikyB 0 condition ELF following equation LikyA B def LikyA B LikyB 7 This deﬁnition likelihood conditioning derived Dempsters rule combination applied consonant belief function plausibility form It conforms likeli hood principle following example demonstrates We use convention Liky 0 Some properties Lik follow directly deﬁnitions Lemma 1 LikyΩ 1 ii LikyA B maxLikyA LikyB iii maxLikyA Liky A 1 A complement A Ω iv If A B LikyA cid1 LikyB Example A rv Y known normal distribution It known mean µ 0 1 standard deviation σ 1 15 Suppose value y 14 observed We 3 Shafer 36 later renounces idea ground set CBFs closed Dempsters rule combination standard rule combine distinct pieces evidence It implies representation compound evidence combination individual evidences However later Walley 40 shows Dempsters rule compatible likelihood principle suitable combining statistical evidence He shows set CBFs closed alternative combination rule With respect conditioning Dempsters rule Walleys alternative identical 142 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 Table 1 Likelihood extended likelihood conditioning lik14 Lik14 Lik14 D ω1 01497 04065 00000 ω2 01721 04673 06704 ω3 03683 10000 00000 ω4 02567 06970 10000 A na 04673 06704 B na 1 1 C na 1 0 D na 06970 10000 want calculate ELF representing uncertainty unknown parameters The known parameter θ µ σ Ω ω1 ω2 ω3 ω4 ω1 0 1 ω2 0 15 ω3 1 1 ω4 1 15 Let A denote event µ 0 B denote µ 1 C denote σ 1 D denote σ 15 That means A ω1 ω2 B ω3 ω4 C ω1 ω3 D ω2 ω4 In ﬁrst row densities 14 normal probability density function given conﬁgu ration mean µ standard deviation σ f 14 µ σ For example f 14 µ 0 σ 1 01497 Obviously density deﬁned set conﬁgurations A B C D Eq 6 calculate second row Suppose addition known σ 15 From statistical point view new situation mean µ unknown parameter The likelihoods µ 0 µ 1 01721 02567 respectively The likelihood ratio 06704 In terms extended likelihood new situation coded conditional Lik14 D This yields Lik14ω1 D Lik14ω3 D Lik14C D 0 Lik14A D Lik14ω2Lik14D 06704 Lik14B D Lik14ω4Lik14 1 The ratio extended likelihoods µ 0 µ 1 06704 Keeping mind likelihood principle holds ratio likelihoods matters deﬁnition conditioning extended likelihoods conforms standard practice statistics It worth noting derivation extended likelihood CBF moti vated statistical considerations properties listed Lemma 1 deﬁning properties possibility measure 1241 What distinguishes possibility function CBF fuzzy set semantics consequently notion ordinal conditioning cid5 πA B 1 πA B πA B πA 8 Technically possibility theory entertain notions conditioning ordinal Eq 8 numerical speciﬁed Eq 7 In sense extended likelihood possibility measure equipped numerical conditioning4 It difﬁcult check previous example Lik updated ordinal conditioning result consistent likelihood principle 4 Dubois Moral Prade 11 possibility measure result taking supremum family likelihood functions On semantics min rule combination possibility measures justiﬁed PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 143 3 A decision theory likelihood uncertainty Let formalize decision problem study We assume decision situation described tuple Ω X A y π Ω set simple hypotheses parameter space X set rewards measured utility currency A set actions form Ω X y dataobservationevidence π ELF 2Ω 0 1 calculated y representing uncertainty hypotheses For actions setting states rewards contracted observable The utility nature rewards implies risk attitude factor decision making ignored Also utility transformed linear function assume rewards restricted unit interval 0 1 For sake clarity assume X ﬁnite elements denoted x1 x2 xr A simple likelihood lottery action coupled likelihood measure Each lottery mechanism delivers rewards associated likelihoods Formally lottery L induced π mapping X 0 1 Lx πa1x x X a1 setvalued inverse mapping action For remainder paper denote simple lottery Lx1x1 Lx2x2 convention xj Lxj 0 omitted In notation consequence x X identiﬁed 1cid1icid1m a1xi Ω Since π unary lottery 1x Notice lottery Lixim ELF Li πa1xi max1cid1icid1m Li 1 i1 cid6 We consider compound lotteries rewards lotteries The set lot teries denoted L 31 Axioms We study preference relation cid9 set lotteries L cid9 L2 Indifference strict preference cid11 relations derived cid9 L1 L2 iff L1 cid9 L2 L2 cid9 L1 L1 cid11 L2 iff L1 cid9 L2 L2 cid7cid9 L1 We postulate cid9 satisﬁes ﬁve axioms similar proposed von Neumann Morgenstern classical linear utility theory form pre sented 29 They follows A1 Order cid9 reﬂexive transitive complete Since consequences X special lotteries cid9 order consequences We assume x1 cid9 x2 cid9 cid9 xr x1 cid11 xr In cases clear dealing best worst consequences special notations x1 xr x x1 x xr A lottery involves best x worst consequences x potential outcomes called canonical lottery The set canonical lotteries denoted Lc A2 Reduction compound lotteries Let L δ1L1 δ2L2 δkLk Li κi1x1 κi2x2 κir xr L κ1x1 κ2x2 κr xr κj max1cid1icid1kδiκij A3 Substitutability If Li Lcid13 δ1L1 δiLi δkLk δ1L1 δiLcid13 δkLk 144 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 A4 Existence equivalent canonical lottery For x X s Lc x s A5 Qualitative monotonicity λx µx cid9 λ cid13 x µ cid13 x iff λ cid2 λ cid13 µ cid1 µ cid13 9 Among axioms A1 A3 standard assumptions preference relation A2 implication conditioning operation Suppose unknown parameter θ vector We think example θ γ σ Let consider compound lottery L δ1L1 δ2L2 δkLk Li κi1x1 κir xr 1 cid1 cid1 k Underlying L fact twostage lottery The ﬁrst stage associated scalar parameter γ It accepts values γ1 γ2 γk likelihoods δ1 δ2 δk respectively If γi true value holder L rewarded simple lottery Li turn associated scalar parameter σ accepts σoi 1 σoi 2 σoi r likelihoods κi1 κi2 κir oi permutation 1 2 3 r When σoi j obtains holder rewarded consequence xj Let consider onestage lottery Lcid13 delivers xj case tuple cid14γiσoi j cid15 true value θ 1 cid1 cid1 k Because conditioning equation 7 Likγiσoi j LikγiLikσ σoi j γ γi δiκij 10 The set tuples xj delivered cid14γiσoi j cid15 1 cid1 cid1 k Thus extended likelihood associated consequence xj lottery Lcid13 cid3 γiσoi j 1 cid1 cid1 k cid4 Lik maxδiκij 1 cid1 cid1 k 11 Since L Lcid13 property matter true value θ conse quences deliver require L Lcid13 axiom A2 Fig 1 shows example k 2 r 2 o11 1 o12 2 o21 2 o22 1 Axiom A4 requires consequence x X canonical lottery c λ1x λ2x x c For clarity let assume x 1 x 0 argument remains valid real values x x long x x For x X need ﬁnd canonical lottery c equivalent x We likelihood gamble purpose There parties game Arbiter House Player The goal game gauge binary utility function Player The game plays follows The Arbiter preselects single parameter probability distribution fθ She predetermines Fig 1 Twostage L onestage Lcid13 equivalent PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 145 2 values θ1 θ2 use unknown parameter Probability distribution fθ possible values parameter revealed parties For example normal distribution5 given standard devision σ 1 fθ θ unknown mean θ 1 1 The Arbiter secretly picks value θ θ1 θ2 generates value y fθ The mechanism Arbiter pick value θ unknown Player House Both Player House told data y The House offers gamble pays x Player value actually Arbiter generate observation θ1 x θ2 What highest price Player willing pay gamble If answer x Player x cid7 Likyθ1x Likyθ2x Likyθ1 fθ1y Likyθ2 fθ2 y cid8 12 One repeat gamble number times table correspondence tween xi Likyi θ1x Likyi θ2x What assume A4 table rich x X look table equivalent Likyθ1x Likyθ2x Comparing likelihood gamble probabilistic gamble6 practice ex tract decision makers unary utility number important differences First instead rv known distribution tossing fair coin rolling dice partially speciﬁed probability model Second rewards Player likelihood gamble contracted observations y unobservable true value parameter θ In sense likelihood gamble simple hypothesis testing problem Player needs decide hypotheses θ θ1 θ θ2 true The relationship clear Fig 5 What kind betting behavior expected rational decision maker Cer tain patterns excluded irrational In example likelihood gamble uses normal distribution known sd σ 1 pays 1 mean 1 0 1 paying 020 gamble y 3 paying 070 y 1 irrational Intuitively y 3 lends support hypothesis θ 1 y 1 Let malize intuition We impose mild constraint form monotonicity axiom A5 Basically require price lottery λ1 µ0 greater equal price λcid131 µcid130 likelihood getting 1 higher λ cid2 λcid13 likelihood getting 0 µ cid1 µcid13 We justify A5 basis ﬁrst order stochastic dominance FSD Not strictly Bayesian wont assume know prior probability P θ θ1 assume prior exists This situation modeled viewing prior θ θ1 rv ρ taking value unit interval The distribution ρ unknown We calculate posterior θ θ1 given y ρ Pρθ θ1 y ρ Likyθ1 ρ Likyθ1 1 ρ Likyθ2 13 5 Any distribution work ﬁne 6 Suppose u0 0 u1 1 d price decision maker willing pay gamble pays 1 toss fair coin turns Head 0 turns Tail ud 05 146 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 The expected payoff likelihood gamble 14 Vyρ Pρθ θ1 y x Pρθ θ2 y x x Pρθ θ1 y x x 15 With x x 0 Vyρ strictly increasing function Pρθ θ1 y When x 1 x 0 Eq 14 simpliﬁed Vyρ Pρθ θ1 y Being function ρ Vyρ rv The concept stochastic dominance SD extensively economics ﬁnance statistics 28 Suppose X Y distinct rv cumulative distrib utions F G respectively We X stochastically dominates ﬁrst degree Y written XD1Y iff F x cid1 Gx x Since X Y distinct strict inequality hold value x FSD important following equiva lence X stochastically dominates ﬁrst order Y iff expected utility X greater equal expected utility Y nondecreasing utility functions XD1Y iff EuX cid2 EuY u U U class nondecreasing utility func tions E expectation operator In immediately following discussion assume x 1 x 0 sake clarity loss generality Lemma 2 For ρ 0 1 Vyρ Vycid13ρ iff cid7 Likyθ11 Likyθ20 cid8 cid11 cid7 Likycid13 θ11 Likycid13θ20 cid8 16 Theorem 1 Suppose ρ rv taking values unit interval Then Vyρ stochastically dominates ﬁrst degree Vycid13 ρ iff cid11 cid7 Likycid13θ11 Likycid13 θ20 cid7 Likyθ11 Likyθ20 cid8 cid8 The order canonical lotteries stipulated axiom A5 order ﬁrst degree stochastic dominance expected payoffs prior rv In Fig 2 lower curve graph V060ρ Y 6 corresponding lottery 30111 10 upper curve graph V026ρ 59451 10 This completes justiﬁcation ﬁve axioms Fig 2 Payoff functions y 60 lower y 26 upper PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 147 32 Binary utility We proceed study preference relation satisfying axioms The follow ing lemma shows set L equivalent classes lotteries wrt indifference relation isomorphic set canonical lotteries Lc Lemma 3 If preference relation cid9 set lotteries L satisﬁes axioms A1 A5 lottery exists canonical lottery indifferent The signiﬁcance Lemma 3 reduces comparison lotteries canon ical lotteries simple structure straightforward interpretation We want represent cid9 utility function comparison lotteries calculation utilities Our main idea use utility scale set isomorphic set canonical lotteries Let deﬁne cid9 U def cid14a bcid15 b 0 1 maxa b 1 cid10 17 In words U set pair numbers unit interval 1 A linear order cid18 U distinguish order cid2 scalars deﬁned cid14a bcid15 cid18 cid14a cid13 cid13cid15 b iff acid13 1 b cid1 bcid13 1 acid13 cid1 1 cid2 acid13 b bcid13 1 18 Strict preference cid18 indifference derivatives The special structure U allows simpliﬁcation order deﬁnition given Eq 18 The proof following lemma straightforward omitted Lemma 4 For cid14a bcid15 cid14acid13 bcid13cid15 U cid13 cid14a bcid15 cid18 cid14a cid18 cid14a cid13 cid14a bcid15 cid14a bcid15 cid14a b cid13 b cid13cid15 b cid13cid15 cid13cid15 iff cid13 iff iff cid2 cid13 b b cid13 b cid1 b cid13 b b cid13 cid13 19 20 21 We refer U equipped order cid18 binary utility scale Roughly inter pret components utility value indices goodness ﬁrst badness second One binary utility value better goodness index higher badness index smaller badness index Note binary utility special case lexicographic utility 16 Lemma 4 shows indices symmetrical roles precedence One index tie breaking case equality holds index 148 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 Fig 3 Binary utility scale U To operate binary utilities extend7 product max operations work pairs follows For scalar α β π γ αcid14β γ cid15 def cid14αβ αγ cid15 cid4 cid3 def cid14α βcid15 cid14γ πcid15 max cid14 cid15 maxα γ maxβ π 22 23 We properties extended max operation The proof straightforward omitted Lemma 5 U closed max u ucid13 U maxu ucid13 U ii max monotone argument example maxu v cid18 maxu vcid13 v cid2 vcid13 33 Representation theorem A utility function mapping set lotteries utility scale U L U We preference relation cid9 represented utility function U L cid9 Lcid13 cid18 U Lcid13 For function f deﬁned set X let f X denote f x x X iff U L We following theorem Theorem 2 cid9 L satisﬁes axioms A1 A5 exists utility function QU L U representing cid9 cid141 0cid15 cid140 1cid15 QUX cid3 cid4 π1L1 πkLk QU cid9 cid10 πiQULi max 1cid1icid1k While proposing axioms A1 A5 argue rationale axiom sep arately consistency axiom The fact axiom represented deﬁned utility function proves free inconsis tency In particular L simple lottery Eq 24 rewritten cid3 cid4 π1x1 πr xr QU cid9 cid10 πiQUxi max 1cid1icid1r 24 25 7 We decided favor overloading operations product max instead creating new symbols Hopefully slight abuse notation lead confusion type arguments indicate rule apply PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 149 Fig 4 Qualitative utility calculation The form QU 25 resembles vNM expected utility expression The expected utility probabilistic lottery p X deﬁned U p def 1cid1icid1r pxiU xi Maximization 25 plays role counterpartadditionin vNM expected utility This similarity leads refer QU expected qualitative utility function cid16 Fig 4 illustrates QU calculation twostage lottery Assuming QUx1 cid141 0cid15 QUx2 cid141 8cid15 QUx3 cid140 1cid15 rollback calculation shows cid3cid7 cid8cid4 QU 14x1 7x2 1x3 51x1 2x3 cid147 1cid15 Although qualitative vNM utilities share fundamental structure important emphasize qualitative utility simple translation vNM utility new language Not properties vNM utility hold qualitative version Notably qualitative utility satisﬁes weaker versions independence Archimedian proper ties 25 Theorem 3 Suppose L1 L2 L3 L λ µ 0 1 maxλ µ 1 If L1 cid9 L2 λL1 µL3 cid9 λL2 µL3 b Suppose L1 L2 L3 L L1 cid11 L2 cid11 L3 Then exists λ µ λcid13 µcid13 0 1 maxλ µ maxλcid13 µcid13 1 cid14λ µcid15 cid14λcid13 µcid13cid15 cid140 1cid15 cid141 0cid15 λL1 µL3 cid11 L2 L2 cid11 λcid13L1 µcid13L3 Note property hold strict preference That general dont λL1 µL3 cid11 λL2 µL3 L1 cid11 L2 34 Related work In AI literature number decision models assume probability studied 72437 Brafman Tennenholtz 7 characterize qualitative decision rules maximin minimax regret competitive ratios maximax They different decision criteria equivalent terms representation power These purely qualitative rules ignore uncertainty relevant choice problem Smets 37 proposes twolevel decision model DempsterShafer belief functions At credal level agent uses belief functions represent reason uncertainty When needs decision translate belief function probability pignistic trans formation Basically transformation allocates probability mass assigned 150 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 focus equally element Smets model able handle ambiguity attitudes For example applied Ellsbergs paradox 15 model produces unintuitive solution Halpern 24 studies general uncertainty measure called plausibility measure To decisions deﬁnes operation maps product consequence domain plausibility domain valuation domain The order valuation domain deﬁned decision rule In 20 study decision making model Spohns theory epistemic beliefs This uncertainty measure closely related extended like lihood interpreted orderofmagnitude approximation probabilities degrees plain beliefs More relevant work approach decision making possibility ory proposed Dubois et al 1013 As noted earlier possibility function satisﬁes Eqs 5 6 deﬁne ELF The main difference conditioning operation Dubois et al use ordinal conditioning deﬁned Eq 8 The likelihood conditioning numerical conditioning deﬁned Eq 7 They distinguish decision crite ria pessimistic optimistic For decision criterion axiom qualitative utility functional representing preference relation satisﬁes axioms A detailed comparative analysis approach vs approach argued Dubois et al presented 22 We approach modiﬁed ordinal conditioning generalizes uniﬁes pessimistic optimistic decision criteria In framework decision makers attitude ambiguity shows basic utility assignment consequences X Recall indifference consequence binary utility value determined likelihood gamble We betting behavior encodes interesting information attitude ambiguity Suppose decision maker equates payoff x canonical lottery λ1 µ0 From Bayesian decision theory point view indifference means expected payoff Vyρ respect prior ρ likelihood gamble equal x Substitute x Vyρ λ µ Likyθ1 Likyθ2 Eq 13 solve ρ ﬁnd ρ xµ 1 xλ xµ From Eq 26 logitρ logitx lnλµ 26 27 logitz def lnz1 z We ρ calculated Eq 27 implicit prior8 obvious reason When λ µ 1 ρ x Therefore ρ interpreted price decision maker pays fair likelihood lottery 11 10 Recall context likelihood gamble ρ probability Players judg ment Arbiter selects θ1 x contracted parameter value gen erate given observation Thus inequality ρ 05 interpreted Player priori deems bad outcome likely good English language 8 It necessary note implicit prior value unique single bet A betting behavior implies different implicit priors different likelihood gambles consistent A5 For details range permissible priors readers referred 19 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 151 risk attitude probability gamble cid1 x ambiguity attitude cid1 cid14λ µcid15 likelihood gamble Fig 5 Risk ambiguity transformation money binary utility speciﬁc mental attitude tends emphasize adverse aspectspessimism Similarly opposite ρ 05 argued manifestation optimism This deﬁn ition pessimism optimism different notion pessimism optimism9 forward Dubois et al 10 property axiom attributed decision maker In paper pessimism optimism property attributed basic utility assignment decision maker Another sensible terminology pessimism optimism A betting behavior said exhibit ambiguity averse ρ 05 ambiguity neutral ρ 05 biguity seeking ρ 05 attitudes It useful analyze similarity distinction notion ambiguity attitude established notion risk attitude The property utility function moneytoutility conversion Risk averse risk neutral risk seeking attitudes correspond concavity linearity convexity utility functions In paper explicitly consider risk attitude issue assumption X measured utility currency Fig 5 illustrates roles risk ambiguity attitudes transformation monetary reward binary utility unary utility In Economics Statistics literature prominent axiomatic decision theory additive probability studied Schmeidler 33 extended Gilboa 23 Sarin Wakker 32 The concept comonotonicity crucial role Schmeidlers Two acts f g comonotonic states s1 s2 f s1 cid11 f s2 gs2 cid11 gs1 The independence property required hold set comonotonic acts The preference relation satisﬁes Schmeidlers axioms represented Choquet expected utility function CEU A realvalued function v 2Ω 0 1 called capacity function v 0 vΩ 1 A B Ω vA cid1 vB CEUvf deﬁned follows For simplicity assume X set reals interpreted utilities def s Ω f s cid2 xkset states ordered x0 x1 xm For act f Af k f delivers xk better consequence Obviously Af Af nested Af Af 1 0 m Ω CEUvf def x0vAf 0 kcid1 i1 xi cid3 vAf vAf cid4 i1 28 The main difference Schmeidlers approach approach role conditioning operation uncertainty measure CEU representation result sidering separation utility probability ii functional representations 9 The deﬁnition pessimism optimism Dubois et al requires possibilistic lottery π preferred preferred lottery π cid13 greater equal possibility getting consequence π π cid9pes π cid13 possibility getting consequence π cid13 π cid13 cid9opt π π cid13 cid2 π 152 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 sum products numbers number probability interpre tation utility interpretation 33 p 584 The updating operation explicitly considered capacity function In contrast approach starts uncertainty calculus properly deﬁned updating rules develops decision theory utility derived probability In sense ELF satisﬁes requirements capacity measure special case capacity deﬁned conditioning operation To difference CEU QU let calculate CEU canonical A act respect ELF π Suppose simplicity x 1 x 1 Since Aa 0 Aa 1 Ω Eq 28 cid4 cid3 Ax Ax CEUπ πA cid4 cid3 1 πA 2πA 1 First observe CEU canonical act depend capacity event leading worst consequence vA cid7 1 vA capacity measure non additive In contrast A5 requires comparison likelihoods getting worst consequence likelihoods getting best consequence equal This observation suggest CEU appropriate existing nonprobabilistic uncertainty calculi DempsterShafer belief functions 35 fuzzy possibility 41 plausibility mea sures 24 welldeﬁned updating rules The lack updating rule capacity subjects CEU following criticism Sup pose v capacity measure deﬁne dual vcid13A def 1 vA A Ω It difﬁcult vcid13 capacity measure It arguable v vcid13 contain information v recoverable vcid13 Despite visible symmetry v vcid13 rankings acts CEUv CEUvcid13 different In sense CEU sensitive information Such criticism void uncertainty calculi deﬁned dating rules The dual probability measure The dual possibility measure necessity measure updating rules different The true dual pair belief plausibility functions DempsterShafer theory Thus measures symmetric despite duals 4 Likelihood solution statistical inference 41 Decisiontheoretic approach statistical inference We review decisiontheoretic approach statistical inference We assume given set alternative actions denoted A sample space Y Y A loss V θ measures loss arises action true value parameter θ 10 A decision rule mapping δ Y A observation y rule recom 10 In terms decision problem deﬁnition Section 3 superset V A Ω set possible loss values set consequences X PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 153 mends action δy The risk function decision rule δ parameter value θ deﬁned cid3 δY θ cid4 R def Eθ V cid3 δY θ cid4 cid3 δy θ cid4 V pθ y 29 cid17 Y The risk function measures average loss adopting rule δ case θ true value The use risk functions depends information assume avail able For point parameter space value risk function In case priori information parameter exists Wald 39 advocated use minimax rule minimizes worst risk attained rule δ minimax arg min δ max θΩ Rδ θ 30 set decision rules δ called minimax solution If assume Bayesian school existence prior distribution parameter risk averaged number called Bayes risk cid17 rδ EρRδ θ Rδ θ ρθ Ω 31 ρ prior distribution θ Then optimal rule minimizes Bayes risk called Bayes solution arg min δ Bayesρ rδ 32 δ Wald 39 pointed exists prior distribution ρ called favorable Bayes solution minimax solution The term Bayes justiﬁed fact solution obtained intuitive route Bayes theorem principle minimizing expected loss Given prior probability distribution ρ Ω data y Y posterior probability Ω obtained Bayes theorem pθ y pθ yρθ Denote apy action minimizes expected loss given data y cid17 apy arg min aA V θ pθ y 33 34 Ω Let deﬁne rule δ minimizes expected loss P y cid21 apy data y rule δ P delivers action Lemma 6 δ P Bayes solution rδ P rδ Bayesρ 42 Likelihood solution Without knowing prior ρ propose following solution based logic P Each y Y associated ELF Liky An action ELF leads δ 154 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 induce likelihood lottery Denote Lay lottery generated action obser vation y Likelihood lotteries compared QU The optimal action given observation y aLiky arg sup aA QU cid4 cid3 Lay 35 cid18 sup11 operation taking maximum element according binary order We deﬁne decision rule δ Liky cid21 aLiky assigns point sample space action maximizes qualitative utility We decision rule likeli hood solution minimax δ Bayes δ There dimensions solutions δ Lik compared The ﬁrst concerns information One differentiate kinds information relevant statistical inference problem extraexperiment information embodied prior probability experimental information embodied likelihood function The Bayesian approach requires kinds utilizes arrive solution In Walds proposal risk function special role actually observed data prior probability considered Thus kinds information ignored The likelihood solution assume knowing prior use likelihood information provided data identifying best action The concept stochastic dominance provides dimension comparing solutions Apart FSD stochastic dominance second higher degree deﬁned For simplicity following 6 assume rv nonnegative cumulative distri bution functions satisfy F 0 0 For cumulative distribution function F deﬁne natural n Fnz zcid17 0 Fn1x dx 36 notation F1 F Suppose X Y rv use symbols cumu lative distribution function X preferred Y according ndegree stochastic dominance write XnSDY Xnz cid1 Ynz z cid2 0 It known ndegree dominance implies higher degree dominance ii higher degree greater rel ative importance assigned small value rv Borch 6 shows Walds minimax rule equivalent stochastic dominance inﬁnite degree The order satisfying vNM axioms viewed zero degree stochastic dominance boils comparison numbersexpected utility valuesthat course singular rv Thus arrange Bayes likelihood minimax solutions increasing order according SD degrees 43 An illustrative example The following example adapted 3 The manufacturer small travel clocks sold chain department stores agrees service clock 11 In contrast max deﬁned Eq 23 operates scalars cid2 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 155 fails operate satisfactorily ﬁrst year purchase For clock decision merely clean replace works set actions A a1 a2 a1 denotes clean clock replace work needed a2 denotes immediately replace works Let assume possible faults Ω θ1 θ2 θ1 means need cleaning θ2 means clock physically damaged works need replacement Utility loss functions given following table The relationship utility u loss V equation V 1 u ua θ a1 a2 θ1 8 5 θ2 3 5 V θ a1 a2 θ1 2 5 θ2 7 5 The loss table roughly estimated fact cleaning clock costs 020 placing works costs 050 If policy replace works clock needing service cost 050 matter problem present If policy clean clock ﬁrst state θ1 service costs 020 case physical damage cleaning obviously ﬁx problem manufacturer ends replacing works Thus total cost 070 The manufacturer ask customer provide symptom malfunction clock sent service center Assume sample space Y y1 y2 y3 y1 means clock stopped operating y2the clock erratic timekeeping y3clock run limited period Such information gives indication θ expressed terms likelihood liky θ pθ y θ1 θ2 y1 1 7 y2 4 2 y3 5 1 For point sample space choose a1 a2 8 possible decision rules total Each decision rule speciﬁes action given observation δj yi y1 y2 y3 δ1 a1 a1 a1 δ2 a1 a1 a2 δ3 a1 a2 a1 δ4 a1 a2 a2 δ5 a2 a1 a1 δ6 a2 a1 a2 δ7 a2 a2 a1 δ8 a2 a2 a2 We calculate risk function values rule parameter value following table Rij θ1 θ2 δ1 2 7 δ2 35 68 δ3 32 66 δ4 47 64 δ5 23 56 δ6 38 54 δ7 35 52 δ8 50 50 Notice rule superior values θ Walds minimax solution δ8 If assume prior distribution θ calculate Bayes risks rules For example prior probability pθ1 7 Bayes risks r7δi 156 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 δ1 35 δ2 449 δ3 442 δ4 541 δ5 329 δ6 428 δ7 401 δ8 50 Thus δ5 Bayes solution The following sensitivity analysis shows Bayes solu tions depend prior pθ1 Bayes solution When δ8 δ7 δ5 δ1 pθ1 cid1 118 118 cid1 pθ1 cid1 250 250 cid1 pθ1 cid1 824 824 cid1 pθ1 In approach suppose unary utility translated binary utility according following table The table obtained assuming ambiguity neutrality For example ﬁnd binary utility equivalent 08 plugging x 08 implicit prior ρ 05 Eq 27 logit08 lnλµ logit05 Therefore λµ 4 Since maxλ µ 1 λ 1 µ 25 Thus 08 cid141 025cid15 Unary utility 8 5 3 Binary utility cid141 25cid15 cid141 1cid15 cid1443 1cid15 Given y1 ELF Liky1θ1 14 Liky1 θ2 1 Action a1 corresponds lottery La1y1 14cid141 25cid15 1cid1443 1cid15 cid4 cid3 La1y1 QU cid9 max cid9 max cid10 14cid141 25cid15 1cid1443 1cid15 cid10 cid1414 035cid15 cid1443 1cid15 cid1443 1cid15 Action a2 associated lottery La2y1 14cid141 1cid15 1cid141 1cid15 QULa2 y1 cid141 1cid15 Thus a2 cid11y1 a1 Given y2 Liky2 θ1 1 Liky2 θ2 5 So QULa1 y2 cid141 5cid15 QULa2 y2 cid141 1cid15 Thus a1 cid11y2 a2 Given y3 Liky2 θ1 1 Liky2θ2 2 QULa1 y3 cid141 25cid15 QULa2 y3 cid141 1cid15 Thus a1 cid11y3 a2 In summary likelihood solution δ5 It interesting know likelihood solutions depend ambiguity attitude It shown Likelihood solution δ7 δ5 Implicit prior ρ cid1 03333 03334 cid1 ρ Let informal comments Depending ambiguity attitude likelihood solution δ7 δ5 minimax solution δ8 As noted ignores uncertainty generated observation If prior probability value interval 0250 0824 Bayes solution δ5 likelihood solution ambiguity attitude ρ 03334 1 If PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 157 prior probability known argue Bayes solution optimal However optimality Bayes solution come cost The prior probability requirement satisﬁed monetary cost research buying deducted beneﬁt having optimal ac tion Alternatively decision maker assume prior distribution ad hoc manner This compromise claimed optimality One extend concept Bayes solution including sensitivity analysis This certainly helps decision maker providing frame reference But sensitivity analysis constitute basis knowing prior probability Moreover parameter space large multiple way sensitivity analysis difﬁcult The behavior comparison likelihood solution Bayes solution ρ pθ1 vary interesting When pθ1 increases 0 1 Bayes solu tion moves δ8 δ7 δ5 δ1 When ρ increases 0 1 likelihood solution moves δ7 δ5 Thus likelihood solutions include δ8 δ1 cor respond Bayes solutions extreme values prior pθ1 In particular δ7 chooses a1 δ8 chooses a2 y3 δ1 chooses a1 δ5 chooses a2 y1 There factors ameliorate discrepancy First extreme values pθ1 far noninformative priors expected situation prior information In words selecting pθ1 close 0 1 decision maker willing assume signiﬁcant priori information comparison likelihood solution void Second extreme values implicit prior ρ utilities a1 a2 ob servation close For example ρ 01 QULa1 y3 cid141 0052cid15 QULa2 y3 cid141 0111cid15 At nonextreme cases likelihood solution Bayes solution basically agree Decision rules δ7 δ5 selected approaches large segments values pθ1 ρ This pattern comforting careful draw Speciﬁcally use agreement justiﬁcation likelihood solution As pointed axioms A1 A5 likelihood solution based structurally similar Luce Raiffa 29 justify expected utility maximization principle ultimately basis Bayes solutions Thus foundational level optimality likelihood solution justiﬁed way optimality Bayes solution optimality concepts obviously different It argued question optimality appropriate depends information available Although pθ1 ρ similar roles behavior solutions different semantics pθ1 speciﬁcation prior probability parameter space Therefore gauges priori information empirical assumed pa rameters In practice space elements speciﬁcation difﬁcult sensitivity analysis complex ρ hand gauges attitude ambiguity decision maker It determined dependently parameter space simple situations hypotheses ﬁxed rewards 158 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 5 Summary conclusion In paper develop decision theory directly utilizes likelihood information assuming knowledge prior probability We extend likelihood functions uncertainty measure pertaining statistical inference problem This extension forming maximum likelihood methods deﬁnes likelihood set parameter values maximum likelihood elements set Our approach axiomatic The axioms considered similar spirit linear utility theory strictly different important aspects We bet ting behavior based likelihood probability This behavior satisﬁes stochastic dominance principle We prove representation theorem preference relation likelihood lotteries newly developed concept binary utility Applied statistical inference problem theory suggests new solution picks action maximizing expected qualitative utility This solution sandwiched Walds minimax solution Bayes solution terms information use demand It makes use uncertainty information ignored minimax solution require prior probability Bayes solution Appendix A Proofs lemmas theorems Proof Lemma 2 By Eq 15 Vyρ Vycid13 ρ iff Pρθ θ1 y Pρθ θ1 ycid13 By Eq 13 Pρθ θ1 y Pρθ θ1 ycid13 iff Likyθ1 Likyθ2 Likycid13θ1 Likycid13θ2 A1 Because maxLikyθ1 Likyθ2 maxLikycid13θ1 Likycid13θ2 1 4 cases consider Eq A1 excludes case Likyθ2 Likycid13θ1 1 For 3 remaining cases If Likyθ1 Likycid13θ1 1 Eq A1 holds iff Likyθ2 Likycid13θ2 b If Likyθ2 Likycid13 θ2 1 Eq A1 holds iff Likyθ1 Likycid13 θ1 c If Likyθ1 Likycid13θ2 1 Eq A1 holds iff Likyθ2 1 Likycid13 θ1 1 By Eq 9 Eq A1 holds iff Likyθ11 Likyθ20 cid11 Likycid13θ11 Likycid13 θ20 cid1 Proof Theorem 1 For v 0 1 let denote roots equations Vyρ v Vycid13 ρ v ρv ρcid13 v v If Likyθ11 Likyθ20 cid11 Likycid13 θ11 Likycid13θ20 Eq 16 Vyρv Vycid13ρv Therefore Vycid13ρcid13 v Vycid13 ρv Because Vycid13 ρ strictly increasing infer ρv ρcid13 v Since Vyρ Vycid13 ρ increasing P Vyρ cid1 v P ρ cid1 ρv P Vycid13 ρ cid1 v P ρ cid1 ρcid13 v P Vyρ cid1 v cid1 P Vycid13 ρ cid1 v This inequality means Vyρ D1 Vycid13 ρ v respectively Vyρv v Vycid13ρcid13 v Because ρv ρcid13 If 0 x 1 Vyx cid1 Vycid13 x assumption VyρD1Vycid13ρ violated Otherwise Eq 16 implies cid8 cid7 Likyθ11 Likyθ20 cid11 cid7 Likycid13θ11 Likycid13 θ20 cid8 cid1 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 159 Proof Lemma 3 We prove existence indifferent canonical lottery induction depth lottery trees For constant lottery depth 0 A4 sequence xi indifferent canonical lottery si Let assume xi si κi1x κir x 1 cid1 cid1 r A lottery depth 1 simple lottery If canonical lottery reﬂexivity canon ical lottery indifferent For simple lottery L π1x1 π2x2 πr xr A3 L L1 L1 π1s1 π2s2 πr sr L1 reduced canon ical lottery L2 L1 L2 follows Let write canonical lottery si form κi1x κi2x2 κir x κij 0 2 cid1 j cid1 r 1 By A2 L1 L2 L2 κ1x κ2x2 κr x κj maxπiκij 1 cid1 cid1 k Since κij 0 2 cid1 j cid1 r 1 κj 0 2 cid1 j cid1 r 1 Thus L2 canonical lottery By transitivity L L2 Suppose lottery depth greater n canonical lottery different For lottery L depth n 1 This lottery compound lottery consequences lotteries depth greater n Because induction hypothesis consequence L indifferent canonical lottery By substitutability L indif ferent compound lottery depth 2 turn indifferent canonical lottery induction hypothesis By transitivity L indifferent canonical lottery Finally canonical lottery indifferent given lottery Suppose canonical lotteries s1 s2 Lc s1 L s2 L By A1 s1 s2 But A5 possible s1 s2 cid1 Proof Theorem 2 Suppose cid9 satisﬁes axioms We exists function QU L U satisﬁes Eq 24 represents cid9 We construct func tion QU follows For canonical lottery deﬁne QUλx µx cid14λ µcid15 Obviously cid141 0cid15 cid140 1cid15 QUX For lottery L Lemma 3 exists unique canonical s L s set QUL QUs Obviously QU deﬁned By Eqs 9 cid18 QUscid13 That fact 18 canonical lotteries s scid13 s cid9 scid13 iff QUs gether Lemma 3 way QU deﬁned allow conclude QU represents cid9 Now QU satisﬁes Eq 24 Consider depthone lottery L π1x1 πr xr By A4 consequence xi lot tery si κi1x κir x Therefore QUxi cid14κi1 κir cid15 Consider lottery Lcid13 π1s1 π2s2 πr sr From A3 L Lcid13 Using A2 argument proof Lemma 3 Lcid13 indifferent canonical lottery s κ1x κr x canonical indifferent κl max 1cid1icid1r πiκil l 1 r A2 Therefore hand QUL QULcid13 QUs cid14κ1 κr cid15 On hand cid9 cid10 πicid14κi1 κir cid15 cid10 cid14πiκi1 πiκir cid15 cid9 cid10 πiQUxi cid9 max 1cid1icid1r max 1cid1icid1r cid14 πiκi1 max 1cid1icid1r Thus QUL max1cid1icid1r πiQUxi By induction lotterys depth cid14κ1 κr cid15 max 1cid1icid1r max 1cid1icid1r πiκir cid15 prove property lottery 160 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 Suppose cid9q represented QU satisﬁes Eq 24 cid141 0cid15 cid141 0cid15 cid18 QULcid13 We cid9q satisﬁes axioms A1 cid18 deﬁned U Eq 18 reﬂexive QUX L cid9q Lcid13 iff QUL A5 A1 satisﬁed relation complete transitive Let L π1L1 πiLi πkLk Lcid13 π1L1 πiLcid13 By deﬁnition cid9q means QULi QULcid13 πkLk As sume Li q Lcid13 Apply Eq 24 twice compound lotteries L Lcid13 We righthand sides identical So lefthand sides QUL QULcid13 equal By deﬁnition cid9q L q Lcid13 Thus A3 satisﬁed Let L π1L1 π2L2 πkLk Li κi1x1 κi2x2 κir xr 1 cid1 cid1 k Let assume QUxj cid14λj µj cid15 1 cid1 j cid1 r Apply Eq 24 Li L cid9 cid10 κij cid14λj µj cid15 cid9 cid10 cid14κij λj κij µj cid15 cid15 max 1cid1j cid1r κij µj max 1cid1j cid1r cid9 cid14 πi cid9cid14 κij λj max 1cid1j cid1r κij λj max 1cid1j cid1r max 1cid1j cid1r cid15cid10 κij µj cid15cid10 κij µj QULi max 1cid1j cid1r cid14 QUL max 1cid1icid1k max 1cid1icid1k cid14 πi max 1cid1j cid1r πi max 1cid1j cid1r cid9 κij λj πi max 1cid1j cid1r cid9 cid10 max 1cid1icid1k cid9 κij λj cid10 πi max 1cid1j cid1r cid10cid15 κij µj cid10cid15 max 1cid1j cid1r πiκij λj max 1cid1icid1k max 1cid1j cid1r πiκij µj cid15 max 1cid1icid1k cid14 max 1cid1icid1k cid14 max 1cid1j cid1r max 1cid1icid1k πiκij λj max 1cid1j cid1r max 1cid1icid1k πiκij µj Let consider simple lottery mentioned A2 Ls κ1x1 κr xr κj max 1cid1icid1k πj κij Apply Eq 24 Ls QULs max 1cid1j cid1r max 1cid1j cid1r cid14 cid9 cid10 κj cid14λj µj cid15 cid9cid14 max 1cid1j cid1r cid9 cid10 cid14κj λj κj µj cid15 cid15cid10 cid15 max 1cid1icid1k πj κij λj max 1cid1icid1k πj κij λj max 1cid1j cid1r Comparing expressions QUL QULs By deﬁnition cid9q L q Ls Thus A2 satisﬁed πj κij µj πj κij µj max 1cid1j cid1r max 1cid1icid1k max 1cid1icid1k Denote x x elements X QUx cid141 0cid15 QUx cid140 1cid15 By Eq 18 deﬁnition cid9q x cid9q x x cid9q x x X For canon ical lottery λx µx maxλ µ 1 Eq 24 QUλx µx maxλcid141 0cid15 µcid140 1cid15 maxcid14λ 0cid15 cid140 µcid15 cid14λ µcid15 Thus Eq 18 conclude A5 satisﬁed Finally x X let assume QUx cid14λ µcid15 By argument QUx QUλx µx By deﬁnition cid9q infer x q λx µx Thus A4 satisﬁed cid1 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 161 Proof Theorem 3 Let assume QULi cid14λi µicid15 1 2 3 If L1 L2 conclusion result substitutability Suppose L1 cid11 L2 This means λ1 cid2 λ2 µ1 cid1 µ2 strict relation Applying Theorem 2 cid4 cid3 λL1 µL3 cid4 cid3 λL2 µL3 cid14 cid14 cid15 maxλλ1 µλ3 maxλµ1 µµ3 cid15 maxλλ2 µλ3 maxλµ2 µµ3 QU QU So maxλλ1 µλ3 cid2 maxλλ2 µλ3 maxλµ1 µµ3 cid1 maxλµ2 µµ3 This means QUλL1 µL3 cid18 QUλL2 µL3 By representation theorem λL1 µL3 cid9 λL2 µL3 b L1 cid11 L2 cid11 L3 means λ1 cid2 λ2 cid2 λ3 µ1 cid1 µ2 cid1 µ3 indices 1 cid1 j cid1 3 λi λj µi µj We identify λ µ cid2 0 satisfying maxλ µ 1 λL1 µL3 cid11 L2 Since QUλL1 µL3 cid14maxλλ1 µλ3 maxλµ1 µµ3cid15 requirement satisﬁed maxλλ1 µλ3 λ2 maxλµ1 µµ3 µ2 If λ1 λ2 choosing λ 1 satisfy inequality Otherwise λ1 λ2 µ1 µ2 We choose λ 1 µ strictly positive small µµ3 µ2 Thus maxλµ1 µµ3 µ2 Similarly choose λcid13 µcid13 L2 cid11 λcid13L1 µcid13L3 cid1 Proof Lemma 6 We need Bayes risk δ P minimal δ rδ P cid1 rδ Substitute Eq 29 Eq 31 cid3 δy θ pθ yρθ rδ V cid17 cid17 cid4 Ω Y cid3 δy θ cid4 V pθ yρθ cid17 cid17 Y Ω A3 A4 cid17 It y Y cid3 cid4 apy θ pθ yρθ cid3 P y θ δ V V cid17 Ω Ω cid4 pθ yρθ cid1 cid17 Ω cid3 δy θ cid4 pθ yρθ V The inequality implication Eqs 33 34 cid1 References 1 Akaike Information theory extension maximum likelihood principle BN Petrox F Caski Eds Second International Symposium Information Theory Academiai Kiado Budapest 1973 p 267 2 M Allais The foundations positive theory choice involving risk criticism postulates axioms American School M Allais O Hagen Eds Expected Utility Hypotheses Allais Paradox Reidel Dordrecht 1979 pp 27145 The English translation Fondements dune Theorie Positive des Choix Comportant Risque et Critique des Postulats et Axiomes LEcole Americaine Econometrie Colloques Internationaux du Centre National la Recherche Scientiﬁque Paris vol XL 1953 pp 275332 3 V Barnett Comparative Statistical Inference edition Wiley New York 1999 162 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 4 D Basu I Ghosh Statistical Information Likelihood A Collection Critical Essays Dr Basu Lecture Notes Statistics Springer New York 1988 5 JO Berger RL Wolpert The Likelihood Principle second edition Lecture NotesMonograph Series In stitute Mathematical Statistics Hayward CA 1988 6 K Borch Utility stochastic dominance M Allais O Hagen Eds Expected utility hypotheses Allais paradox Reidel Dordrecht 1979 pp 193202 7 RI Brafman M Tennenholtz An axiomatic treatment qualitative decision criteria J ACM 47 3 2000 452483 8 DR Cox DV Hinkley Theoretical Statistics Chapman Hall London 1974 9 A Dempster A generalization Bayesian inference J Roy Statist Soc Ser B 30 1968 205247 discussion 10 D Dubois L Godo H Prade A Zapico On possibilistic decision model decision certainty casebased decision Internat J Uncertainty Fuzziness Knowledgebased Syst 7 6 1999 631670 11 D Dubois S Moral H Prade A semantics possibility theory based likelihoods J Math Anal Appl 205 1997 359380 12 D Dubois TH Nguyen H Prade Possibility theory probability fuzzy sets D Dubois H Prade Eds Handbook Fuzzy Sets Series Kluwer Academic Boston 2000 pp 344438 13 D Dubois H Prade Possibility theory basis qualitative decision theory Proceedings 14th International Joint Conference Artiﬁcial Intelligence IJCAI95 Montreal Quebec vol 2 Morgan Kauf mann San Mateo CA 1995 pp 19241930 ftpftpiritfrpubIRITRPDMPPTBQDTpsgz 14 AWF Edwards Likelihood Cambridge University Press Cambridge 1972 15 D Ellsberg Risk ambiguity Savages axioms Quart J Econ 75 4 1961 643669 16 PC Fishburn Lexicographic orders utilities decision rules A survey Management Sci 20 11 1974 14421471 17 PC Fishburn Nonlinear Preference Utility Theory The Johns Hopkins University Press Baltimore 1988 18 RA Fisher On mathematical foundation theoretical statistics Philos Trans Royal Soc London A 222 1922 309368 Reprinted JH Bennett Ed Collected Papers RA Fisher vol 1 University Adelaide 1971 19 PH Giang A decision theory nonprobabilistic uncertainty applications PhD thesis University Kansas Lawrence Kansas 2003 20 PH Giang PP Shenoy A qualitative linear utility theory Spohns theory epistemic beliefs C Boutilier M Goldszmidt Eds Uncertainty Artiﬁcial Intelligence Proceedings Sixteenth Con ference UAI2000 San Francisco CA Morgan Kaufmann San Mateo CA 2000 pp 220229 21 PH Giang PP Shenoy Statistical decisions likelihood information prior probabilities A Darwiche N Friedman Eds Uncertainty Artiﬁcial Intelligence Proceedings Eighteenth Con ference UAI2002 San Francisco CA Morgan Kaufmann San Mateo CA 2002 pp 170178 22 PH Giang PP Shenoy Two axiomatic approaches decision making possibility theory European J Oper Res 162 2 2005 450467 23 I Gilboa Expected utility purely subjective nonadditive probabilities J Math Econ 16 1987 6588 24 JY Halpern Reasoning Uncertainty MIT Press Cambridge MA 2003 25 NE Jensen An introduction Bernoullian utility theory I Utility functions Swedish J Econ 69 1967 163183 26 WCM Kallenberg Asymptotic Optimality Likelihood Ratio Tests Exponential Families Mathemati cal Centre Tracts vol 77 Mathematisch Centrum Amsterdam 1978 27 EL Lehmann G Casella Theory Point Estimation second edition Springer Texts Statistics Springer New York 1998 28 H Levy Stochastic dominance expected utility Survey analysis Management Sci 38 4 1992 555593 29 RD Luce H Raiffa Games Decision Wiley New York 1957 30 J Neyman ES Pearson On use interpretation certain test criteria purposes statistical inference 1 Biometrica 20A 1928 175240 In J Neyman ES Pearson Joint Statistical Papers University California Press 1967 PH Giang PP Shenoy Artiﬁcial Intelligence 165 2005 137163 163 31 WB Poland RD Shachter Three approaches probability model selection R Lopez Mantaras D Poole Eds Uncertainty Artiﬁcial Intelligence Proceedings Tenth Conference UAI94 Mor gan Kaufmann San Mateo CA 1994 32 R Sarin P Wakker A simple axiomatization nonadditive expected utility Econometrica 60 6 1992 12551272 33 D Schmeidler Subjective probability expected utility additivity Econometrica 57 3 1989 571587 34 G Schwarz Estimating dimension model Ann Statist 6 1978 461464 35 G Shafer A Mathematical Theory Evidence Princeton University Press Princeton NJ 1976 36 G Shafer Belief functions parametric models J Royal Statist Soc Ser B 44 3 1982 322352 37 P Smets The transferable belief model quantiﬁed belief representation DM Gabbay P Smets Eds Handbook Defeasible Reasoning Uncertainty Management System vol 1 Kluwer Dordrecht 1998 pp 267301 38 J von Neumann O Morgenstern Theory Games Economic Behavior second edition Princeton University Press Princeton NJ 1947 39 A Wald Statistical Decision Function Wiley New York 1950 40 P Walley Belief function representation statistical evidence Ann Statist 15 4 1987 14391465 41 L Zadeh Fuzzy set basis theory possibility Fuzzy Sets Systems 1 1978 328