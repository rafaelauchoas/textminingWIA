Artiﬁcial Intelligence 172 2008 300324 wwwelseviercomlocateartint Automatic scoring short handwritten essays reading comprehension tests Sargur Srihari Jim Collins Rohini Srihari Harish Srinivasan Shravya Shetty Janina BruttGrifﬂer Center Excellence Document Analysis Recognition CEDAR University Buffalo State University New York Amherst NY 14228 USA Received 14 September 2006 received revised form 27 June 2007 accepted 29 June 2007 Available online 24 July 2007 Abstract Reading comprehension largely tested schools handwritten responses The paper describes computational methods scoring responses handwriting recognition automatic essay scoring technologies The goal assign hand written response score comparable human scorer machine handwriting recognition methods high transcription error rates The approaches based coupling methods document image analysis recognition automated essay scoring Document imagelevel operations include removal preprinted matter segmentation handwritten text lines extraction words Handwriting recognition based fusion analytic holistic methods contextual processing based trigrams The lexicons recognize handwritten words derived read ing passage testing prompt answer rubric student responses Recognition methods utilize childrens handwriting styles Heuristics derived reading comprehension research employed obtain additional scoring features Results meth ods essay scoringboth based learning humanscored setare described The ﬁrst based latent semantic analysis LSA requires reasonable level handwriting recognition performance The second uses artiﬁcial neural network ANN based features extracted handwriting image LSA requires use large lexicon recognizing entire response ANN requires small lexicon populate features making practical current word recognition technology A testbed essays written response prompts statewide reading comprehension tests scored humans train evaluate methods Endtoend performance results far automatic scoring based perfect manual transcription demonstrating handwritten essay scoring practical potential 2007 Elsevier BV All rights reserved Keywords Automatic essay scoring Contextual handwriting recognition Reading comprehension Latent semantic analysis Artiﬁcial neural networks 1 Introduction Reading comprehension important component learning schools Tasks require students write texts ubiquitous levels schooling assessment lowperforming writers difﬁculty Corresponding author Email address sriharicedarbuffaloedu S Srihari 00043702 matter 2007 Elsevier BV All rights reserved doi101016jartint200706005 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 301 tasks For example recent New York State assessment fourth grade English language arts asked students write reading essay poem whales prompt clearly speciﬁed students use information texts read responses The test prompt responses follows Test Prompt Do think ﬁshing boats allowed waters whales swim Why Use details BOTH article poem support answer In answer sure state opinion explain reasons opinion support opinion information BOTH article poem Low Scoring Response They loud whale Because whale need swim die High Scoring Response I think ﬁshing boats allowed whales people hurt whale ﬁshing net whale eat ﬁsh ﬁshing net people throw spear They kill whale reason They hurt whale boat killed way That I think ﬁshing boats allowed whales Whereas second writer presents relatively logically connected error free response ﬁrst writer uses information minimally far extent necessary form skilled argument While electronically written responses standard college level entrance testing handwritten responses principal means statewide testing schools This issues early introduce keyboarding skills academic integrity closely spaced test stations network downtime testing Since approach handwritten essays reading comprehension evaluation efﬁcient reliable likely remain key component learning Writing hand primary means testing students state assessments Consider example New York State English Language Assessment ELA administered statewide grades 5 8 In reading test student asked read passage given Fig 1 grade 8 example respond prompts writing An example prompt How Martha Washingtons role First Lady different Eleanor Roosevelt Use information American First Ladies answer The completed answer sheets different students prompt given Fig 2 The responses scored human assessors sevenpoint scale 06 A rubric scoring given Table 1 This referred holistic rubricwhich contrast analytic rubric captures writing traits Assessing large numbers handwritten responses relatively timeconsuming monotonous task At time intense need speed enhance process rating handwritten responses main taining cost effectiveness The assessment source timely relatively inexpensive responsible feedback writing The paper describes ﬁrst attempt designing reading scoring analyzing handwritten essays large scale assessments provide assessment results feedback Success designing allow timely feedback students provide feedback education researchers educators There signiﬁcant practical pedagogical value computerassisted evaluation tests The task scoring reporting results assessments timely manner difﬁcult relatively expensive There intense need test later year purpose capturing student growth time meet requirement report student scores summer break The biggest challenge reading scoring handwritten portions largescale assessments From research viewpoint automated solution allow studying patterns handwritten essays laborious impossible For instance metrics obtained identifying difﬁculties struggling students having measuring repetition sections original passage identifying language constructs speciﬁc population The assessment problem welldeﬁned problem solution push forward existing technologies handwriting recognition automatic essay scoring A grand challenge artiﬁcial intelligence AI 302 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 Fig 1 Text passage read From New York English Language Arts assessment Grade 8 2001two pages story American First Ladies shown Fig 2 Sample answer sheets students ac based reading comprehension passage Fig 1 The human assigned scores essays scale 06 2 4 4 respectively program read chapter freshman physics textbook answer prompts end chapter 27 Our challenge way evaluate student responses handwritten Much AI research progressed quest solutions speciﬁc problems problem promises exciting S Srihari et al Artiﬁcial Intelligence 172 2008 300324 303 Table 1 Holistic rubric chart prompt How Martha Washingtons role First Lady different Eleanor Roosevelt 6 Understanding text Understanding similarities differences roles Characteristics ﬁrst ladies Complete accurate insightful Focused ﬂuent engaging 5 Understanding roles ﬁrst ladies Organized 4 Logical accurate Only literal understanding article 3 Partial Understanding Drawing conclusions roles ﬁrst ladies 2 Readable 1 Brief Not logical Repetitive Not thoroughly elaborate Organized Sketchy Limited understanding Understood sections Too generalized Weak Facts synchronization terms task use Solving problem promises reduce costs raise efﬁciency largescale assessments This interdisciplinary project involving distinct knowledge areas optical handwriting recognition OHR automatic essay scoring AES reading comprehension studies OHR ﬁrst viewed largely engineering enterprise concerning data input However challenges posed deciphering handwriting particularly children makes truly difﬁcult AI task AES topic involving computational linguistics prac tical solutions dealing noisy textual input calls new methods Reading comprehension studies conducted education researchers As successful AI project demonstrates working domain experts key developing methods heuristics The rest paper organized follows Section 2 brief review areas research handwriting recognition automatic essay scoring reading comprehension Choices designing different parts scoring described Sections 34 describing document analysis handwriting recognition aspects describing different scoring methods latent semantic analysis feature based classiﬁcation methods illustrated Grade 8 prompt described earlier Section 5 describes design evaluation aspects methods testbed consisting 300 handwritten responses Grade 8 prompt 205 responses Grade 5 prompt Section 6 discussion results 2 Previous work This project involves integrating knowledge methods areas reviewed 21 Handwriting recognition The ﬁrst step reading handwritten material scanned image answer sheet booklet page While computers indispensable tools Rs viz arithmetic writing use R reading emerging OHR involves processing steps form rule line removal lineword segmentation recognition individual words Handwriting recognition concerned transforming image handwritten text textual form A sur vey online called dynamic offline static optical handwriting recognition 24 While widely tablet PCs PDAs successful constrained domains postal addresses To distinguish types handwriting recognition offline case referred optical handwriting recognition OHR The higher complexity OHR stems lack temporal information complexity document analysis 304 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 Word segmentation The extraction word images page image requires preprocessing steps performed detecting eliminating extraneous information preprinted matter removing ruled lines margin lines Separating lines text separating individual words challenging task addressed context historical manuscripts 21 Within handwritten text ordering lines determined line words need segmented A reading unconstrained handwritten pages known PENMAN developed 31 developed CEDARFOX analysis handwritten documents forensic analysis 32 These systems tools grayscale binary thresholding rule line removal lineword segmentation There interactive user interfaces available analysis documents researchers The CEDARFOX research described Section 3 Word recognition Once word image isolated subjected tasks character recognitionif word reliably segmented charactersor segmentationfree word recognition Recognition characters words performed twostep process feature extraction followed classiﬁcation 3 Word spotting task directly ﬁnding key words document image 35 Here features handwritten keywords matched candidate word images It require segmentation characters requires set handwritten word prototypes Features raw image pixels shape descriptors Features character level called analytic recognition word level holistic recognition Handwritten word recognition typically involves lexicon possible words The task ranking lexiconwhich performed reasonably correctly segmented words small lexicons The process error prone missegmented text large lexicons words spelling errors Word recognition rates correctly segmented words range 70 95 lexicon sizes 20 Linguistic constraints Exploiting statistical dependencies words ﬁrst explored OCR domain 13 extended online handwriting 29 Statistical dependencies word tags corresponding parts speech POS words explored Handwriting interpretation Handwriting interpretation goaloriented task goal recognizing character word perfectly perform overall task accurate manner It involves basic handwriting recognition tools contextual information solve speciﬁc tasks signiﬁcant uncertainty speciﬁc components For instance domain postal addresses developed determining destination irrespective individual components correctly written 2033 The strategy recognize easily recognizable parts address ﬁrst case consists ZIP code street number These islands narrow lexicon choices street simpliﬁes task recognizing street The ZIP code constrained city state names The mutual constraints lead correct interpretation despite spelling errors mistakes illegibility Today 90 handwritten addresses United States interpreted OHR This triangulation useful recognition essay words constraints imposed certain words disambiguate illegible words Childrens handwriting Adapting methods OHR childrens handwriting unexplored frontier This attributable fact OHR general adult handwriting difﬁcult task Childrens handwriting hand easier recognize better formed character shapes However layout words spatially poorer words lines text merged creating signiﬁcant recognition ambiguity Also linguistic constraints recognition work spelling mistakes poorly formed sentence constructs 22 Automatic essay scoring AES Automated essay scoring topic research decades A limitation past work essays readable form A survey AES methods electronically represented essays Palmer et al 23 Project Essay Grade PEG 22 uses linguistic features multiple regression equation developed In Production Automated Essay Grading System grammar checker program identify words sentences software dictionary partofspeech tagger parser gather data Erater 4 uses combination statistical NLP techniques extract linguistic features Larkey 1998 implemented AES approach based text categorization techniques TCT A powerful approach AES based technique developed information retrieval community known latent semantic indexing Its application AES known latent semantic analysis LSA uncovers lexical semantic S Srihari et al Artiﬁcial Intelligence 172 2008 300324 305 links essay gold standard 18 A matrix essay built transformed algebraic method singular value decomposition SVD approximately reproduce matrix reduced dimensional matrices built topic domain Using SVD new relationships words documents uncovered existing relationships modiﬁed represent signiﬁcance Using LSA similarity essays measured despite differences individual lexical items A preliminary version LSAbased approach handwritten essay scoring given 34 The Intelligent Essay Assessor IEA welldeveloped widely LSA based machinescoring method 17 It incorporates statistical variables allow return diverse differentiated scores tutorial feedback coherence wordchoice plagiarism IEA use goldstandard It uses variant nearestneighbor algorithm It compares scored essay 100200 essays previously scored expert human readers It ﬁnds small set thereof typically 10 similar semantic content new essay applies algorithm predict score judges given new essay Thus directly mimicking humans It correlates closely human raters human raters correlate 17 Hybrid systems combine word vector similarity metrics structurebased linguistic features ETS score essays GMAT TOEFL GRE exams One widelyused Erater 4 uses simpler form LSA called content vector analysis CVA Erater trained 300 handgraded essays question prompt A predictive statistical model developed set scored essays beginning set 5070 features stepwise linear regression select features necessary assign score 16 Erater uses speech POS tagging shallow parsing identify subjunctive auxiliary verbs complex clause types complement inﬁnitive subordinate clauses discourse cue words summary example Discourse cue words individual features way divide essays labeled discourse segments The score combination overall score scores discourse segment Additional features include presence words like possibly presence sentenceinitial inﬁnitive phrases discoursedeictic words like To evaluate content word choice Erater uses vectors word frequencies The training set collapsed categories scoring value discourse segment scored comparing categories The mean argument scores adjusted number arguments penalize shorter essays Analysis essays based linguistic features value scoring providing student feedback Some features general vocabulary passage related vocabulary percentage difﬁcult words percentage passive sentences rhetorical features usage conjunctions pronouns punctuations connectedness This approach employed automated Japanese Essay Scoring System Jess 14 ﬁnal weighted score calculated penalizing perfect score based features recognized essay Crater offers automated analysis conceptual information shortanswer free responses 19 Most features advanced technologies Erater Crater depend strongly accurately representing word sequence Thus advanced scoring technologies expected work output handwriting recognition Simpler methods baseline CVA elaborationsmodiﬁcations LSA featurebased neural networks feasible ones 23 Reading comprehension In AI project domain knowledge key success Studies ﬁndings reading comprehension pertinent context automated tools useful obtain heuristics automatic scoring meaningfully structure inputs outputs evaluate performance Reading writing involve processes construction integration connection 81628 Literacy achieved tools construct integrate connect meanings appropriate cultural settings Studies reading comprehension guides writing reading called thinksheets They effective tools guiding writing processes struggling students 671026 Thinksheets accompanying teacher feedback positive impact measures writing reading internal external connectedness conventions Internal connectedness refers coherence cohesion essay external connectedness refers representation ideas reading writing conventions refer spelling mechanics writing 306 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 Human analysis prototypical automated analysis samples 5th grade students measures reading writing achievement shows improved student performance time Essays written midpoint school year demonstrate higher mean scores overall quality internal external connectedness conventions The second key ﬁnding pertains internal connectedness At end academic year substantial growth internal connectedness seen ability signal ambiguity relations clauses logical causal coordinate subordinate The mean score internal connectedness rose M 170 M 244 M 356 While substantially increasing scores internal connectedness students able maintain higher quality scores reached slightly higher values automated analysis essay length conventions decreasing scores overlapping strings words literary selection written compared scores achieved midpoint year Their performance endoftheyear assessment suggests new developmental stage characterized increased scores internal connectedness suggesting students greater control language rhetoric reliance direct borrowing copying reading compared midpoint year Another relevant work measuring coherence The Cohmetrix 11 uses set 200 features computes series scores meant indicate coherent given text reader This accomplished measuring internal cohesiveness 50 axes LSA model mental representation reader particular level K12 college text compared The assumption highknowledge readers beneﬁt gaps texts internal cohesion necessitating inference previous textual cues andor readers world knowledge Cohmetrix determine appropriate text reader particular level The Cohmetrix designed reading passages student responses 3 Analysis recognition handwritten responses The process analyzing handwritten responses begins answer sheets scanned The standard prac tice handwriting recognition scan gray scale images resolution 300 pixels inch Several preliminary image processing steps ﬁrst needed They include extracting foreground background eliminating noninformative material rule lines printed markings determining presence hand written words reading sequence Several operational modules useful processing scanned essays viz ruleline removal textline segmentation word segmentation word recognition word spotting contextual word recognition brieﬂy described 31 Ruleline removal Guide lines provided answer sheets lines handwriting straight However come way automated recognition removed image The need ruleline removal eliminated lines printed ink invisible scanner Since present todays answer sheets dealt Line removal algorithms attempt remove lines unduly breaking handwriting One process detects straight lines Hough transform 9 The process line removal illustrated Fig 3 The method basically looks pixel counts high direction polar coordinate repre sentation image coordinates eliminates pixels image While works printed straight lines guidelines introduced writer cause difﬁculties imperfections 32 Text segmentation The task extracting word images divided segmentation lines words handwritten text division tasks possible Line segmentation difﬁcult task lines overlap The result line segmentation overlap lines shown Fig 4a The algorithm line segmen tation based computing horizontal projection proﬁle vertical strips document image The valleys projection ﬁle indicate presence line gaps When components ambiguous probability belongs line employed When lines overlapping method cutting writing employed 1 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 307 Original image b Image guidelines removed Fig 3 Ruleline removal scanned grayscale image b rulelines detected Hough transform removed Word segmentation Gaps words segment words text Several features perform classiﬁcation gap true word gap Examples features convex hull distance components widths heights components sizes current neighboring gaps To determine gap true gap features taken account current document solely rely learning set The result word segmentation performed artiﬁcial neural network 15 shown Fig 4b 33 Word recognition Word recognition task ranking lexicon word choices based input word image The shapes word vary signiﬁcantly The method word recognition adopted combined results processes analytic recognizer holistic recognizer The based character shapes uses global shapes words The results methods combined weighting scheme Analytic recognition This method relies segmenting words characters recognizes aid lexicon Examples handwritten word Eleanor student essays Fig 5 different letter formations interletter spacings For lexicon entry word image divided corresponding number characters potential character sent character recognizer Word recognition relies lexicon wordswhich derived sources text passage prompt rubric sample responses The result recognition shown Fig 6 There sources compiling lexicon text passage prompt answer rubric samples student writing As illustration lexicon compiled reading passage Grade 8 prompt shown Fig 7 The lexicon increased accommodate larger student vocabulary However performance word recognizer decreases increasing lexicon size Holistic recognition word spotting The second method uses known prototypes handwritten words matches segmented words scanned image This ﬂexible template matching method known word spotting Given scanned corpus handwritten responses training prototype templates obtained words These templates matched word query document process called word spotting The number templates 308 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 Lines text b Words text Fig 4 Segmentation text lines words extracted lines text b extracted words Fig 5 Samples handwritten Eleanor handwritten responses available depends training set available Examples templates derived 150 student responses shown Fig 8which template word remarkable ﬁve templates equal The word spotting algorithm based extracting set 1024 binary features representing shape word image The shapes compared correlation similarity measure 35 Each prototype word image matched word essay results ranked according similarity An example matching prototype words essay shown Fig 9 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 309 Fig 6 Word recognition results words highest conﬁdence superimposed corresponding word images Fig 7 Lexicon 276 unique words American First Ladies reading passage Combining analytic holistic recognition results The ﬁnal output word recognition obtained combining individual distance values returned characterbased word recognition word spotting methods word lexicon An optimal weighting scheme distance values simple neuron classiﬁer inputs corresponding distance values single output specifying probability input corresponds distances non matching word The distance values noted random choices matching nonmatching words sample essays optimal weights distances learnt gradient descent algorithm The ﬁnal automatic word recognition results obtained sorting sum weighted distance values ascending order Word phrase spotting analytic recognition important tool words recognized The presence key phrases image feature based approach scoring 310 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 Fig 8 Word templates templates words shown Fig 9 Word spotting query phrase returns images choices locations Transcript mapping Since wordspotting requires way obtaining prototype word images method transcription sample answer essays 12 As example following transcript handwritten essay shown Fig 3 Lady Washington role hostess nation Its different Lady Washington speaking nation Anna Roosevelt speaking people ran wer travet president It automatically mapped image resulting transcriptmapped image shown Fig 10a Since transcript mapping gets 85 words right method correcting results needed An interactive tool performing correction task shown Fig 10b Here cursor automatically positioned word image user types correct truth word S Srihari et al Artiﬁcial Intelligence 172 2008 300324 311 Transcript mapped image b Tool entering word truth Fig 10 The transcript handwritten essay associate word truth word image transcript mapped image b interactive tool correcting transcript map 34 Contextual postprocessing A trigram model based approach correct errors word recognition The set unique words obtained sample essays forms lexicon automatic word recognition The transition probability pair words word lexicon calculated sample essays The automatic word recognizer outputs distance words lexicon indicates conﬁdence level hand written word answer document similar lexicon The word recognizer returns word distance recognized word result words wrongly recognized So lexicon words m scores segmented word images handwritten answer document considered error correction This based assumption actual word recognized m choices With data Viterbi trellis T states built T corresponds number segmented handwritten words passage Thus trigram approach T number words answer document word position t depends words position t 1 t 2 Given automatic word recognition handwritten answers based lexicon possible recognize words students vocabulary lexicon But advantage possible overlap strings words sure sequence words common students answer sample essays recognized correctly Trigram language model interpolated KneserNey smoothing A trigram language model create transition matrix sample essays This matrix keeps track transition probabilities previous words actual passage For example If Eleanor Roosevelts role combination P roleEleanor Roosevelts P Eleanor Roosevelts roleP Eleanor Roosevelts The trigram bigram unigram counts sample essays insufﬁcient accurate measure transition probabilities data sparseness Smoothing increases low probability values like zero proba bilities decreases high probabilities increasing accuracy model There smoothing techniques 5 interpolated KneserNey smoothing perform speech recogni tion perplexity metric The interpolated KneserNey smoothing interpolates trigram model bigram unigram models ﬁxed discount subtracted nonzero count This technique ensures unigram bigram counts word proportional number occurrences wordbigram instead depends number different contexts wordbigram follows In model probability pwiwi1 win1 frequency word wi occurs given previous n words wi1 win1 given cid2 wiwi1 in1 cid3 pKN maxcwi cid4 in1 D 0 cwi in1 cid4 wi D cwi in1 cid2 wi1 in1 cid3 pKN cid2 wiwi1 in2 cid3 N1 1 wi 312 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 n trigram model 3 c count number times ngram wi in1 occurs D absolute discount value set n1n1 2n2 n1 n2 total number ngrams exactly counts respectively cid2 wi1 2 notation N1 meant evoke number words counts evoke free variable summed cid2 wi1 in1wi wi c in1 N1 0 cid7cid5 cid5 cid5 cid5 cid6 cid3 cid3 Viterbi decoding A second order Hidden Markov Model infer words passage The segmented handwritten words represent observed states actual words lexicon represent hidden states The m results output word recognition segmented handwritten word possible hidden states time step The state probabilities time step obtained distance values returned automatic word recognition The transition probabilities word given words previous time steps obtained smoothing technique described previously Second order Viterbi decoding infer words passage It evaluates probabilities partial observation sequence ending time t transition pair consecutive states t 1 t It stores previous state time t 2 best probability vector outputs likely sequence words The partial probabilities state particular word pair given cid2 αij t 1Tij k αj kt P st1 j st k O1t max cid3 Akyt 3 joint probability having j hidden variable step t 1 k step t observing O1t time steps 1 t Here s refers hidden state recognized character T transition probability A emission probability t current time step This expressed terms α time t 1 Tij k probability transitioning characters ij k similar trigram model Akyt emission probability hidden state k emitting observed yt time step t The state corresponding highest probability likely word sequence Word segmentation errors lead erroneous sequences handled adding null string list m possible states time step This handle cases small word segmented different word likely sequence probably identify segment null string correct word identiﬁable remaining segmented word The transition probabilities form P st st1 φ st2 P st st2 The resulting output sequence words scoring process Example trigram processing An example essay postprocessing given The sample essay lexiconbased word recognition wordspotting combination lady washingtons role hostess nation different lady washingtons speeches martha taylor roosevelt meetings people vote polio president The ﬁnal result contextual processing trigram model m 15 lady washingtons role hostess nation different george washingtons different nation eleanor roosevelt people ladies late travel president S Srihari et al Artiﬁcial Intelligence 172 2008 300324 313 While semantics text garbled cases number word errors fewer trigram processing shown underlined parts While errors recognized text effect scoring true measure performance 4 Automatic scoring methods When OHR method produces reasonable number correctly recognized words textbased approach The LSA approach chosen depend heavily word sequences methods expected robust word recognition errors The implementation uses nearest neighbor approach described 17 A second approach scoring chosen different types features semantic imagebased The features assign score artiﬁcial neural network Both approaches need availability training corpus The training corpus consists humanscored answer documents In training phase parameters learnt set humanscored samples In testing phase parameters scoring 41 Latent semantic analysis approach The LSA method implemented core approach fullﬂedge LSA The ﬂow processes LSA implementation shown Fig 11 Fig 11 Operational steps latent semantic analysis 314 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 After words scanned answer documents recognized OHR resulting word sequences written text ﬁles These text ﬁles preprocessed AES include following steps Removing punctuation special characters b Converting upper case lower case generalization c Stop word removalremoving common words occur signiﬁ importance d Stemmingmorphological variants words similar semantic interpretations stemming algorithm reduce word stem root form The algorithm 25 uses technique called sufﬁx stripping explicit sufﬁx list provided condition sufﬁx removed replaced form stem word common variations For example word reading sufﬁx stripping reduced read The underlying semantics training corpus extracted LSA use external knowledge The method captures variations term choices variations answer document meanings related However consideration order occurrence words This implies students different words convey message LSA capture corelation documents This LSA depicts meaning word average connotation documents occurs It similarly judge correctness answer document average measure correctness words contains Mathematically explained simultaneous representation answer documents training corpus points semantic space initial dimensionality order number terms document This dimensionality reduced optimal value large represent structure answer documents small facilitate elimination irrelevant representations The answer document graded placed reduced dimensionality semantic space large termbased similarity document training corpus determined measuring cosine angle documents origin A good approximation score human score heavily depends optimal reduced dimen sionality This optimal dimension related features determine term meaning derive hidden correlations terms answer documents However general method determine optimal dimension open research problem Currently brute force approach adopted Reducing dimensions omitting inconsequential relations retaining signiﬁcant ones A factor analysis method Singular Value Decomposition SVD helps reduce dimensionality desired approximation The ﬁrst step LSA construct t n termbydocument matrix M entries frequencies SVD twomode factor analysis decomposes rectangular matrix matrices 2 The SVD rectangular matrix M deﬁned M T SD cid3 4 prime cid3 indicates matrix transposition M rectangular term document matrix t rows n columns T t m matrix describes rows matrix M left singular vectors derived orthogonal factor values D n m matrix describes columns matrix M right singular vectors derived orthogonal factor values S m m diagonal matrix singular values T S Dcid3 matrix multiplied M reconstructed m rank M mint n To reduce dimensionality value k matrix S delete m k rows columns starting contain smallest singular value form matrix S1 The corresponding columns T rows Dcid3 deleted form matrices T1 Dcid3 1 respectively The matrix M1 approximation matrix M reduced dimensions follows M1 T1S1D cid3 1 5 Standard algorithms available perform SVD To illustrate documentterm matrix constructed 31 essays American First Ladies example shown Figs 1 2 given Table 2 Since corpus contains 31 documents 154 unique words M dimensions t 154 m 31 The ﬁrst principal components plotted Fig 12 The principal components signiﬁcant dimensions term document matrix shown Table 2 applying SVD This representation documents semantic space The similarity documents semantic space measured cosine angle documents origin S Srihari et al Artiﬁcial Intelligence 172 2008 300324 Table 2 An example 154 31 term document matrix M Mij frequency ith term j th answer document D4 TermDoc D8 D1 D2 D6 D7 D5 D3 T1 T2 T3 T4 T5 T6 T7 T8 T9 T154 0 2 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 3 3 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 2 2 0 1 2 0 1 0 0 1 1 0 0 0 0 0 0 315 D31 0 2 1 0 0 0 0 0 0 Fig 12 Projected locations 50 answer documents twodimensional plane Data preparation phase The following steps performed training phase 1 Answer documents preprocessed tokenized list words termsusing document pre processing steps described Section 31 2 An Answer Dictionary created assigns unique ﬁle ID answer documents corpus 3 A Word Dictionary created assigns unique word ID words corpus 4 An index word ID number times occurs word frequency 31 documents created 5 A TermbyDocument Matrix M created index Mij frequency ith term j th answer document Training validation phases A set human graded documents known training set determine optimal value k employing leave cross validation technique Each queries passed validation query vectors compared remaining documents training corpus The following steps repeated document 1 A vector term frequencies query document selected validation query vector Q 2 Q added 0th column matrix M matrix Mq 316 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 3 SVD performed matrix Mq T SDcid3 matrices 4 Steps 510 repeated dimension values k 1 mint m 5 Delete m k rows columns S matrix starting smallest singular value form matrix S1 The corresponding columns T rows Dcid3 deleted form matrices T1 Dcid3 6 Construct matrix Mq1 multiplying matrices T1S1Dcid3 1 7 The similarity query document x 0th column matrix Mq1 docu ments y training corpus subsequent columns matrix Mq1 determined cosine similarity measure deﬁned 1 respectively CosineSimilarity 6 cid4 n i1 xiyi cid4 n i1 yi cid8cid4 n i1 xi 8 The training documents highest similarity score compared query answer documents selected human scores associated documents assigned documents question respectively 9 The mean difference LSA graded scores assigned query human grader calcu lated dimension queries 10 Return step 4 11 The dimension mean difference selected optimal dimension k testing phase Testing phase The testing set consists set scored essays training validation phases The termdocument matrix constructed training phase value k determined validation phase determine scores test set 42 Featurebased approach An alternative approach automatic essay scoring extract set features essay Given set human scored essays features derived essays classiﬁer trained associate feature values score Ideally features shown effective studies reading comprehension described Section 23 Some features computed transcription essay relevance score number words ii number sentences iii average sentence length iv essay length Others com puted information extraction based approach iv number verbs v number nouns vi number noun phrases vii number noun adjectives 30 In addition features derived answer rubric based connectivity analysis concepts connected essay 8 These include viii count use ix count bigramstrigrams reading passage example Martha Washington question number mentions Washingtons role number mentions different x uniquely words Once features essay computed remaining task assign particular combination features particular score There methods implementing classiﬁer based features simple artiﬁcial neural network ANN The input nodes correspond features output nodes correspond possible scores The design ANN features described hidden nodes shown Fig 13 The ANN trained learn weights connections network set scored responses While feature set useful typed manuallytranscribed text case handwritten input feature set simpler difﬁculty computing The modiﬁed set features number words automatically segmented ii number lines iii average number character segments line iv count Washingtons role automatic recognition v count differed different automatic recognition vi total number character segments document vii count automatic recognition An example handwritten response Martha Washington prompt ANN features shown Fig 14 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 317 Fig 13 Artiﬁcial neural network score handwritten essays speciﬁc essay Examples phrases features Prompt 1Washingtons role different Prompt 2Nechitas paintings Fig 14 Example handwritten response Martha Washington prompt ANN features Information extraction features An important role played information extraction IE features IE provides sentence In addition relationships entities entity proﬁles including modiﬁers descriptions hostess nation identiﬁed An example result IE processing student essay given Fig 15 This output screen Semantex engine shows Marta Washington detected person entity ii Eleanor Roosevelt coreference person To handle spelling recognition errors proﬁles Martha Washington Marta Washington merged noting spelling semantic similarities 5 Evaluation testbed performance The dataset design evaluation methods described given Two sets prompts corre sponding responses Grade 8 Grade 5 1 Prompt 1 Grade 8 The student required read American First Ladies Fig 1 respond writing prompt How Martha Washingtons role First Lady different Eleanor Roosevelt There total 300 handwritten responses prompt The score range 16 indicated holistic rubric Table 1 2 Prompt 2 Grade 5 The student required read passages titled The Languages Art A Piece Art Fig 16 concerned child artist Alexandra Nechita second transcript 318 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 Fig 15 Information extraction result processing student essay Semantex The lower righthand pane shows essay processed Marta Washington highlighted The lefthand pane shows partial token list gives syntactic parse semantic features Marta Washington identiﬁed group G The righthand pane shows proﬁle Marta Washington identiﬁed noun phrase named entity tag person different Eleanor Roosevelt interview Nechita The test prompt Write newspaper article encouraging people attend art Alexandra Nechita showing paintings Use information BOTH articles read In article sure include Information Alexandra Nechita ii Different ways people ﬁnd art interesting iii Reasons people enjoy Alexandra Nechitas painting There total 205 handwritten responses prompt The scoring range 14 Ground truth scoring project created having handwritten response scored education researchers There agreement point 95 cases prompt 1 96 cases prompt 2 For small number cases disagreement greater point agreement achieved reading The ﬁnal agreedupon score referred gold standard S Srihari et al Artiﬁcial Intelligence 172 2008 300324 319 Fig 16 Two text passages reading comprehension test Grade 5 second interview transcript Ground truth recognition project created having handwritten responses manually transcribed MT text Any spelling mistakes transcribed verbatim Having MT responses allows different approaches compared effect scoring OHR errors The handwritten responses divided training test sets For ﬁrst prompt corpus divided 150 training 150 testing samples equal numbers score For second prompt corpus divided 103 samples training 102 testing approximately equal number samples score 51 Training data LSA Three textual sources build vocabularies learning phase LSA 1 Prompt 1 Grade 8 vocabulary 150 300 responses words reading passage 2 Prompt 2 Grade 5 vocabulary 103 205 responses words reading passages 3 Text book passages long general passages text books Grade 5 Grade 8 This set scoring merely increase vocabulary LSA The total number terms combining corpora 2078 52 OHR performance For ﬁrst prompt lexicon OHR consisted words 150 training samples size 454 The lexicon number word image templates available word shown Fig 17 This lexicon larger 276 words passage shown Fig 7 The word recognition rate combining analytic holistic recognition results trigram contextual processing 57 For second prompt fullﬂedged OHR This OHR results poorer lower Grade 5 students Causes poor handwriting recognition errors line segmentation word segmentation lexicon size Thus LSA method depends words tested conjunction OHR 320 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 Fig 17 Lexical words use OHR responses prompt 1 Compiled 150 student responses 454 words word counts shown parentheses While ANN method IE features presence key phrases spotted ANN testing Such wordsphrases spotted image based method word spotting described Section 33 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 321 Table 3 LSA performance differences human automaticallyassigned scores Diff cid2 1 Score range Mean diff Diff 0 Diff cid2 2 Diff cid2 3 Diff cid2 4 Diff cid2 5 Prompt 1 MT Prompt 1 OHR Prompt 2 MT 16 16 14 135 158 096 28 25 31 64 58 79 83 75 93 92 87 100 97 96 100 100 53 Scoring performance Both LSA featurebased ANN approaches evaluated The scenarios manually tran scribed LSA ii OHR LSA iii manually transcribed ANN iv OHR ANN Each scenarios compared gold standard humanscored responses The cases evaluated test beds prompts 1 2 mentioned exception OHR LSA prompt 2 extreme poor word recognition It important mention ﬂexibility ANN respect LSA method The LSA method depends entire set words handwritten response recognized requires large lexicon word recognition It known fact larger lexicon implies poorer word recognition performance additionally handwritten responses prompt 2 grade 5 poorer legibility prompt 1 grade 8 On hand ANN method require entire handwritten response recognized requires count occurrences phrases useful making features ANN Hence lexicon phrases need recognized resulting better performance word recognition The performance scenario compared random guess score assigning possible scores 16 prompt 1 14 prompt 2 randomly response The average difference random score gold standard prompt 1 203 prompt 2 125 This evaluated uniform distribution model random score expected mean difference calculated analytically avoiding need statistical tests signiﬁcance Any useful automatic method smaller difference LSA performance The ﬁrst set experiments performed LSA method scoring Separate training validation phases conducted MT OHR essays For MT optimal value k best dimension determined 47 prompt 1 213 prompt 2 For OHR essays corresponding values prompt 1 k 50 Table 3 summarizes differences humanassigned scores goldstandard automatically assigned scores based MT prompt 1 ii automatically assigned scores based OHR prompt 1 iii automati cally assigned scores based MT prompt 2 The mean differences percentiles shown The interpretation cell entry row 1 column 4 prompt 1 machine transcription humanassigned automatically assigned scores differed 1 64 time Note LSA prompt 2OHR attempted poor word recognition The LSA method OHR performs signiﬁcantly better random guess It demonstrates robustness OHR errors ANN performance A second set experiments ANN method scoring performed manual transcription OHR The ANN score response compared human score difference determined With manual transcription MT mean difference ANN human scores prompt 1 test 150 cases 079 ANN scores differed human scores 1 82 cases With OHR mean difference human ANN scores 102 In case 71 responses assigned score cid2 1 true score For prompt 2 mean difference 102 responses MT OHR 066 078 respectively Table 4 summarizes results 322 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 Table 4 ANN performance differences human automaticallyassigned scores Diff cid2 1 Score range Mean diff Diff 0 Diff cid2 2 Diff cid2 3 Diff cid2 4 Diff cid2 5 Prompt 1 MT Prompt 1 OHR Prompt 2 MT Prompt 2 OHR 16 16 14 14 079 102 066 078 49 33 44 39 82 71 89 82 95 94 100 100 99 99 100 100 100 100 100 100 Fig 18 Differences human automaticscores prompts 1 2 Results shown random score assignment ii latent semantic analysis LSA iii artiﬁcial neural network NN For case mean differences human scores shown LSAOHR prompt 2 absent poor word recognition 54 Comparison LSA ANN The ANN numbers Table 4 clearly better LSA numbers Table 3 The average differences gold standard human scores methods prompts shown sidebyside bar chart Fig 18 The differences human scores randomly assigned scores shown With manual transcription corresponds perfect near perfect OHR scoring performance better actual OHR Also ANN performed better LSA In particular ANN effectively scenarios OHR poor LSA method employed case prompt 2 The ANN approach need entire handwritten response recognized certain wordsphrases populate features The robustness ANN method uses features contentindependent words sentences average sentence length contentdependent count phrases response connectors nouns verbs In fact ANN method difference unity human score In testing practice scores differ score response Thus ANN method passes test useful scorers practical scenario However caveats concerning comparison LSA ANN First conducted limited testing scenario involving prompts Second features ANN coachable test taker instructed use certain phrases produce certain length response Finally LSA method described trained small set textual passages In practice LSA systems trained large general corpus text encyclopedia plus training essays use 300 SVD dimensions opposed 47 213 experiments described S Srihari et al Artiﬁcial Intelligence 172 2008 300324 323 6 Summary discussion Reading comprehension important learning task children It commonly tested reading passage test prompt requires composition handwritten essays Handwriting continues standard method providing responses opposed online composition issues academic integrity downtime questions early introduce keyboarding skills Given advances technologies automatic essay scoring handwriting recognition methods automatic scoring handwritten essays explored The recognition solution contend standard difﬁculties recognizing handwriting writing skills children The task involves integrating methods different areas cognitive science viz imagespatial reasoning computational linguistics Contextual information crucial handwriting recognition available abundantly presence reading passage prompt potentially scoring rubric sample responses The limited vocabulary language constructs school scenario positive factor automatic methods However poor writing skills spelling errors challenge Scoring methods evaluated research LSA featurebased approach The LSA approach proven work textual input However errorfree transcription handwritingtotext reached current handwriting recognition technology The featurebased approach alternative scoring solution use variety inputs including imagelevel features textual features features computed information extraction techniques textual input Endtoend results testbed handwritten essays different prompts LSA featurebased methods promise The featurebased methods usable recognition rates poor Moreover scores point human scored essayswhich measure scoring acceptability State art essay scorers ETSs erater Persons IEA achieve agreement score point 90 essays While featurebased method appears perform better LSA partial recognition results available fair test LSA practice trained large text inputs Also featurebased methods need user input specifying key phrases needed LSA Finally surface features featurebased method coachable Despite errors word recognition scoring performance promising testing limited prompts As handwriting recognition applications evaluation based word recognition rates terms overall application performance acceptable The phenomenon observed postal address reading goal read word correctly achieve correct overall sortation determine ZIP 4 Code The holistic scoring approaches need extended analytic scoring attempt quantify idea development organization cohesion style grammar usage conventions Such approaches useful assessing responding meaningfully writing students monitor student progress provide feedback guide integrated reading writing instruction Languagebased methods likely play important role scoring recognition Information extraction techniques assist frontend handwriting recognition backend essay scoring References 1 M Arivazhagan H Srinivasan SN Srihari A statistical approach segmentation scanned handwritten documents Document Recog nition Retrieval XIV Proceedings SPIE San Jose vol 6500 2007 pp 6500T16500T11 2 R BaezaYates B RibeiroNeto Modern Information Retrieval New York AddisonWesley 1999 3 R Bozinovic SN Srihari A multiresolution perception approach cursive script recognition Artiﬁcial Intelligence 33 2 1987 217255 4 J Burstein The Erater scoring engine Automated essay scoring natural language processing MD Shermis Y Burstein Eds Automated Essay Scoring A CrossDisciplinary Perspective Lawrence Erlbaum Associates Inc Hillsdale NJ 2003 5 SF Chen J Goodman An empirical study smoothing techniques language modeling A Joshi M Palmer Eds Proceedings ThirtyFourth Annual Meeting Association Computational Linguistics Morgan Kaufmann Publishers San Francisco 1996 pp 310 318 6 J Collins Strategies Struggling Writers Guilford New York 1998 7 J Collins GV Godinho Help struggling writers Learning Disabilities Research Practice 11 1996 177182 8 JL Collins J Lee J BruttGiﬂer J Fox T Madigan E Vosburgh The writing intensive reading comprehension study Technical Report University Buffalo June 2006 9 RO Duda PE Hart Use Hough transform detect lines curves pictures Communications ACM 15 1972 1115 324 S Srihari et al Artiﬁcial Intelligence 172 2008 300324 10 CS Englert Teaching written language skills P Cigilka W Berdine Eds Effective Instruction Students Learning Difﬁculties Allyn Bacon Boston MA 1995 pp 304343 11 AC Graesser DS McNamara MM Louwerse Z Cai Cohmetrix Analysis text cohesion language Behavior Research Methods Instruments Computers 36 2004 193202 12 C Huang SN Srihari Mapping transcripts handwritten text Proceedings 10th International Workshop Frontiers Handwrit ing Recognition LaBaule France Universite Rennes 2006 pp 1520 13 JJ Hull Incorporation Markov model syntax text recognition algorithm Proceedings Symposium Document Analysis Information Retrieval 1992 pp 174183 14 T Ishioka M Kameda Automated Japanese essay scoring Jess Proceedings 15th International Workshop Database Expert Systems Applications 2004 15 G Kim SN Srihari A segmentation recognition strategy handwritten phrases Proceedings International Conference Pattern Recognition Vienna Austria IEEE Computer Society Press 1996 pp D510D514 16 W Kintsch Comprehension A Paradigm Cognition Cambridge University Press Cambridge England 1998 17 T Landauer D Laham P Foltz Automated scoring annotation essays Intelligent Essay Assessor Automated Essay Scoring A CrossDisciplinary Perspective Lawrence Erlbaum Associates Inc Hillsdale NJ 2003 18 TK Landauer PW Foltz D Laham An introduction latent semantic analysis Discourse Processes 25 1998 259284 19 C Leacock M Chodorow Crater Scoring shortanswer questions Computers Humanities 37 4 2003 389405 20 U Mahadevan SN Srihari Parsing recognition city state ZIP codes handwritten addresses Proceedings Fifth International Conference Document Analysis Recognition ICDAR Bangalore India IEEE Computer Society Press 1999 pp 325328 21 S Nicolas T Paquet L Heutte Complex handwritten page segmentation contextual models Proceedings International Workshop Document Image Analysis Libraries DIAL Lyons France IEEE Computer Society Press 2006 pp 4657 22 EB Page Computer grading student prose modern concepts software Journal Experimental Education 62 1961 127142 23 J Palmer R Williams H Dreher Automated essay grading applied ﬁrst year university subjecthow better Informing Science June 2002 12211229 24 R Plamondon SN Srihari Online offline handwriting recognition A comprehensive survey IEEE Transactions Pattern Analysis Machine Intelligence 22 1 2000 6384 25 MF Porter An algorithm sufﬁx stripping Program 14 3 1980 130137 26 T Raphael BW Kirschner CS Englert Acquisition expository writing skills J Mason Ed Reading Writing Connections 1988 27 R Reddy Three open problems Artiﬁcial Intelligence Journal ACM 50 1 2003 28 V Sanjosé E VidalAbarca OM Padilla A connectionist extension Kintschs constructionintegration model Discourse Processes 42 2006 135 29 RK Srihari S Ng CM Baltus J Kud Use language models online sentencephrase recognition Proceedings International Workshop Frontiers Handwriting Recognition Buffalo 1993 pp 284294 30 RK Srihari W Li T Cornell C Niu InfoXtract A customizable intermediate level information extraction engine Journal Natural Language Engineering 2006 31 SN Srihari G Kim PENMAN A reading unconstrained handwritten page images Proceedings Symposium Document Image Understanding Technology SDIUT 97 Annapolis MD 1997 pp 142153 32 SN Srihari B Zhang C Tomai S Lee Z Shi YC Shin A handwriting matching recognition Proceedings Symposium Document Image Understanding Technology SDIUT 03 Greenbelt MD 2003 pp 6775 33 SN Srihari EJ Keubert Integration handwritten address interpretation technology United States Postal Service Remote Computer Reader System Proceedings Fourth International Conference Document Analysis Recognition ICDAR 97 Ulm Germany 1997 pp 892896 34 SN Srihari J Collins RK Srihari P Babu H Srinivasan Automatic scoring handwritten essays based latent semantic analysis H Bunke A L Spitz Eds Document Analysis Systems VII Proceedings Seventh International Workshop Document Analysis Systems Nelson New Zealand SpringerVerlag February 2006 pp 7183 35 B Zhang SN Srihari Word image retrieval binary features Proceedings Document Recognition Retrieval XI EH Smith J Hu J Allen Eds Proceedings SPIE vol 5296 2004 pp 4553