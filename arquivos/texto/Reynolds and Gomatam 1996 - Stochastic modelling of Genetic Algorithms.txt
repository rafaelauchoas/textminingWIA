ELSEVIER Artificial Intelligence 82 1996 303330 Artificial Intelligence Stochastic modelling Genetic Algorithms David Reynolds Jagannathan Gomatam Department Mathematics Glasgow Caledonian University Cowcaddens Road Glasgow G4 OBA UK Received July 1994 Abstract distinctions replacement convergence Genetic Algorithms practical This paper presents stochastic models classes Genetic Algorithms We present classes Genetic Algorithms sample important terms search dynamics For classes analyse special cases algorithm derive sufficient conditions Genetic Algorithm optimisation We derive longrun measure crossover bias optimisation theoretical choice crossover operators For class Genetic Algorithms provide algorithms underpinning increase For degenerate alternative accompanies excessive crossover rates In formulating important definitions introduced capture simple form probabilistic properties genetic operators provides models independent results proving search mutation probabilities degeneration class Genetic Algorithms class empirically derived solution encoding schemes implications respect costindependent randomised models 1 Introduction reasons Genetic Algorithms wide variety combinatorial including NPhard 310 Theoretical GAS set heuristic search algorithms optimisation applied success problems analyse deterministic mathematical models GAS 12 lo formulate investigate application stochastic models based theory Markov Chains 4 5 79 15 17 181 In paper shall present number stochastic models GAS success divided mainly investigations camps Corresponding author Email dregcalacuk 000437021961500 SSDI 0004370294000913 0 1996 Elsevier Science BV All rights reserved 304 D Reynolds I Gomatam I Artificial Intelligence 82 1996 303330 We begin giving brief introduction GAS Section 2 making important properties 451518 proceed authors GA operators representationindependent homogeneous Markov Chains probabilistic formulate In Section 3 present brief introduction old ones sampling replacement In Sections 4 5 introduce new definitions large classes GAS create new populations distinctions sample solutions solutions replacement theory 7 summarise current stochastic models GAS 79 171 The work reported paper generalise extend previously unknown results reported describing stochastic models definitions classes GAS mentioned The models investigate properties GAS We analyse special cases optimisation GAS given certain choices mutation crossover rates GAS reduce search solutions role played cost function despite GAS For selection operator presence expected numbers converge generation We present bounds long run based optimal solutions population probability creation solutions crossover class GAS operate basis sampling replacement Finally discuss analysis models contained potential paper respect longrun probability distribution generalised GA 7 obtaining rates convergence analysing cases distribution use 2 Definitions GAS k formulation behaviour We stipulate concepts necessary The objective section formulate definitions GAS assumptions optimi mathematical models sation problem k 0 candidate solutions k integer We assume assigned bijective mapping set solutions integers 1 defined cost fitness J restricted 0 A CQ Thus set fitness values f solutions fi7 fk For purposes formulating models merely assume lo solution repre solutions sented analysis base 10 version binary representation assume particular encoding scheme solutions assigned natural binary string encoding set developing s si s2 sk s k corresponds solution labelling corresponds 1 index A GA mentioned solving characterised possessing following features finite discrete maximisation 3 lo problems type scheme encoding solutions optimisation problem solved chromosomes ii evaluation function rates solution assigning positive cost fitness D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 305 iii initialisation procedure candidate solutions generating initial population size N iv set operators manipulate genetic composition population generations v set parameter values stoppingcriteria This algorithm genetic operators implemented recent different optimisation problems fitness evaluationselection representation common different ways 6 For example schemes 6 candidate solutions binary strings fixed length L Also different ways mutation crossover operators implemented 7 6 including introduction Further order operators applied order generate new populations varied 6 However divide classes majority current population solutions sampling solutions replacement sample solutions genetic operators A pseudocode description genetic operators implement algorithms form new populations GAS use sampling replacement timevarying mutation operator existing GAS implementing replacement GAIWIN begin s f fitness selection mutation crossover Initialise population size N generation REPEAT WHILE BEGIN Popt l N t 0 Select p 2 2 parent solutions replacement Popt fitness selection Carry mutation copies selected parents Combine mutant parents form c 3 1 child solutions crossover Place child solutions new population Popt 1 END ttl UNTIL stoppingcriteriareached end Here follows mutation crossover predefined operators We shall consider fitness selection follows implemented roulette wheel selection selected parent solutions GAWI shall common immediately selection consider old population Popt subsequently operate copies parents For GAS operate basis sampling replacement pseudocode description replaced lo Further GA WON s f fitness selection mutation crossover begin 306 D Reynolds J Gomatam Artijicial Intelligence 82 1996 303330 Initialise population size N N generation REPEAT t 0 Select N parent solutions replacement Popt fitness selection form population Popt solution Carry mutation Popt form population Pop t Carry croSSover pairwise solutions Popt form N new child solutions form population Popt Set Popt 1 Popt ttl UNTIL stoppingcriteriareached end GAW0 note algorithms contain sampling replacement It important fitness selection operator crossover operators implemented basis sampling current population tions Note described choice solution models formulate independent GA applica 6 The operators replacement algorithms respect 9 GAS contain replacement According scheme common representation implementations mutation representation 3 Current stochastic models We present brief introduction current approaches 51518 details discuss Markov Chains We proceed stochastic modelling GAS The reader referred 31 Homogeneous Markov Chain theory Definition 31 A stochastic process sequence random variables time Xt exhibits Markov dependence called Markov process PrXt x 1 Xt x Xto x PrXt s x 1 Xt xn qx t 31 32 33 tt t A realisation Xt time called Markov Chain The Markov Chains shall discuss paper realisations random variables defined discrete statespaces discrete time If Markov process said homoge parameters vary time process case probabilities neous In homogeneous inhomogeneous D Reynolds I Gomatam I Artificial Intelligence 82 1996 303330 307 transiting state state j t t defined time steps t m t n depend PI PrXjXi 34 A Markov Chain said irreducible timestep transition probability matrix 1 G S st Pii 0 chain said aperiodic For irreducible finite length Markov Chains following theorems hold aperiodic corresponding If chain states irreducible 32 Theorem irreducible n 3 N nstep transition probability matrix P zero elements 15 p 471 Let P transition probability matrix finite Markov Chain Then exists N st aperiodic Theorem irreducible Sstate finite Markov Chain Then 33 15 p 881 Let P transition probability matrix 9T L1 9 n LilPl 35 36 37 wheremrrrz swithOrrlandmlll The following theorem shows irreducible geometric aperiodic Markov Chains possess geometric rate stationarity converge ergodicity 151 Theorem 34 15 p 901 Let P transition matrix irreducible aperiodic Sstate Markov Chain Let limiting probabilities defined 35 Then exists constants c r c 0 0 r 1 st P r eY I 11 11 ely cm When PO c 1 Finally following theorem presents stationary irreducible aperiodic Markov Chain terms corresponding probability matrix distribution transition Theorem 35 15 p 921 Given transition probability matrix P aperiodic irreducible exists unique probability vector II 7r1 n CTJ TV l l 1 Sstate finite Markov Chain IlPIIPlT 38 308 D Reynolds J Gomatam I Artcial Intelligence 82 1996 303330 II matrix row vector identical r The probability vector w gives stationary distribution process Notice 38 implies nP n In rest paper shall refer 38 invariant equation We proceed current approaches subsection stochastic modelling Genetic Algorithms 32 General stochastic models GAS discuss Most current models formulated probabilistic search carried properties primitive shown genetic operators GAS mainly based general matrix properties cast binary string encoding scheme Thus irreducible stochastic matrices example properties matrices stationary distribution holds models generally consider certain classes GA 79171 However action mentioned operators states algorithm populations difficult obtain results optimisation problem 17 Thus transition probability matrices current models based large irreducibility primitivity means models properties certain genetic operators particular formulated solution created mutation crossover algorithm parameters Thus corresponding search dynamics main stochastic model 17 basis costs solutions extracted respect algorithms For example actual solutions little information probability PCMS 39 acting P transition probability matrix underlying stochastic process C M S irreducible matrices corre Genetic Algorithm states genetic operators spond algorithm The stochastic model contained abstract generalisation appears oversimplified 17 main model 9 Note 817 globally optimal GA given maintains elitism lo currently optimal solution generation global optimality algorithm In 17 conclusion trick We verify conclusion explicitly depends essentially algorithmic paper carrying analyses special cases mentioned previously 8 essentially population generation reached 33 Explicit stochastic models GAS In 7 description binary encoded GA sequence random vectors models GAS implement sampling replacement given application analysis modelling 411 Thus shown 7 stationary distribution exists certain classes genetic operators basis instances GAWI binary encoding D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 309 equations modified lo The stationary distribution GAS described 7 given scheme transition probability matrices terms characteristic main work 7 concerned analysis timevarying However mutation probabilities Genetic Algorithms generalise classes Genetic Algorithm discussion In paper present formulat formalise differing ing stochastic models search properties stationary dis literature The models tribution GAS certain cases provide practical guidance parameterisation distinction algorithms GAWI GAW0 algorithm explicitly differing properties discussed present explicitly algorithms 4 Stochastic model GAWI The objective section formulate stochastic model class solutions algorithms GAWI purely basis sampling replacement current population operating copies sampled solutions mentioned genetic operators create new populations 41 Ksolution 1 operator GAIWIN s We present stochastic model GAIWIN s fitness selection mutation crossover operators We begin formulating essential definitions Definition 41 Let Xi represent GA WI time t Then X X2 X represents population integer numbers solution population numbers solutions time t X X2 X N Xi positive Definition 42 Let PlXX x 1 2 X XXXN Xi positive integer represent set consisting valid states algorithm GAWI Thus GAWI samples solutions immediate replacement copies genetic operators implements distinction states I Since numbers solution random variable subject vectors Essentially X X2 X N Therefore X X2 X E Slkl random vector ll states GAWI random analysis properties GAWI respect permutations solutions population population collection sampled solutions 310 D Reynolds J Gomatam I Artijicial Intelligence 82 1996 303330 heuristic search optimisation probability distributions given random variablesvectors reduces certain cases analysis In order formulate conver gence results GAWI following definition matrix multiplica tion general matrices indexed vectors transition probability matrices corresponding Definition 43 Let A E R BXy E 8 Slkl x ISkll matrices XY E real Slkl Then define ZJth element matrix product AB number c Am c AIDiBDJ VZ J ESLk DESkl Iskll il 41 summation Di meant list vectors formed arbitrary bijective mapping 12 Is Skl Thus D dummy vector 41 Only existence arbitrary mapping 19 When successive matrix important multiplications assumed mapping Stkl mappings carried matrices indexing purposes summation From general definition following definition premultipli cation Stkll x ISLkll matrix 1 x 11 column vector Definition 44 Let qr E 3 Bxy E 3 B s x IsJ matrix q 1 x ISfkl column vector XY E Skl Then define Zth element matrix product qB real number c qD DESkl Iskll 2 il qDd VJ E SIkl 9 42 summation Di meant list vectors formed arbitrary bijective mapping 12 SLklj Slkl Definition 43 summation indexing notation This notation enables ignore particular mapping elements transition matrices retain vector follow useful terms estimating marginal probability distributions transition matrices 1151 clear It usual formulating stochastic models existence bijective mappings previous definitions use index states described GA 791 However gives useful retain identity solutions states GAWI information solutions states long run search properties GAS respect paper require restriction preferring GAS A result given 717 concerning number states GA terms D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 311 chosen present representation scheme following general result fixed length binary strings We Proposition 45 GAIWI population size N order population solution space size IsI k searches statespace size ISkll stored irrelevant sampling replacement GA operating pkl Proof A population configuration XXXN Xi X X valid state GAWI 43 44 definition X E Stkl Thus total number valid states given total number distinct solutions equation integers wellknown problem combinatorics solution stated 19 0 nonnegative Therefore number states GAWI function solution space population size regardless chosen solution encoding scheme It shown number states algorithm GAS contain operators GAW0 sample replacement GA WOtype algorithms shown states contain operators fundamental GAWI difference later With necessary definitions underlying solutions states following stochastic model place random vectors conditional probability distributions entities proceed calculate GAIWIN sampled population X X X X E Stkl XN 1 c d k probability Y Yi Y _ Y E Stkl instances solutions Therefore 1 k time t 1 given X Xi X X instances time t s random sampling solutions random variables probability solution PrY1 yZ Ykrl 1 cxl x2 xkt PXY YY N yk zL g 45 This equation gives conditional Yi Y2 Yk time random statespace Markov vector process defined 45 space defined Definition 42 consists distinct vectors Xi X X E Stk Each solution step conditional probability distribution given ll t 1 Note distribution probability whereXYES kl Substituting 45 46 shows numbers solution 46 312 D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 1 c 6 k population binomial distribution investigated time In 7 certain basic properties t Xi random variable 45 model case binary representation schemes 42 Incorporating fitnessbased selection GAIWIN s f roulette wheel We consider standard roulettewheelbased xJ E S corresponds solution strictly positive Since Xi x2 5 0 15 S k select population time t replacement basis roulettewheel sampled population X E Skl fitnesses probability fitness vector cost f selection procedure fitness value fi 310 fk solution Xf 47 PrYlYYllllxZxXOj_ 48 N rxi meant relative fitness solution conditional population X Since fitness solution assumed fixed model firstorder Markov process states defined defines timehomogeneous This model discussed 7 byXXX solutions lo In section special case binary string representation discuss problem introducing GA mutation crossover operators model form leaves model representationindependent XES 43 Incorporating mutation crossover GAIWIN s f roulette wheel mutation crossover Since models representationindependent following simple form stochastic properties genetic definitions capture operators mutation crossover Definition 46 Let r rowstochastic mutation matrix transforms probability solution solution j mutation 77ij stores jijl jl 49 For example fixed mutation probabilities p c l2 6 lo binary representation strings fixed length L D Reynolds J Gomatam I Artijkial Intelligence 82 1996 303330 qij yyl pmLHij Tij Tji 0 313 410 Hamming distance j 17 To incorporate 17 Hi j represents encodings solutions representationindependent probability fixed number ordered operation minimal crossover probability matrix defined binary string crossover remain define crossover probability matrix gives fixed number ordered parent solutions generate action crossover triples The indexed ordered pairs child solutions matrix Thus Definition 47 Let C m j rowstochastic crossover probability matrix mlCijml VlSiSjGk 411 stores probability solutions j produce solution m 1 s c j s k 1 S m s k Moreover define C 0 action crossover Cijj 0 nonzero probability parental retention Note rowsof C indexed ordered pairs parent solutions columns single child solutions An example given Appendix A crossover probability matrix ordered pair forces string length 2 Note binary string encoding solutions force gathered parent uniqueness reference solutions place definition implemented possible lchild crossover operation particular 2parent 14 2parent solutions generate child It noticed fact possible define With croSSover example parents Xparent Ychild crossover operation pointed descriptions crossover instances Xparent Ychild crossover operation easily extended triples distinct requirement production probabilities crossover overunderestimated C matrix Since definition Chain model GAWI uses definition As usual previous definitions apply given genetic operators scheme literature mere C matrix essential solution simplest possible shall develop Markov regardless solution encoding triples parents pairs 6 X 2 2 Y 2 1 Therefore children probability With definitions mutation crossover calculate X1X parents terms unions intersections probabilistic events replacement mutant nonmutant solution given X fitness selection action roulettewheel mutation parent crossover produce solution clearly given place proceed produced XkEPl 1 pi s k 314 D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 Pr U jfS n U jb n U d n d bi bEs dEs I jES subscript fs refers fitness selection probability 412 413 414 pxi meant GAWI conditional population X 1 s s k This gives stochastic model GAWI given operators probability generation solution N PXY yy 415 Y E Skl Note independence parent selection gives 413 412 The rowstochasticity P follows given pxi terms definitions properties multinomial follows previous distribution stochastic model obtained 12 With mutation parents similar manner X YE Skl 416 44 Analysis models GAIWIN s f roulette wheel mutation crossover results relating present We proceed section stationary distribution search important properties GAWI The result presents sufficient conditions GAWI converge GAWI terisation approximation We usefulness independence models presenting theorem search second result presents special case Genetic Algorithm parame implications result presents longrun crossover solution encoding schemes 415 A convergence result GA WI respect implementation 416 obtained similarly representation issues following model 4 m_ I P 4 y D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 315 441 Parameter choice convergence Theorem 48 GA I WI 77 0 C defined converges limit stationary probability distribution q qx strictly positive X E Skl Also convergence takes place geometrically Pi qr ei states X YE Sk letl rf 417 exists 0 s r 1 st 418 419 Finally q independent initial choice population XO Proof Suppose given arbitrary states X YE Skl transit X Y P given 415 Then time step according possible cases appropriate probability Case 1 X 0 1 I s k Then exists component Xj relative fitness rZj greater zero population X corresponding fixed size N Thus pIrj77ilriCjI0 pIrj17irjCjr0 jsZ jZ Case 2 XO 16Isk Then pxI 1711r11 0 420 421 Therefore arbitrary states X Y E Slkl entry P consists product strictly positive numbers I arbitrary implies P strictly positive The result follows application Theorems 32 33 q Note mutation implemented binaryencoded GAS way force n 0 mentioned previously 17171 In section removes bias possible solutions based cost way completely parameterise GAWI 442 Special case Proposition 49 GAWI randomsearchtype algorithm solution space special case exists choice C st underlying stochastic process GA I WI Markov Chain given k 1 solutions 316 D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 represented independent identically distributed random variables Further stationarity immediately Markov Chain generation choice C converges Proof Set Cbd llkVlbdk lsttk Then pxillk Vlsisk VXES substitution 414 N 1 Pxy yly2 Yk kN 422 423 Y E Skl Since process exists unique guess stationary distribution homogeneous stochastic N qxxx2xk 1 kN check substitution 38 424 c 4XPH XESkl c 4x1 XEskl N xEstl x X x 1 kN YlY2 N 1 Yk 2 I PXY 425 qo vx 426 X E Stkl Thus chosen q stationary distribution GAWI C l lk To GA converges generation observe 427 P limiting matrix repeated substitution To random variables Xi 1 d s k marginal distributions observe random variables marginal distribution stationarity binomially distributed probability parameter unconditional lk given probability obtaining stationarity j solution PrXijrilPj t12 428 use 46 holds 1 s k Notice X1 X2 X N VX E Skl k 1 given random variables independent ll proof claimed completes 0 Again analogous result holds model 416 GAWI mutation algorithm previous crossover operator parents We D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 317 search implications parameterisation choice random random variables Xi 1 s s k identically distributed ail times search algorithm converges selection bias solution based cost immediately result In fact choices C n provide sought prove existence result special case The solution encoding result important schemes Genetic Algorithms respect crossover Essentially GAWItype Genetic Algorithms relate probability properties given parents child production croover degenerate strongly conjecture success binaryencoded Genetic Algorithms depends certain extent properties binary encoding scheme In practical terms binary encoding scheme solutions multidimensional In section extract information model 415 provides measure crossover bias respect search optimal solutions reason observed choice crossover operators algorithms respect implementation fundamental search algorithms degeneration GAWItype automatically prevents random GAS 443 Long run approximation result We present general result GAWI mutation carried 415 As analogous results exist case 416 To proceed formulate prop parent mutation parents definitions certain parameters GAWI capture erties operators carried fundamental Definition 410 Let 0 min Cbd Vl s b s d G k 16 t s k Thus 0 minimum component vector tth column C Note f3 vary columns C solutions Definition 411 Let E max Cbd Vl s b d d s k 1 s t d k Thus E maximum component vector tth column C Note E vary columns C solutions Definition 412 Let py long run expected numbers solution population distribution q 1 s t G k t expected value random variable X stationary Definition 413 Let e matrix rows store population vectors order index P q e size ISlkll x IsI Then e vector containing X solution t populations With guarantee definitions state prove following approximation GA WI mutation parent 318 D Reynolds J Gomatam Artijicial Intelligence 82 1996 303330 Theorem 414 For GAIWI mutation parent 415 77 0 following holds N8sNe 429 Proof By definition multivariate distribution expected 11121 value random variable N YIYil I P T x1 IxSkl 1 fact q stationary distribution expected value multinomial distribution gives 430 P By formula pN c XEsl 431 parameters By substituting result follows simple substitution given 0 E 431 Proposition 49 cases bounds exact return Nk expected Again justifies long run use term random search proposition expect equal numbers solutions population Note analogous result holds model 416 guarantee Therefore algorithms long run approximation analyse certain cases crossover given population size seen lower bound pr increases value population size N larger 19 0 0 increases upper bound y decreases size E decreases facts intuitively obvious population definition GAWItype Section 2 Thus bounds existence crossover bias GAS bounds given highlight costs solutions The existence bias independent importance fundamental GAS given problem k generally large costs f known optimisation lower cost existence crossover bias example scheme choice crossover solutions operator generally undesirable bounds depend particular Another prove useful analysis nonbinary representation encoding immediately apparent depending given encoding scheme schemes 610 example important point choice crossover operator terms optimisation lower costs solutions Finally note justified calculating expected values D Reynolds J Gomatam I Artijicial Intelligence 82 1996 303330 319 stationary Theorem 48 distribution stochastic process converges limit 5 Explicit stochastic model GAWON s f roulette wheel mutation crossover We proceed vectorindexed matrix multiplication important size statespace convergence formulate stochastic model GAWO proceed resultant model slightly faster pace GAWI partly simpler form partly analogous concepts respect need results GAWOtype Genetic Algorithms brevity We present sufficient respect limit algorithms special case analysis conditions underpins rates performance algorithm respect discovery cause degradation results higher fitness solutions GAWItype Genetic Algorithms relationship possess GAWI GAW0 differing search prop order erties finally algorithms GAWO solutions stored population affects search fundamentally dynamics algorithm transition probability matrices results observed experimentally possess differing statespaces excessive mutation 610 We present GAWO search important differing 51 Definitions GAI WO statesloperators In GAWO genetic operators acts population GAWI new population applied singly specific locations opposed produces operators mutation assume solutions stored population GA implemented GA WO separately stochastic process mutation crossover population crossover pairwise merely listlike fashion 6 Thus introduce new definitions states effect effected locations In particular specific Definition 51 Let contained population GAW0 iI iNr store order solutions time t 1 s s k 16 m s N Thus component GAW0 state vectors solution component GA WI state vectors counts solution Definition 52 Let SN1 iI 1 s s k 1 S m s N Thus SfN1 set consisting valid populations GAWO These definitions lead 320 D Reynolds J Gomatam I Artijicial Intelligence 82 1996 303330 Proposition 53 GA WO population size N operating solution space size IsI k searches statespace size ISfN1j Proof The total number population number distinct permutations population states GAW0 51 given total states GAWI 52 ISrNI kN x2 state vector X E S Ikl GA WI bracketed distinct corresponding states given l p 491 Cl permutations GAWO result 51 follows modification wellknown term 52 distinct result Thus present following inequality GAWI GAWO Theorem 54 Let ISCkll given 43 ISfNJ 51 Then ISNII ISkll kl Nl Proof Observe Nk k N 1 kN 1 Thus k2k NkkklkN1 IsdN11 kN kk lNl pq completes proof 0 53 54 Note larger optimisation nontrivial strictly k 1 corresponds number states GAW0 N 1 shown nontrivial Genetic Algorithm Thus GA WI This fact previously authors lefthand 54 ignored literature size Genetic Algorithm statespace 17 righthand 7 Here shown Genetic Algorithms possess statespace statespace GA respect WO strictly larger GAWI implementation genetic operators As evident definitions GAWI crossover probability matrix insufficient GAW0 Therefore introduce crossover operator produces GAWO singlechild stochastic properties children parents Definition 55 Let C rowstochastic crossover probability matrix D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 321 Ii Ii Cob l VlLzbk gl hg action crossover stores define Cijij 0 solutions combined probabilistic probability solutions b produce solutions g h 1 s Z b G k 1 s g h c k Moreover result test 6 lo Note force parent child solutions ordered pair forces uniqueness reference The 2parent 2child crossover probability matrix following useful property gathered Proposition 56 gl Ci hg Cabhgl Vlsasbsk hl gt Proof Settingmkgl lsgk nkhl lchsgck gives gl hl il gg h l Vlcabsk _ middle sum merely rearrangement 0 completes proof outer sums This gives following useful property Proposition 57 fi gl hgl c cl c Vlabsk gl hl Proof Each sum term excluding sums written Proposition 56 completes proof 0 With definitions results place simple form stochasticity GA WO croSSover operator formulate definition use relates selection operator GAWI GAW0 322 D Reynolds J Gomatam I ArtiJicial Intelligence 82 1996 303330 sampling replacement transition matrix selection operator GAWO selection operators It formulate Definition 58 Let Xi br store numbers solutions b population GAW0 time tie Xide3m md mm Vlsyzsd st il imd b Thus Xil Xik manytoone mapping states GAW0 states GAWI iI iN GAW0 counting vector tion 42 represent 1 s s N i1 iN E SfIN1 unique Xr Xik given Xi X X E Skl Defini total occurrences solutions counts 0 x different iI iN E TIN1 vectors 11 55 52 Stochastic model GAIWON s f roulette wheel mutation crossover We present section stochastic model GAWO begin presenting stochastic model selection operator An important point j E SlN1 counting vector Y E Slkl populations E SN1 probability production GAW0 fitness selection operator unimportant placed j E SfN1 important Definition 52 different j E SlN1 equal probability occurrence permutations sampling replacement solution b population roulettewheel selection events GAWI Therefore implies independence relative order solutions selected ordering population E SlN1 given order fitness operator lsbck Fij Prjl j2 j 1 iI iN n rf bl k 56 57 transition matrix selection operator GAWO j E SrLN1 X Y E Slkl counting vectors populations ly j respective The transition matrix GAW0 mutation operator simple form D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 323 mutation transforms population carried independently population listlike manner j ij E SN1 population N Mij Prjl j I il iN n Vidjd 58 dl The construction transition matrix croSSover operator GAW0 definition relates crossover probabilities nontrivial C matrix Definition 59 Let C defined c abcd C abcd c p abdc acb ab b c bndc 1 ab csd csd cd cd cd g ives appropriate value C crossover arbitrarily c iey labelled solutions Since crossover operator GAW0 transforms population j ijESIN crossover probabilities creation solutions pairwise following equation child solutions placed j E SN1 population relates Prj2dI hd tf3 h 1 i2dly d cay b Pr j2d1y j2d thy 8 1 2d1 kd ca2 b 59 1 d s N2 relevant 59 ordered pair solutions Thus define ordering new pair child solutions locations j stipulated equally likely term Definition 510 Let fx y defined Note f symmetric x y Thus necessary definitions place observe PrjZdl j2d k h 1 i2dly d CUT b WabT gh n j2d1 hd k hl fg hCb 3 510 term brackets ordered pair Thus general formula 324 D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 conditional probability obtaining j2d_1 jZd i_ crossover Prj2dl 9 j2d I Cid1 7 i2dl ftj2dl j2dCrd_li2dj2d_i 511 1 d d d N2 Denoting operator Q transition matrix given crossover I1 VG2d19 dl j2dcr2_2dj2d_ljdl 3 512 pairwise crossover events independent To complete construction Q state prove following Proposition 511 Let Q defined 512 Then Q rowstochastic matrix Proof Observe c jcsNl Q jll jzl 5 f Mj2d17 iCd_l2dj2d_lj2dl jNl dl jl j21 jN_ll KNI jNC_liNjN_ljN jl 3 513 general term 5 j2dll l fj2d1y j2dCI_ijzd_1iZd ZZ i_ _i 12d11 12d12dll 2dli2dj2dj2d1 k c Ci2d_li2dTj2dlj2dl j2d11 properties fx v assuming i_ d loss generality sum overj components 1 s d d N2 By Proposition 57 sums equal added sum gives D Reynolds J Gomatam Artificia2 Intelligence 82 1996 303330 325 Definition 55 Since d arbitrarily chosen product ls Q rowstochastic 512 shown finite 0 F easily shown rowstochastic properties overall analysis Q repeated rowstochastic Thus distribution Note multinomial simpler form M stochastic model GAW0 PFMQ 2 C KbMbQ SINl bEsNl vi j E IiN 7 514 predict 415 416 GAW0 F M Q rowstochastic matrices defined 57 58 512 Thus seen vectorindexed matrix multiplication transition matrices GAWI 514 differ generally higher order transition matrix GAW0 GAWI Since knowledge transition matrix stochastic process behaviour process time steps given sufficient 15 initial probability corresponding Markov Chain implies concise form models Notice distinct orderings solutions E SfN1 essentially transition probabilities differing states GA WO corresponding 514 populations GAW0 GAW0 415 416 514 capture search dynamics algorithm distinct search algorithms solutions stored distinction GAWI distribution determines order differing 53 Analysis model GAIWON s f roulette wheel mutation crossover In section present analyses model given usual way implemented possesses stationary distribution fundamental 514 We mutation operator 6 171 GAW0 row mutation probability matrix discrete uniform distribution GA WO converges search conducted search set solutions s si s2 sk costindependent immediately 531 Parameter choice convergence We proceed present similar result Section 441 derive stationary GAW0 limit sufficient distribution We formulate definitions essential converge conditions method proof Definition 512 Let fmin min fi f 0 326 D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 Thus fmin equal cost solutions lowest cost Definition 513 Let f maxfr fk 0 Thus fm equal cost solutions largest cost Definition 514 Let rmin minij nij Thus nmin smallest entry mutation probability matrix It greater zero n 0 Definition 515 Let Cmin minisi C 0 Thus Cmin smallest probability crossover operator It greater GAW0 pair parents retained zero Definition 55 516 GAIWO 77 0 C defined Theorem stationary probability distribution q qj strictly positive valid population state algorithm converges 515 Also convergence takes place geometrically exists 0 r 1 st Pi qj lel S rf Finally q independent initial choice population Proof Observe Pij F M Q 2 FiiMijQ jj Vi j E StLN1 516 517 518 vectorindexed multiplication Definitions 43 44 Now carried general sense bl rxb afminlNfmax VlSbck fitness solutions denominator maximum fitness VXESlkl h w ere numerator given fraction component value b smaller cost population D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 327 Fii fi bl n 0 Qz O VjEYLN1 519 520 521 definition Q righthand aperiodic irreducible 518 strictly positive Vi j E SN1 Since P product given imply result follows use Theorems 33 34 532 Special case following special case GAWO In described shows case GAWI GAW0 respect absence bias cost parameterise algorithms paper contain similar degenerate cases following result Proposition 49 parameterised algorithms identical search properties choice operator different Theorem GAIWO 517 Let 7 lk Then resultant stationary distribution qjs C Q aJ jESN tZESNJ Proof By substitution r 58 follows 1 Mijs VijESN Thus substitution 514 PO Q ViESrEN c ESN 522 523 524 Vij E SfN F rowstochastic Substitution 522 equation Q invariant 38 P given 524 obtains result observing definition qj eO VEES The corresponding P 524 identical rows P Proposition 49 result immediate convergence follows essentially 0 525 Within relaxed theoretical GAWI degenerates result framework discussion surprising immediately search com fitnessfree 328 D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 plete crossover regardless mutation GA WO degenerates fitnessfree search complete mutation regardless crossover It worthy note q 522 discrete uniform lZ SN case crossover actually takes place crossover parameter p 0 lo identity matrix I Again GAWI Q case SlN1 parameterizations GAW0 produce costindepen dent search case sought prove existence result immediately 1 x SNI measures crossover bias The extension approximation guarantee currently GAWI given Section 443 GAWOtype developed authors reported pointed distributions given rows matrix defined 514 nonstandard problem element intractability probability distributions future publication introduce algorithms 6 Conclusions future directions In paper described number models GAS analyse convergence properties given algorithms We defined crossover operators terms stochastic matrices genetic mutation way captured resultant essential stochastic properties solutions yielded sufficient models independent representation distinction GAS conditions convergence We important terms populations sample solutions replacement size statespace algorithms We presented definitions stochastic models classes algorithm We genetic operators analysed particular cases genetic search showing sufficient conditions classes degeneracy guarantee indicates solutions Future approximation optimisation sampling replacement GAS guarantee given existence bias GA crossover operator theoretical work concentrate presentation search presented randomised important represents classes algorithm The extension stationary distributions GAS parameters special case analyses estimation moments stationary distributions GAWItype GAS higher moments important estimation moments stationary distribution algorithms provides guidance respect algorithm parameterisation possible crossover probability matrices Other important work concerns phenomenon premature 36 lo rate convergence Genetic Algorithms stationary distributions investigated authors reported theoretical practical work significant multivariate nature shown Sections 442 443 It moments particular cost functions mutation analysis Genetic Algorithms currently future publication These 18 use models convergence estimate known D Reynolds J Gomatam I Artijicial Intelligence 82 1996 303330 329 tasks represent aspects optimisation Genetic Algorithms important problems respect theoretical practical Acknowledgements Both authors like thank Dr CNB Martin Clean Energy Systems work David National Engineering Laboratory Glasgow Reynolds financial support Glasgow Caledonian University work He like express thanks members staff Department Mathematics Glasgow Caledonian University encouragement grateful Appendix A Example crossover probability matrix binary string encoding scheme length 2 Example A1 Binary string uniform crossover 316 This implemented simultaneously moving parents selecting bit parent probability case strings length 2 crossover probability matrix given Table Al l2 Thus Table A1 Uniform crossover probability matrix binary string L 2 GA 00 1 05 05 025 0 025 0 0 0 0 01 0 05 0 025 1 025 05 0 0 0 10 0 0 05 025 0 025 0 1 05 0 11 0 0 0 025 0 025 05 0 05 1 c rn 00 00 00 01 00 10 0011 0101 01 10 01 11 10 10 10 11 1111 References l I Anderson A First Course Combinatorial Mathematics OUP Oxford 1985 2 DL Battle MD Vose Isomorphisms genetic algorithms Artif Intell 60 1993 155165 3 D Beasley DR Bull RR Martin An overview Genetic Algorithms Part 2 research topics Univ Comput 15 1993 170181 4 RN Bhattacharya EC Waymire Stochastic Processes Applications Wiley New York 1990 5 E Cinlar Introduction Stochastic Processes PrenticeHall Englewood Cliffs NJ 1975 330 D Reynolds J Gomatam I Artificial Intelligence 82 1996 303330 6 L Davis What Genetic Algorithm L Davis ed Handbook Genetic Algorithms Van Nostrand Reinhold New York 1991 Chapter 1 7 TE Davis JC Principe A simulated annealing theory simple genetic algorithm RK Belew LB Booker eds Proceedings Fourth Conference Genetic Algorithms San Mateo CA Morgan Kaufmann San Mateo CA 1991 174181 8 AE Eiben EHL Aarts KM Van Hee Global convergence genetic algorithms Markov chain analysis HP Schwefel R Manner eds Parallel Problem Solving Nature Springer Berlin 1991 412 like convergence 9 DE Goldberg Finite Markov chain analysis Genetic Algorithms ed Proceedings Second International Conference Genetic Algorithms Lawrence Erlbaum Hillsdale NJ 1987 l8 JJ Grefenstette lo DE Goldberg Genetic Algorithms Wesley Reading MA 1989 Search Optimisation Machine Learning Addison ll AF Karr Probability SpringerVerlag New York 1993 12 W Mendenhall DD Wackerly RL Scheaffer Mathematical Statistics Applications Wiley New York 1993 13 H Mint Nonnegative Matrices Wiley New York 1988 14 DJ Montana Automated parameter ed Handbook Genetic Algorithms tuning interpretation synthetic images L Davis Van Nostrand Reinhold New York 1991 15 U Narayan Bhat Elements Applied Stochastic Processes Wiley New York 2nd ed 1984 evaluation improved 16 JC Potts TD Giddens SB Yadav The development Genetic Algorithm based migration artificial selection IEEE Trans Syst Man Cybern 24 1 1993 7386 17 G Rudolph Convergence analysis canonical Genetic Algorithms IEEE Trans Neural Net 5 1 1994 96101 18 E Seneta Nonnegative Matrices Markov Chains SpringerVerlag New York 2nd ed 1981 19 JH van Lint RM Wilson A Course Combinatorics CUP Cambridge 1993