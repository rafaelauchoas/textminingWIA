Artiﬁcial Intelligence 137 2002 217238 wwwelseviercomlocateartint A hybrid graphical model rhythmic parsing Christopher Raphael Department Mathematics Statistics University Massachusetts Amherst MA USA Received 4 October 2001 Abstract A method presented rhythmic parsing problem Given sequence observed musical note onset times simultaneously estimate corresponding notated rhythm tempo process A graphical model developed represents evolution tempo rhythm relates hidden quantities observable performance The rhythm variables discrete tempo observation variables continuous We compute globally likely conﬁguration tempo rhythm variables given observation note onset times Experiments presented MIDI data data set derived audio signal A generalization computing MAP estimates arbitrary conditional Gaussian distributions outlined 2002 Elsevier Science BV All rights reserved Keywords Conditional Gaussian distribution Rhythmic parsing MAP estimate Dynamic programming Music recognition Hybrid graphical model 1 Introduction Rhythm aspect music deals events occur Typically rhythm Western music notated way expresses position note rational number usually terms relatively small common denominator For instance use measure unit notated position sequence measure positions m0 0 m1 14 m2 1 expresses notion ﬁrst note occurs beginning 1st measure second note occurs 14 way 1st measure note occurs beginning 2nd measure If music performed mechanical precision single number tempo map measure positions This extended version paper presented 17th Conference Uncertainty Artiﬁcial Intelligence UAI2001 Seattle WA USA This work supported NSF grants IIS0113496 IIS9987898 Email address raphaelmathumassedu C Raphael 0004370202 matter 2002 Elsevier Science BV All rights reserved PII S 0 0 0 4 3 7 0 2 0 2 0 0 1 9 2 3 218 C Raphael Artiﬁcial Intelligence 137 2002 217238 actual times For instance tempo 3 seconds measure notes occur 0 secs 34 secs 3 secs However performance nearly impossible human performer create undesirable Much expressive quality musical performance comes way actual note times deviate prescribed literal interpretation printed music In particular primary components expressive timing 8 Firstly actual tempo constant continually varied evolution performance Secondly local note note distortions accidental result interpretive considerations We focus problem encountered music information retrieval MIR Given sequence measured note onset times wish identify corresponding sequence measure positions We process rhythmic parsing The time sequences forming input procedure estimated audio signal come directly MIDI musical instrument digital interface ﬁlea sequence timetagged musical events note beginnings endings For example consider data left panel Fig 1 containing estimated note times excerpt Schumanns 2nd Romance Oboe Piano oboe The actual audio ﬁle heard httpfafnermathumassedurhythmic_parsing Our goal assign proper score position measures observed times When correctly Fig 1 observed times seconds plotted score positions measures trace curve local slope gives players local tempo Applications rhythmic parsing numerous Virtually commercial score writing program offers option creating scores directly entering MIDI data keyboard Such programs infer rhythmic content actual times musical events occur address rhythmic parsing problem When input data played mechanical precision transcription degrades rapidly difﬁculty computing correct rhythmic parse Rhythmic parsing applications musicology separate inherently intertwined quantities notated rhythm expressive timing Either rhythmic data timing information focal point study Additionally applications rhythmic parsing related efforts music information retrieval follows The musical world eagerly awaits compilation music databases containing virtually kind public domain music facilitating searching studying comparing understanding music The construction data bases likely involve transcription efforts including optical music recognition musical audio signal recognition MIDI transcription Rhythmic parsing essential ingredient efforts Finally decade seen virtual explosion music data available World Wide Web Unfortunately contentbased searches analogous performed text possible present time However automated music transcription progress sufﬁcient level searchable descriptions musical content constructed automatically Such development dramatically increase access music web Rhythmic parsing play signiﬁcant role endeavor As mentioned commercial scorewriting address rhythmic parsing problem Usually efforts attempt quantize observed note lengths C Raphael Artiﬁcial Intelligence 137 2002 217238 219 Fig 1 Left Real time seconds vs Musical time measures Schumann data Right The actual durations seconds notes grouped musical duration measures precisely interonset intervals IOIs closest note values eighth note quarter note given known tempo quantize observed note onset times closest points rigid grid 24 While quantization schemes work reasonably music played robotic precision metronome perform poorly faced expressive accurate playing typically encountered Consider right panel Fig 1 plotted written note lengths measures versus actual note lengths IOIs seconds musical excerpt The large degree overlap empirical distributions note length class demonstrates futility assigning note lengths notebynote quantization example In particular example overlap empirical distributions attributable tempo ﬂuctuations performance In addition commercial systems aware research efforts related rhythm transcription Some research addresses problem beat induction tempo tracking tries accomplish equivalent foot tappingestimating sequence times corresponding evenly spaced rhythmic intervals beats given sequence observed note onset times 13691114 A complementary research effort addresses problem assigning rhythmic values simple integer ratios observed note lengths corresponding estimation tempo 4810 The assume beat induction performed assumes tempo variations signiﬁcant obscure ratios neighboring note lengths In kinds music believe exceedingly difﬁcult independently estimate tempo rhythm previously cited research observed data formed complex interplay That independent estimation tempo rhythm leads chicken egg problem One easily estimate rhythm knowing tempo viceversa In work address problem simultaneous estimation tempo rhythm From problem domain point view signiﬁcant contrast work efforts cited The research effort closest spirit recent work Cemgil 2 probabilistically models tempo rhythm jointly seeks globally optimal data interpretations computing posterior distribution particle ﬁltering techniques 220 C Raphael Artiﬁcial Intelligence 137 2002 217238 There signiﬁcant distinctions work Cemgil deals chicken egg problem approximating marginal distribution rhythm integrating tempo variables instead estimate tempo rhythm jointly Perhaps important distinction provide dynamic programming technique identiﬁes globally optimal data interpretation Cemgils method approximate The paper organized follows Section 2 develops generative graphical model simultaneous evolution tempo rhythm processes incorporates prior knowledge concerning nature rhythm process simple reasonable model tempo evolution This section describes computational scheme identifying likely conﬁguration MAP estimate unobserved processes given observed musical data Section 3 demonstrates application scheme musical examples Section 4 brieﬂy summarizes discusses aspects approach rhythmic parsing Our method identifying MAP estimate speciﬁc model treated generalizes particular model Section 5 sketches generalization methodology generic MAP estimation unobserved variables conditional Gaussian CG distributions To knowledge MAP estimation CG distributions studied previously potentially useful Finally appendix lists easilyderived results Gaussian kernels preced ing sections 2 Rhythmic parsing 21 The model While musical rhythm usually composed rhythmic fragments repeat verbatim rhythm typically cyclic component certain tendencies repeat periodic fashion This periodic nature music basic ﬁgures prominently way Western music notated As sequence measuresunits musical time obey similar subdivision rules The probabilistic modeling periodic behavior central approach taken present evidence Section 3 advantage In follows use term measure denote obvious period rhythmic structure Usually notated measure Suppose musical instrument generates sequence times o0 o1 oN seconds note onsets occur Suppose ﬁnite set S composed possible measure positions note occupy For instance music 44 time believe subdivision occurs eighth note S i8 0 7 More complicated subdivision rules lead sets S evenly spaced multiples common denominator We assume possible onset positions S rational numbers 0 1 decided advance Our goal associate note onset score positiona measure number element S We model situation follows Let S0 S1 SN discrete measure position process Sn S n 0 N In interpreting positions assume consecutive pair positions differs measure For instance 44 example given Sn 08 Sn1 18 mean nth note begins start C Raphael Artiﬁcial Intelligence 137 2002 217238 221 measure n 1th note begins eighth note later Sn 08 Sn1 08 mean notes begin start measure We use cid1 lsn sn1 sn1 sn 1 sn1 sn sn1 cid1 sn cid2 unambiguously represent gap measures associated transition sn sn1 Thus s0 s1 sN known assign score position mn observation n1 mn s0 ν0 lsν sν1 We believe assumption interonset intervals measure appropriate examplesespecially composite rhythm generated superposing musical parts studied Chopin example Section 3 However complicated models allow longer IOIs greatly increasing number parameters learned We model S process timehomogeneous Markov chain initial distribution I s0 P S0 s0 transition probability matrix Rsn sn1 P Sn1 sn1 Sn sn The tempo important link prescribed score observed Let T1 T2 TN continuouslyvalued tempo process measured seconds measure model cid4 cid3 T1 N ν φ2 Tn Tn1 δn n 2 3 N δn N0 τ 2Sn1 Sn This model captures property tempo tends vary smoothly allows variance tempo increment depend transition Sn1 Sn For instance expect greater variability associated longer transitions Finally assume observed interonset intervals IOI yn on1 n 1 2 N approximated product lSn1 Sn measures Tn secs measure Speciﬁcally Yn lSn1 SnTn εn εn N0 ρ2Sn1 Sn Note observation variance allowed depend transition capture notion long transitions associated greater variability IOIs The variables T1 δ2 δN ε1 εN assumed mutually independent T1 independent S0 δn εn independent S0 Sn1 These modeling assumptions lead graphical model directed acyclic graph given Fig 2 The model composed discrete Gaussian variables property conﬁguration discrete variables continuous variables multivariate Gaussian distribution Thus S0 SN T1 TN Y1 YN collectively conditional Gaussian CG distribution 222 C Raphael Artiﬁcial Intelligence 137 2002 217238 Fig 2 The DAG describing dependency structure variables model Circles represent discrete variables squares represent continuous variables Such distributions introduced Lauritzen Wermuth 1819 developed Lauritzen 16 Lauritzen Jensen 17 evidence propagation methodology described enabling computation local marginal distributions Using ideas principle ﬁx Y1 y1 YN yN proceed compute marginal distributions Sn choose estimate Sn sn arg max sS P Sn s Y1 y1 YN yN However computations rely construction triangulated graph strong root The additional edges involved construction strong root leads graph single clique contains entire collection Sn variables 20 The following computations intractable Furthermore guarantee sequence s0 sN reasonable P S0 s0 SN sN Y1 y1 YN yN 0 calling estimate question Rather desire conﬁguration unobserved variables greatest probability given observation Thus y1 yN ﬁxed seek estimate ˆs ˆt arg max st Ls t y 1 Ls t y joint likelihood s s0 sN t t1 tN y y1 yN The computation MAP estimators networks composed entirely discrete variables known 57 In follows demonstrate new methodology exact computation global maximizer ˆs ˆt mixed discrete continuous case 22 Computing rhythmic parse Deﬁne ndimensional Gaussian kernel Kx θ Kx h m Q 2 x nvector h nonnegative constant m nvector Q n n nonnegative deﬁnite matrix Note require Q invertible 2 xmtQxm 1 C Raphael Artiﬁcial Intelligence 137 2002 217238 223 function Kx θ necessarily correspond scaled Gaussian density function We write θ hθ mθ Qθ represent components θ It possible perform number operations Gaussian kernels multiplication kernels maximizing subset variables representing conditional Gaussian distributions performing transformations parameters involved The appendix gives account easily derived results involving Gaussian kernels The joint likelihood function Ls t y y held ﬁxed represented follows We deﬁne L1s0 s1 t1 I s0Rs0 s1N cid4 cid3 t1 θ cid14s0 s1 K cid3 t1 ν φ2 cid3 cid4 N y1 ls0 s1t1 ρ2s0 s1 cid4 3 N µ σ 2 K 2πσ 212 µ 1σ 2 univariate normal density function In Eq 3 θ cid14s0 s1 computed conﬁguration s0 s1 representing conditional density y1 Gaussian kernel y1 t1 Eq A7 eliminating y1 kernel holding ﬁxed Eq A5 multiplying kernels Eq A1 absorbing constants I s0 Rs0 s1 hθ cid14s0 s1 Using notation aj cid4 t n1 1 ai ai1 aj deﬁne cid4 Cnsn1 sn tn1 tn cid3 sn1 0 Ln cid3 0 t n sn Ln1 1 n 2 N Cnsn1 sn tn1 tn cid3 Rsn1 snN cid3 tn1 tn θ c K tn tn1 τ 2sn1 sn cid4 nsn1 sn cid3 cid4 N yn lsn1 sntn ρ2sn1 sn cid4 4 Eq 4 computed representing conditional normal densities Gaussian kernels Eq A7 eliminating yn second density Eq A5 extending second density function tn tn1 Eq A6 multiplying factors Eq A1 absorbing constant Rsn1 sn Note LN sN 1 joint likelihood Ls t y y held ﬁxed vector observations We compute MAP estimate maximizing LN dynamic programming follows 0 t N Deﬁne H1s1 t1 max s0 Hnsn tn max L1s0 s1 t1 cid4 cid3 0 t n sn 1 Ln sn1 0 t n1 1 max sn1 0 t n1 1 cid3 sn1 0 Ln t n1 1 cid4 sn tn n 2 N The fundamental observation dynamic programming compute Hn recursively 224 C Raphael Artiﬁcial Intelligence 137 2002 217238 Hn1sn1 tn1 max 0 t n sn 1 max sn 0 t n 1 max sntn n 1 N 1 cid3 cid4 Ln1 cid3 Ln t n1 1 sn1 0 cid4 Cnsn sn1 tn tn1 0 t n sn 1 Hnsn tnCnsn sn1 tn tn1 5 Consider ﬁrst computation H1s1 t1 computed maxing s0 variable Eq 3 Thus H1s1 t1 max s0 max L1s0 s1 t1 max s0 Kt1 θ1 max t1 θ cid14s0 s1 Kt1 θ1 cid3 K cid4 6 7 θ1 cid5Θ1s1 θ1Θ1s1 cid5Θ1s1 θ cid14s0 s1 s0 S Θ1s1 Thin cid5Θs1 ThinΘ smallest subset Θ Kt θ max θΘ max θThinΘ Kt θ 8 This computation depicted Fig 3 We remark simple matter identify Θ1s1 Thin cid5Θs1 build maximum Eq 6 incrementally adding components cid5Θ1s1 discarding leave maximum unchanged This algorithm precise Section 23 The computational feasibility dynamic programming algorithm follows form Eq 7a maximum Gaussian kernelsis invariant operation Eq 5 That assuming Hnsn tn max Ktn θn 9 θnΘnsn Hn1sn1 tn1 max sntn max sntn Hnsn tnCn1sn sn1 tn tn1 cid3 tn θnKtn tn1 θ c cid3 tn tn1 θ c cid4 cid4 n1sn sn1 n1sn sn1 cid4cid4 n1sn sn1 max θnΘnsn K max snθnΘnsn max snθnΘnsn Ktn θnK cid3 θn θ c max tn cid3 tn1 θ Ktn1 θn1 K 10 11 max θn1 cid5Θn1sn1 max θn1Θn1sn1 going Eq 10 11 computing θ θn θ c Eqs A1 A6 A4 cid5Θn1sn1 preceding given nsn sn1 θn Θnsn sn S cid5Θn1sn1 Ktn1 θn1 cid3 θn θ c cid6 θ cid7 cid4 Θn1sn1 Thin cid5Θn1sn1 This computation depicted Fig 4 nsn sn1 use C Raphael Artiﬁcial Intelligence 137 2002 217238 225 Fig 3 The construction H1s1 t1 Top 9panel The graph s0 s1 position gives Ls0 s1 t1 Middle 3panel Maxing s0 corresponds superimposing graphs column taking maximum shown bold Bottom 3panel The thinning operation removes kernels representation affecting maximum Note middle plot panel composed kernels While comparison Eqs 9 11 suggest Θnsn increases exponentially n growth controlled thinning operation In fact behavior 226 C Raphael Artiﬁcial Intelligence 137 2002 217238 Fig 4 The construction Hn1sn1 tn1 Top 9panel maxtn Hnsn tnCn1sn sn1 depicted The continuous variable tn1 Middle 3panel Maxing sn gives Hn1sn1 tn1 shown bold Bottom 3panel Hn1sn1 tn1 represented fewer kernels thinning observed experiments anticipate typical Θnsn increased manageable number dynamic programming iterations ﬂuctuated number following iterations Details given Section 3 C Raphael Artiﬁcial Intelligence 137 2002 217238 227 221 Recovering optimal parse The maximal value L LN easily computed follows Deﬁne cid8 ΘnS Θnsn snS 12 n 1 N let ˆtN ˆθN arg max tN θΘN S KtN θ computed letting cid3 ˆθN arg max θΘN S arg max max tN hθ θΘN S cid4 KtN θ taking ˆtN m ˆθN Then KˆtN ˆθN max tN max sN tN max sN tN max 0 t N sN 1 max θΘN S max θΘN sN HN sN tN cid4 cid3 0 t N sN 1 LN KtN θ KtN θ Thus KˆtN ˆθN maximal value likelihood function L We wish recover rhythmic parse ˆsN 0 ˆt N 1 attains maximum Considering Eq 11 element θn1 Θn1sn1 generated unique predecessor parent Paθn1 ΘnS That θn ΘnS cid3 θn1 θ θn θ c n1sn sn1 Θn1sn1 cid4 Paθn1 θn Thus trace optimizing sequence parameter values ˆθn Pa ˆθn1 n 0 N 1 Fig 5 Then optimizing sequence measure positions S given ˆsn s ˆθn n 0 N sθn sn θn Θnsn Having identiﬁed ˆtN ˆs0 ˆsN recover optimal ˆt1 ˆtN Hnˆsn tnCnˆsn ˆsn1 tn ˆtn1 Ktn ˆθnK Ktn θn cid3 tn ˆtn1 θ c n1ˆsn ˆsn1 cid4 ˆtn arg max tn arg max tn arg max tn m θn θn computed eliminating ˆtn1 Eq A5 multiplying kernels Eq A1 228 C Raphael Artiﬁcial Intelligence 137 2002 217238 Fig 5 The ﬁgure corresponds situation S 2 parameter values level 0 parameter value 2 child parameters parameter values depicted nodes tree Each parameter θ ΘnS unique parent Paθ optimal sequence parameter values θ0 θN shown solid circles traced leaf root ˆθN marked optimal parameter ﬁgure Terminal nodes tree levels N correspond parameter values pruned thinning algorithm 23 Thinning The computational feasibility dynamic programming algorithm relies thinning operation Section 22 operation complexity representation Hn grows exponentially Recall ThinΘ smallest subset Θ Eq 8 holds When Θ composed parameters onedimensional Gaussian kernels Section 22 algorithm computing ThinΘ straightforward follows Suppose Θ θ 1 θ I Deﬁne ˆθ arg max θθ 1θ Kt θ 1 I note ˆθ t piecewise constant written Nicid9 ˆθ θ k1xi k1t kxi k1 xi 2 xi 1 xi concerned deﬁnition ˆθ points t xi cid10 Clearly ThinΘ Ni xNi1 θ k NI k1 θ I k θ 1 θ We need k maximizer unique Note ˆθ computed iteratively letting ˆθ 1t θ 1 noting ˆθ arg max θ ˆθ i1t θ Kt θ 13 C Raphael Artiﬁcial Intelligence 137 2002 217238 229 ˆθ computed interval xi1 θ i1 k k To simply ﬁnd solutions t quadratic equation xi1 k1 ˆθ i1t cid4 cid4 0 cid3 t θ i1 k cid3 t θ log K log K lie xi1 k1 These points partition interval xi1 xi1 k1 subintervals ˆθ constant need identify ˆθ Eq 13 interior point subintervals Having interval xi1 k1 ﬁnd ˆθ constant neighboring subintervals In case neighbors simply merged form compact representation ˆθ xi1 xi1 14 k k k 231 Constrained optimal parse With minor variation thinning algorithm cases compute constrained optimal parse deﬁned Eq 1 subject tlow tn thigh n 1 N ﬁxed constants tlow thigh This helpful restriction rhythmic parsing problem know tempo positive reasonably restricted maximum value Such constraint increase efﬁciency algorithm decrease number kernels needed represent Hn Eq 9 We proceed follows Deﬁne modiﬁed thinning procedure ThinmΘ minimal subset Θ Kt θ max θΘ max θThinmΘ Kt θ tlow t thigh ThinmΘ constructed thinning algorithm given retaining solutions t Eq 14 satisfy tlow t thigh Next deﬁne H m n sn tn result applying dynamic programming iteration Eq 5 Thinm place original thinning operation Then deﬁne H c n sn tn result constrained optimization employ Eq 5 optimize tlow tn thigh The computation H c n considerably difﬁcult H m n Hn operation maxing easily adapted constrained case H c n welldeﬁned lead optimal constrained parse We cases obtain constrained optimal parse computing H c n It easily seen induction n H m n sn tn cid1 H c n sn tn tlow tn thigh H c nsn tn achieved optimizing subset real line entire real line modiﬁed thinning operation Thinm 0 ˆt N affect values H m 1 algorithm Section 22 modiﬁed thinning procedure ﬁnd tlow ˆtn thigh n 1 N cid3 N ˆsN ˆtN The ﬁrst equality immediate second inequality follows tlow ˆtn thigh value LN ˆsN 1 clearly achieved constrained optimization n sn tn inside tlow thigh However construct ˆsN N ˆsN ˆtN LN 0 ˆt N ˆsN 0 ˆt N H c H m 15 cid4 1 230 C Raphael Artiﬁcial Intelligence 137 2002 217238 surpassed Eq 15 Thus ˆsN 0 ˆt N 1 constrained optimal solution H c N ˆsN ˆtN H m tlow tN thigh sN N ˆsN ˆtN cid1 H m N sN tN cid1 H c N sN tN While guarantee condition tlow ˆtn thigh hold n 1 N condition satisﬁed nearly experiments performed Furthermore reasonable expect solution ˆsN 1 constructed nearly satisﬁes tlow tn thigh nearly constrained optimal solution The computational advantage seeking constrained optima demonstrated following section 0 ˆt N 3 Experiments We performed experiments different data sets derived audio data taken MIDI performance 31 Schumann Romance data The ﬁrst data set derived performance ﬁrst section Schumanns 2nd Romance Oboe Piano oboe excerpt depicted Fig 1 The original data heard httpfafnermathumassedurhythmic_parsing sampled audio signal inappropriate experiments Instead extracted sequence 129 note onset times data HMM methodology described 22 These data available web page In performance excerpt tempo changes freely necessitating simultaneous estimation rhythm tempo Since musical score excerpt available extracted complete set possible measure positions cid1 S 0 1 1 8 1 4 1 3 3 8 5 12 15 32 1 2 5 8 3 4 7 8 cid11 The position 1532 corresponds grace note modeled 32nd note coming 3rd beat 44 time The crucial parameters model compose transition probability matrix R The extreme choices R uniform transition probability matrix Runifs s cid14 1S matrix ideally suited particular recognition experiment Rideals scid14 n Sn s Sn1 scid14 n Sn s Rideal unrealistically favorable experiments choice R optimal recognition purposes incorporates information normally unavailable Runif C Raphael Artiﬁcial Intelligence 137 2002 217238 231 unrealistically pessimistic employing prior information whatsoever The actual transition probability matrices experiments convex combinations extremes R αRideal 1 αRunif constants 0 α 1 A intuitive description effect particular α value perplexity matrix produces PerpR 2H R H R log2 entropy corresponding Markov chain Roughly speaking transition probability matrix perplexity M corresponding Markov chain indeterminacy chooses randomly M equally likely possible successors state The extreme transition probability matrices cid3 Perp cid3 Perp cid4 Rideal cid4 Runif 192 11 S In experiments chose initial distribution I s0 uniform assuming starting measure positions equally likely The remaining constants ν φ2 τ 2s scid14 ρ2s scid14 chosen experimentation In particular modeled τ 2s scid14 β1ls scid14 ρ2s s β2ls s cid14 cid14 values ν φ2 β1 β2 set hand The computational feasibility approach relies representation Hn Eq 9 staying manageably small n increases The left panel Fig 6 shows evolution ΘnS n 0 128 PerpR 4 The ﬁgure shows results basic algorithm presented Section 23 constrained version discussed Section 231 In version constrained tempo variables lie 1 5 corresponding range 48240 beats minute composers tempo marking 104 beats minute Both versions complexity representation Hn grow n increases The average number kernels representation Fig 6 Left The number Gaussian kernels necessary represent Hn ΘnS function n Right The number errors produced different perplexities different numbers errors corrected 232 C Raphael Artiﬁcial Intelligence 137 2002 217238 cid2 Hnsn tn unconstrained case 128 n0 ΘnS129 S 422 constrained case 959 The rhythmic parsing problem pose based solely timing information Even aid pitch interpretive nuance trained musicians occasionally difﬁculty parsing rhythms For reason terribly surprising parses contained errors However virtue approach parses incrementally improved allowing user correct individual errors These corrections treated constrained variables subsequent passes recognition algorithm Due global nature recognition strategy correcting single error ﬁxes parse errors automatically Such technique useful sophisticated music recognition unrealistic hope achieve necessary degree accuracy aid human guide In Fig 6 number errors produced experimental conditions The traces plot correspond perplexities 2 4 6 8 individual trace gives number errors produced recognition correcting 0 7 errors In pass ﬁrst error previous pass corrected In case able achieve perfect parse correcting 7 fewer errors Fig 6 demonstrates recognition accuracy improves decreasing perplexity showing signiﬁcant beneﬁt results transition probability matrix wellsuited actual test data The experiments depicted Fig 6 performed tn constrained line 1 5 constrained thinning algorithm Section 231 Over experiments 129 8 4 4128 estimated tempo variables slightly outside range Thus parses exact constrained MAP estimates likely good approximations 32 Chopin Mazurka data In considerably ambitious example parsed MIDI performance Chopin Mazurka Op 6 No 3 solo piano Unlike monophonic instrument previous example piano play notes single score position Thus simultaneous notes corresponding transitions form Sn Sn1 possible occur frequently For example 34 time took possible measure positions actual score giving set cid1 S 0 1 1 24 1 12 1 9 1 6 2 9 1 4 1 3 1 2 13 24 7 12 2 3 5 6 11 12 23 24 cid11 Again measure positions correspond grace notes Rather ﬁxing parameters model hand instead estimated actual data The transition probability matrix R estimated scores different Chopin Mazurkas simply counting transitions data smoothing resulting conditional distributions The result transition probability matrix having PerpR 202 providing model greatly improved predictive power uniform transition model having perplexity PerpR S 15 C Raphael Artiﬁcial Intelligence 137 2002 217238 233 We learned variances model τ 2s scid14 ρ2s scid14 different MIDI Mazurka performance known score clamping variables S0 SN known values Once discrete variables ﬁxed model consists entirely Gaussian variables familiar techniques Kalman Smoother methods Bayesian networks estimate posterior distributions δn εn variables given observed data y1 yN We EM algorithm iterate forth computation posterior distribution reestimation desired variances To smooth estimates modeling assumptions cid14 τ 2 τ 2s s ρ2s scid14 ρ2 cid14 cid3 cid3 Q cid3 ls s cid3 ls scid14 Q cid4cid4 cid4cid4 Q function quantizes transition lengths small number categories In addition slight variation model presented Section 21 includes MIDI pitch note observable variable In particular assume given measure position Sn MIDI pitch nth note conditionally independent variables model In intention capitalize relationship measure position pitch For instance Mazurka beginning measure usually marked low note The conditional distributions pitch given measure position learned Mazurka scores binning pitch measure position small number categories smoothing empirical distributions Fig 7 Results rhythmic parses Chopin Mazurka Op 6 No 3 234 C Raphael Artiﬁcial Intelligence 137 2002 217238 With extended automatically trained model iterated procedure parsing data ﬁxing error beginning longest run consecutive errors The results experiments 1334note data set shown Fig 7 The actual MIDI performance heard httpfafnermathumassedurhythmic_parsing We couple corrections error rate 23 range We remark error rate slightly misleading arbitrary rhythmic notation grace notes render ground truth somewhat arbitrary Many errors occurred grace notes 4 Discussion We presented method simultaneous estimation rhythm tempo given sequence note onset times Our method assumes collection possible measure positions given advance We believe assumption relatively simple way limiting complexity recognized rhythm produced algorithm When arbitrary rhythmic complexity allowed penalty ﬁnd rhythm arbitrarily accurate match observed time sequence Thus expect approach rhythm recognition need way limit penalize rhythmic complexity Other collection possible measure positions parameters model learned actual data Section 32 Our experience R matrix represents prior assumptions rhythm sequences contains important parameters model The estimation matrix requires set training data matches rhythmic content test data For example expect successful results trained model 44 time movements Beethovens piano sonatas recognized Madonnas Material Girl In experiments Chopin Mazurka Section 32 training data wellmatched test data examples genre composer It likely precise match training test prove workable Another possibility estimate model parameters onlinehowever initial experiments direction produced signiﬁcant beneﬁt In experiments possible perform dynamic programming calculations representation remained bounded complexity described left panel Fig 6 We note behavior guaranteed kernels small variance highly dispersed thinning procedure produce decrease complexity Hn necessary calculations feasible However anticipate behavior observed rule exception The experiments presented deal estimating composite rhythm obtained superimposing parts A disadvantage approach composite rhythms complicated individual voices simple repetitive rhythmic structure For instance consider case voice uses triple subdivisions use duple subdivisions A possible extension simultaneous estimation rhythm tempo voicing That model observed data superposition independent rhythmic sources seek C Raphael Artiﬁcial Intelligence 137 2002 217238 235 separate sources recognize rhythm tempo Rhythm voicing collective constitute lions share needs automatic transcription MIDI data 5 Generalization While methodology Section 2 developed particular graphical model Fig 2 ideas extend arbitrary graphical models conditional Gaussian distributions While complete description generalization scope paper sketch extension A complete description work 23 A mixed collection discrete continuous variables X conditional Gaussian CG distribution conﬁguration discrete variables conditional distribution continuous variables multivariate Gaussian 1819 We assume representation CG distribution terms DAG discrete nodes continuous parents If components X observed factor conditional density remaining unobserved variables XU cid12 f xU φCxC CC 16 C cliques junction tree potential functions φCxC depend indicated variables When C contains continuous variables φC shown form φC xC K cid3 xΓ C θ xC cid4 17 Γ C C index continuous discrete variables C Otherwise φC usual discrete potential The idea dynamic programming extended linear graph structure encountered Section 2 maximize function form Eq 16 clique potentials Eq 17 In context deﬁne cid12 HCxC max xUC φcid5C xcid5C cid5Ccid1C cid5C C C lies unique path cid5C root junction tree tree grows downward Then HC computed recursively dynamic programming iteration HCxC φC xC cid12 Scid5C C max xcid5CS Hcid5Cxcid5C 18 C cid5C C S cid5C mean C cid5C neighboring cliques separated S 236 C Raphael Artiﬁcial Intelligence 137 2002 217238 As Section 2 speciﬁc functional form represent HC functions dynamic programming recursion Suppose C continuous components consider form HCxC max θΘxC KxΓ C θ 19 HC nonnegative function xC discrete components The terminal cliques clearly HC form maximum single Gaussian kernel Furthermore child cliques C representation Eq 18 leads similar representation HC Having computed HCr root clique Cr easily trace calculations ﬁnd optimal conﬁguration ˆxU While methodology presented Section 2 extends straightforward manner general domain CG distributions notable exception The computation Eq 19 involves thinning operation Eq 8 collection kernels consider necessarily onedimensional Thus algorithm Section 23 inherently onedimensional applied We anticipate smarter algorithm compute approximate thinning operation higher dimensions The development algorithm missing link proposed methodology fully general approach ﬁnding MAP estimates unobserved variables CG distributions Appendix A A Gaussian kernel multivariate function form Eq 2 The following identities hold functions The derivations results straightforward included Multiplication Kx h1 m1 Q1Kx h2 m2 Q2 Kx h m Q A1 1 1Q1m1mt 2 mt h h1h2e m QQ1m1 Q2m2 Q Q1 Q2 2Q2m2mtQm Q generalized inverse Q 1521 We deal nonnegative deﬁnite symmetric matrices case Q expressed Q U DU t Q U DU t U unitary D diagonal D diagonal cid1 D ii 1Dii Dii 0 Dii 0 0 C Raphael Artiﬁcial Intelligence 137 2002 217238 237 Maxing Let m Q partitioned m Q cid14 cid13 cid13 m1 m2 Q11 Q12 Q21 Q22 cid14 Then cid13cid13 cid14 cid14 K max x2 x1 x2 h m Q Kx1 h m1 cid5Q cid5Q Q11 Q12Q 22Q21 A2 A3 A4 In event x1 components maximized variables kernel interpret Kx1 h m1 cid5Q constant h Fixing variables Let m Q partitioned Eqs A2 A3 Regarding x2 ﬁxed cid13cid13 cid14 cid14 K x1 x2 h m Q Kx1 h m cid5Q A5 11Q12x2m2 1 2 x2m2tQ22Q21Q h 11Q12x2 m2 m m1 Q cid5Q Q11 Extension The kernel Kx1 h m Q viewed function x1 x2 cid13cid13 cid14 cid13 cid14 cid13 cid14cid14 Kx1 h m Q K x1 x2 h m 0 Q 0 0 0 A6 Conditional Gaussian densities If x2 αtx1 β ξ x2 univariate ξ Nµ σ 2 conditional density x2 given x1 cid13cid13 cid14 cid14 fvx2 x1 K x1 x2 h m Q A7 cid3 2πσ 2 cid412 h cid13 cid14 0 β µ m Q 1 σ 2 cid13 cid14 ααt α αt 1 238 C Raphael Artiﬁcial Intelligence 137 2002 217238 References 1 P Allen R Dannenberg Tracking musical beats real time Proceedings International Computer Music Conference International Computer Music Association San Francisco CA 1990 pp 140143 2 AT Cemgil Tempo tracking rhythm quantization sequential Monte Carlo Advances Neural Information Processing Systems Vol 14 MIT Press Cambridge MA 2002 3 AT Cemgil B Kappen P Desain H Honing On Tempo Tracking Tempogram representation Kalman ﬁltering J New Music Res 2001 press 4 AT Cemgil P Desain B Kappen Rhythm quantization transcription Computer Music J 24 2000 6076 5 RG Cowell AP Dawid SL Lauritzen DJ Spiegelhalter Probabilistic Networks Expert Systems Springer New York 1999 6 R Dannenberg B MontReynaud Following improvisation real time Proceedings International Computer Music Conference International Computer Music Association San Francisco CA 1987 pp 241248 7 AP Dawid Applications general propagation algorithm probabilistic expert systems Statist Comput 2 1992 2536 8 P Desain H Honing The quantization musical time A connectionist approach Computer Music J 13 3 1989 9 P Desain H Honing Foot tapping A brief introduction beat induction Proceedings International Computer Music Conference International Computer Music Association San Francisco CA 1994 pp 7879 10 P Desain R Aarts AT Cemgil B Kappen H van Thienen P Trilsbeek Robust timequantization music performance score Proceedings 106th Audio Engineering Society Conference Munich 1999 11 S Dixon A beat tracking audio signals Proceedings Diderot Forum Mathematics Music Austrian Computer Society 1999 12 S Dixon A lightweight multiagent musical beat tracking Proceedings AAAI Workshop Artiﬁcial Intelligence Music Towards Formal Models Composition Performance Analysis Austin TX 2000 13 M Goto Y Muraoka An audiobased realtime beat tracking applications Proceedings International Computer Music Conference International Computer Music Association San Francisco CA 1998 pp 1720 14 M Goto Y Muraoka A realtime beat tracking audio signals Proceedings International Computer Music Conference International Computer Music Association San Francisco CA 1995 pp 171174 15 F Graybill Matrices Applications Statistics Wadsworth International Group Belmont CA 1969 16 SL Lauritzen Propagation probabilities means variances mixed graphical association models J Amer Statist Assoc Theory Methods 87 420 1992 10981108 17 SL Lauritzen F Jensen Stable local computation conditional Gaussian distributions Technical Report R992014 Department Mathematic Sciences Aalborg University 1999 18 SL Lauritzen N Wermuth Mixed interaction models Technical Report R848 Institute Electronic Systems Aalborg University 1984 19 SL Lauritzen N Wermuth Graphical models associations variables qualitative quantitative Ann Statist 17 1989 3157 20 U Lerner R Parr Inference hybrid networks Theoretical limits practical algorithms Proceedings Seventeenth Conference Uncertainty Artiﬁcial Intelligence UAI 2001 Seattle WA Morgan Kauffman San Mateo CA 2001 pp 310318 21 CR Rao SK Mitra Generalized Inverse Matrices Applications Wiley New York 1971 22 C Raphael Automatic segmentation acoustic musical signals hidden Markov models IEEE Trans Pattern Anal Machine Intelligence 21 4 1999 360370 23 C Raphael Map estimation unobserved variables conditional Gaussian distributions J American Statist Assoc 2001 submitted 24 P Trilsbeek H van Thienen Quantization notation Methods commercial music software 106th Audio Engineering Society Conference Munich 1999