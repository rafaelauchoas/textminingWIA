Artiﬁcial Intelligence 173 2009 13431366 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Data reductions ﬁxed parameter tractability random weighted dCNF satisﬁability Yong Gao Department Computer Science Irving K Barber School Arts Sciences University British Columbia Okanagan Kelowna Canada V1V 1V7 r t c l e n f o b s t r c t Article history Received 19 December 2008 Received revised form 11 June 2009 Accepted 13 June 2009 Available online 17 June 2009 Keywords Weighted CNF satisﬁability Fixed parameter tractability Data reduction Random instances Phase transitions Probabilistic analysis Resolution complexity Data reduction key technique study ﬁxed parameter algorithms In AI literature pruning techniques based simple eﬃcienttoimplement reduction rules play crucial role success industrialstrength solvers Understanding effectiveness applicability data reduction technique designing heuristics intractable problems main motivations studying phase transition randomlygenerated instances NPcomplete problems In paper initiative study power data reductions context random instances generic intractable parameterized problem weighted dCNF satisﬁability problem We propose nontrivial random model problem study probabilistic behavior random instances model We design algorithm based data reduction algorithmic techniques prove algorithm solves random instances high probability ﬁxedparameter polynomial time O dknm n number variables m number clauses k ﬁxed parameter We establish exact threshold phase transition solution probability region problem space unsatisﬁable random instances problem parametric resolution proof ﬁxedparameter polynomial size Also discussed general random model generalization results model 2009 Elsevier BV All rights reserved 1 Introduction The theory parameterized complexity ﬁxedparameter algorithms active research area recent years 2446 Parameterized complexity provides new perspective hard algorithmic problems ﬁxedparameter algorithms applications variety research ﬁelds Parameterized problems arise areas artiﬁcial intelligence AI research including satisﬁability automated reasoning logic programming constraint programming probabilistic inference 8104748 We refer reader 3435 thorough survey recent literature Data reduction key technique designing eﬃcient algorithms ﬁxed parameter tractable problems 3746 exact exponentialtime branchandreduce algorithms known searchtree method NPhard problems 27 In areas AI pruning techniques based simple eﬃcienttoimplement reduction rules widely notably satisﬁability testing constraint processing backtracking interleaved use highly eﬃcient implementation unit propagation consistency propagation played key role success Part results appeared Proceedings AAAI08 Y Gao Phase transitions complexity weighted satisﬁability intractable parameterized problems Proceedings 23th AAAI Conference Artiﬁcial Intelligence AAAI08 2008 pp 265270 28 The research supported National Science Engineering Research Council Canada NSERC RGPIN 32758706 RGPIN 32758709 Email address yonggaoubcca 00043702 matter 2009 Elsevier BV All rights reserved doi101016jartint200906005 1344 Y Gao Artiﬁcial Intelligence 173 2009 13431366 industrialstrength solvers heuristic state space search heuristic function usually employed reduce search space The power data reductions demonstrated empirically NPhard problems intractable parameterized problems clique cover 36 dominating set 4 road network related problem 50 Hamiltonian cycle 49 Experiments revealed simple data reduction rules usually better performance predicted theoretical analyses 113640 Despite success stories understanding effectiveness applicability data reduction technique designing heuristics intractable problems far complete The continued past years study phase transition phenomenon random instances NPcomplete problems largely motivated expectation study help shed lights simple heuristics work typical problem instances situations See 1714192030333851 references Recently problem detecting backdoor sets attracted attention The existence smallsized backdoors naturally leads eﬃcient algorithms problems hard solve While backdoor detection problem NPcomplete andor ﬁxedparameter intractable types backdoors practical SATsolvers able exploit existence small sized backdoors effectively 2348 In work initiative extend line research phase transitions intractable parameterized prob lems We hope current work ﬁxedparameter tractability random instances intractable parameterized problems previous work typicalcase behavior random NPcomplete problems help shed light power datareduction based heuristics hardness detecting smallsized backdoors We study random instances weighted dCNF satisﬁability problem WEIGHTED dSAT1 An instance F k problem consists dCNF formula F ﬁxed parameter k 0 The question decide satisfying assignment Hamming distance k allzero assignment A random instance weighted dCNF satisﬁability n Boolean variables consists ﬁxed parameter k random dCNF formula F np kd generated follows subset d variables probability p pn clause d variables selected uniformly random set 2d 1 possible clauses contain negated literal This random model CNF formulas similar random models study standard propositional satisﬁability problem Due recent result Marx 41 complexity parameterized Boolean constraint satisfac tion problems forbidding clauses contain positive literals restriction far parameterized tractability concerned A detailed argument given Section 2 We discuss general model F np We design analyze algorithm based data reduction algorithmic techniques It shown algorithm solves random instances F np kd high probability ﬁxedparameter polynomial time O dknm n number variables m number clauses formula We establish exact threshold phase transition solution probability region problem space unsatisﬁable random instances problem parametric resolution proof ﬁxedparameter polynomial size The results obtained paper complete characterization typicalcase behavior random instances WEIGHTED dSAT cid2 1 d negated literals forbidden Except exact threshold phase transition complexity typical instances certain range p model pose interesting challenge researchers areas AI theoretical science To best knowledge author work ﬁrst literature ﬁxedparameter tractability random instances intractable parameterized problems We expect proposed random models analysis help facilitate future studies parameterized problems backdoor detection problem solution space geometry standard satisﬁability problem design effective neighborhood operators local search algorithms cid2 d clauses containing d kd d cid2 11 Main results Throughout paper use n number Boolean variables m number clauses d clause size CNF formula We use k parameter WEIGHTED dSAT problem The symbol p pn reserved clause probability c constant usually appearing expression p All logarithms paper natural logarithms base e The main results paper include 1 algorithm analysis showing instances random distribution F np cally ﬁxedparameter tractable clauseprobability pn particularly p c log n 2 exact threshold phase transition F np kd 3 results parametric resolution complexity random unsatisﬁable instances 4 extension results general model F np cid2 kd d kd WEIGHTED dSAT typi nd1 c 0 constant 1 In AI literature k usually clause size Unfortunately study parameterized algorithms k reserved parameter We decide use k parameter use d clause size Table 1 The behavior random instances F np unknown c threshold corresponding model kd A mark Y Gao Artiﬁcial Intelligence 173 2009 13431366 1345 indicates case completely resolved A question mark indicates case completely Parameters Threshold FPT d 2 d 2 d 2 d 2 d 2 d 2 Th 2 Th 2 Th 2 Th 2 NA Th 5 WEIGHTED dSAT F np kd Th 1 Th 1 Renormalized version WEIGHTED dSAT F np kd WEIGHTED dSAT F np kd d cid2 1 d c c c kc Th 4 Corol 11 cid2 d NA c 2c Th 6 NA c 2d cid2k d cid22c Th 6 FPT Proof size Th 4 c 2k2c Th 3 c c Th 4 Theorem 1 There O dknmtime algorithm solves high probability random instance F np p pn cid2 1 m number clauses formula kd k WEIGHTED dSAT The term dk theorem fact need solve subproblems equivalent parameterized d 1hitting set problem In case d 2 term dk replaced k As proof Theorem 1 indicates variable involved l clauses term dk replaced 2ld running time bruteforce method relevant subproblems Depending relation l k n bounds worse O dk case pn Ω k log n nd1 better O dk case pn cid2 log n nd1 For random instances renormalized version WEIGHTED dSAT 46 question ﬁnd satisfying assignment weight k log n algorithm theorem works clause probability pn certain range Corollary 11 There O dknm algorithm solves high probability random instance F np WEIGHTED dSAT p c log n nd1 c k2d 1d 1 kd k renormalized version To clear picture behavior random instances F np kd helpful understand phase transition solution probability We establish following exact threshold phase transition Note threshold depend ﬁxed parameter k somewhat surprising Theorem 2 Let p c log n nd1 c 0 constant Consider random instance F np kd k WEIGHTED dSAT We cid2 P lim n F np kd satisﬁable cid4 cid3 1 0 c c c c 11 c 2d 1d 1 For case d 2 d 3 thresholds respectively c 3 c 14 For unsatisﬁable instances clear algorithm Theorem 1 simulated resolution proof But similar idea lead following Theorem 3 Let p c log n resolution proof size O dkn constructed O dkn O 1 time nd1 c 2k22d 1d 1 With high probability random instance F np kd k WEIGHTED dSAT For case WEIGHTED 2SAT renormalized version random unsatisﬁable instances shown resolution proof size O kn Theorem 4 For F np n constructed O kn O 1 time k2 p 3log nc1 log log n c1 1 parametric resolution proof size O kn exists high probability In Table 1 summarize results obtained paper behavior F np kd 1346 12 Outline Y Gao Artiﬁcial Intelligence 173 2009 13431366 The section contains preliminaries detailed description random model F np kd related work In Section 3 present details ﬁxedparameter algorithm WSAT In Section 4 prove algorithm WSAT succeeds high probability random instances WEIGHTED dSAT In Section 5 establish exact threshold phase transition solution probability In Section 6 prove results resolution complexity random instances WEIGHTED dSAT In Section 7 discuss algorithm analysis extended random instances cid2 results renormalized version WEIGHTED dSAT In Section 8 discuss generalized model F np threshold resolution complexity In section conclude discuss directions future work Some necessary lemmas proof included appendices interesting right kd d 2 Preliminaries random models related work 21 Parameterized complexity An instance parameterized decision problem 2446 pair I k I problem instance k ﬁxed problem parameter Usually parameter k speciﬁes size desired solution related structural property underlying problem treewidth graph For example instance I k parameterized vertex cover problem I graph k size vertex cover The question decide I vertex cover size k Whereas ﬁxed k vertex cover problem solved bruteforce O nk time theory parameterized complexity concerned algorithm worstcase running time avoids exponential dependency problem size n parameter k A parameterized problem ﬁxedparameter tractable FPT algorithm solves instance I k f kIO 1 time f k computable function depends k For example known parame terized vertex cover problem FPT solved O 128k kn time n number vertices graph 46 Parameterized problems interrelated parameterized reductions resulting classiﬁcation parameterized prob lems hierarchy complexity classes FPT W1 W2 XP At lowest level class FPT problems The class W1 contains parameterized problems reduced weighted 2CNF satisﬁability problem deﬁned subsection The level XP contains problems solved time f kngk It widely believed containment strict notion completeness deﬁned parameterized reductions 2446 Unless FPT W1 likely algorithm WEIGHTED dSAT d cid3 2 eﬃcient O nktime bruteforce algorithm enumerates assignments It shown recently stronger assumption unlikely solve WEIGHTED dSAT time nok 16 It proved P NP implies FTP W1 cid5 n k cid6 22 Weighted CNF satisﬁability problem As theory NPcompleteness satisﬁability problem plays important role theory parameter ized complexity A CNF formula set Boolean variables conjunction disjunctions literals A dclause disjunction dliterals A dCNF formula CNF formula consists dclauses Deﬁnition 21 An assignment set n Boolean variables vector TRUE FALSEn The weight assignment number variables set TRUE assignment It convenient identify TRUE 1 FALSE 0 Thus assignment regarded vector 0 1n weight assignment Hamming distance allzero assignment A representative W 1complete problem following weighted dCNF satisﬁability problem 46 Problem 1 WEIGHTED dSAT Instance A CNF formula consisting collection dclauses Parameter A positive integer k Question Is satisfying assignment weight k Unlike situation standard satisﬁability problem WEIGHTED dSAT W1complete d 2 consequently intractable perspective parameterized complexity It recent consider renor malization parameterized problem The renormalized version WEIGHTED dSAT follows 46 Y Gao Artiﬁcial Intelligence 173 2009 13431366 1347 Problem 2 MINIWEIGHTED dSAT Instance A CNF formula consisting collection dclauses Parameter A positive integer k Question Is satisfying assignment weight k log n 23 Parameterized proof systems parameterized DPLL algorithms The study parameterized proof complexity weighted CNF satisﬁability recently initiated Dantchev et al 22 established lower bounds parameterized resolution proof CNF formulas encode ﬁrst order combinatorial principle A formal deﬁnition parameterized treelike resolution proof weighted CNF satisﬁability given 22 Basically parameterized resolution instance coW2 problem regarded classical resolution access free clauses k negated variables k parameter weighted satisﬁability For instances coW1 complete problem need free access clauses contain n k positive literals contradiction coW1 complete problem WEIGHTED dSAT formula doesnt satisfying assignment weight exactly k Accordingly consider parameterized version DPLL algorithm satisﬁability problem It proceeds way standard DPLL algorithm exception node search tree fails 1 clause falsiﬁed partial assignment 2 k variables assigned true partial assignment 24 Random models WEIGHTED dSAT We use Gn p denote ErdösRényi random graph 12 n number vertices p edge prob cid5 edges appears independently probability p A random hypergraph Gn p d n ability possible cid6 cid5 2 n possible hyperedges appears independently probability p Throughout paper hypergraph d high probability abbreviated whp mean probability event consideration 1 o1 n goes inﬁnity cid6 We working following random model WEIGHTED dSAT The model similar spirit known random models study standard constraint satisﬁability See 303344 references Deﬁnition 22 Let X x1 xn set Boolean variables p pn function n k d positive constants The random model F np kd WEIGHTED dSAT deﬁned follows To generate instance F np kd ﬁrst construct random hypergraph Gn p d X vertex set For select dclause uniformly random set 2d 1 nonmonotone dclauses deﬁned A monotone clause clause contains positive literals hyperedge xi1 xid variables xi1 xid Note monotone clauses forbidden F np note range clause probability primarily interested pn c log n nd1 explain following rationale kd allzero assignment satisfying assignment Also constant c 0 We 241 WEIGHTED dSAT instances reduce instances monotone clauses forbidden In 41 Marx studied complexity general parameterized Boolean constraint satisfaction problems calls WEIGHTED F SAT He proved F SAT ﬁxedparameter tractable variable bounded number occurrences constraints weakly separable In mean time Marx showed W1completeness case implication clause x y type constraints In proving results Marx observed suﬃcient consider constraints 0valid constraints satisﬁed allzero assignment We state following Marxs observation terms WEIGHTED dSAT Lemma 21 See Lemma 41 Marx 41 An instance F k WEIGHTED dSAT reduced dk WEIGHTED dSAT instances monotone clauses forbidden In view lemma believe F np kd natural model captures essential characteristics WEIGHTED dSAT instance We remark clauseprobability pn cid3 c log n constant c case discussed paper nd1 number variables bounded number occurrences o1 whp Marxs result 41 ﬁxed parameter tractability F SAT bounded variable occurrences apply random instances dealing 1348 Y Gao Artiﬁcial Intelligence 173 2009 13431366 242 Relation planted models standard SAT Even random instance F np kd allzero assignment planted solution sense standard satisﬁability WEIGHTED dSAT asks weightk satisfying assignment satisfying assignment Ham ming distance exactly k allzero assignment This major difference WEIGHTED dSAT instances considered paper standard SAT instances hidden solutions studied literature See example 13851 references 243 Trivial random instances We note forbidding monotone clauses pn o log n nd1 random instances WEIGHTED dSAT trivial This proved simple randomgraph arguments We state following observations proof Appendix C Lemma 22 1 If F np kd monotone clauses forbidden whp exist k disjoint monotone clauses pn extremely small Consequently random instance unsatisﬁable whp 2 If pn c log n nd1 c small constant2 pn o log n kd trivially satisﬁable existence large number variables x isolated sense x appear negated literal clause want positive pure literals Simply setting k positive pure literals TRUE remaining variables FALSE gives weightk satisfying assignment nd1 random instances F np 25 Relation random models dCNF formulas In study phase transition standard CNF satisﬁability problem slightly different random models The widelystudied model F n m n Boolean variables m clauses selected cid5 n d cid6 2d possible clauses uniformly random replacement A common aspect models range m likelihood extremely low random formula contain clauses set d variables To convince reader brieﬂy following case Let C1 C2 Cm m clauses selected replacement uniformly random cid6 2d possible clauses Then cid9 j probability Ci C j deﬁned set d variables cid5 n d 2d cid6 cid5 n d The expected number pairs clauses set d variables cid8 cid7 m 2 2d cid6 cid5 n d d 2 d 2 probability clauses F n m set By Markovs inequality m d variables asymptotically zero cid6 cid5 n 2 In paper study random model F np In theory random graphs closely related random models Gn p Gn m In Gn p edges appears independently probability p In Gn m m edges selected uniformly random cid6 possible replacement It turns situations pleasant work model Gn p cid5 n d possible subsets d variables appears formula probability p The decision focus model largely technical convenience Since properties concerned paper including satisﬁability existence kfrozen variables size connected components CNF formula monotone regard model F np clauses selected uniformly random equivalent case random graphs Theorem 22 12 kd exactly 2d 1 clauses deﬁned kd model p cid5 n d cid6 The fact models clauses set variables rarely appear limi tation This reasons study probabilistic behavior standard CNF formulas researchers study random models socalled generalized satisﬁability problem set randomly selected variables clauses selected We believe results similar paper obtained random instances generalized satisﬁability problem constraint satisfaction problem 2 For case d 2 c 3 2 26 Residual graphs CNF formulas induced formulas Y Gao Artiﬁcial Intelligence 173 2009 13431366 1349 Associated CNF formula residual graph known Gaifman graph set variables involved formula There edge variables occur clause The residual graph random instance F np kd primal graph3 random hypergraph Gn p d k2 exactly random graph Gn p The residual graph random instance F np By connected component CNF formula F mean maximal subformula F cid2 connected component residual graph CNF formula F Let F dCNF formula V X subset variables The induced formula FV V deﬁned CNF residual graph F cid2 formula FV consists following types clauses 1 clauses F involve variables V 2 clauses size 2 obtained removing literal corresponding variable X V Note case 2CNF formulas FV contains clauses ﬁrst type In deﬁnition induced formula V include induced unit clauses clauses size 1 obtained removing literal corresponding variable X V This makes easier clear algorithm analysis For details proof Theorem 1 end Section 4 27 Related work There extensive literature study phase transitions random instances NPcomplete problems implication design heuristics practical solvers polynomialtime algorithms solve random instances whp 21930334344 The threshold behavior random CNF satisﬁability general constraint satisfaction problems graph coloring random graphs attracted lot attention determining exact threshold phase transitions remains challenging open problem 2 There empirical studies power data reduction heuristic hard problems different settings Here mention examples motivated study phase transitions random problem instances In 49 backtracking algorithm reduction rules based local vertex degree information shown able solve random instances Hamiltonian cycle problem phase transitions easily One important observations study phase transition hard problems existence backbone variables variable value ﬁxed optimal solutions 132145 Whereas identifying backbone variables easy task shown 52 statistical information backbone variables utilized guide variable selection local search algorithms obtain great performance improvement There recent designing whp polynomialtime algorithms random instances planted solutions aka hidden solutions 515182639 random instances planted solutions empirical studies 13851 In 30 random instances constraint satisfaction problem designed include hidden consistency core planted solution Weighted CNF satisﬁability generic intractable parameterized problem In addition work Marx 41 mentioned previous subsection work motivated current research random instances intractable parameterized problems include study parameterized proof complexity weighted CNF satisﬁability recently initiated Dantchev et al 22 study backdoor set detection problem parameterized complexity recent AI literature 234748 In current work initiative extend lines research random instances intractable parameter ized problems To best knowledge author ﬁrst work literature studies ﬁxedparameter tractability random instances W1complete problem 3 A ﬁxedparameter algorithm instances F np kd In section present details algorithm random instances F np kd analyze time complexity The results section section prove Theorem 1 31 General idea The algorithm WSAT major steps The ﬁrst step data reduction step second step solves reduced formula enumeration dynamic programming 3 The primal graph hypergraph graph pair vertices edge vertices appear simultaneously hyperedge 1350 Y Gao Artiﬁcial Intelligence 173 2009 13431366 311 STEP 1 Data reduction We use data reduction rule similar Busss reduction vertex cover 2446 If variable x appears set l cid3 k clauses form x y11 y1d1 x y21 y2d1 x yl1 yld1 set monotone clauses y11 y1d1 y21 y2d1 yl1 yld1 satisfying assignment weight k 1 set x FALSE The correctness rule obvious For WEIGHTED 2SAT rule implemented O n2 time count number clauses form x y For WEIGHTED dSAT d 2 later O dknmtime algorithm implements reduction correctly Unlike case vertex cover reduction rule result reduced formula ﬁxed size course expected 312 STEP 2 Connected components dynamic programming We use observation reduced formula ﬁxed size breaks connected components contains log n variables Section 4 devoted proving observation Let Fi 1 cid2 cid2 N N cid2 n collection connected components reduced formula For connected assignment component Fi use bruteforce ﬁnd set integers Li k variables Fi satisﬁes Fi cid2 Li weightk cid2 Finally O k2ntime dynamic programming algorithm ﬁnd collection k positive integers cid4 ki j 1 cid2 j cid2 k Li j ki2 kik ki j ki1 k 313 A remark A typical criticism scheme structure random instance distribution design algorithms heuristics We argue algorithms especially eﬃcient ones designed exploiting special problem structures way optimal subproblem structures restricted graph classes restricted parameter size Our algorithm analysis exactly demonstration kind structures appear typical random instance intractable problem exploited reduction rules similar led eﬃcient algorithms tractable problems We note similar structures exploited studies notably N Alon N Kahales seminal work algorithms coloring random 3colorable graphs 5 followups 15182639 In authors previous work 29 similar connectedcomponent structure arises different setting 32 Deﬁnitions kfrozen variables We formalize concepts mentioned Section 31 description analysis algorithm Deﬁnition 31 Let F k instance WEIGHTED dSAT F dCNF formula k parameter Consider variable x collection subsets variables Y Y 1 cid2 cid2 l Y yi j 1 cid2 j cid2 d 1 subset X x We collection Y freezes x following conditions satisﬁed 1 1 cid2 cid2 l clause x yi1 yid1 formula F 2 set clauses yi1 yid1 1 cid2 cid2 l satisfying assignment weight k 1 The variable x said kfrozen respect subset V variables frozen collection subsets variables Y 1 cid2 cid2 l Y V 1 cid2 cid2 l A variable kfrozen respect set variables simply called kfrozen variable Y Gao Artiﬁcial Intelligence 173 2009 13431366 1351 It obvious kfrozen variable set TRUE satisfying assignment An important observation study random instances NPcomplete problems existence frozen variables known backbone variables 132145 Even detecting backbone variables usually task easier solving original satisﬁability problem information backbone variables utilized guide variable selection heuristics search algorithms 52 The concept frozen variable respect partial assignment concept core set frozen variables study geometric structure solution space phase transitions 3 Similar concepts play important role study random CNF formulas planted solution 182639 Our notion kfrozen variables viewed ﬁxedparameter generalization stronger version concept backbone variables A kfrozen variable forced value satisfying assignments variable forced value satisfying assignments necessarily kfrozen As later unlike general backbone variables kfrozen variables detected eﬃciently For 2CNF formulas variable x kfrozen needs count number clauses form x y For dCNF formulas d 2 kfrozen variables detected O dknmtime algorithm In analysis probabilistic behavior algorithm Section 4 use stronger notion kfrozenness We variable x dCNF formula F strongly kfrozen4 collection k clauses x yi1 yid1 1 cid2 cid2 k F Y yi1 yid1 1 cid2 cid2 k variabledisjoint subsets A strongly kfrozen variable obviously kfrozen The chief reason focus strongly kfrozen variables clear achieve better bounds relevant probabilities considering kfrozen variables We note task deciding strongly kfrozen variable equivalent d 1dimensional matching problem NPcomplete d cid3 4 polynomial solvable d 2 3 k input For ﬁxed k dealing paper d 1dimensional matching problem ﬁxed parameter tractable currently best algorithms exponential dependency parameter k worse straightforward bounded searchtree algorithm parameterized hitting set problem 1725 The following concept necessary description algorithm Deﬁnition 32 Let F CNF formula We use LF denote set integers 0 k k satisfying assignment weightk F cid2 cid2 LF 33 The algorithm WSAT time complexity The algorithm described Algorithm 1 We explain purpose subroutine REDUCE subsec tion Lemma 31 There O dk Ltime algorithm checks variable x kfrozen L number clauses contain x The running time O n2 2CNF formula Proof Consider set clauses x negated literal x yi1 yid1 1 cid2 cid2 l According deﬁnition x kfrozen collection subsets yi1 yid1 1 cid2 cid2 l hitting set5 size k 1 solved bounded search tree method time O dk L branches element subset 46 In case 2CNF formulas needs count number clauses form x y x kfrozen cid2 We remark random instances F np nd1 lemma necessary shown Chernoff inequality Markov inequality whp variable appears c log n clauses Consequently bruteforce search check kfrozen variables runs O ncm time Lemma 31 necessary order deal case p Ω nd1cid3 cid3 0 avoid exponential dependency c running time kd p c log n 1 We algorithm WSAT runs ﬁxedparameter time correct returns satisfying assignment reports UNSAT Proposition 31 The algorithm WSAT correct returns satisfying assignment reports UNSAT The running time WSAT O dknm pn cid2 1 m number clauses dCNF formula Proof Since kfrozen variables forced truth value FALSE subroutine REDUCE assigns TRUE variable fact monotone clause formula formula F weightk satisfying assignment reduced formula F cid2 Satisfying assignments connected components F cid2 4 We thank referees suggesting 5 A hitting set H collection subsets S1 Sn universe U subset H U H contains element subset S 1352 Y Gao Artiﬁcial Intelligence 173 2009 13431366 Input A random instance F np Output A satisfying assignment weight k UNSAT FAILURE kd k WEIGHTED dSAT x kfrozen set x FALSE let U U x 1 variable x 2 3 Let F cid2 REDUCEF U reduced formula 4 Find connected components F1 FN F cid2 5 If connected component contains log n variables return FAILURE 6 Otherwise connected component Fi use brute force ﬁnd LFi 7 Find set k indices j 1 cid2 j cid2 k set integers ki j 1 cid2 j cid2 k ki j LFi j kcid13 j1 k ki j Return UNSAT index set 8 For Fi j use bruteforce ﬁnd weightki j assignment variables Fi j satisﬁes Fi j 9 Combine assignments form weightk satisfying assignment formula F Algorithm 1 WSAT combined falsifying clauses So long sum weight assignments connected components equal k WSAT ﬁnds weightk satisfying assignment Line 6 Line 8 Due Lemma 31 takes O dknmtime ﬁnd kfrozen variables Lines 1 2 Lines 3 5 O nmtime depend k Line 6 ﬁnished O nmtime enumerate elements LFi Fi contains log n variables Line 8 repeats work Line 6 We Line 7 O k2n time dynamic programming Consider integer k collection Li 1 cid2 cid2 m Li subset integers 0 1 k We integer achievable Li 1 cid2 cid2 m set indices Ia j 1 cid2 j cid2 l satisfying following condition j ki j Li j lcid13 j1 ki j We index set Ia representative set The purpose Line 7 check integer k achievable YES return representative set k The lemma shows implement task Lemma 32 Given integer k collection Li 1 cid2 cid2 l subsets integers 0 1 k dynamic programming algorithm ﬁnds representative set k k achievable reports k achievable It runs time O k2l Proof Let At Ia 0 cid2 cid2 k set pairs Ia 0 cid2 cid2 k integer achievable Li 1 cid2 cid2 t Ia representative set Let A0 We At 1 union At set pairs form b Ia cid14 Ia At b Lt1 Ia Ia t b cid2 k A typical application dynamic programming computes A0 A1 Al The value k achievable Li 1 cid2 cid2 l pair k Ik Al Since size At k algorithm runs O k2l time cid2 For case Line 7 n subsets integers corresponds LFi connected component Fi The running time Line 7 O k2n The proposition follows cid2 34 The subroutine REDUCEF U The purpose subroutine REDUCEF U simplify formula F variables U assigned FALSE It works way unitpropagationbased inference wellknown DPLL procedure stan dard satisﬁability search It removes clause satisﬁed assignment variables U deletes occurrences literal FALSE assignment assigns proper value variables value forced literaldeletion The procedure terminates variable value forced Y Gao Artiﬁcial Intelligence 173 2009 13431366 1353 Due nature WEIGHTED dSAT random model note REDUCE assigns TRUE variable This begins set variables U assigned FALSE formula F contains monotone clause As consequence REDUCE create contradiction It possible REDUCE returns formula F cid2 signifying clauses satisﬁed process However searching satisfying assignment weight k case In description Algorithm 1 omitted simple special case The following lemma describes situation handled Lemma 33 If F cid2 REDUCEF U F weightk satisfying assignment k variables assigned REDUCE returns Proof F cid2 fact REDUCE sets variables FALSE fact F cid2 assigned arbitrary truth value cid2 obtained assigning variables U FALSE simplifying formula The lemma follows variable assigned 4 The algorithm WSAT succeeds high probability In section prove algorithm WSAT succeeds whp random instances F np kd Due Proposition 31 need probability WSAT report FAILURE asymptotically zero Recall WSAT fails reduced formula F cid2 obtained Line 3 connected component contains log n variables nd1 c 2k22d 1d 1 later proof Theorem 3 We following lemma whp variables kfrozen set FALSE Consequently reduced formula algorithm returns correct answer NO First present result case pn c log n Lemma 41 For random instances F np kd pn c log n nd1 c 2k22d 1d 1 whp variables kfrozen Proof See Appendix A cid2 We focus case pn c log n nd1 c cid2 2k22d 1d 1 Proposition 41 Let F F np kd input random CNF formula WSAT V set variables kfrozen With high probability residual graph induced formula FV V decomposes collection connected components contains log n variables Proof Let X x1 xn set Boolean variables U set kfrozen variables V X U Since p c log n nd1 c 0 kfrozen variables size U large If U randomly selected subset variables proposition easy prove The diﬃculty case U randomlyselected consequently FV assumed distributed manner input formula F To diﬃculty instead directly upper bound probability P subgraph tree T given set V T log n variables variable x V T kfrozen Since variables FV kfrozen upper bound probability P upper bound probability residual graph FV contains subgraph tree size log n We use upper bound Markovs inequality probability tends zero residual graph FV connected component log n variables residual graph F np kd contains events Let T ﬁxed tree subset V T log n variables A complication estimating P 1 F np kd induces T 2 variable T kfrozen independent To decouple dependency consider following events 1 A event residual graph F np 2 B event F np kd contains tree T subgraph kd variables V T involves set k clauses following form x yi1 yid1 1 cid2 cid2 k yi j s distinct variables yi j X V T j 1354 Y Gao Artiﬁcial Intelligence 173 2009 13431366 By deﬁnition event variable x kfrozen implies event x kfrozen respect subset X V T variables turns implies event x involved set k clauses form x yi1 yid1 1 cid2 cid2 k yi j s distinct variables yi j X V T j It follows cid2 PA B P We claim Lemma 42 The events A B independent PAB PB 42 43 Proof Note event A depends dclauses contain variables V T event B depends dclauses contain exactly variable V T By deﬁnition random model F np kd appearance clause deﬁned dtuple variables independent appearance clauses The lemma follows cid2 Based Eq 42 Lemma 42 need estimate PA PB separately To proceed need following Chernoff bound tail probability binomial random variable Lemma 43 Let I binomial random variable expectation μ We cid2 P I μ t cid3 cid2 2e t2 3μ The following lemma bounds probability variable kfrozen Lemma 44 Let x variable W X x W W n log n Then Px kfrozen respect W cid2 O 1 max cid8 cid7 1 nδ log2 n n 0 δ c 32d1d1 44 Proof Let Nx number clauses form x y1 yd1 y1 yd1 W Due deﬁnition F np kd random variable Nx follows binomial distribution Binp m p 1 Note 2d1 ﬁxed constant cid3 0 integer Ncid3 0 n Ncid3 nd1 m cid5 nlog n d1 c log n cid6 cid7 cid8 n log n d 1 cid7 1 log n d n cid8 d1 pm 1 2d 1 c log n nd1 c 2d 1d 1 1 cid3c cid3 cid3 2d 1d 1 log n Write α c 2d1d1 By Lemma 43 suﬃciently large n cid3 PNx k cid2 P cid2 Nx pm pm k pmk2 3pm cid2 2e 2e 1 cid2 2e cid5 O n 1 3 pm1 k pm 2 3 1cid33α log n δ cid6 k pm cid3 45 0 δ α 3 Let D event random formula F clauses cid4 x y11 y1d1 x y12 y2d1 Y Gao Artiﬁcial Intelligence 173 2009 13431366 1355 y11 y1d1 y12 y2d1 cid9 The total number possible pairs clauses d 1 cid7 n log n d 1 cid8cid7 cid8 n log n d 2 The probability speciﬁc pair random formula cid7 1 2d 1 c log n nd1 cid8 2 By Markovs inequality cid7 cid8 PD O log2 n n By deﬁnition variable x kfrozen Nx k event D occurs Therefore probability variable x kfrozen cid2 P Nx k D The lemma follows cid2 cid3 From Lemma 44 Lemma 45 For suﬃciently large n cid5 PB O 1 n cid6 δ log n 0 δ min c 32d1d1 1 46 Proof Let E x event variable x V T kfrozen respect X V T Since V T log n bound obtained Lemma 44 applies W X V T Since x V T event E x depends existence clauses form x yi1 yid1 yi1 yid1 X V T collection events E x x V T mutually independent The lemma follows Lemma 44 cid2 Next following upper bound probability PA Its proof based counting argument slightly generalizes 2639 See Appendix B details Lemma 46 The probability event A bounded PA cid2 log nd1n f dc1log n2 log nn log n f d c function depends d c Continuing proof Proposition 41 combine results Lemma 45 Lemma 46 PA B cid2 log nd1n f dc1log n2 log nn log n cid6 δ cid5 n log n Since total number trees size log n n vertices nlog nlog nlog n2 probability induced formula FV connected component log n variables upper bounded nlog nlog nlog n2PA B cid2 log nd1n f dc1log n3 log n cid6 δ cid5 n log n 47 tends zero ﬁrst terms righthand oncid3 log n cid3 0 Proposi tion 41 follows cid2 Proof Theorem 1 Recall deﬁnition induced formula FV set V variables kfrozen consists types clauses 1356 Y Gao Artiﬁcial Intelligence 173 2009 13431366 1 clauses F involve variables V 2 clauses size 2 obtained removing literal corresponding variable X V We claim formula F cid2 obtained Line 3 algorithm WSAT subformula FV sparser This clause satisﬁed application REDUCE contain literals variables V Therefore Proposition 41 high probability F cid2 decomposes collection connected components contains log n variables It follows WSAT succeeds whp Combining conclude Algorithm WSAT ﬁxedparameter algorithm succeeds whp ran dom instances F np kd This proves Theorem 1 cid2 5 The threshold behavior solution probability In section prove Theorem 2 establish exact threshold phase transition solution probability Unlike threshold random instances NPcomplete problems exact threshold open question exact threshold weighted satisﬁability problem established ﬁrstmoment method secondmoment method Proof Theorem 2 Let T collection subsets d variables let s assignment variables We subset T x1 xd T sgood 1 T doesnt contribute clause F np 2 dclause F np kd kd contributed T satisﬁed assignment s Let S set assignments weight k Recall weight assignment number variables set TRUE set TRUE assignment Consider assignment s S k variables Y yi1 yik From deﬁnition F np kd probability T T sgood cid14 PT sgood 1 1 pn T Y 1 2d1 58 Let Ts T collection subsets d variables nonempty intersection Y We Ts cid7 n k d j dcid13 j1 cid8 cid8cid7 k j Note summation ﬁrst term F np kd We cid6 cid5 nk d1 cid6cid5 k 1 dominates Let X number assignments S satisfy EX cid13 cid15 sS cid13 T T cid15 PT sgood PT sgood T Ts cid8cid7 sS cid7 n cid8cid7 k cid7 n k 1 c log n nd1 cid8cid16 d j1 nk d jk j 1 2d 1 cid8nk d1k 1 1 c log n nd1 1 2d 1 nke kc log n 2d 1d1 means asymptotically equivalent The upper bound threshold c asymptotic expression E X use Chebyschevs inequality To lower bound threshold c P X 0 cid2 EX 2 EX2 1 follows Markovs inequality 59 Y Gao Artiﬁcial Intelligence 173 2009 13431366 1357 We assignments s1 s2 S overlaps exactly variables set true assignments Let D number pairs satisfying assignments S overlaps We represent E X 2 cid18 cid17 E X 2 kcid13 i1 ED Let cid3 0 number We claim c cid14 ED o limn D0 cid5 n2kcid3icid3 cid6 cid5 EX cid6 2 1 1cid3 2d1d1 510 511 By deﬁnition cid13 cid15 ED PT s1good s2good s1s2 T sum ordered pairs weightk assignments overlaps product subsets T d variables Consider weightk assignments s1 s2 S overlaps Wlog assume set variables assigned TRUE s1 y1 yki yki1 yk set variables assigned TRUE s2 yki1 yk yk1 y2ki Write Y s1s2 y1 yk y2ki The probability set d variables T T s1good s2good estimated follows 1 If T Y s1s2 2 If T Y s1s2 PT s1good s2good 1 cid9 PT s1good s2good 1 pn nonempty intersection y1 yk yki1 y2ki Therefore To note case T PT s1good 1 pn PT s2good 1 pn cid7 cid8 1 2d 1 1 2d1 cid7 cid8 1 2d 1 As total number T T T Y cid9 cid8cid7 cid8 cid7 dcid13 j1 n 2k d j 2k j follows 1 ED cid8cid7 cid7 n k n k k cid8 cid15 cid7 T T Y cid9 cid8 1 pn 1 2d 1 cid8cid16 d j1 n2ki d j 2ki j cid7 n2ki 1 pn 1 2d 1 2kic log n 2d 1d1 n2kie n2kcid3icid3 512 means asymptotically equivalent For case 0 shown limn D0 E X2 This proves claim The theorem follows Eqs 59 510 512 Finally note calculations hold random instances MINIWEIGHTED dSAT question ﬁnd satisfying assignment Hamming distance k log n allzero assignment cid2 6 Parametric resolution complexity unsatisﬁable instances F np kd Even algorithm WSAT solves satisﬁable unsatisﬁable instances unclear simulate dynamic programming phase Line 7 WSAT resolution proof F np In section prove Theorems 3 4 parametric resolution complexity random unsatisﬁable instances kd We begin Theorem 3 deals case d 2 The proof based fact certain range p variable kfrozen kfrozen variable x parametric resolution derivation x size O dk constructed 1358 Y Gao Artiﬁcial Intelligence 173 2009 13431366 For random WEIGHTED 2SAT results minimum degree random graph Theorem 35 12 applied c1 k 1 variable kfrozen whp A parametric resolution proof based p 3log nc1 log log n kfrozenness variables immediate n The proof Theorem 4 resolution complexity random instances WEIGHTED 2SAT instead exploits existence Hamiltoniancyclelike clauses theorem holds WEIGHTED 2SAT MINI WEIGHTED 2SAT The study parameterized proof complexity weighted CNF satisﬁability recently initiated Dantchev et al 22 established lower bounds parameterized resolution proof CNF formulas encode ﬁrst order combinatorial principle Following deﬁnition parameterized resolution proof unsatisﬁable instances coW1 complete problem deﬁned classical resolution access free clauses contains k negated literals n k positive literals k problem parameter 61 Proof Theorem 3 resolution complexity F np kd d 2 Proof Theorem 3 We establish Theorem 3 making use fact established Lemma 41 p c log n c 2k22d 1d 1 variables kfrozen whp nd1 Since variables kfrozen construct parametric tree resolution proof follows First variable x parametric resolution derivation size O dk described following lemma Lemma 61 If variable x kfrozen parametric resolution derivation x size O dk Proof We parametric resolution derivation size O dk obtained set C k clauses x y11 y1d1 x yk1 ykd1 freeze x Consider DPLLstyle search tree method ﬁrst assigns x TRUE enumerates possible assignments k variables set yi j 1 cid2 j cid2 d 1 1 cid2 cid2 k order satisfy k clauses C x removed The size search tree O dk leaf node antimonotone clause size k 1 Since parametric resolution proof proof free access antimonotone clauses size k 1 way tree resolution proof constructed DPLL search tree CNF satisﬁability problem tree parametric derivation x constructed search tree cid2 Continuing proof Theorem 3 follows lemma size O dkn parametric resolution derivation set singleliteral clauses x x X From set clauses x x X monotone cid19 n i1 xi says variable set TRUE parametric resolution proof size O n clause easily constructed clause contradiction cid2 62 The resolution complexity F np k2 Proof Theorem 4 We prove Theorem 4 resolution complexity F np k2 exploiting interesting connection tween parameterized resolution complexity WEIGHTED 2SAT existence Hamiltonian cycle properly deﬁned directed graph The following lemma establishes connection Lemma 62 Consider instance F k WEIGHTED 2SAT arbitrary ordering x1 xn variables If F contains following cycle forcing clauses x1 x2 x2 x3 xn1 xn xn x1 parametric resolution proof size O kn F Furthermore parameterized version DPLL algorithm constructs resolution proof Proof Since parametric resolution proof access clauses contain k negated variables n k positive variables cid3 1 resolve xi xi1 xik xik1 xi1 xik1 derive xi These xi s x1 xnk1 result contradiction cid2 Y Gao Artiﬁcial Intelligence 173 2009 13431366 1359 We emphasize cycle forcing clauses exists automatically exploited DPLLstyle algorithms In random CNF formula generated F np k2 existence cycle forcing clauses shown result McDiarmid relation existence Hamiltonian cycle long path random graph existence directed Hamiltonian cycle directed long path directed random graph deﬁned follows Deﬁnition 61 See Section 4 McDiarmid 42 Let V vertex set p 0 The directed random graph D 2 deﬁned directed graph directed edge E probability p constraints pV E 1 appearance directed edges different unordered pairs independent 2 pair vertices u v cid2 cid3 P u v E v u E max0 2p 1 It noted 42 p 1 2 D2 p obtained randomly directing edges undirected random graph Gn 2p Lemma 63 See Theorem 44 McDiarmid 42 Let 0 p 1 D2 p random directed graph n vertices Then cid2 cid3 p directed Hamiltonian cycle D2 P cid2 cid3 Gn p Hamiltonian cycle cid3 P By Lemma 62 suﬃcient directed Hamiltonian cycle following directed graph cid2 Each vertex corresponds variable There directed edge xi x j 2clause xi x j DF n p random formula F np k2 By deﬁnition F np k2 DF n p cid2 1 probability p x y x y F np follows distribution directed random graph randomly directing edge G X E pcid2 discussed Lemma 63 edge 3 p To consider random graph G X E set variables x y E cid2 3 p The directed graph DF n p k2 Thus G X E random graph edge probability 2 cid2 exactly directed random directed graph D2 The result follows Lemma 63 threshold existence Hamiltonian cycle random graph Gn p cid2 edge probability p cid2 log nb log log n b 1 Gn p cid2 Hamiltonian Theorem 89 12 cid2 n 7 WSAT MINIWEIGHTED dSAT In section simple modiﬁcation algorithm WSAT solve whp random instances MINI WEIGHTED dSAT F np kd p pn certain range prove Corollary 11 Recall random instance F np kd k MINWEIGHTED dSAT looking satisfying assignment weight k log n Thus algorithm WSAT needs use existence k log nfrozen variables To guarantee WSAT succeeds whp need prove result similar Proposition 41 This amounts showing probability variable x k log nfrozen small For p c log n nd1 c k2d 1d 1 case Proposition 71 Let p c log n kd input random CNF formula WSAT customized MINIWEIGHTED dSAT based k log nfrozen variables V set variables k log nfrozen With high prob ability residual graph inducedformula FV decomposes collection connected components contains log n nd1 c k2d 1d 1 Let F F np Proof The proof proof Proposition 41 need establish upper bound probability variable k log nfrozen For c k2d 1d 1 Lemma 43 tail probability binomial random variable works Using notation proof Lemma 44 PNx k log n cid2 P cid2 cid2 2e 2e cid2 2e cid3 Nx pm pm k log n pmk log n2 3pm 1 3 pm1 k log n pm 2 1 3 1cid3 f cdk log n f c d k depends c d k The arguments second half proof Lemma 44 proof Lemma 45 valid The difference accuracy upper bound suﬃcient result hold cid2 1360 Y Gao Artiﬁcial Intelligence 173 2009 13431366 A complication detection k log nfrozen variables Note bounded searchtree method Lemma 31 work resulting running time O dk log n O nk To overcome diﬃculty use fact pn c log n nd1 c constant set clauses given variable x appears decomposes connected components contains log n variables consequently check variable k log nfrozen bruteforce connected components We observation precise following proposition Proposition 72 Let F np clauses y1 yd1 x y1 yd1 F np variables We kd random dCNF formula x variable Consider d 1CNF formula F x consists kd Let E event F x connected component log n PE cid2 n f dclog n2 log nn 1 d2 log n Proof Let T ﬁxed tree vertex set V T X x size log n Similar argument proof Lemma 46 probability residual graph d 1CNF formula F x contain tree T subgraph log nd2n f dclog n2 log nn log n 1 d2 log n 713 As number trees size log n nlog nlog nlog n2 proposition follows cid2 By Markovs inequality Proposition 72 whp variables x corresponding d 1CNF formula F x connected component log n variables 8 A general model F np kd d cid2 In section discuss generalize model F np cid2 deﬁned follows instead set nonmonotone clauses select uniformly random set clauses xi1 xid kd 1 First following result exact threshold phase transition cid2 cid2 d consider model F np negated literals Note F np contain d kd F np kd Let 1 cid2 d kd d cid2 Theorem 5 Consider random instance F np αdd d kd d cid2 k WEIGHTED dSAT Let p c log n ndd cid2 c 0 constant let c cid2 αd number dclauses ﬁxed set d variables contain d cid2 negated literals We cid2 P cid2 F np kd d lim n satisﬁable cid4 cid3 1 0 c c c c Proof Same proof Theorem 2 cid2 We following result parametric resolution complexity unsatisﬁable random instances F np kd d cid2 Theorem 6 Let pn c log n ndd dSAT resolution proof size O d d cid2 c 2αdd cid2k d cid2kd nd cid22d d constructed O d d cid2 cid2 cid2 With high probability random instance F np cid2 cid2kd n O 1 time kd k WEIGHTED cid2 Proof Extending notion kfrozen variable set d following k d clauses random CNF formula cid2 y11 y1ddcid2 xid xi1 xi1 xid cid2 ykdcid21 ykdcid2ddcid2 cid2 variables S xi1 xid cid2 frozen tuple yi j s distinct variables It clear satisfying weightk assignment allowed assign d frozen tuple TRUE We claim c 2αdd variable S xi1 xid cid2k d cid22d d cid2 whp d tuples variables frozen tuples For given set cid2 consider subhypergraph G contains hyperedges y1 yddcid2 cid2 cid2 variables cid2 d clause xi1 xid cid2 y1 yddcid2 Y Gao Artiﬁcial Intelligence 173 2009 13431366 1361 F np kd d cid2 We G follows distribution random hypergraph Gn d cid2 p d d cid2 Applying Lemma A2 PS frozen tuple cid2 n 1cid3c 2αd kd cid22dd cid2 Since cid2 Similar proof Theorem 3 frozen tuple S xi1 xid possible subsets d variables claim follows Markovs inequality cid2 parametric resolution derivation size cid6 cid5 n dcid2 d d cid2kd cid2 exists clause xi1 xid From collection cid2 exists collection cid6 cid5 n dcid2 cid5 n dcid21 clauses xi1 cid6 xid clauses size d cid2 1 cid2 1 cid2 j cid2 n j cid9 il parametric resolution derivation size cid5 n dcid21 cid6 n xi1 cid21 1 cid2 j cid2 n j cid9 il xid Continuing way parametric resolution derivation clauses xi 1 cid2 cid2 n size cid6 cid2 cid5 O d d n exists sizen parametric proof size n exists contradiction This completes dcid2 proof cid2 cid2kd For satisﬁable region best currently clause probability pn o log n nd1 random instances shown satisﬁable observation similar Lemma 22 In contrast phase transition occurs pn Θ log n cid2 One possible approach extending idea algorithm WSAT use notion kfrozen ndd tuple proof Theorem 6 reduce random formula frozen tuples We kfrozen tuples random formula unable extended algorithm succeeds high probability We leave future work challenge researchers AI algorithms progress closing huge gap 9 Conclusions Data reduction powerful pruning technique widely areas AI algorithmics Un derstanding effectiveness applicability data reduction technique design heuristics intractable problems main motivations study phase transitions randomlygenerated NPcomplete problems The current paper takes ﬁrst step extend line research intractable parameterized problem We proposed nontrivial random model generic intractable parameterized problem weighted dCNF satisﬁability problem provided complete characterization probabilistic behavior model To best knowledge author algorithm analysis present ﬁrst sound theoretical evidence effectiveness simple reduction rules solve intractable parameterized problems We believe results insights obtained study potential applications characterizing structure solution space standard propositional satisﬁability problem 3 improving effectiveness eﬃciency localsearchbased satisﬁability algorithms It interesting use models ideas developed work study parametric problems especially related backdoor detection problems PSPACEcomplete AI planning problems With regard future work random models weighted CNF satisﬁability proposed paper list following interesting challenging tasks 1 In paper limited success establishing lower bounds parametric resolution complexity random instances F np kd MINIWEIGHTED dSAT Establishing lower bounds size general parametric tree resolution proof systems require new techniques shown powerful study nonparametric resolution complexity random CNF formulas 9 2 As mentioned Section 3 p c log n nd1 c small suﬃcient number isolated variables simply setting k variables TRUE remaining variables FALSE weightk satisfying assignment It interesting happen isolated variables removed 3 More importantly thorough understanding general model F np cid2 challenging task requiring new ideas analytical techniques signiﬁcant empirical studies We leave challenge researchers ﬁelds AI algorithms study behavior general model kd d Acknowledgements I like thank anonymous referees careful reading paper thoughtful feedbacks Their detailed suggestions criticisms helped improve paper signiﬁcantly 1362 Y Gao Artiﬁcial Intelligence 173 2009 13431366 Appendix A Proof Lemma 41 For case WEIGHTED 2SAT Lemma 41 statement similar minimum vertex degree random graph results random graph literature applied Theorem 35 12 For case WEIGHTED dSAT d 2 complication require hyperedges variable belongs pairwise vertexdisjoint Note Lemmas 44 45 deal complication term log2 n n bound strong guarantee whp variables kfrozen To achieve resort extended Janson inequality Theorem 812 6 note approach doesnt work MINIWEIGHTED dSAT instances Lemma A1 The Extended Janson Inequality Theorem 812 6 Let 0 1Ω P independent product probability space Ω ﬁnite set I ﬁnite index set Ai I subset Ω For I let B event PB B j j means cid9 j Ai A j cid9 Assume cid8 cid3 μ We cid16 μ ω ω j 0 1Ω ω j 1 j Ai cid16 PB cid8 cid4 cid20 cid21 j cid3 cid2 P cid2 e μ2 2cid8 B We ﬁrst establish result existence kdisjoint hyperedges random hypergraph interesting right Remark We thank referees noticed original proof given context random CNF formulas actually applies general case random hypergraphs After checking literature result regarded generalization result random graphs bound lower tail probability small subgraph counts Theorem 872 6 Theorem 41 12 Lemma A2 Let Gn p d random hyper graph edge probability p pn b log n nd set k vertexdisjoint hyperedges Gn p d M complement M We let M event exists PM cid2 n 1cid3b 2k2d constant cid3 0 A1 Proof We prove lemma extended Janson inequality For purpose let P family collections k pairwise disjoint subsets d vertices cid2 P Y 1 cid2 cid2 k Y V Y Y j Y d cid3 We require vertices collection Y 1 cid2 cid2 k distinct Here set possible hyperedges plays role Ω set P plays role I sets k hyperedges play role Ai s extended Jansons inequality For given Y Y 1 cid2 cid2 k P let BY event hyperedges Y 1 cid2 cid2 k random hypergraph Gn p d We There PBY cid5 n d cid6cid5 P 1 k cid5 cid6 k pn cid5 cid6 nk1d d n d d cid8cid7 cid8 d nd d cid7 n cid6 ways choose k vertexdisjoint subsets size d Consequently size P cid7 cid8 n k 1d d 1 k ways arrange k subsets It follows expected number sets k disjoint hyperedges μ cid13 YP PBY bounded cid7 1 k 1d n cid8 kd 1 kd cid5 pnnd cid5 cid6 k cid2 μ cid2 1 k pnnd cid6 k A2 Y Gao Artiﬁcial Intelligence 173 2009 13431366 1363 To apply extended Janson inequality estimate cid8 Lemma A1 cid13 cid8 PBY1 BY2 Y1Y2cid9 sum ordered pairs Y1 Y2 P P Y1 Y2 cid9 For pair Y1 Y2 Y1 Y2 cid6 pn 2ki cid5 PBY1 BY2 A3 The total number ordered pairs Y1 Y2 overlaps equal total number ways select k k 2k pairwise disjoint subsets k variables play special role shared subsets cid8 cid8cid7 cid8 cid7 1 ik ik cid7 n d n d d n 2k 1d d A4 term 1 ikiki takes care different ways arrange subsets different parts pair subsets Let si cid13 Y1Y2i PBY1 BY2 From Eqs A3 A4 pn b log n cid7 cid8 cid7 nd 2ki si cid2 1 ik ik 1 ik ik cid7 b log n nd b log n d cid8 2ki follows cid8 2ki nd d Write t b log n d si cid2 ikiki t2ki We 1 k1cid13 cid13 cid8 PBY1 BY2 k1cid13 i1 si i1 k1cid13 i1 cid2 Y1Y2i 1 ik ik t2ki 1 k 1k 1 t2k1 k1k1 cid7 1 g2 k t g3 k t2 cid8 gk1 k tk1 A5 gi k ikiki constant k constant Since limn t cid3 0 integer N Ncid3 0 n Ncid3 term 1 g2 gk1 tk1 upper bounded 1 cid3 Therefore k t k g2 k t2 cid8 cid2 1 cid3 1 k 1k 1 t2k1 Therefore μ2 2cid8 asymptotically lower bounded 1 cid3b log n 2k2d It follows extended Jansons inequality cid21 PM P BY cid2 e 1cid3b 2k2d log n n 1cid3b 2k2d cid4cid20 Y This completes proof lemma cid2 An immediate application Lemma A2 following corollary minimum number vertexdisjoint hyperedges vertex random hypergraph 1364 Y Gao Artiﬁcial Intelligence 173 2009 13431366 Corollary A1 Let Gn p d random hyper graph edge probability p pn b log n vertexdisjoint hyperedges vertex We b 2k2d 1 nd Let δ minimum number Pδ k 0 lim n A6 Note extra term 2k2 lower bound b compared similar results minimum vertex degree random graph Theorem 35 12 We believe requirement vertexdisjointness know improved Proof For given vertex subhypergraph V x contains hyperedges y1 yd1 x y1 yd1 hyperedge Gn p d follows distribution random hypergraph Gn 1 p d 1 Ap plying Lemma A2 Markovs inequality whp vertices incident k vertexdisjoint hyperedges Gn p d cid2 We ready use Lemma A2 prove Lemma 41 Let x ﬁxed variable Consider subhypergraph G set variables X x contains hyperedges Y y1 yd1 x y1 yd1 clause appearing random CNF formula F np kd We G random hypergraph Gn 1 p d 1 edge probability pn c log n n1d1 b c follows Lemma A2 nd1 2d1 Applying Lemma A2 Gn 1 p d 1 p b logn1 1 2d1 Px kfrozen cid2 PG contain k disjoint hyperedges A7 cid3 0 If c 2k22d 1d 1 small cid3 0 1 cid3c 2k22d 1d 1 For n Ncid3 Markovs inequality probability variables kfrozen 1cid3c 2k22d 1d1 cid2 e log n 1cid3c 2k22d 1d1 1 ne log n 1 o1 This proves Lemma 41 Appendix B Proof Lemma 46 Proof Recall A event random instance F np kd induces edge ﬁxed tree T vertex set V T size log n We estimate number ways random formula induces copy tree T The counting argument generalization 2639 Let F T set clauses edge T induced clause F T We F T minimal deleting clause leaves edge T uncovered Consider different ways cover edges T clauses Treat clauses F T grouped d 1 different groups S 1 cid2 cid2 d 1 A clause group S charge covering exactly edges T Note clause group S accidently cover edges responsibility As long clause dedicated set edges cover wont risk undercounting Let si S 1 cid2 cid2 d 1 Since log n 1 edges T clause S dedicated edges T 0 cid2 si cid2 log ni d1cid13 isi log n 1 i1 ways pick dedicated sets edges si clauses group S Counting crudely cid6 cid5 Since T tree set edges T involves 1 variables consequently 2d 1 n di1 ways select clause set edges Given ﬁxed si 1 cid2 cid2 d 1 let E T s1 sd1 expected number clause sets F T cover edges T clause group S dedicated edges We cid6si cid5 log n B1 E T s1 sd1 cid2 cid7 dcid15 cid8 si log n i1 cid7 n d 1 cid8 cid5 cid7 cid6 2d 1 cid8 si c log n 2d 1 1 nd1 cid2 log n cid16 d1 i1 isi n cid16 d1 i1 di1si cid5 2d 1 cid6cid16 d1 i1 di1si cid7 c log n 2d 1 1 nd1 cid8cid16 d1 i1 si cid16 d1 i1 isi n f dclog nlog n cid2 log nlog nn n f dclog n2 log nn log n1 f d c function depends d c By Markovs inequality PA upper bounded Y Gao Artiﬁcial Intelligence 173 2009 13431366 1365 PA cid2 log ncid13 log ncid13 log ncid13 E T s1 sd1 s11 s21 sd11 cid2 log nd1n f dc1log n2 log nn log n This proves Lemma 46 cid2 Appendix C Proof Lemma 22 We proof Lemma 22 trivial random instances First consider case monotone clauses kd Let G hypergraph set X n variables contains edges Y y1 yd kd We G distribution random hypergraph forbidden F np monotone clause y1 y2 yd appears F np Gn p It follows Lemma A2 pn cid3 b log n cid2 d edge probability p cid2 pn 1 2d1 nd cid2 P F np kd contains k disjoint monotone clause cid3 cid3 1 n 1cid3b 2k2d 1 o1 extremely small probability average number clauses F np kd O log n This proves Note b log n nd Lemma 221 given variable appear negated literal F np kd To prove Lemma 222 consider probability p We cid7 cid5 p cid6 1 pn pn cid8 n d1 2d1 1 2d 1 cid7 1 2d1 21 cid2 cid8 nd1 d1 pn For p c log n asymptotically greater nd1 p c 2d1 2d 1 n 1 d1 It follows expected number variables appear negated literal F np kd p n cid3 n 1c 2d1 2d 1 1 d1 goes inﬁnity cid7 c 2d1 2d 1 1 d 1 cid81 Using Chebyschevs inequality shown whp k variables appear negated literal F np nd1 small c pn o log n nd1 kd p c log n References 1 D Achlioptas H Jia C Moore Hiding satisfying assignments Two better Journal Artiﬁcial intelligence 24 2005 623639 2 D Achlioptas Y Peres The random kSAT threshold 2k log 2ok Proceedings 35th Annual Symposium Theory Computing STOC03 2003 pp 223231 3 D Achlioptas F RicciTersenghi On solutionspace geometry random constraint satisﬁability problems Proceedings 38th Annual Symposium Theory Computing STOC06 2006 pp 130139 4 J Alber N Betzler R Niedermeier Experiments data reduction optimal domination networks Annals Operations Research 146 2006 105117 5 N Alon N Kahale A spectral technique coloring random 3colorable graphs SIAM J Computing 26 1997 17331748 6 N Alon J Spencer The Probabilistic Method Wiley 2000 7 P Beame R Karp T Pitassi M Saks The eﬃciency resolution DavisPutnam procedures SIAM Journal Computing 31 4 2002 10481075 8 A Becker R BarYehuda D Geiger Randomized algorithms loop cutset problem Journal Artiﬁcial Intelligence 2000 219234 9 E BenSasson A Wigderson Short proofs narrowresolution simple Journal ACM 49 2 2001 149169 10 C Bessiére E Hebrard B Hnich Z Kiziltan C Quimper T Walsh The parameterized complexity global constraints Proceedings 23th AAAI Conference Artiﬁcial Intelligence AAAI08 2008 pp 235240 11 S Böcker S Briesemeister G Klau Exact algorithms cluster editing Evaluation experiments Proceedings 7th International Workshop Experiment Algorithms WEA08 2008 pp 289302 1366 Y Gao Artiﬁcial Intelligence 173 2009 13431366 12 B Bollobas Random Graphs Cambridge University Press 2001 13 B Bollobas C Borgs J Chayes J Kim D Wilson The scaling window 2SAT transition Random Structures Algorithms 18 3 2001 201256 14 P Cheeseman B Kanefsky W Taylor Where hard problems Proceedings 12th International Joint Conference Artiﬁcial Intelligence Morgan Kaufmann 1991 pp 331337 15 H Chen A Frieze Coloring bipartite hypergraphs Proc 5th International IPCO Conference Integer Programming Combinatorial Optimization 1996 pp 345358 16 J Chen B Chor M Fellows X Huang D Juedes I Kanj G Xia Tight lower bounds certain parameterized NPhard problems Information Computation 2005 216231 17 J Chen S Lu S Sze F Zhang Improved algorithms path matching packing problems Proceedings 18th Annual ACMSIAM Sympo sium Discrete Algorithms 2007 pp 298307 18 A CojaOghlan M Krivelevich D Vilenchik Why satisﬁable kcnf formulas easy Proc 13th International Conference Analysis Algorithms 2007 pp 89102 19 S Cook D Mitchell Finding hard instances satisﬁability problem A survey Du Gu Pardalos Eds Satisﬁability Problem Theory Applications DIMACS Series Discrete Mathematics Theoretical Computer Science vol 35 American Mathematical Society 1997 20 N Creignou H Daudé U Egly Phase transition random quantiﬁed XORformulas Journal Artiﬁcial Intelligence Research 29 2007 118 21 J Culberson I Gent Frozen development graph coloring Theoretical Computer Science 265 12 2001 227264 22 S Dantchev B Martin S Szeider Parameterized proof complexity Proceedings 48th Annual Symposium Foundations Computer Science FOCS07 IEEE Press 2007 pp 150160 23 B Dilkina C Gomes A Sabharwal Tradeoffs complexity backdoor detection Proceedings 13th International Conference Principles Practice Constraint Programming CP07 2007 pp 256270 24 R Downey M Fellows Parameterized Complexity Springer 1999 25 M Fellow C Knauer P Ragde F Rosamond U Stege D Thilikos S Whitesides Faster ﬁxedparameter tractable algorithms matching packing problems Algorithmica 2 2008 167176 26 A Flaxman A spectral technique random satisﬁable 3CNF formulas Proc 14th ACMSIAM Symposium Discrete Algorithms 2003 pp 357 363 27 F Fomin F Grandoni D Kratsch Some new techniques design analysis exact exponential algorithms Bulletin EATCS 87 2005 Tech rep 28 Y Gao Phase transitions complexity weighted satisﬁability intractable parameterized problems Proceedings 23th AAAI Conference Artiﬁcial Intelligence AAAI08 2008 pp 265270 29 Y Gao J Culberson An analysis phase transition NK landscapes Journal Artiﬁcial Intelligence Research 17 2002 309332 30 Y Gao J Culberson Consistency random constraint satisfaction models Journal Artiﬁcial Intelligence Research 28 2007 517557 31 I Gent T Walsh Analysis heuristics number partitioning Computational Intelligence 14 3 1998 430451 32 C Gomes C Fernandez B Selman C Bessiere Statistical regimes constrainedness regions Constraints 10 4 2005 313337 33 C Gomes T Walsh Randomness structure F Rossi P van Beek T Walsh Eds Handbook Constraint Programming Elsevier 2006 pp 639 664 34 G Gottlob F Scarcello M Sideri Fixedparameter complexity AI nonmonotonic reasoning Artiﬁcial Intelligence 138 12 2002 5586 35 G Gottlob S Szeider Fixedparameter algorithms artiﬁcial intelligence constraint satisfaction database problems The Computer Journal 51 3 2008 303325 36 J Gramm J Guo F Hüffner R Niedermeier Data reduction exact heuristic algorithms clique cover Proceedings 8th Workshop Algorithm Engineering Experiments ALENEX06 2006 pp 8694 37 J Guo R Niedermeier Invitation data reduction problem kernelization SIGACT News 38 1 2007 3145 38 H Jia C Moore D Strain Generating hard satisﬁable formulas hiding solutions deceptively Journal Artiﬁcial Intelligence Research 2007 107 118 39 M Krivelevich D Vilenchik Solving random satisﬁable 3CNF formulas expected polynomial time Proc 17th ACMSIAM Symposium Discrete Algorithms 2006 pp 454463 40 M Langston A Perkins A Saxton J Schaffer B Voy Innovative computational methods transcriptomic data analysis A case study use FPT practical algorithm design implementation The Computer Journal 51 2008 2638 41 D Marx Parameterized complexity constraint satisfaction problems Computational Complexity 2 2005 153183 42 C McDiarmid General percolation random graphs Adv Appl Prob 13 1981 4060 43 M Mezard R Zecchina The random ksatisﬁability problem From analytic solution eﬃcient algorithm Phys Rev E 66 2002 44 M Molloy Models thresholds random constraint satisfaction problems Proceedings 34th ACM Symposium Theory Computing ACM Press 2002 pp 209217 45 R Monasson R Zecchina Statistical mechanics random ksat model Phys Rev E 56 1997 1357 46 R Niedermeier Invitation FixedParameter Algorithms Oxford Univ Press 2006 47 N Nishimura P Ragde S Szeider Detecting backdoor sets respect Horn binary clauses Proceedings Seventh International Conference Theory Applications Satisﬁability Testing SAT04 2004 48 S Szeider Backdoor sets DLL subsolvers Journal Automated Reasoning 13 2005 7388 49 B Vandegriend J Culberson The Gnm phase transition hard Hamiltonian Cycle problem Journal Artiﬁcial Intelligence Research 9 1998 219245 50 K Weihe Covering trains stations power data reduction Proceedings Workshop Algorithm Experiments ALEX98 2006 pp 8694 51 K Xu F Boussemart F Hemery C Lecoutre Random constraint satisfaction Easy generation hard satisﬁable instances Artiﬁcial Intelli gence 171 89 2007 514534 52 W Zhang A Rangan M Looks Backbone guided local search maximum satisﬁability Proceedings 18th International Joint Conference Artiﬁcial Intelligence IJCAI03 2003 pp 11791184