Artiﬁcial Intelligence 180181 2012 2033 Contents lists available SciVerse ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint On approximation ability evolutionary optimization application minimum set cover Yang Yu Xin Yao b ZhiHua Zhou National Key Laboratory Novel Software Technology Nanjing University Nanjing 210093 China b Center Excellence Research Computational Intelligence Applications School Computer Science University Birmingham Birmingham B15 2TT UK r t c l e n f o b s t r c t Article history Received 23 December 2010 Received revised form 8 December 2011 Accepted 8 January 2012 Available online 10 January 2012 Keywords Evolutionary algorithms Approximation algorithm Approximation ratio kSet cover Time complexity analysis Evolutionary algorithms EAs heuristic algorithms inspired natural evolution They obtain satisﬁcing solutions practice In paper investigate largely underexplored issue approximation performance EAs terms close solution obtained optimal solution We study EA framework named simple EA isolated population SEIP implemented single multiobjective EA We analyze approximation performance SEIP partial ratio characterizes approximation ratio guaranteed Speciﬁcally analyze SEIP set cover problem NPhard We ﬁnd simple conﬁguration SEIP eﬃciently achieves Hnapproximation ratio asymptotic lower bound unbounded set cover problem We ﬁnd SEIP eﬃciently achieves Hk k1 8k9 approximation ratio currently bestachievable result kset cover problem Moreover instance class kset cover problem disclose SEIP onebit bitwise mutation overcome diﬃculty limits greedy algorithm 2012 Elsevier BV All rights reserved 1 Introduction Evolutionary algorithms EAs 3 successfully applied ﬁelds achieve extraordinary perfor mance addressing realworld hard problems particularly NPhard problems 1618174 To gain understanding behavior EAs theoretical studies focused running time required achieve exact optimal lutions 1433262 In practice EAs commonly obtain satisﬁcing solutions theoretical studies approximation ability EAs emerged recently He Yao 15 ﬁrst studied conditions widegap far distance narrowgap long distance problems hard approximate EAs Giel Wegener 12 investigated 1 1EA maximum matching problem time taken time ﬁnd exact optimal solutions exponential O n2cid31cid2cid4 1 cid2approximate solutions demonstrates value EAs approximation algorithms Subsequently results approximation ability EAs reported For 1 1EA simplest type EA classes results obtained On hand 1 1EA arbitrarily poor approximation ratio minimum vertex cover problem minimum set cover problem 1128 On hand 1 1EA provides polynomialtime randomized approximation scheme subclass partition problem 32 Furthermore subclasses minimum vertex cover problem 1 1EA gets stuck multiple restart strategy allows EA recover optimal solution high probability 28 Another result Corresponding author Email addresses yuylamdanjueducn Y Yu xyaocsbhamacuk X Yao zhouzhnjueducn ZH Zhou 00043702 matter 2012 Elsevier BV All rights reserved doi101016jartint201201001 Y Yu et al Artiﬁcial Intelligence 180181 2012 2033 21 1 1EA improves 2approximation algorithm 2 2napproximation minimum vertex cover problem 10 This implies useful postoptimizer Recent advances multiobjective usually biobjective EAs shed light power EAs approximation optimizers For singleobjective problem multiobjective reformulation introduces auxiliary objective function multiobjective EA optimizer Scharnow et al 30 ﬁrst suggested multiobjective reformulation superior use singleobjective EA This conﬁrmed problems 24251127 showing singleobjective EA stuck multiobjective reformulation helps solve problems eﬃciently Regarding approximations shown multiobjective EAs effective NPhard problems Friedrich et al 11 proved multiobjective EA achieves ln napproximation ratio minimum set cover problem reaches asymptotic lower bound polynomial time Neumann Reichel 23 showed multiobjective EAs achieve kapproximation ratio minimum multicuts problem polynomial time In present study investigate approximation ability EAs introducing framework called simple evolu tionary algorithm isolated population SEIP uses isolation function manage competition solutions By specifying isolation function SEIP implemented single multiobjective EA Multiobjective EAs previ ously analyzed 221123 viewed special cases SEIP term solutions maintained population By analyzing SEIP framework obtain general characterization EAs guarantee approximation quality We study minimum set cover problem MSCP NPhard problem 9 We prove bounded MSCP simple conﬁguration SEIP eﬃciently obtains Hkapproximation ratio Hk harmonic number cardinality largest set asymptotic lower bound 9 For minimum kset cover problem approach eﬃciently yields Hk k1 8k9 approximation ratio currently bestachievable quality 13 Moreover subclass minimum kset cover problem demonstrate SEIP onebit bitwise mutation overcome diﬃculty limits greedy algorithm The remainder paper organized follows After introducing preliminaries Section 2 SEIP Section 3 characterize behavior approximation Section 4 We analyze approximation ratio achieved SEIP MSCP Section 5 In Section 6 conclude paper discussion advantages limitations SEIP framework 2 Preliminaries We use bold small letters w x y z represent vectors We denote m set 1 2 m 2S nth harmonic number Note Hn ln n power set S consists subsets S We denote Hn ln n cid2 Hn cid2 ln n 1 cid2 n i1 1 In paper consider minimization problems follows Deﬁnition 1 Minimization problem Given evaluation function f set feasibility constraints C ﬁnd solution x 0 1n minimizes f x satisfying constraints C A problem instance speciﬁed parameters n f C In deﬁnition minimization problem solutions represented binary vectors When aim minimiza tion problem ﬁnd subset universal set equivalently use binary vector represent subset element vector indicates membership corresponding element universe set For example given universal set U 1 2 3 4 5 subset S 1 3 5 represented binary vector v 1 0 1 0 1 deﬁne U v S Considering equivalence sets binary vectors apply set operators binary vectors confusion For example 1 0 1 0 1 3 1 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 We denote x 0 0 vector corresponding set We investigate minimum set cover problem MSCP NPhard problem Deﬁnition 2 Minimum set cover problem MSCP Given set n elements U n collection C S 1 S2 Sm m nonempty subsets U S associated positive cost wS ﬁnd subset X S X wS minimized respect C cid2 cid3 S X S U Using binary vector representation denote instance MSCP parameters n w C U C m w cost vector The MSCP involves ﬁnding vector xOPT equivalent set representation X solving constrained optimization problem xOPT arg min x01m cid4 w x S U st SCx 22 Y Yu et al Artiﬁcial Intelligence 180181 2012 2033 w x inner product vectors w x Cx denotes set consisting elements collection C indicated binary vector x Deﬁnition 3 Minimum kset cover problem An MSCP n w C U kset cover problem constant k holds S cid2 k S C denoted n w C U k A solution called feasible satisﬁes constraints C called infeasible solution partial solution paper Here assume evaluation function f deﬁned input space evaluates possible solutions regardless feasibility For example evaluate solution x MSCP w x evaluation function calculated solution Given minimization problem denote xOPT optimal solution problem OPT f xOPT For feasible OPT approximation ratio If approximation ratio feasible solution upper solution x regard ratio f x bounded value r 1 cid2 f x OPT cid2 r solution called rapproximate solution An algorithm guarantees ﬁnd rapproximate solution arbitrary problem instance polynomial time rapproximation algorithm The greedy algorithm 5 described Algorithm 1 wellknown approximation algorithm MSCP This greedy algorithm consists sequence steps The cost candidate set deﬁned weight divided number elements covered quantity r S line 3 The algorithm picks candidate set smallest cost solution line 4 marks newly covered elements line 6 This simple algorithm yields Hnapproximation ratio exactly Hk k cardinality largest set 5 The key proof approximation ratio deﬁnition price elements line 5 The price element equals cost set ﬁrst covers total price elements equals total cost solution Furthermore noted element covered set lowest cost covered set optimal solution higher cost Therefore price element upperbounded optimal cost approximation ratio upperbounded For detailed proof refer Cheátal 5 Algorithm 1 Greedy algorithm See 5 Given minimum kset cover problem n w C U k greedy algorithm consists following steps 1 X R 2 R cid12 U 3 4 5 S C S R 0 let r S wS SR ˆS arg minS r S let pricee r ˆS e ˆS R let R R ˆS X X ˆS 6 7 end 8 return X Several studies shown approximation ratio MSCP lowerbounded Ωln n P NP unlikely 293191 Therefore greedy algorithm achieves asymptotic lower bound approximation ratio MSCP Although Hnapproximation ratio asymptotically tight unbounded MSCP better approximation ratio achieved minimum kset cover problem k constant It proved unweighted minimum kset cover problem Hk 1 2 approximation ratio achieved 8 k cid3 4 improved ratio Hk 196 390 achieved 20 For weighted minimum kset cover problem greedyalgorithmwithwithdrawals GAWW presented achieved Hk k1 8k9 approximation ratio 13 The GAWW algorithm presented Algorithm 2 modiﬁcation greedy algorithm In iteration algorithm chooses taking greedy step greedy algorithm withdrawal step replaces set current solution k candidate sets It evaluates cost candidate sets greedy algorithm evaluates beneﬁt withdrawal calculated lines 4 5 When beneﬁt withdrawal step large according criterion line 6 algorithm takes greedy step takes withdrawal step To prove approximation ratio price elements deﬁned similarly line 7 greedy step line 10 withdrawal step later proofs paper Algorithm 2 GAWW See 13 Given minimum kset cover problem n w C U k GAWW consists following steps 1 X R αk 1 1 k3 Y Yu et al Artiﬁcial Intelligence 180181 2012 2033 23 2 R cid12 U 3 S C S R 0 let r S wS SR S X Q C Q cid2 k ˆS arg minS r ˆS S Q arg minSQ Q cid2k rSQ r ˆS cid15 R 0 let rSQ Scid15Q S cid3 αk cid2 r S Q greedy step let pricee r ˆS e ˆS R let R R ˆS X X ˆS r S Q r ˆS αk withdrawal step cid3 let pricee r S Q e let R SQ S R SQ S R X X Q S cid3 4 5 6 7 8 9 10 11 cid2 cid3 S cid15 c S cid15Q c S cid15Q Scid15R S choose minimal number sets cases ties end 12 13 end 14 return X The 1 1EA simplest EA implementation described Algorithm 3 Starting solution generated uniformly random 1 1EA repeatedly generates new solution current mutation operator current solution replaced new solution better equal ﬁtness Algorithm 3 1 1EA Given minimization problem n f C solution encoded binary vector length m 1 1EA minimizing f consists following steps 1 x solution generated uniformly random 2 stop cid12 true cid15 3 Mutate x generate x cid15 cid2 f x x feasible f x 4 5 cid15 x x end 6 7 end 8 return x Two mutation operators commonly implement mutate step line 3 Onebit mutation Flip randomly selected bit position x generate x Bitwise mutation Flip bit x probability 1 cid15 m generate x cid15 It shown 1 1EA arbitrarily poor approximation ratio MSCP 11 Laumanns et al 19 multiobjective reformulation multiobjective EA named SEMO achieve ln napproximation ratio The SEMO algorithm described Algorithm 4 objectives presented f 1 f 2 To apply SEMO MSCP let f 1 evaluate cost solution f 2 evaluate number uncovered elements Thus SEMO minimizes cost number uncovered elements solutions simultaneously A notable difference SEMO 1 1EA SEMO uses nondominance relationship implemented dominate function SEMO The population SEMO maintains nondominant solutions solution superior objectives Algorithm 4 SEMO See 19 Given twoobjective minimization problem n f 1 f 2 solution encoded binary vector length m SEMO minimization f 1 f 2 consists following steps 0 0 0 1 P x 2 stop cid12 true 3 cid15 4 Mutate x generate x 5 Choose x P uniformly random x P dominatex x 6 7 Q x P dominatex cid15 Q P P x cid15 false cid15 x true end 8 9 end 10 return P dominate function solutions deﬁned dominatex y true following rules satisﬁed 24 Y Yu et al Artiﬁcial Intelligence 180181 2012 2033 1 f 1x f 1 y f 2x cid2 f 2 y 2 f 1x cid2 f 1 y f 2x f 2 y 3 f 1x f 1 y f 2x f 2 y x y dominatex y false 3 SEIP The SEIP framework depicted Algorithm 5 It uses isolation function μ isolate solutions For integer q function μ maps solution subset q If solutions x1 x2 mapped subsets cardinality μx1 μx2 solutions compete In case solutions isolation q 1 isolations subsets q q 1 different cardinalities Algorithm 5 SEIP Given minimization problem n f C isolation function μ encodes solution binary vector length m SEIP minimization f respect constraint C consists following steps 0 0 0 1 P x 2 stop cid12 true 3 cid15 4 Mutate x generate x 5 Choose x P uniformly random x P superiorx x 6 7 Q x P superiorx cid15 Q P P x cid15 false cid15 x true end 8 9 end 10 return best feasible solution P superior function solutions determines solution superior This deﬁned follows superiorx y true following rules satisﬁed 1 μx μ y 2 f x f y f x f y x y superiorx y false When isolation function puts solutions isolation particular instance degrades 1 1 EA The isolation function conﬁgured simulate dominance relationship multiobjective EAs SEMOGSEMO 19 DEMO 23 If dealing kobjective optimization discrete objective values simple approach use objective functions f 1 ﬁtness function use combination values remaining k 1 objective functions f 2 fk isolation functions Thus solutions compete f 1 share objective values f 2 fk This simulation shows nondominant solutions multiobjective EA kept SEIP population nondominant solution reside SEIP popu lation solution dominates Hence SEIP viewed generalization multiobjective EAs terms solutions retained This simulation reveals SEIP retains solutions multiobjective EA dominance relationship This hand SEIP takes time manipulate larger population multiobjective EA overcome deﬁning isolation function aggregates nearby solutions DEMO 23 On hand SEIP opportunities available ﬁnd better approximation solution relationship dominates b imply deﬁnitely leads better approximation solution b Taking MSCP n w C U example use ﬁtness function f x w x sum costs selected sets For isolation function use μx x feasible 1 x infeasible isolates feasible infeasible solutions q 1 use isolation function μx SxC S solutions compete cover number elements q n cid3 The mutation operator use onebit bitwise mutation Usually onebit mutation considered local searches bitwise mutation suitable global searches positive probability producing solution We denote SEIP onebit mutation LSEIP SEIP bitwise mutation GSEIP L G denote local global respectively For convenience SEIP set start solution x random solution commonly EAs Under condition solution better ﬁtness 1 bit turned 0 bound difference From random solution SEIP takes O qm ln m expected steps random initialization starting x according following argument Suppose worst case random initialization generates solution ﬁnd x equivalent solving OneMax problem 1 bits according ﬁtness function condition ﬁnding x randomized local search 1 1EA takes O m ln m steps LSEIP GSEIP 7 Furthermore note q solutions population costs SEIP q expected steps choose particular solution population The stop criterion described deﬁnition SEIP EAs usually anytime algorithms practice We analyze approximation ratio corresponding computational complexity SEIP Y Yu et al Artiﬁcial Intelligence 180181 2012 2033 25 4 General approximation behavior SEIP For minimization problems consider linearly additive isolation functions μ linearly additive isolation function cid5 integer q μx q μx y μx μ y feasible solutions x solutions x y The quality feasible solution measured terms approximation ratio To measure quality partial infeasible solution deﬁne partial reference function partial ratio follows Deﬁnition 4 Partial reference function Given set q value v function Lqv 2 function q R partial reference 1 Lqv q v 2 Lqv R1 Lqv R2 R1 R2 q R1 R2 For minimization problem optimal cost OPT isolation function μ mapping feasible solutions set q denote partial reference function respect q OPT LqOPT When problem isolation function clear omit subscripts simply denote partial reference function L Deﬁnition 5 Partial ratio Given minimization problem n f C isolation function μ partial ratio partial solution x respect corresponding partial reference function L pratiox f x Lμx conditional partial ratio y conditioned x pratiox y f y x Lμ y μx f y x f x y f x Lμ y μx Lμ y μx Lμx The partial ratio extension approximation ratio Note partial ratio feasible solution equals approximation ratio We properties partial ratio One nonincreasing SEIP stated Lemma 1 decomposability stated Lemma 2 Lemma 1 Given minimization problem n f C isolation function μ SEIP generated offspring x partial ratio p respect corresponding partial reference function L solution y population μ y μx partial ratio y p Proof x population generated solution x f x nonincreasing cid2 cid15 μx The lemma proved Lx L y superior function cost cid15 cid2 f x case let x x μx cid15 cid15 From Lemma 1 know partial ratio isolation remains nonincreasing Since SEIP repeatedly tries generate solutions isolation SEIP considered optimizing partial ratio isolation Lemma 2 Given minimization problem n f C isolation function μ partial solutions x y z z x y pratioz cid2 max cid6 cid7 pratiox pratio y x respect corresponding partial reference function L Proof Since z x y deﬁnition f z f x f y x μz μx y μx μ y 26 Y Yu et al Artiﬁcial Intelligence 180181 2012 2033 Thus pratioz f z Lμz cid5 f x f y x Lμx μ y f y x Lμ y μx f x Lμx cid6 cid7 pratiox pratio y x f x f y x Lμx Lμ y μx cid8 cid2 cid2 max max Lemma 2 reveals partial ratio solution related conditional partial ratio building block This considered way SEIP optimizes partial ratio isolation optimizing conditional partial ratio building block partial solution We following theorem Theorem 1 Given minimization problem n f C isolation function μ mapping subsets q assume solution encoded mlength binary vector For constant r cid3 1 respect corresponding partial reference function L 1 pratiox 2 partial solution x pratiox cid2 r SEIP takes x parent solution generates offspring partial solution cid2 r y μx μx y pratio y x cid2 r polynomial time q m SEIP ﬁnds rapproximate solution polynomial time q m Proof Starting x ﬁnd sequence partial solutions x1 x2 xcid5 x cid5cid4 i1 xi feasible cid9 1 cid5 pratio xi x cid10 x j cid2 r i1cid4 j1 conditions Note partial solution added solution offspring solution different isolation parent solution Since isolation function linearly additive length sequence cid5 greater number isolations q 1 Let t time expected SEIP generate partial solution xi sequence parent solution polynomial q m condition It takes O q expected steps SEIP pick parent q 1 solutions population Therefore total time reach feasible solution x O t q cid5 O t q2 polynomial q m By Lemma 2 feasible solution x composed x partial solutions x1 x2 xm approximation ratio x large maximum conditional partial ratio partial solutions r cid2 Theorem 1 reveals SEIP work achieve approximate solution Starting set SEIP uses mutation operator generate solutions isolations ﬁnally generates feasible solution During process SEIP repeatedly optimizes partial ratio isolation ﬁnding partial solutions better conditional partial ratios Since feasible solution viewed composition sequence partial solutions set approximation ratio related conditional partial ratio partial solution In Theorem 1 approximation ratio upperbounded maximum conditional partial ratio building block partial solutions lower conditional partial ratios utilized Moreover Theorem 1 restrict SEIP append partial solutions GSEIP remove partial solutions bitwise mutation The approximation ratio tighter bound consider issues Applying principle Theorem 1 present theorem GSEIP particular leads tighter approximation ratio Deﬁnition 6 Nonnegligible path Given minimization problem n f C isolation function μ mapping subsets q assume solution encoded mlength binary vector A set solutions N nonnegligible path ratios riq1 N pair solutions y N solution x N exists solution x i0 gap c x satisﬁes cid15 x y y y cid2 c y 1 1 cid2 y f y 2 3 μx q μx y x cid2 rμx OPT y y μx Y Yu et al Artiﬁcial Intelligence 180181 2012 2033 27 Theorem 2 Given minimization problem n f C isolation function μ mapping subsets q assume solution encoded mlength binary vector If exists nonnegligible path ratios riq1 q1 i0 ri approximate solution expected time O q2mc i0 gap c GSEIP ﬁnds cid2 Proof We prove theorem tracking process GSEIP nonnegligible path We denote xcur solution want operate Initially xcur x μxcur 0 GSEIP takes O q expected steps operate xcur q 1 solutions population GSEIP selects operate step According deﬁnition nonnegligible path exists pair solutions y The probability mutation operator generates solution x y respect xcur cid15 1 cid2 y 1 y m c m1 cid2 c We denote x cid15 xcur y y m lc implies O mc expected steps According deﬁnition nonnegligible path suppose μxcur f y y cid15 decomposed recursively according theorem conditions xcur cid2 ri OPT Note f x cid12 cid15 x cid11 cid11 f y f y ri OPT f xcur cid12 cid11 xcur f cid12 cid11 cid12 xcur icid13 j0 r j OPT f cid12 cid11 x icid13 j0 r j OPT Let L corresponding partial reference function Thus pratiox cid15 cid2 j0 r j OPT Lμxcid15 Given μxcur according deﬁnition nonnegligible path μx cid15 solution x population exists solution x cid15 ratio x Lemma 1 substitute x cid15cid15 cid15cid15 μx cid15cid15 μx cid15 μx Then store smaller partial cid15cid15 cid15 x j0 We pratioxcur cid2 cid15 Now let xcur x After q iterations update xcur μxcur q means xcur feasible Thus q1 j0 r j approximation ratio partial ratio xcur pratioxcur q1 j0 r j OPT OPT q1 j0 r j OPT Lμxcur Thus q jumps needed reach feasible solution takes O mc expected steps operation particular solution takes O q expected steps choose particular solution Overall takes O q2mc expected steps achieve feasible solution cid2 Lμxcid15 cid2 cid2 cid2 cid15 x cid2μxcur 1 r j OPT Using Theorem 2 prove approximation ratio GSEIP speciﬁc problem need ﬁnd nonnegligible path calculate conditional evaluation function jump path One way ﬁnding nonnegligible path problem follow existing algorithm problem This lead proof EA achieve approximation ratio simulating existing algorithm Similar ideas conﬁrm EAs simulate dynamic programming 6 In addition note concrete form partial reference function required theorem 5 SEIP MSCP To apply SEIP MSCP use ﬁtness function f x w x objective minimizing total weight For solution x denote Rx set elements covered x We use isolation function μx Rx cid3 SxC S Rx cid15 C owing effect isolation function makes solutions compete cover number elements We regard partial reference function L x minimum price optimal solutions pay covering number elements covered x necessary calculate partial reference function Instead directly assessing minimum kset cover problem n w C U k analyze EAs extended input cid15 U k 13 The original problem extended ﬁrst taking closure C subset operation n w cid15S j cid15 C 2S S C weight vector w C extended accordingly w S S1 S2 S j Then optimal solution contains set k elements construct new problem stance U added minimum number dummy elements sets optimal solution ﬁlled ksets dummy elements keeping weights unchanged Therefore extended problem optimal solution containing ksets Analysis extended input leads result original problem shown Lemma 3 The lemma derived Lemmas 2 3 13 cid15S minw cid15S2 w cid15S1 w cid15 28 Y Yu et al Artiﬁcial Intelligence 180181 2012 2033 Fig 1 The matrix M representation 13 elements minimum kset cover problem containing exactly k rows Lemma 3 The extended input affect optimal cost optimal solutions We assume loss generality k optimal solution xOPT consists ksets S disjoint S j S S 1 S 2 S L j Thus optimal solution represented matrix M sponds elements S exactly k elements For element e denote M contains e We denote w time e covered e cost M Note exactly k rows M elements plotted Fig 1 column corre set optimal solution contains e column e belongs set xOPT e e Ne number uncovered elements column M 51 SEIP ratio unbounded MSCP In Theorem 3 SEIP achieves Hkapproximation ratio k cardinality largest set It proved SEMO 11 achieves Hnapproximation ratio MSCP known asymptotic lower bound problem The theorem conﬁrms SEIP simulate multiobjective EAs terms solution retained SEIP able achieve approximation ratio obtained multiobjective EAs Theorem 3 Given MSCP n w C U C m GSEIP ﬁnds Hkapproximate solution expected time O mn2 k size largest set C The theorem proved simulating greedy algorithm property greedy algorithm Lemma 4 derived 5 Lemma 4 Given MSCP n w C U arbitrary partial solution x let ˆS arg minS r S respect x For element e ˆS exists set M e optimal solution covers e holds pricee cid2 wM e Me Rxcur Proof Theorem 3 We ﬁnd nonnegligible path following greedy rule given current partial solution add set ˆS minimum r ˆS Algorithm 1 We denote xcur current solution operated We ﬁnd y xcur Let y Thus y y 1 μx y y cid3 μx 1 partial solution x By Lemma 4 e ˆS Rxcur exists set M e optimal solution covers e suppose ˆS set ˆS minimizes r ˆS respect pricee cid2 wM e Me Rxcur In worst case ˆS Rxcur 1 added set covers uncovered element e In case according deﬁnition pricee w ˆS pricee We cid11 f y xcur y cid12 cid11 f xcur y cid12 cid11 cid12 xcur f 1 Me Rxcur cid11 cid12 e M w w ˆS cid2 Thus ﬁnd nonnegligible path gap 1 sum ratios Y Yu et al Artiﬁcial Intelligence 180181 2012 2033 29 cid13 e 1 Me Rxcure cid11 cid12 e M w cid2 xOPT cid13 cid13 j1 eS j xOPT cid13 cid13 j1 eS j 1 Me Rxcure cid11 cid12 e M w 1 Me Rxcure cid11 cid12 j S w 1 Me Rxcure xOPT cid13 j1 xOPT cid13 cid11 cid12 j S w kcid13 i1 cid11 cid12 j S w Hk j1 Hk OPT xcure denotes partial solution cover e step k size largest set C By Theorem 2 GSEIP ﬁnds Hkapproximate solution Note isolation function maps n isolations nonnegligible path constant gap 1 solution encoded mlength binary vector GSEIP takes expected time O mn2 cid2 Note proof Theorem 3 respect xcur ﬁnd y 0 y 1 Thus proof adapted LSEIP directly Theorem 4 Theorem 4 Given MSCP n w C U C m LSEIP ﬁnds Hkapproximate solution expected O mn2 time k size largest set C 52 Ratio GSEIP minimum kset cover problem In section prove Theorem 5 GSEIP achieves Hk k1 8k9 approximation ratio GAWW Algo rithm 2 13 current best algorithm minimum kset cover problem This result reveals problem bounded likely realworld situations GSEIP yield better approximation ratio unbounded situation Since greedy algorithm achieve approximation ratio lower Hn result implies GSEIP essential nongreedy behavior approximations Theorem 5 Given minimum kset cover problem n w C U k C m denote Rx Rx ﬁnds Hk k1 8k9 approximate solution expected time O mk1n2 cid3 Sx S GSEIP μx When applying GAWW rule select sets use Lemmas 5 6 Owing assignments price total price elements covered X equals cost X We set S lastcovered e S Ne 0 Lemma 5 Lemma 4 13 In step GAWW partial solution H disjoint Lemma 6 Lemma 5 13 In step GAWW assume loss generality set added X S element common set xOPT Q Lemmas 7 10 derived Lemmas 8 9 10 13 required calculating weights sets GSEIP selects following GAWW rule Lemma 7 Given minimum kset cover problem n w C U k arbitrary partial solution x GAWW rule uses drawal step add sets Q S1 S2 Sl x withdrawal S x denoting R cid3 S Q S cid13 S Q wS cid2 w S cid13 eR S e w Ne 1 cid13 eR S w e k4 30 Y Yu et al Artiﬁcial Intelligence 180181 2012 2033 Lemma 8 Given minimum kset cover problem n w C U k arbitrary partial solution x GAWW rule selects set S lastcovered add x greedy step element e cid15 S cid12 cid11 e cid15 cid12 cid11 e cid15 w price cid14 1 Li 1 1 4k5 cid15 wS cid2 cid13 eS e w Ne 1 cid13 eS e w 8k8 Lemma 9 Given minimum kset cover problem n w C U k arbitrary partial solution x GAWW rule selects set S lastcovered add x greedy step followed set S elements e S cid15 pricee cid3 w cid14 cid12 cid11 e cid15 1 hi 1 1 4k5 cid15 wS w cid12 cid15 cid11 S cid2 cid13 eS e w Ne 1 cid13 eS e w 8k8 Lemma 10 Given minimum kset cover problem n w C U k arbitrary partial solution x GAWW rule selects set S lastcovered add x greedy step e w Ne 1 wS cid2 cid13 eS Proof Theorem 5 We ﬁnd path isolations following GAWW rule Note n 1 isolations For xcur belonging isolation μxcur path GAWW rule selects sets satisfying Lemmas 7 8 9 10 ﬁnd y containing sets added y containing set withdrawn Thus y y Since GAWW rule covers uncovered element μxcur y As long lastcovered set included Lemmas 7 8 9 partial ratio f y cid2 k 1 y μxcur y xcur w y w y upperbounded cid11 w y cid12 cid12 cid11 y cid2 w cid13 cid14 cid3 e S y cid3 S y e w Ne 1 w e 8k8 cid15 GAWW rule selects lastcovered set greedy step Lemma 10 noting y e w Ne 1 w cid13 cid2 cid15 cid14 w cid3 cid3 y y cid12 cid11 cid11 cid12 e S y S y In worst case 1k elements lastcovered Therefore ﬁnd nonnegligible path By Theorem 2 GSEIP ﬁnds solution approximation ratio cid14cid13k i1 1 OPT cid15 OPT k 1 k OPT 8k8 Hk k 1 8k9 expected time O mk1n2 cid2 53 Comparison greedy algorithm LSEIP GSEIP We assess greedy algorithm LSEIP GSEIP subclass minimum kset cover problem denoted prob lem I We Propositions 1 3 LSEIP GSEIP overcome diﬃculty limit greedy algorithm yield better approximation ratios Problem I minimum kset cover problem n w C U constructed follows Note n kL integer L L i1 contains k elements U Imagine The collection sets C consists weight 1 cid2 cid2 0 assign S j weight 1 j Problem I constructed The optimal solution consists L nonoverlapping sets S elements S sets S S j Assign S shown Fig 2 ordered let S j contain jth element set S Y Yu et al Artiﬁcial Intelligence 180181 2012 2033 31 Fig 2 Subclass I minimum kset cover problem Proposition 1 Given arbitrary value ξ 0 approximation ratio greedy algorithm problem I lowerbounded Hk ξ Proof Note greedy algorithm adds set minimum cost solution step On initialization k S ik smallest cost Thus S ik added cost S k1 S ik1 The greedy algorithm continues choose cid2 1cid2 Let 1cid2 solution Then cost S nonoptimal set Finally sets S j added solution The approximation ratio Hk Hk ξ Hk cid2 1cid2 ξ arbitrarily small positive value cid2 arbitrarily small cid2 k higher cost 1 1cid2 k1 higher 1 Proposition 2 With probability 1 1 1 k n3 expected steps k1 LSEIP ﬁnds Hk k n Hk 1approximate solution problem I O 1 Proof Let LSEIP run k elements uncovered solution identiﬁed This takes O mn2 expected steps In Theorem 4 O 1 1 worst case assume k elements set S k n The uncovered k elements covered sets S k n3 m 1 1 Given solution operated S probability k cover k elements S m set Sˆi j j 1 2 k selected m remaining probability elements covered return solution Therefore k1 set Sˆi j j 1 2 k selected probability selected probability 1 ˆi ˆi ˆi selected probability 1 ˆi k k1 Suppose set Sˆi ˆj selected To cover uncovered element S 1 2 ˆj k selected probability k1 k Therefore set S selected probability ˆi ˆi selected probability 1 k Sˆi j j 1 k 1 1 k cid15 cid14 1 1 k 1 1 2 cid14 k1cid16 cid15 1 1 i3 1 2 2 k 1 1 k 1 k k 1 1 k k 1 k 1 1 1 k 1 k k 1 O k 1mn steps overwhelmed O mn2 In worst case set S ratio ˆi optimal solution selected feasible solution Thus approximation L 1Hk 1 cid2 L1 cid2 cid2 L 1 L Hk 1 L Hk 1 L Hk 1 Hk k n Hk 1 cid2 Proposition 3 GSEIP ﬁnds optimal solution problem I O 1 k 1 1 k k1 nk3 expected steps 32 Y Yu et al Artiﬁcial Intelligence 180181 2012 2033 Proof Let GSEIP run feasible solution takes O mn2 expected steps according Theorem 3 In worst case suppose feasible solution consists sets S j approximation ratio Hk ξ arbitrary small value ξ 0 Keep GSEIP running optimal solution GSEIP chooses operate feasible solution probability 1 n n isolations implies O n steps Operating feasible solution GSEIP uses mutation operator replace sets S j probability m1 S steps Once sets S j solution retained j m k1 k 1 bits solution ﬂipped implies O mk1 partial ratio approximation ratio decreases mutated k k1 Therefore GSEIP takes O mn2 nmk1 L steps note O mn2 nmk1 L O mn2 n2mk1k O 1 k m mk1 1 j replaced S 1 1 nk3 m n1 1 k cid2 For GSEIP derive Proposition 4 proof similar Proposition 3 Proposition 4 GSEIP ﬁnds Hk c k c 0 1 n k n Hk 1approximate solution problem I O mn2 cn2mk1k expected steps This proposition illustrates interesting property compared greedy algorithm performance improved given extra time SEIP seeks better approximate solutions Users allocate running time tradeoff better solutions However solution quality improved EA long time practical HPhard problems Thus users assume useful relationship time allocated approximate ratio 6 Conclusion We studied approximation performance EA framework SEIP introduces isolation function manage com petition solutions conﬁgured single multiobjective EA We analyzed approximation performance SEIP partial ratio obtained general characterization SEIP approximation behavior Our analysis conﬁrms SEIP achieve guaranteed approximate solution tries optimize partial ratio solu tions isolation ﬁnding good partial solutions partial solutions form feasible solution good approximation ratio We studied performance SEIP MSCP NPhard Previous studies 1128 showed 1 1EA good solver MSCP multiobjective EA achieves similar approximation ratio greedy algorithm Our analysis extends previous work unbounded MSCP SEIP achieves Hkapproximation ratio Hk harmonic number cardinality largest set asymptotic lower bound For minimum kset cover problem achieves Hk k1 8k9 approximation ratio current bestachievable result 13 ability greedy algorithm Moreover subclass MSCP SEIP onebit bitwise mutation overcome diﬃculty limits greedy algorithm We discussed advantages limitations SEIP approximations To prove SEIP approximation ratio MCSP problem SEIP simulate greedy algorithm Since greedy algorithm general scheme approxi mations analyzed problems SEIP analysis extended cases greedy algorithm applied easily SEIP 1 k approximation algorithm kextensible systems 21 including bmatching maximum proﬁt scheduling maximum asymmetric TSP problems Moreover prove approx imation ratio SEIP minimum kset cover problem SEIP simulate GAWW algorithm implies SEIP extra behaviors provide opportunities exceed greedy algorithm However limitations SEIP Theorem 2 There situations SEIP fail SEIP required ﬂip number bits time depends n achieve good solution In situation ﬂip required number bits onebit mutation limited ﬂips bit time bitwise mutation limited requires exponential time Further designs elegant mutation operators possible However solution space size 2n mutation assign exponentially small probability distant mutations Once distant mutations required exponential time required Another view limitation mutation operator allows limited steps SEIP overoptimize partial ratios like greedy algorithm overoptimizes step Our theoretical analysis suggests EAs achieve solutions guaranteed performance We believe guaran teed better approximation performance achieved better EA design future Acknowledgements We thank Dr Per Kristian Lehre Dr Yitong Yin helpful discussions This work partly supported National Fundamental Research Program China 2010CB327903 National Science Foundation China 61073097 61021062 EPSRC UK EPI0102971 EU FP7PEOPLE2009IRSES project Nature Inspired Computation Applications NICaiA 247619 Y Yu et al Artiﬁcial Intelligence 180181 2012 2033 33 References 1 N Alon D Moshkovitz S Safra Algorithmic construction sets krestrictions ACM Transactions Algorithms 2 2 2006 153177 2 A Auger B Doerr Theory Randomized Search Heuristics Foundations Recent Developments World Scientiﬁc Singapore 2011 3 T Bäck Evolutionary Algorithms Theory Practice Evolution Strategies Evolutionary Programming Genetic Algorithms Oxford University Press Oxford UK 1996 4 E Benkhelifa G Dragffy A Pipe M Nibouche Design innovation real world applications evolutionary algorithms 2009 IEEE Congress Evolutionary Computation Trondheim Norway 2009 pp 918924 5 V Chvátal A greedy heuristic setcovering problem Mathematics Operations Research 4 3 1979 233235 6 B Doerr AV Eremeev C Horoba F Neumann M Theile Evolutionary algorithms dynamic programming Proceedings 11th ACM Conference Genetic Evolutionary Computation Conference GECCO09 Montreal Canada 2009 pp 771778 7 S Droste T Jansen I Wegener A rigorous complexity analysis 1 1 evolutionary algorithm linear functions boolean inputs Evolu tionary Computation 6 2 1998 185196 8 R Duh M Fürer Approximation kset cover semi local optimization Proceedings 29th Annual ACM Symposium Theory Computing STOC97 El Paso TX 1997 pp 256264 9 U Feige A threshold ln n approximating set cover Journal ACM 45 4 1998 634652 10 T Friedrich J He N Hebbinghaus F Neumann C Witt Analyses simple hybrid algorithms vertex cover problem Evolutionary Computa tion 17 1 2009 319 11 T Friedrich J He N Hebbinghaus F Neumann C Witt Approximating covering problems randomized search heuristics multiobjective models Evolutionary Computation 18 4 2010 617633 12 O Giel I Wegener Evolutionary algorithms maximum matching problem Proceedings 20th Annual Symposium Theoretical Aspects Computer Science Berlin Germany 2003 pp 415426 13 R Hassin A Levin A betterthangreedy approximation algorithm minimum set cover problem SIAM Journal Computing 35 1 2005 189200 14 J He X Yao Drift analysis average time complexity evolutionary algorithms Artiﬁcial Intelligence 127 1 2001 5785 15 J He X Yao An analysis evolutionary algorithms ﬁnding approximation solutions hard optimisation problems Proceedings 2003 IEEE Congress Evolutionary Computation CEC03 Canberra Australia 2003 pp 20042010 16 T Higuchi M Iwata D Keymeulen H Sakanashi M Murakawa I Kajitani E Takahashi K Toda N Salami N Kajihara N Otsu Realworld applications analog digital evolvable hardware IEEE Transactions Evolutionary Computation 3 3 1999 220235 17 GS Hornby A Globus DS Linden JD Lohn Automated antenna design evolutionary algorithms Proceedings 2006 American Institute Aeronautics Astronautics Conference Space San Jose CA 2006 pp 1921 18 JR Koza MA Keane MJ Streeter Whats AI lately Genetic programmings humancompetitive results IEEE Intelligent Systems 18 3 2003 2531 19 M Laumanns L Thiele E Zitzler E Welzl K Deb Running time analysis multiobjective evolutionary algorithms simple discrete optimization problem Proceedings 7th International Conference Parallel Problem Solving Nature PPSN02 London UK 2002 pp 4453 20 A Levin Approximating unweighted kset cover problem Greedy meets local search SIAM Journal Discrete Mathematics 23 1 2008 251264 21 J Mestre Greedy approximation algorithms Proceedings 14th Annual European Symposium Algorithms ESA06 Zurich Switzerland 2006 pp 528539 22 F Neumann M Laumanns Speeding approximation algorithms NPhard spanning forest problems multiobjective optimization Proceed ings 7th Latin American Symposium Theoretical Informatics Valdivia Chile 2006 pp 745756 23 F Neumann J Reichel Approximating minimum multicuts evolutionary multiobjective algorithms Proceedings 10th International Con ference Parallel Problem Solving Nature PPSN08 Dortmund Germany 2008 pp 7281 24 F Neumann I Wegener Minimum spanning trees easier multiobjective optimization Proceedings 7th ACM Annual Conference Genetic Evolutionary Computation Conference GECCO05 Washington DC 2005 pp 763769 25 F Neumann I Wegener Can singleobjective optimization proﬁt multiobjective optimization J Knowles D Corne K Deb Eds Multiobjec tive Problem Solving Nature From Concepts Applications Springer Berlin Germany 2007 pp 115130 26 F Neumann C Witt Bioinspired Computation Combinatorial Optimization Algorithms Their Computational Complexity SpringerVerlag Berlin Germany 2010 27 F Neumann J Reichel M Skutella Computing minimum cuts randomized search heuristics Proceedings 10th ACM Annual Conference Genetic Evolutionary Computation GECCO08 Atlanta GA 2008 pp 779786 28 P Oliveto J He X Yao Analysis 1 1EA ﬁnding approximate solutions vertex cover problems IEEE Transactions Evolutionary Computation 13 5 2009 10061029 29 R Raz S Safra A subconstant errorprobability lowdegree test subconstant errorprobability PCP characterization NP Proceedings ACM Symposium Theory Computing STOC97 El Paso TX 1997 pp 475484 30 J Scharnow K Tinnefeld I Wegener Fitness landscapes based sorting shortest paths problems Proceedings 7th International Conference Parallel Problem Solving Nature PPSN02 Granada Spain 2002 pp 5463 31 P Slavík A tight analysis greedy algorithm set cover Journal Algorithms 25 2 1997 237254 32 C Witt Worstcase averagecase approximations simple randomized search heuristics Proceedings 22nd Annual Symposium Theoretical Aspects Computer Science STACS05 Stuttgart Germany 2005 pp 4456 33 Y Yu ZH Zhou A new approach estimating expected ﬁrst hitting time evolutionary algorithms Artiﬁcial Intelligence 172 15 2008 18091832