Artiﬁcial Intelligence 170 2006 472506 wwwelseviercomlocateartint Experiment selection discrimination semiquantitative models dynamical systems Ivayla Vatcheva Hidde Jong b Olivier Bernard c Nicolaas JI Mars d German Cancer Research Center DKFZ Im Neuenheimer Feld 280 69120 Heidelberg Germany b Institut National Recherche en Informatique et en Automatique INRIA Unité recherche RhôneAlpes 655 avenue lEurope Montbonnot 38334 Saint Ismier Cedex France c Institut National Recherche en Informatique et en Automatique INRIA Unité recherche Sophia Antipolis 2004 route des Lucioles BP 93 06902 Sophia Antipolis France d Materials Science Centre Department Mathematics Natural Sciences Rijksuniversiteit Groningen Nijenborgh 4 9747 AG Groningen Netherlands Received 19 September 2005 received revised form 13 November 2005 accepted 13 November 2005 Available online 9 December 2005 Abstract Modeling experimental results number alternative models justiﬁed available ex perimental data To discriminate models additional experiments needed Existing methods selection discriminatory experiments statistics artiﬁcial intelligence based entropy criterion socalled infor mation increment A limitation methods welladapted discriminating models dynamical systems conditions limited measurability Moreover generic procedures computing information increment experiment models qualitative semiquantitative This motivated development method selec tion experiments discriminate semiquantitative models dynamical systems The method implemented existing implementations qualitative semiquantitative simulation techniques QSIM Q2 Q3 The applicabil ity method realworld problems illustrated means example population biology discrimination competing models growth phytoplankton bioreactor The models traditionally considered equivalent practical purposes Using model discrimination approach experimental data superior describing phytoplankton growth wide range experimental conditions 2005 Elsevier BV All rights reserved Keywords Qualitative semiquantitative modeling simulation Model discrimination Information theory Population biology Computersupported modeling Corresponding author Email addresses IVachevadkfzheidelbergde I Vatcheva HiddedeJonginrialpesfr H Jong OlivierBernardsophiainriafr O Bernard NJIMarsfwnrugnl NJI Mars 00043702 matter 2005 Elsevier BV All rights reserved doi101016jartint200511001 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 473 1 Introduction Finding adequate model functioning complex systemeither natural manmadeis problem confronting practitioners different domains For instance arises population biologist studies ecosystem electrical engineer diagnoses fault electronic circuit medical doctor tries infer causes illness patient Given preeminence modeling human endeavor comes surprise methods computersupported modeling subject active research artiﬁcial intelligence For instance machine learning techniques infer model observations behavior 47 automated modeling techniques qualitative reasoning able derive model description user question domain theory 405163 The complexity task modeling cases available information allow decide alternative models study In examples interactions species ecosystem imagined fault electronic circuit failure different components symptoms patient variety causes The different assumptions structure behavior result number competing models justiﬁable available observations The existence set competing models gives rise problem model discrimination To discriminate number competing models identify adequately describes actual situation new observations needed These obtained performing additional experiments An experiment discriminates models predictions models ﬁt newly obtained data predictions Since reallife applications large number experiments performed cost considerable important experiments selected carefully In fact desirable experiments selected way set competing models maximally reduced systematic model discrimination minimal costs efﬁcient model discrimination Notice efﬁciency requirement necessarily minimizing number experiments cheap experiments cost single expensive experiment The problem model discrimination received substantial attention statistical literature 2829 reviews This resulted criteria determining experiment optimally discriminates different models These criteria based concepts derived information theory optimization theory applied variety problems biology biotechnology 15375557 physics 1645 chemical engineering 125 Similar criteria developed artiﬁcial intelligence especially ﬁeld modelbased diagnosis MBD 31 In case criteria play key role reducing number candidate diagnoses generated set hypotheses accounting observed faulty behavior device In order discriminate candidate diagnoses ﬁnd actually wrong methods selecting optimal measurements experimental conditions developed 202253 All methods share underlying intuition To evaluate discriminatory potential ex periment outcome predicted competing models The experiment model predictions differ highest chance discriminating models selected optimal discriminatory experiment Often intuition formalized means optimal information increment maximal difference entropy execution experiment The expected value information increment available experiments determined model predictions A ﬁrst problem existing methods model discrimination information increment criteria welladapted dynamical systems The criteria account possible states temporal ordering It shown certain conditions temporal evolution state necessary model discrimination 5354 These conditions fulﬁlled practice As consequence important account differences temporal behavior A second problem existing methods difﬁculty computing expected value information incre ment model predictions This especially true qualitative semiquantitative models like developed ﬁeld qualitative reasoning QR 265662 Qualitative models deal incomplete im precise information assigning symbolic values parameters initial conditions 42 In addition qualitative models contain incompletely speciﬁed functional relations variables deﬁned monotonicity properties Qualitative models extended semiquantitative models specifying numerical intervals bounding parameter values envelopes bounding monotonic functions 438 The models useful 474 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 scientiﬁc engineering domains deal parametric functional tolerances described intervals bounding curves However existing methods model discrimination focus numerical models allow qualitative semiquantitative models provide generic domainindependent computational framework computing expected information increment The limitations methods model discrimination statistics modelbased diagnosis mo tivated work described paper We present method systematic efﬁcient discrimination semiquantitative models dynamical systems 5859 The selection optimal discriminatory experiment based entropy criterion exploits model prediction temporal evolution state In addition method provides computational procedures actually calculate entropy criterion model predictions Overall model discrimination proceeds iteratively similarly sequential diagnosis strategy 2230 The algorithm starts set competing models initial probabilities assigned At step experiment highest discriminatory potential determined experiment executed experi mental outcome recompute probabilities competing models reﬁne parameter intervals This process continues models reached cutoff probability models zero probabilities possible experiments exhausted The method implemented Common Lisp qualitative semiquantitative simulators QSIM Q2 Q3 We demonstrate effectiveness method context real application population biology In domain competing models bound occur fact models based empirical relationships variables rarely appropriately validated More precisely problem discriminate competing models nutrientlimited phytoplankton growth chemostat The choice optimal discriminatory experiments critical application experiments weeks complete Semiquantitative models appropriate case biological systems available data noisy fragmentary The models traditionally considered equivalent practical purposes By applying model discrimination approach employing real experimental data superior reproducing phytoplankton growth wide range experimental conditions These socalled Droop CaperonMeyer models closely related assumptions underlying growth processes strike right balance empirical validity mathematical simplicity The article organized follows In section basic concepts deﬁned method model discrimination informally introduced The method based generalized entropy criterion Section 3 guides selection optimal discriminatory experiments In Section 4 algorithm model discrimination presented The results application method modeling nutrientlimited phytoplankton growth chemostat presented Section 5 In Section 6 method model discrimination discussed context related work section summarizes contributions indicates directions research 2 Basic concepts outline This section provides framework method model discrimination The concepts experimental sys tem experiment observation model competing models introduced outline method given 21 Experimental systems experiments An experimental physical chemical biological created sustained experimental setup 18 The experimental setup deﬁnes range experimental conditions Characteristic properties experimental systems behavior controlled observed Control achieved maintaining structure imposing experimental conditions Observations allow properties determined Here concerned dynamical systems That systems state evolves time For example consider experimental consisting phytoplankton culture chemostat Fig 1 The chemostat type bioreactor nutrients required cell growth supplied ﬁxed rate culture vessel contents continuously mixed Medium cells byproducts continually removed maintaining culture vessel constant volume The experimenters control things inﬂow rate I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 475 Fig 1 Schematic illustration chemostat growth medium light intensity temperature In addition observe phytoplankton biomass concentration remaining nutrients time An experiment action speciﬁc experimental conditions imposed temporal behavior observed conditions In context phytoplankton growth experiment consist observing evolution phytoplankton biomass given initial conditions concentration feeding substrate ﬁxed 22 Observations experimental systems The state experimental evolves time described set continuous variables called state variables More precisely state variable x function time deﬁned x R Dx Dx R1 In cases state completely determined limited measurability This means state variables observed timecourse experiment Usually certain quantities continuous functions state variables observed called observed variables denoted vector y In practice value y measured speciﬁed sampling points precision measurements limited Consequently available measurements restricted qualitative semi quantitative properties behavior deﬁned formally remainder section Following 42 deﬁne domain variable y quantity space The quantity space set totally ordered landmark values landmarks corresponding qualitativelysigniﬁcant values variable Some landmark values deﬁned beginning initial values Others introduced temporal evolution extreme values equilibrium values Most time exact landmark values known denote symbol The vector l denotes landmarks observed variables y Time variable quantity space composed landmarks special kind socalled distinguished timepoints At distinguished timepoint tj variable changes value landmark The qualitative value y timepoint tj interval successive timepoints tj tj 1 expressed terms landmarks quantity space direction change std dec The qualitative state timepoint timepoints consists tuple qualitative values variable The qualitative behavior timeinterval t0 tn given sequence qualitative states traversed interval That qualitative behavior deﬁned sequence qualitative states alternating states hold timepoint states timeinterval 42 details Each point state denotes qualitatively signiﬁcant event time evolution sense landmark value variable reached As remarked landmark values usually unknown But possible bound values numerical intervals In case concept qualitative behavior generalizes semiquantitative behavior 394258 1 R represents extended set real numbers including 476 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 By extension speak semiquantitative behavior subset variables instead entire An observation experiment formally deﬁned Deﬁnition 1 Observation An observation experimental experiment e semiquantitative behavior observed variables y landmark values l timeinterval experiment In cases useful adopt slightly modiﬁed deﬁnition observation For example obser vations landmarks l measured In addition landmarks deﬁned functions landmarks l measured amplitude period oscillation In follows assumption sampling frequency measurements chosen way observed qualitative behavior y corresponds real qualitative behavior y That exclude observation gaps In context phytoplankton growth observed variables biomass concentration remaining substrate The observations consist semiquantitative behavior variables For instance observation biomass ﬁrst reaches maximum followed steady state time substrate concentration decreases steady state This gives rise introduction landmark values corresponding maximum equilibrium values observed variables The observation provide interval bounds landmarks 23 Models experimental systems The relations quantities dynamical traditionally modeled ordinary differential equations ODEs equations form x f x u p xt0 x0 y gx u p 1 x vector state variables u vector control variables y vector observed variables x0 vector initial conditions p parameter vector The state variables observed variables functions time A control variable generally function time u R Du Du R However restrict attention timeinvariant controls The parameters timeinvariant deﬁnition Fig 2 shows ODE models describing nutrientlimited growth phytoplankton chemostat The Monod model 48 assumes consumed nutrient instantaneously transformed biomass This assumption ex pressed linear proportionality growth rate µ nutrient uptake rate ρ The Droop model 11 23 uncouples growth rate external nutrient concentration introducing intracellular store nutrients The growth rate µ hypothesized depend quantity q called cell quota average stored nutrients cell In cases knowledge experimental incomplete imprecise ODEs abstracted qual itative differential equations QDEs 42 In ﬁrst step ODE decomposed set basic mathematical equations possibly introducing additional auxiliary variables variables distinguished 1 Second variables parameters assigned quantity space landmarks basic equations mapped straints qualitative values variables parameters x µsx Dx s Dsin s ρsx µs µmax ρs 1 Y µs s sks Monod x µqx Dx q ρs µqq s Dsin s ρsx cid1 1 kq µq µ q s ρs ρmax sks cid2 Droop Fig 2 Monod Droop models describing nutrientlimited growth phytoplankton chemostat x denotes total biomass unit volume s concentration remaining nutrient q internal cell quota The following parameters dilution rate D input nutrient concentration sin maximum growth rate µmax halfsaturation constant ks growth yield Y maximum growth rate µ minimum cell quota kq maximum uptake rate nutrients ρmax See Fig 8 units variables parameters models I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 477 Consider instance Monod model given Fig 2 The ﬁrst equation x µs Dx decomposed following basic equations x bx b µ D D 0 b auxiliary variables Next equations mapped constraints qualitative values variables parameters DDTx MULTb x ADDb D µ CONSTANTD Often quantitative information available form numerical ranges parameters initial conditions numerical envelopes functional relations In cases QDE extended semiquantitative differ ential equation SQDE For instance QDEs obtained models Fig 2 converted SQDEs specifying interval bounds parameters initial conditions µmax 12 16 µ 17 23 x0 0088 0165 ks 001 02 ρmax 925 955 s0 44 46 sin 80 120 Y 015 06 kq 16 20 D 038 042 q0 16 762 2 More precisely SQDE intervals associated landmark values quantity space variables parameters When lead ambiguities simply speak interval bounds parameters initial conditions 3 In remainder article assume experimental systems modeled semiquantitative differential equations Predictions SQDEs derived means semiquantitative simulation A variety semiquantitative interval simulation techniques developed reviewed 175658 Here employ techniques developed ﬁeld qualitative reasoning particular technique QSIM 42 extensions Q2 174243 Q3 4 Essentially semiquantitative simulation consists reﬁning predictions qualitative simulator QSIM integration quantitative information Q2 Q3 In general model discrimination method presented paper depend particular set simulation techniques The requirement simulation techniques yield semiquantitative behavior predictions observed variables The QSIM algorithm predicts possible qualitative behaviors experimental based QDE scription Q2 Q3 exploit semiquantitative information SQDE reﬁne qualitative behavior tree produced QSIM More speciﬁcally rule qualitative behaviors transform semiquantitative behaviors computing reﬁning numerical bounds landmark values The behaviors observed vari ables resulting simulation Monod Droop models Fig 2 interval bounds 3 shown Fig 3 The table ﬁgure shows predicted interval bounds landmarks introduced simulation QSIM Q2 Q3 proven sound 44243 That possible semiquantitative behaviors consistent SQDE generated simulation algorithms On hand QSIM extensions incom plete sense spurious qualitative behaviors generated landmark bounds overestimated2 Given predicted semiquantitative behavior interval bounds parameter values reﬁned execution ex periment integrating measurements observed variables 2439 Measurements obtained previous experiments integrated deriving additional constraints comparison models describing different experiments This achieved means SQCA technique semiquantitative comparative analysis dynamical systems described SQDEs 5860 24 Competing models experimental systems To compare models observations need deﬁne means model observation consistent In follows let m denote SQDE model We deﬁne ym observed variables occurring model m Note general ym subset entire set observed variables y 2 The use terms soundness incompleteness consistent interpretation simulation logical inference process 41 The disjunction qualitative semiquantitative behaviors generated simulation true sense includes genuine behaviors soundness However simulation able infer true disjunction genuine spurious behaviors incompleteness See 52 alternative interpretation 478 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 Deﬁnition 2 Consistency predictions observations A predicted observed semiquantitative behavior experimental consistent ym 1 The observed sequence qualitative values ym predicted sequence qualitative values 2 The interval bounds corresponding landmark values predicted observed behavior overlap By extension model m consistent observed semiquantitative behavior predicted semiquantitative behaviors consistent observation If SQDE model consistent observed behavior entire range possible experimental conditions model correct This suggests criteria SQDE satisfy qualify candidate model experimental In particular require SQDE consistent available observations usually cover small fraction range possible observations Deﬁnition 3 Candidate model An SQDE model m candidate model experimental al ready performed experiment observed semiquantitative behavior consistent model consistency deﬁned Deﬁnition 2 Consider example phytoplankton growth chemostat The observed variables include biomass x concentration remaining nutrient s These state variables Monod model M x sT If available experiments predicted values x s consistent observations yM according Deﬁnition 3 Monod model qualiﬁes candidate model experimental The problem model discrimination arises candidate models making different assumptions structure behavior experimental The models competing common observed variables In addition candidate models yield different predictions variables range experimental conditions study These criteria summarized following deﬁnition Deﬁnition 4 Competing models Let M set candidate SQDE models Furthermore let yM denote observed variables shared models set The models M competing 1 yM 2 For pair models m mcid6 M ﬁnd experimental conditions semiquantitative behavior predictions yM differ The deﬁnition states m mcid6 competing predict different semiquantitative behaviors yM experiment Difference means predicted sets qualitative behaviors differ case models predict exactly set qualitative behaviors numerical bounds corresponding landmark values behavior completely overlap In follows assume notational simplicity observed variables y occur models M y yM As seen Fig 2 Monod Droop models share observed variables biomass x concentration limiting nutrient s Furthermore simulation results Fig 3 given experimental conditions models predict different sets qualitative behaviors variables Hence according Deﬁnition 4 models competing For m set competing models M deﬁne pm stand probability m correct model experimental range experimental conditions A priori estimates probabilities determined available experimental data If data exist assume models equiprobable priori When new data available probability estimates updated according match model predictions observations Bayes rule I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 479 Monod b1 Droop b1 Droop b2 Monod b1 Droop b1 Droop b2 smax 4775 11836 440 11517 440 11809 t1 071 14709 053 0 015 3 s10 311 10769 082 2743 082 2743 t2 121 116 052 xmin 0076 0165 t3 117 x 1198 720 3011 6261 3011 6261 Fig 3 Semiquantitative behaviors biomass x remaining substrate concentration s predicted Monod Droop models numerical ranges 3 The Monod model predicts single semiquantitative behavior b1 x increases asymptotically equilibrium x The Droop model predicts semiquantitative behaviors b1 b2 Behavior b1 qualitatively equivalent behavior predicted Monod model In behavior b2 x ﬁrst reaches minimum followed maximum s equilibrium approached smax s denote corresponding landmark values predicted interval bounds given table s passes maximum reaching equilibrium s xmin x 25 Experiment selection model discrimination Discrimination competing models M achieved selecting performing experiments predetermined set possible experiments E The experiments E assumed chosen range experimental conditions relevant problem study For e E m M simulated appropriate parameter values initial conditions order determine predictions m semiquantitative behavior e The predictions competing models current probability estimates models compute expected information increment e Fig 4 The expected information increment criterion measures discriminatory potential experiment Intuitively experiment model predictions differ expected lead better discrimination experimental outcome generally agree fewer predictions In Section 3 intuition elaborated means approach based concepts information theory Once optimal discriminatory experiment determined executed The observation obtained adjust probability estimates pm models m M reﬁne interval bounds parameter values The experiment discriminates models M observation changed probability estimates models Optimal discrimination achieved observation consistent predictions single model If observation consistent predictions models experiments need selected carried In way problem model discrimination iterative process The procedure selecting experiment performing experiment updating probability estimates competing models Fig 5 repeated following happens model sufﬁciently high probability models M zero probability inconsistent observations set possible experiments E exhausted 480 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 Fig 4 Schematic overview selection experiments model discrimination Fig 5 Model discrimination iterative process 3 Criterion experiment selection In section propose criterion selection experiments discriminating competing semi quantitative models 5859 The criterion formalized means concepts information theory generalizes previous work statistics modelbased diagnosis 31 Information increment experiment Let M set competing models experimental priori probabilities pm m M We common assumption M contains single correct model sense Section 24 cid3 mM pm 1 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 481 3 Although 3 strong assumption practical consequences limited violation tested We assume set possible experiments E experimental given let Oe denote observation experiment e E A standard measure information theory information increment experiment e E 928 The infor mation increment deﬁned difference entropy execution experiment cid3 cid3 cid2H Oe pm ln pm pem Oe ln pem Oe 4 mM mM pem Oe denotes posteriori probability m given observation Oe e As easily veriﬁed cid2H reaches maximum posterior probabilities zero That observation e conﬁrms predictions single model On hand minimal value attained posterior probabilities equal Recall case observation Oe speciﬁc form semiquantitative behavior Deﬁnition 1 Execution experiment gives rise tuple Oe cid7le becid8 denotes observed qualitative behavior vector le denotes measurements landmarks observed variables instance minima maxima equilibrium values This allows write 4 follows cid3 cid3 cid2H le pm ln pm pem le ln pem le 5 mM mM pem le posteriori probability m given qualitative behavior observed e le vector measurements landmark values Criteria evaluating discriminatory potential experiment proposed statistics 2 25282935 modelbased diagnosis MBD 202253 But general information increment 5 proposed In particular work statistics omits qualitative behavior means 5 reduces cid2H le pm ln pm pem le ln pem le 6 cid3 cid3 mM mM The sophisticated criteria MBD 53 account qualitative features dynamics assume value landmark measured certain qualitative state This gives rise following expression information increment experiment cid3 cid3 cid2H le Se pm ln pm pem le Se ln pem le Se 7 mM mM Se set qualitative states observed e le vector measurements landmark values Notice temporal ordering qualitative states Se speciﬁed unlike qualitative behavior occurring 5 By disregarding greater lesser extent information provided semiquantitative behavior criteria 6 7 underestimate discriminatory potential experiment Section 62 Since posteriori probabilities models depend outcome experiment formed cid2H computed directly Instead compute expected value expected information increment cid2J e cid5 cid4 cid2H le cid2J e E 8 The expected value cid2H computed averaging possible experimental outcomes predicted competing models This easy achieve case model discrimination problems interested First models M semiquantitative differential equations SQDE predict semi quantitative behaviors experiment Second measurements taken experiments noisy best described random variables certain probability distribution Existing work statistics MBD provide help actually computing cid2J general form 8 Statistical criteria easily computable restricted algebraic equations exact numerical values 482 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 parameters initial conditions MBD approaches provide help calculating cid2J qualitative models case measurement selection 20 But provide generic procedures calculate cid2J information contained semiquantitative differential equation models problem far straightforward general In Section 32 derive expression expected information increment applying discrimination competing semiquantitative models dynamical systems This expression involves probability distributions estimated semiquantitative simulations experimental In Sections 33 34 propose procedure actual computation probability distributions 32 Expected information increment experiment Recall information increment cid2H experiment e deﬁned 5 expected information increment given 8 For clarity presentation assume moment single landmark l observed variable y measured experiment e The measured value denoted le Obviously landmark value included domain y le Dy le D short The expected value information increment experiment e cid2J e computed stages ﬁrst averaging predicted qualitative behaviors second taking behavior average model predictions landmark value That cid2J e E cid5 cid4 cid2H le cid5 cid4 peb cid2H le b cid3 E bBe Be set possible qualitative behaviors b e predicted competing models peb probability exhibits behavior b e Ecid2H le b expected value cid2H relative conditional distribution landmark value given b behavior That cid4 cid5 cid2H le b E cid2H l bf elb dl cid6 lD f elb conditional probability density function pdf landmark value given b behav ior experiment e Substituting expression Ecid2H le b 9 obtain expected information increment e cid2J e cid2H l bf elbpeb dl 10 According law total probability express probability b weighted sum conditional 9 11 behavior probabilities pebm cid3 peb pebmpm cid6 cid3 bBe lD mM cid3 pebm probability behavior observed e b provided m correct model Similarly according law express conditional pdf f elb follows f elb f elb mpeb m mM f elb m modelspeciﬁc pdf landmark value given b behavior e m correct model peb m probability model m correct b behavior e According Bayes rule peb m pebmpm Hence f elb cid3 mM f elb f elb mpebmpm 12 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 483 The modelspeciﬁc pdfs f elb m conditional behavior probabilities pebm satisfy following malization conditions cid6 f elb m dl 1 lD cid3 pebm 1 13 14 bBe m Be determination modelspeciﬁc pdfs behavior probabilities m set qualitative behaviors e predicted m Sections 33 34 consider In following proposition probability density function f elb probability peb normalization conditions 3 13 14 derive expression expected information increment cid2J Proposition 1 The expected information increment experiment e E given cid2J e cid3 mM pm cid3 bBe m pebm f elb m ln lD cid6 f elb mpebm f elbpeb dl Proof By substituting deﬁnition cid2H 10 cid3 cid7 cid3 cid3 cid6 cid2J e peml b ln peml b cid8 f elbpeb dl pm ln pm mM bBe lD mM peml b f el bmpm f el b f elb mpebmpm f elbpeb 15 16 17 Bayes rule Combining 16 17 obtain cid3 cid3 cid7 cid6 cid2J e pm bBe cid3 lD mM cid3 pm f elb mpebm f elbpeb cid6 pebm f elb m ln ln f elb mpebmpm f elbpeb cid8 ln pm f elbpeb dl f elb mpebm f elbpeb dl bBe m pm ln pm mM cid3 mM lD cid3 cid6 bBe m lD pebm f elb m dl cid3 mM pm ln pm cid6 cid3 bBe m lD f elbpeb dl Using normalizations 3 13 14 obtain cid3 cid3 cid6 pm ln pm pm ln pm mM cid3 mM pebm f elb m dl bBe m cid3 cid6 bBe m lD lD f elbpeb dl cid3 mM cid3 mM pm ln pm pm ln pm With equalities second expression cid2J 0 15 obtained cid1 The criterion cid2J ranks experiments E according expected information increment The optimal discriminatory experiment experiment expected informative informative experiment short That experiment cid2J e maximal Occasionally model predictions lead simpliﬁed expression cid2J The following corollary Propo sition 1 provides expression cid2J models predict qualitative behavior 61 484 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 Corollary 1 Let models M predict qualitative behavior b experiment e E Then 15 takes form cid6 cid2J e cid3 mM pm f elb m ln lD f elb m f elb dl 18 Proof If models predict qualitative behavior 15 rewritten cid2J e cid3 mM pmpebm f elb m ln lD cid6 f elb mpebm f elbpeb dl Moreover model predicts single qualitative behavior b conditional probability behavior equals 1 models That pebm 1 m M Consequently total probability behavior 1 cid3 cid3 peb pebmpm pm 1 mM mM After replacing value expression cid2J e result 18 obtained cid1 The following corollary derives expression cid2J reverse situation model predicts different set qualitative behaviors Corollary 2 Assume given experiment e E model m M predicts different set qualitative behaviors Then cid3 cid2J e pm ln pm mM 19 Proof Let mcid6 M m cid9 mcid6 From given assumptions pebmcid6 0 b Be expression f elb given 12 yields cid3 f elbpeb cid6 f elb m cid6 pebm cid6 pm f elb mpebmpm m This fact mcid6M b Be m Taking result account 15 takes form cid2J e cid3 mM pm cid3 bBe m pebm f elb m ln lD 1 pm dl cid6 equivalently cid2J e cid3 mM pm ln pm cid3 bBe m cid6 pebm f elb m dl lD By applying normalization conditions 13 14 expression 19 obtained cid1 Note 19 indicates maximum value cid2J e This conforms intuition e optimal discriminatory experiment outcome guaranteed consistent predictions model The criterion 15 applies landmark measured function landmarks observed variables Section 22 In addition easily generalizable case multiple landmarks measured In case substitute probability distributions joint probability distributions integral multiple integral landmarks In 21 described entropy criterion generalized account varying costs experiments I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 485 33 Estimation probability density functions The computation cid2J e requires modelspeciﬁc probability density functions f elb m landmark values The determination f elb m based predictions m Moreover important deﬁnition f elb m incorporates measurement uncertainty landmark Let l landmark observed variable y measured experiment e typically maximum minimum equilibrium value variable To account experimental noise measurement l assumed random variable mean le probability density function helle known analytic form uniform normal interval D R 28 The functions f elb m required computation cid2J e modelspeciﬁc estimations pdf helle In case quantitative models single pointvalue prediction le m landmark value provided m usually interpreted mean measurement 28 Hence f elb m deﬁned equal helle m In case semiquantitative differential equations predictions landmark values intervals Consequently different approach estimating functions f elb m needed m We assume predicted interval refers mean landmark value probability density function gexb m mean predicted interval known gexb m speciﬁes mean landmark measurement distributed given b behavior e m correct model Then pdf f elb m landmark deﬁned expected value cid6 f elb m helx b gexb m dx xD 20 In words deﬁne f elb m average possible values helx b weighted correspond ing probabilities gexb m The modelspeciﬁc pdfs mean landmark gexb m obtained directly model predic tions Recall predictions competing models landmark values obtained QSIM Q2 Q3 form intervals Section 23 Since known distribution predicted interval D interval predicted m landmark l assume uniform distribution More speciﬁcally Le m m 0 denotes interval length gexb m 1Le m x Le Assume moment measured value landmark uniformly distributed conﬁdence interval measurement That helx b 1ε l x ε2 x ε2 ε size conﬁdence interval The integral 20 computed exactly More speciﬁcally f elb m ε2 lLe m εLe m 1 Le m ε2 lLe m εLe m 0 l Le m l Le m ε2 Le m ε2 Le m ε2 ε2 l Le m l Le m ε2 Le m ε2 Le m ε2 ε2 21 m Le m lower upper bound interval prediction Le Le m respectively Fig 6 shows estimate modelspeciﬁc pdf x equilibrium value biomass behavior b1 predicted Monod model Fig 3 The expression f elb m deﬁned assumes mean landmark value uniformly distributed predicted interval Better estimations probability density functions gelb m f elb m obtained following way Let θ vector landmarks corresponding parameters initial conditions m given beginning experiment Because imprecise incomplete knowledge landmark values θ e approximated corresponding interval vector Θ e We partition Θ e vectors intervals Θ e j This results j approximation probability distribution θ Θ e Obviously know probability Θ e specify joint probability pθ Θ e 486 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 Fig 6 Plot function f elb m equilibrium biomass labeled x Fig 3 The predicted interval equilibrium x 1198 7199 The size conﬁdence interval ε set equal 3 behavior b1 predicted Monod model distributions parameters initial conditions assume independent uniform corresponding intervals That cid2 cid13 cid1 θ Θ e j p cid1 θi Θ e j cid2 p iI I set indices landmarks corresponding parameters initial conditions cid2 cid1 θi Θ e j p cid14 cid14Θ e j cid14 cid14 cid14Θ e cid14 cid14 cid14 Θ e denoting interval bounds θi e We simulate m vectors Θ e m bounding landmark values For predicted intervals Le Le j xb m 1Le mean That ge mj modelspeciﬁc pdf gexb m j As result obtain set usually overlapping intervals Le mj mj assume uniform distribution mj 0 This results following estimate x Le gexb m cid1 θ Θ e j cid2 ge j xb m p cid3 j J J set indices subintervals Θ e By subdividing Θ e ﬁner subintervals Θ e progressively better estimates gexb m f elb m j obtain Consider instance Monod model given Fig 2 Assume landmarks corresponding parameters Y sin m ks distributed corresponding intervals 3 shown Fig 7a Every interval subdivided number subintervals Monod model simulated combination subintervals The resulting predictions estimate modelspeciﬁc pdf gexb m equilibrium value x biomass In comparison Fig 6 uniform distribution mean predicted interval x assumed reﬁned estimate f elb m obtained Fig 7b Because approach arrives precise estimates modelspeciﬁc pdfs prediction optimal discriminatory experiments improved But improved predictions come higher computational costs In example instance 1440 simulation runs necessary obtain precise estimate 20 For complex models involving parameters beneﬁt increased precision outweigh computational costs Section 63 The approach straightforwardly generalized case multiple landmarks taken account For computational simplicity assume independent Hence corresponding joint pdf obtained product pdfs individual measured landmarks I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 487 Fig 7 Approximate probability distributions landmarks corresponding parameters y sin m ks Monod model given form histograms b Estimation probability density x behavior b1 Monod model Fig 3 obtained taking account distributions 34 Estimation behavior probabilities To compute cid2J e modelspeciﬁc behavior probabilities pebm known Obviously b m pebm 0 If b behaviors predicted m predicted m experiment e b Be b Be m estimate pebm obtained means following approach As let θ vector landmarks corresponding parameters initial conditions model m given Θ e beginning experiment let Θ e vector interval bounds θ e Furthermore let Θ e b vector interval bounds θ giving rise behavior b Be m obtained interval constraint propagation algorithms Q2 Q3 The programs launched simulation reﬁne behaviors intervals Θ e speciﬁed model Assume probability distributions parameters initial conditions given Having determined interval vector Θ e r ebm p b b Be cid1 cid2 θ Θ e b m deﬁne pθ Θ e independently distributed b probability θ lies Θ e b If assume parameters initial conditions r ebm cid1 θi Θ e bi cid2 p cid13 iI I set indices landmarks corresponding parameters initial conditions pθi Θ e probability value θi lies interval Θ e normalizing r ebms r ebm bi bi The modelspeciﬁc probability behavior b estimated 22 pebm cid15 r ebcid6m bcid6Be m If probability distributions θi s unknown assume uniform That cid2 cid1 θi Θ e bi p Θ e bi Θ e Intuitively pebm given fraction parameter volume giving rise b Notice reﬁned estimates behavior probabilities developed similar way Section 33 But omitted 488 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 Consider behaviors b1 b2 Fig 3 generated simulation Droop model b1 obtained initial cellular quota q0 192 762 b2 obtained q0 16 266 If assume q0 uniformly dis tributed interval 16 762 procedure outlined gives rb1D 09468 rb2D 01761 D stands Droop model After normalization obtain probability estimates pb1D 08432 pb2D 01568 Alternative approaches estimating probabilities qualitative behaviors proposed Berleant et al 3 Leitch Shen 44 In 3 interval bounds parameters initial conditions derive lower upper bound probability qualitative behavior We adopted approach computation expected information increment requires modelspeciﬁc behavior probabilities real values Leitch Shen 44 proposed algorithm prioritize qualitative behaviors model The method uses imprecise numerical information form fuzzy numbers deﬁne distance successor states qualitative behavior tree Each state given priority label according value distance The priority behavior estimated basis priorities states For purposes disadvantage algorithm orders behaviors b likely occur bcid6 derive quantitative estimate relative priorities b likely occur bcid6 35 Properties expected information increment The criterion cid2J important properties summarized theorems below3 The ﬁrst theorem asserts expected information increment experiment nonnegative That experiment expected informative average This property conforms intuition measurements experiment help decide models Theorem 1 The expected information increment experiment e E nonnegative cid2J e cid1 0 23 Equality holds models predictions Assume experiment e landmark values l1 l2 determined Theorem 2 shows cid2J desirable property measuring l1 l2 performing e expected informative measuring landmarks Theorem 2 Let cid2J e1 Ecid2H le measured cid2J e12 Ecid2H le l2 taken account Then 1 expected information increment e E landmark l1 2 expected information increment e landmarks l1 1 le cid2J e12 cid1 cid2J e1 In summary Theorem 2 says measure landmarks experiment expected information incre ment experiment higher measure Or equivalently expect better discriminate models observe The expected information increment cid2J deﬁned measures discriminatory potential single experi ment In section formulate method model discrimination sequential approach That step optimal discriminatory experiment determined experiment executed model probabilities updated light experimental outcome 3 The proofs theorems included Appendix A I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 489 4 Algorithm model discrimination 41 Description algorithm On basis cid2J criterion simple algorithm discrimination competing models formulated We assume model m M correct probability estimate predeﬁned threshold value α 0 α cid2 1 Algorithm 1 Model discrimination Let pm priori probabilities models m M E set possible experiments perform While m M pm cid9 0 m M pm α E cid9 Step 1 Determine predicted behaviors m M experiments e E Step 2 Use model predictions compute cid2J e e E Select e E cid2J e maximal Step 3 Perform experiment e determine le Step 4 Compute posteriori probabilities pemle models Set pm pemle Step 5 Reﬁne interval bounds parameters models M Step 6 Remove e E The algorithm iterates model sufﬁciently high probability pm cid1 α models zero proba bilities possible experiments executed Obviously algorithm terminates pm 0 m M assumption M contains correct model violated In ﬁrst step algorithm competing models m M simulated QSIM Q2 Q3 Section 23 order derive semiquantitative behaviors possible experiment e E In step 2 value expected information increment cid2J e computed experiment e E The computation cid2J e exploits predictions behavior e obtained models M More speciﬁcally predictions determine estimations modelspeciﬁc probability densities behavior probabilities Sections 33 34 The experiment yielding highest value expected information increment performed step 3 The results experiment qualitative behavior observed variables measurements landmarks le step 4 compute posterior model probabilities Bayes rule pemle f elebe mpebempm f elebepebe f elebe m modelspeciﬁc pdf Section 33 evaluated measurements landmarks le pebem probability behavior conditional model m Section 34 The total behavior probability pebe value conditional pdf f elebe computed 11 12 respectively The measurements landmarks le step 5 reﬁne interval bounds parameters models M interval constraint propagation algorithms Q2 SQCA In step algorithm performed experiment removed set possible experiments E 42 Implementation performance The algorithm model discrimination implemented Sun SparcStation5 running SunOS 551 The program written Common Lisp existing implementations QSIM Q2 Q3 27 58 contains approximately 1200 lines code4 The core implementation module computing expected information increment experiment It includes modules determining modelspeciﬁc probability density functions model predictions computing posteriori model probabilities Bayes rule The program takes input behavior predictions competing models possible experiments generated QSIM Q2 Q3 list initial model probabilities A teletype interface allows user 4 Another platformindependent implementation developed Java 490 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 specify values probability threshold α type distribution measurements The implementation application described Section 5 To evaluate performance method model discrimination investigated selection experiments according expected information increment criterion leads efﬁcient model discrimination More speciﬁcally studied efﬁciency method comparing number steps performed algorithm experiments selected according expected information increment versus experiments selected random For purpose following strategy adopted 5861 First competing models arbitrarily selected Exact parameter values randomly chosen corresponding interval ranges The resulting quantitative model exact predictions behavior numerical simulation5 The predicted landmark values treated mean measurements Finally measurements algorithm model discrimination applied number times different values ε α For performance study competing SQDE models massspring making differ ent assumptions spring friction forces The results reported 5861 shown expected average number experiments performed higher case random experiment selection These results demonstrate ability method discriminate efﬁciently semiquantitative models random choice experiments The simulation study shown average number performed ex periments decreases considerably landmarks taken account This conﬁrms intuition measurements experiment information behavior available better discrimination achieved Theorem 2 Interestingly massspring ex ample use reﬁned estimates pdfs described Section 33 lead signiﬁcant reduction number experiments needed model discrimination 5 Application discrimination models phytoplankton growth The method model discrimination presented previous section applied selection ex periments discriminating competing models phytoplankton growth chemostat In section discuss results application 51 Biological background Phytoplankton microscopic plants playing key role marine ecosystems Many phytoplankton species ex ist characteristic size shape growth properties 33 Like terrestrial plants phytoplankton contain chlorophyll necessary photosynthesis In photosynthesis sunlight energy source fuse wa ter molecules carbon dioxide carbohydrates plant food In addition light phytoplankton require nutrients growth A nutrient compound present sufﬁcient concentrations limiting growth phytoplankton Nutrient limitation primary factor determining abundance phytoplankton region world ocean As processes regulating phytoplankton growth difﬁcult study open sea growth conditions recreated laboratory means type bioreactor known chemostat Fig 1 It advantage certain biological parameters presumably inﬂuencing growth controlled experimenter The chemostat mainly study growth populations nutrient limitation Chemostat experiments investigate growth properties unicellular marine alga Dunaliella tertiolecta nitrate limitation The population growth studied different values dilution rate D F V F inﬂow rate V denotes volume culture vessel After inoculation chemostat organisms undergo stress phase adaptation new environmental conditions takes place After initial adaptation phase D 0 value dilution rate modiﬁed transient behavior new equilibrium observed Once reached equilibrium dilution rate experiment performed changing value D observing evolve 5 For numerical simulations fourthﬁfth order RungeKutta method implemented Maple I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 491 equilibrium Within run number dilution rate experiments performed lasting couple weeks The continuous supply medium allows frequent measurements biomass concentration remaining nitrate computermonitored environment disturbing behavior However data obtained noisy case biological systems 7 For instance phytoplankton biomass estimated phytoplankton biovolume difﬁcult measure high precision Furthermore measurements remaining substrate concentration unreliable small concentration values detection limit apparatus 52 Modeling phytoplankton growth A variety models proposed describing growth phytoplankton nutrient limitation chemostat All available models share basic idea low intra extracellular nutrient concentrations uptake rate ρ rate nutrient consumption growth rate µ limited proportional nutrient concentration b high nutrient concentrations uptake growth rates saturate constant 36 In study models growth phytoplankton considered The models different assumptions consumption nutrients inﬂuence biomass growth rate population relation growth uptake rates In addition Monod Droop models 112348 presented Section 2 consider models proposed Contois 14 Caperon Meyer 12 Fig 8 The Contois model variant Monod model growth rate population µ assumed inhibited biomass x Similarly Droop model CaperonMeyer model assumes intracellular storage nutrients However model differs Droop model assuming different expression growth rate population Because coarsegrained noisy data precise numerical estimations values parameters obtained This motivates use semiquantitative models The interval bounds parameter values x µsx Dx s Dsin s ρsx µs µmax ρs 1 Y µs s sks x µsx Dx s Dsin s ρsx µs x µmax ρs x 1 s skx x Y µs x Monod Contois x µqx Dx q ρs µqq s Dsin s ρsx µq µ1 kq q s ρs ρmax sks Droop x µqx Dx q ρs µqq s Dsin s ρsx µq µmax ρs ρmax qkq qkq k0 s sks CaperonMeyer Parameter Unit Meaning Interval value D sin µmax ks Y kx µ kq ρmax k0 1day µmoll 1day µmoll µm3µmol µmolµm3 1day µmolµm3 µmolµm3 day µmolµm3 dilution rate input nutrient concentration maximum growth rate halfsaturation constant growth yield halfsaturation constant maximum growth rate minimum cell quota maximum uptake rate nutrients halfsaturation constant 80 120 120 160 001 020 015 060 000 002 170 230 160 200 925 955 200 240 Fig 8 The Monod Contois Droop CaperonMeyer models nutrientlimited phytoplankton growth chemostat The models contain variables x s q x µm3l denotes total biomass unit volume s µmoll concentration remaining nutrient q µmolµm3 internal cell quota The parameters interval bounds given accompanying table The value D depends experiment consideration 492 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 estimated data obtained preliminary experiments 5 All experiments carried Laboratoire dOcéanographie VillefranchesurMer France 53 Experiment selection approach In order discriminate competing models discussed previous section considered chemostat experiments consisting changes value dilution rate D In response changes population attains new equilibrium value Section 51 We considered 21 possible experiments corresponding equispaced values D range 0 1 D 0 D 005 D 1 Taking account 5 measurement uncertainty values D bounded intervals During experiments biomass x concentration remaining nutrient s measured We consider following landmarks observed variables detection limit apparatus minima maxima equilibria x xmin xmax x minima maxima equilibria s smin smax s To obtain predictions required computing expected information increment experiments models simulated qualitative simulator QSIM semiquantitative extensions Q2 Q3 In general semiquantitative simulation leads prediction multiple qualitative behaviors models This consequence complexity models large intervals parameters initial conditions We veriﬁed qualitative behavior predictions spurious comparing output QSIM Q2 Q3 analysis models 6 In sections simulation results order experiments according expected information increment The criterion computed described Section 3 In particular standard instead reﬁned estimates probability distributions order reduce simulation costs The predicted optimal discriminatory experiment compared experiment actually carried Next data experiment taken account update model probabilities reﬁne interval bounds parameters The equilibrium data initial conditions simulate models predict optimal dilution rate experiment 54 Selection initial experiment The ﬁrst experiment performed default consists initial phase cells adapt new exper imental conditions D 0 In section investigate discriminating experimental results obtained setting D value For purpose simulated models QSIM Q2 Q3 dilution rate experiments The initial conditions Table 1 determined measurements biomass substrate concentration internal quota beginning experiment For D 0 models predict single qualitative behavior x asymptotically increases equilib rium x s asymptotically decreases s behavior b1 Fig 9 For values D models Table 1 Initial conditions applied dilution rate experiments considered text The reﬁned intervals parameters applying constraint propagation algorithms Q2 SQCA presented Experiment 1 2 3 Initial conditions x0 0088 0165 s0 50 55 x0 307 362 s0 0 001a q0 139 183b x0 253 283 s0 0 001a q0 282 474b Under detection limit b Computed auxiliary model based mass conservation 8 Applied D D 0 D 095 D 045 New parameter intervals MC Y 055 06 DCM kq 16 196 q0 54 76 D kq 165 19 CM kq 16 174 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 493 Fig 9 Selection initial experiment Qualitative behaviors growth Dunaliella tertiolecta predicted Monod M Contois C Droop D CaperonMeyer CM models dilution rate experiments considered initial conditions b1 predicted models experiment D 0 b2 predicted dilution rate experiments D 0 Fig 10 Selection initial experiment Expected information increment cid2J dilution rate experiments D 1 predicted optimal discriminatory experiment Experiment D 0 performed predict qualitative behavior equilibrium biomass x reached asymptotically remaining substrate concentration s ﬁrst reaches maximum decreasing equilibrium behavior b2 Fig 9 Because models predict single behavior b1 b2 depending value D pb1 1 pb2 1 The models assumed equiprobable priori pM pC pD pCM 025 Using initial probability estimates interval predictions x s smax behavior probabilities value expected information increment cid2J computed dilution rate experiments Fig 10 The ﬁgure shows optimal discriminatory experiment D 1 expected information increment cid2J 084 As explained single qualitative behavior b2 predicted The interval predictions models experiment shown Fig 11a The ﬁgure shows predictions x s predictions smax broad largely overlapping models As seen predictions Droop CaperonMeyer models included Monod Contois models precise The experiment actually performed D 0 turns experiment lowest expected information increment cid2J 033 Fig 11b displays predictions x s D 0 Notice models predict s 0 explains low cid2J value experiment comparison experiment D 1 We taken account results experiment D 0 update probability estimates models As seen Fig 12a x s asymptotically reach equilibrium agreement predicted qualitative behavior b1 interval predictions models As result models ruled Using Bayes rule posteriori model probabilities computed pM 008 pC 008 pD 041 pCM 041 24 494 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 b Fig 11 Selection initial experiment Interval predictions competing models s In predictions optimal discriminatory experiment D 1 given b shows predictions experiment actually carried D 0 In ﬁgures stronger shading designates overlap predictions x The posteriori model probabilities estimation quality ﬁt model predictions observation precision predictions The predictions Droop CaperonMeyer models include measurements x This case predictions Monod Contois models explains lower probability The measurements allow numerical bounds parameters competing models reﬁned interval constraint propagation algorithms Q2 SQCA Section 23 giving rise intervals Table 1 These reﬁned parameter intervals determination optimal discriminatory experiment 55 Selection second experiment After reached equilibrium value D changed behavior new equilibrium observed In order determine dilution rate experiment optimal applied QSIM Q2 Q3 simulate competing models possible experiment The new initial conditions determined equilibrium values x s q experiment D 0 Table 1 Obviously D 0 state change start equilibrium reached previous step For experiment semiquantitative simulation results single qualitative behavior models Fig 13 The behavior consists minimum x followed maximum s Of course probability behavior pb1 equals 1 Using model probabilities 24 simulation results expected information increment dilution rate experiments computed Fig 14 The results experiment D 1 optimal cid2J 069 Fig 15 summarizes model predictions x s xmin smax omitted discriminatory As seen predictions Monod Contois models hand Droop CaperonMeyer models overlap Even taking account uncertainty I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 495 Fig 12 Plot measurements temporal evolution biomass x approximated biovolume substrate concentration s NO3 initial experiment D 0 b second experiment D 095 c experiment D 045 Bernard Sciandra unpublished data Fig 13 Selection second experiment Qualitative behavior growth D tertiolecta predicted competing models dilution rate experiment For D 0 D cid2 1 single qualitative behavior b1 predicted measurement x performance experiment D 1 likely eliminate models This guaranteed case experiments The experiment D 1 performed data experiment D 095 cid2J value available Fig 12b The curve agrees predicted qualitative behavior equilibrium values Table 1 provide following posteriori model probabilities pM 0 pC 0 pD 056 pCM 043 25 Notice Monod Contois model eliminated measurements predictions lie outside measured interval x The Droop CaperonMeyer models approximately equally probable surprising given predictions overlapping large extent As shown Table 1 experi mental data reﬁne interval bounds parameter kq 496 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 Fig 14 Selection second experiment Expected information increment cid2J varying values dilution rate Experiment D 1 optimal discriminatory experiment experiment D 095 performed Fig 15 Selection second experiment Interval predictions competing models experiments D 1 optimal discriminatory experiment The predictions concern landmarks x s 56 Selection experiment After ﬁrst steps left models Which experiment able discriminate Droop CaperonMeyer models As simulate models equilibrium attained previous step For experiment models predicts possible qualitative behaviors biomass x Fig 16 For D 095 biomass expected increase asymptotically equilibrium behavior b1 ﬁrst pass maximum behavior b2 For D 095 models predict x decreases asymptotically new equilibrium behavior b3 ﬁrst passes minimum behavior b4 Estimation modelspeciﬁc behavior probabilities explained Section 33 shows pb1 pb2 05 pb3 pb4 05 models experiments Computation expected information increment shown indicates D 09 optimal discrimina tory experiment In reality D 045 performed In experiment x reach equilibrium passing maximum Fig 12c As consequence behavior b1 ruled The landmark values xmax x measured lie 413 437 348 383 respectively These results agreement predictions models yield following posteriori probabilities pD 041 pCM 059 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 497 Fig 16 Selection experiment Qualitative behaviors growth Dunaliella tertiolecta predicted competing models dilution rate experiment Behaviors b1 b2 predicted experiments D 095 behaviors b3 b4 predicted experiment D 095 That experiment succeeded discriminating models The predictions Caperon Meyer model precise Droop model shown explains slightly higher probability We break model discrimination process point data available run experiments We remark passing theory predict D 005 optimal discriminatory experiment In summary application illustrates choice experiments plays crucial role model discrimination If chosen experiment D 1 instead D 0 initial experiment obtained negligible posteriori probabilities Monod Contois model ﬁrst step This subsequent steps unnecessary Also chosen experiment low D value second experiment Monod Contois models probably ruled This complements results obtained Section 42 showed simulation study selecting experiments according expected information increment leads efﬁcient discrimination random selection experiments Two models ruled model discrimination process data experiments actually performed instead predicted optimally discriminatory In process interval bounds parameters remaining models considerably reﬁned Although Monod model variants like Contois model widely practice results study demonstrate suitable represent broad range phytoplankton growth conditions Instead Droop model closelyrelated Caperon Meyer model preferred The difﬁculty discriminate models reﬂects similarity Further experiments performed conditions predictions models diverge needed discriminate models 6 Discussion related work The method described paper domainspeciﬁc assumptions guarantees discrimination competing models wide range experimental systems variety scientiﬁc domains However requirements method applicable determined assumptions underlying key elements Figs 4 5 models experiments simulation techniques model discrimination criterion model discrimination strategy These assumptions discussed context related work 61 Models Most model discrimination methods developed quantitative models particular algebraic equation ordinary differential equation ODE models These models allow precise numerical predictions behavior use requires precise numerical values parameters exact functional relations 498 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 variables In situations available information incomplete imprecise impeding application quantitative models This especially domains mathematical modeling widespread far like biology medicine chemistry The inability quantitatively monitor behavior time frequentlyoccurring problem complicate use ODE models In response problems researchers qualitative reasoning QR proposed qualitative models dy namical systems typically qualitative differential equation QDE models 17265662 These models widely domains ODE models difﬁcult formulate For model discrimination qualitative haviors produced QSIM qualitative simulators sufﬁciently precise In addition experience upscaling problems explosion number qualitative behaviors spurious The semiquantitative models strike compromise precision quantitative models applicability qualitative models situations available information incomplete imprecise More particularly semiquantitative differential equations SQDEs extend qualitative differential equations specifying interval bounds parameter values numerical envelopes monotonic functions 438 The use weak numerical information helps alleviate upscaling problems experienced qualitative simulation sense number qualitative behaviors generated reduced spurious behaviors ruled But upscaling problems remain partly lack suitable tools Section 63 62 Criteria experiment selection In order discriminate competing models dynamical establish criterion allows ranking possible experiments according discriminatory potential Criteria determination optimal discriminatory experiments developed statistics AI They wide range problems different domains application biology biotechnology 15375557 physics 1645 chemical engineering 125 modelbased diagnosis 202253 Most criteria experiment selection based principle maximum divergence 225282935 Intu itively speaking means measure difference model predictions response different experimental conditions deﬁned followed search conditions measure maximized Here focused particular type maximum divergence criterion maximum entropy criterion examples references given The basic idea underlying maximum entropy criterion ﬁnd experiment highest information increment cid2H 4 experiment difference entropy execution maximal The expected value cid2J information increment available experiments determined model predictions The speciﬁc form maximum entropy criterion 4 takes resulting ranking experi ments critically dependent characteristics behavior dynamical wish consider In article proposed criterion given 5 speciﬁcally adapted semiquantitative description dynamics takes account qualitative behavior interval bounds land mark values variables This generalizes maximum entropy criteria statistical MBD literature given 6 7 respectively While omits qualitative behavior considers qualitative states temporal ordering qualitative behaviors The use generalized maximum entropy criterion increase discriminatory potential method Consider case competing models predict single observed variable reach equilibrium value experiment If models predict overlapping values equilibrium value experiment assigned low expected information increment according 6 However appropriate models predict different qualitative behaviors asymptotic increase versus decrease observed variable equilibrium value The criterion propose given 5 case assign high expected information increment experiment desired taking account predicted difference qualitative behavior It argued order discriminate models necessary account quali tative behaviors In fact information observed qualitative states leaving aside temporal ordering qualitative behaviors sufﬁce refute models This idea based insight models predicting different qualitative behaviors differ possible qualitative states I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 499 predict 54 It underlies maximum entropy criterion 7 proposed Struss 53 context MBD gener alizing earlier work Kleer Williams 22 Kleer 20 The criterion 7 advantage computationally expensive criterion 5 require transitions qualitative states computed However relies capability observe qualitative states predicted different models This possible variables observed situation uncommon practice In case experiment assigned low expected information increment according 7 receive high expected information increment The additional computational costs criterion 5 pay They increase discriminatory potential exploiting information time evolution particular conditions limited measurability To practically useful information increment 5 expected value 8 computed predictions models To end proposed problemindependent computational framework appropriate SQDE models speciﬁcally framework based semiquantitative simulation Several technical difﬁculties solved achieve notably computation modelspeciﬁc probability density functions f elb m landmark values Section 33 modelspeciﬁc behavior probabilities pebm Section 34 We aware existing work addressing problems Methods statistics deal quantitative models While MBD methods allow qualitative semiquantitative models specify computational procedures develop procedures speciﬁc certain type problem 2022 example case The development expression expected information increment Section 32 implicitly assumes determining optimal experiment need look step ahead However imagine better estimate cid2J obtained evaluating consequences carrying consecutive experiments limit proceeding single model remains 22 The increase discriminatory potential optimal experiment obtained multistep lookahead instead onestep lookahead approach needs carefully balanced additional computational costs involved Kleer et al 21 context diagnosis electronic circuits onestep lookahead leads nearoptimal results 63 Simulation techniques Simulation crucial step method model discrimination The expected information increment experiment evaluated basis predictions derived competing models As consequence techniques derive possible predictions predictions precise possible Omitted pre dictions cause model falsely ruled predictions derived model match observation experiment Precise predictions important efﬁciently discriminate models overestimation real solutions instance cause model corroborated ruled The techniques employed work satisfy ﬁrst requirement QSIM Q2 Q3 SQCA proven sound Section 23 As consequence models ruled But incompleteness simulation techniques spurious behaviors generated interval predictions overestimate real solutions This leads imprecise estimates modelspeciﬁc probability density functions behavior probabilities imprecise estimates cid2J Moreover spurious predictions lead imprecise estimates posterior model probabilities The simulation techniques employed paper aim obtaining interval predictions landmarks precise possible Q2 adds quantitative information output qualitative simulator QSIM propagating numerical bounds parameter values functions Q3 improve results Q2 reﬁning timestep simulation Within computational framework Q2 reﬁne interval bounds parameter values propagating results conducted experiments The reﬁnement parameter values integration measurements improved SQCA infers additional constraints comparison models describing previously performed experiments As noted previously increased precision predictions obtained techniques cost For example algorithm underlying Q3 stepsize reﬁnement interpolates new states given semiquantitative behav ior leading expansion constraint network derived corresponding SQDE Consequently constraint propagation needs time strain memory resources These similar problem simulation com putational bottleneck approach presented article especially case large models reﬁned 500 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 estimates modelspeciﬁc probability density functions Section 33 modelspeciﬁc behavior probabilities Section 34 The upscaling problems partly lack highperformance tools semiquantitative sim ulation But efﬁcient tools existed remains fundamental tradeoff precision predictions hand computational costs In cases price intensive simulation studies aimed highprecision predictions high beneﬁts avoiding costly timeconsuming experiments outweigh computational costs 64 Discriminatory experiments The ability discriminate competing models strongly depends set experiments carried This set assumed consist restricted number experiments selected domain expert taking account constraints feasibility safety Sometimes difﬁcult impossible intervene behavior In cases experiment se lection model discrimination restricted measurement selection 224649 In measurement selection determines optimal measurement perform Obviously experiment selection goes measurement selection determine optimal measurement perform optimal experimental conditions apply In fact measurement selection makes sense costs individual measurements taken account Indeed shown Theorem 2 experiments mentioned Section 42 measures landmarks experiment expected information increment experiment increases If measurements costly select informative subset obeys speciﬁed cost limits techniques similar experiment selection Experiment selection starts set available experiments One argue provides guar antee optimal experiment included set If cid2J known suspected nonsmooth function discretization continuous range experimental conditions introduce bias experiment design option The basic idea experiment design deﬁne expected information increment cid2J function experimental conditions need ﬁxed experiment The problem ﬁnding optimal experiment mapped optimization problem ﬁnd experimental conditions func tion reaches maximum 1132528 By determining optimal experimental conditions continuous range experiment design offers greater discriminatory capability But increases computational complex ity model discrimination problem global optimization approaches require large simulation runs 34 Given simulation computational bottleneck discrimination semiquantitative models Section 63 experiment design unfeasible practice Even ambitiously experiment design ﬁxing certain parameter value initial condition apply broader aspects experimental conditions experimental setup A explorations form experiment design AI literature instance work Rajamoney 50 Bradley et al 10 Generally speaking experiment design conceived requires explicit representation elements experimental setup methods construct model experimental domain theory description experimental setup This introduces issues knowledge representation automated reasoning fall outside scope article 65 Model discrimination strategy In order discriminate set models adopted method iterates selection execution experiments selection step based expected information increment criterion 5 We carried extensive simulation study test performance strategy case discrimination semi quantitative models simple mechanical Section 42 Under wide range conditions approach model discrimination turned efﬁcient random choice experiments sense average number experiments required discriminate models lower criterion 5 employed The iteration selection execution experiments amounts sequential strategy model discrim ination 2230 One imagine strategy consisting ﬁrst determination priori single I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 501 discriminatory experiment sequence experiments guaranteed discriminate models Once experimental plan computed executed second step As Struss 53 observes sequen tial approach save computational time refuted models need simulated determining optimal experiments In addition render experiments unnecessary models supposed discriminate ruled previous experiments Bradley colleagues proposed strategy problem related model discrimination ﬁnd simplest model valid representative range experimental conditions 10 Instead starting explicitlydeﬁned set possible models approach starts simplest model consistent userspeciﬁed hypotheses domain theory This model tested available observations increasingly precise sophisticated techniques analyze model ranging qualitative simulation numerical parameter estimation simulation bifurcation analysis If model fails reproduce data detailed model constructed On hand model succeeds reproducing data experiments corroborate refute model proposed executed The method terminates model globally valid range experimental conditions The idea hierarchical testing model validity postponing computationally intensive tests model successfully passed simpler tests proﬁtably model discrimination However testing model time signiﬁcantly raise computational costs model space large particular simple models inconsistent data For model discrimination strategy adopted article consists ﬁnding optimal experiments refute models possible general efﬁcient computationally experimentally 7 Conclusions work Different assumptions structure behavior result number competing models justiﬁable available observations This gives rise problem model discrimination occurs guises practically domain science engineering To discriminate models new exper iments needed Most experiment selection methods developed statistics artiﬁcial intelligence based information increment experiment difference entropy execution experiment Existing model discrimination methods limited respects First information increment criteria welladapted discrimination models dynamical systems conditions lim ited measurability Second generic domainindependent procedures computation expected information increment models qualitative semiquantitative Many applications concern dynamical systems variables measured great difﬁculty Moreover information required specify numerical models absent The situation motivated development method selection experiments discriminate semiquantitative models dynamical systems The method implemented existing imple mentations qualitative semiquantitative simulation techniques QSIM Q2 Q3 derive model predictions The method implementation independent particular application em ploy domainspeciﬁc knowledge experimental In fact numerical bounds parameters functional relations formulated set discriminatory experiments exists method described paper applicable The practical applicability method demonstrated real problem ﬁeld population biology In particular shown method predicts informative experiments discriminate competing models growth phytoplankton chemostat This achieved presence complicating factors particular complexity models crude estimations parameter values difﬁculty observe behavior Our results widelyused Monod model variants valid broad range phytoplankton growth conditions Droop CaperonMeyer model preferred In addition model discrimination process led reﬁned interval bounds key parameter models Several directions work identiﬁed First discussion previous section brought fore central role semiquantitative simulation model discrimination method In particular use simulation involves fundamental tradeoff experimental computational costs On hand reﬁne ment interval bounds lead method propose better discriminatory experiments precise 502 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 estimations cid2J On hand application sophisticated simulation techniques cause time spent computing cid2J explode More efﬁcient implementations current semiquantitative simulation techniques relieve upscalability problems Another possible solution combine semiquantitative Monte Carlo simulation Semiquantitative simulation derive guaranteed probably overes timated intervals values model variables Monte Carlo simulation derive fast approximations probability distributions More generally method model discrimination described paper integrated tools computersupported modeling tools model building model validation model revision giving rise integrated environments computersupported modeling 1019 Model building conceived composition model set reusable model fragments induction model observed behavior experimental 405163 lead large set competing models The selection optimal experiments help determining correct model systematically efﬁciently The explicit representation domain knowledge knowledge experimental setup provide necessary prerequisites developing ambitious forms experiment design Acknowledgements The authors like thank JeanLuc Gouzé contributions work presented reviewers comments previous versions article Most work described accomplished Ivayla Vatcheva PhD student Department Computer Science University Twente Netherlands Hidde Jong Nicolaas Mars Ivayla Vatcheva acknowledge ﬁnancial support Programme dactions intégrées franconéerlandaises Van Gogh dossier 99033 Appendix A Proofs theorems This appendix details proofs theorems given Section 35 Theorem 5 The expected information increment experiment e E nonnegative cid2J e cid1 0 Equality holds models predictions A1 Proof From Theorem 204 32 following inequality established cid6 cid3 bBe m cid1 ξml bf elbpeb ln ξml b dl lD cid3 cid6 bBe m lD ξml bf elbpeb dl ln cid15 bBe cid15 m cid16 lD ξml bf elbpeb dl lD f elbpeb dl cid16 bBe m A2 peb probability behavior b Be m f elb conditional pdf landmark given 12 ξml b bounded function Equality holds ξml b constant independent particular b l Deﬁne ξml b f elb mpebm f eybpeb m f elb m modelspeciﬁc pdf landmark pebm modelspeciﬁc probability b Be Hence rewrite righthand A2 follows cid6 cid3 bBe m lD f elb mpebm dl ln bBe cid15 m cid15 cid16 lD f elb mpebm dl cid16 lD f elbpeb dl bBe m A3 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 503 Taking account normalization conditions cid6 f elb m dl 1 lD cid3 bBe m pebm 1 given 13 14 f elb cid3 cid3 cid3 cid6 cid6 f elbpeb dl cid15 mcid6M f elb mcid6pebmcid6pmcid6peb 12 obtain cid6 f elb m cid6 pebm cid6 pm 1 bBe m lD bBe m lD mcid6M Consequently argument logarithmic function 1 expression A3 simpliﬁes zero Hence cid3 cid6 bBe m lD ξml bf elbpeb ln ξml b dl cid1 0 Since expression expected information rewritten form cid6 cid3 pm bBe m lD cid2J e cid3 mM ﬁnally obtain cid2J e cid1 0 ξml bf elbpeb ln ξml b dl Equality holds ξml b constant m This happens pebms f elb ms behaviors models That models rise identical predictions cid1 Theorem 6 Let cid2J e1 Ecid2H le landmark l1 measured cid2J e12 Ecid2H le landmarks l1 l2 taken account Then 1 expected information increment experiment e E 2 expected information increment e 1 le cid2J e12 cid1 cid2J e1 Proof In theorem consider landmarks single behavior The formula expected information incre ment simpliﬁes expression given Corollary 1 By Corollary 1 cid6 cid2J e1 cid3 mM pm f el1b m ln l1D1 f el1b m f el1b dl1 Using normalization condition cid6 f el2l1 b m dl2 1 l2D2 deﬁnition joint pdf l1 l2 product individual pdfs f el1 l2b m f el2l1 b mf el1b m rewrite A4 cid2J e1 cid3 mM Given cid6 cid6 pm f el1 l2b m ln l1D1 l2D2 f el1 l2b f el2l1 bf el1b f el1 l2b m f el2l1 b mf el1b dl1 dl2 A4 A5 A6 A7 504 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 Eq A6 written cid2J e1 cid3 mM cid6 cid6 l2D2 l1D1 cid6 cid6 pm f el1 l2b m ln cid3 mM pm f el1 l2b m ln l1D1 l2D2 f el1 l2b m f el1 l2b dl1 dl2 f el2l1 b m f el2l1 b dl1 dl2 A8 Notice ﬁrst expression righthand A8 equals cid2J e12 Corollary 1 The second expression rewritten means A5 function ζ deﬁned follows ζ l1 cid3 mM This results cid6 pm f el2l1 b m ln l2D2 cid6 f el2l1 b m f el2l1 b dl2 cid2J e1 cid2J e12 ζ l1f el1b m dl1 l1D1 A9 A10 In fact ζ l1 expected information increment form 18 ζ l1 cid1 0 Theorem 1 As consequence integral second expression righthand A10 greater equal zero represents expected value ζ This results cid2J e12 cid1 cid2J e1 cid1 References 1 S Asprey S Macchietto Designing robust optimal dynamic experiments J Process Control 12 2002 545556 2 A Atkinson D Cox Planning experiments discriminating models J Roy Statist Soc 36 1974 321348 3 D Berleant A Chandra K Bognaes CG Liaw L Sheng J Chng Probabilities qualitative behaviors dependability analysis faulttolerance model Proceedings ACMSIGAPP Symposium Applied Computing ACM Press New York 1992 pp 883889 4 D Berleant B Kuipers Qualitative quantitative simulation Bridging gap Artiﬁcial Intelligence 95 2 1997 215256 5 O Bernard Étude expérimentale et théorique la croissance Dunaliella tertiolecta soumise à une limitation variable nitrate PhD thesis Université Pierre MarieCurie Paris France 1995 6 O Bernard JL Gouzé Global qualitative description class nonlinear dynamical systems Artiﬁcial Intelligence 136 1 2002 2959 7 O Bernard G Malara A Sciandra The effects controlled ﬂuctuating nutrient environment continuous cultures phytoplankton monitored computers J Experimental Marine Biology Ecology 197 2 1996 263278 8 O Bernard G Sallet A Sciandra Nonlinear observers class biological systems Application validation phytoplanktonic growth model IEEE Trans Automat Control 43 8 1998 10561065 9 G Box W Hill Discrimination mechanistic models Technometrics 9 1 1967 5771 10 E Bradley M Easley R Stolle Reasoning nonlinear identiﬁcation Artiﬁcial Intelligence 133 12 2001 139188 11 D Burmaster The unsteady continuous culture phosphatelimited Monochrysis lutheri Droop Experimental theoretical analysis J Experimental Marine Biology Ecology 39 2 1979 167186 12 J Caperon J Meyer Nitrogenlimited growth marine phytoplankton I Changes population characteristics steadystate growth rate DeepSea Research 19 1972 601618 13 B Chen S Asprey On design optimally informative dynamic experiments model discrimination multiresponse nonlinear situa tions Industrial Engineering Chemistry Research 42 7 2003 13791390 14 D Contois Kinetics bacterial growth Relationship population density speciﬁc growth rate continuous cultures J General Microbiology 21 1959 4050 15 M Cooney K McDonald Optimal dynamic experiments bioreactor model discrimination Applied Microbiology Biotechnol ogy 43 5 1995 826837 16 C Dariva J Oliveira J Pinto Experimental design model discrimination thermodynamic models Fluid Phase Equilibria 146 12 1998 3550 17 H Jong Qualitative simulation related approaches analysis dynamical systems Knowledge Engineering Review 19 2 2005 93132 18 H Jong NJI Mars P van der Vet Computersupported resolution measurement conﬂicts A casestudy materials science Founda tions Science 4 4 1999 427461 19 H Jong A Rip The revolution science steps realization computersupported discovery environments Artiﬁcial Intelligence 91 2 1997 225256 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 505 20 J Kleer Using crude probability estimates guide diagnosis Artiﬁcial Intelligence 45 3 1990 381391 21 J Kleer O Raiman M Shirley One step lookahead pretty good W Hamscher L Console J Kleer Eds Readings Model based Diagnosis Morgan Kaufmann San Mateo CA 1992 pp 138142 22 J Kleer B Williams Diagnosing multiple faults Artiﬁcial Intelligence 32 1 1987 97130 23 M Droop Vitamin B12 marine ecology IV The kinetics uptake growth inhibition Monochrysis lutheri J Marine Biological Assoc 48 3 1968 689733 24 D Dvorak B Kuipers Process monitoring diagnosis modelbased approach IEEE Expert 6 2 1991 6774 25 D Espie S Macchietto The optimal design dynamic experiments AIChE 35 2 1989 223229 26 B Faltings P Struss Eds Recent Advances Qualitative Physics MIT Press Cambridge MA 1992 27 A Farquhar B Kuipers J Rickel D Throop QR Group QSIM The program use Technical report UTAI90123 University Texas Austin TX 1993 28 V Fedorov Theory Optimal Experiments Academic Press New York 1972 29 V Fedorov P Hackl ModelOriented Design Experiments Springer New York 1997 30 G Gorry G Barnett Experience model sequential diagnosis Computers Biomedical Research 1 1968 490507 31 W Hamscher L Console J Kleer Eds Readings ModelBased Diagnosis Morgan Kaufmann San Mateo CA 1992 32 G Hardy J Littlewood G Pólya Inequalities Cambridge University Press Cambridge MA 1967 33 G Harris Phytoplankton Ecology Structure Function Fluctuation London New York 1986 34 R Horst P Pardalos Eds Handbook Global Optimization Kluwer Dordrecht 1995 35 T Hsiang P Reilly A practical method discriminating mechanistic models Canadian J Chemical Engineering 49 1971 865871 36 S Hsu S Hubbell P Waltman A mathematical theory singlenutrient competition continuous cultures microorganisms SIAM J Appl Math 32 2 1977 366383 37 T Ideker V Thorsson R Karp Discovery regulatory interactions perturbation Inference experimental design R Altman K Lauderdale A Dunker L Hunter T Klein Eds Proceedings Paciﬁc Symposium Biocomputing PSB 2000 vol 5 World Scientiﬁc Publishing Singapore 2000 pp 302313 38 H Kay SQSIM A simulator imprecise ODE models Computers Chemical Engineering 23 1 1998 2746 39 H Kay B Rinner B Kuipers Semiquantitative identiﬁcation Artiﬁcial Intelligence 119 12 2000 103140 40 J Keppens Q Shen On compositional modelling Knowledge Engineering Review 16 2 2001 157200 41 B Kuipers Qualitative simulation Then Artiﬁcial Intelligence 59 12 1993 133140 42 B Kuipers Qualitative Reasoning Modeling Simulation Incomplete Knowledge MIT Press Cambridge MA 1994 43 B Kuipers D Berleant Using incomplete quantitative knowledge qualitative reasoning Proceedings 7th National Conference Artiﬁcial Intelligence AAAI88 Morgan Kaufmann Los Altos CA 1988 pp 324329 44 R Leitch Q Shen Prioritising behaviors qualitative simulation J McDermott Ed Proceedings 13th International Joint Con ference Artiﬁcial Intelligence IJCAI93 Morgan Kaufmann San Mateo CA 1993 pp 15231528 45 C Lund C Surko M Maple S Yamamoto Model discrimination oscillatory CO oxidation platinum catalysts atmospheric pressure Surface Science 459 2000 413425 46 S McIlraith R Reiter On tests hypothetical reasoning Readings ModelBased Diagnosis Morgan Kaufmann San Mateo CA 1992 pp 8996 47 T Mitchell Machine Learning McGrawHill New York 1997 48 J Monod Recherches sur la croissance des cultures bactériennes Hermann Paris 1942 49 S Narasimhan P Mosterman G Biswas A systematic analysis measurement selection algorithms fault isolation dynamic systems Working Notes 8th International Workshop Principles Diagnosis DX98 Cape Cod MA 1998 pp 94101 50 S Rajamoney The design discrimination experiments Machine Learning 12 1993 185203 51 C Schut B Bredeweg An overview approaches qualitative model construction Knowledge Engineering Review 11 1 1996 125 52 P Struss Mathematical aspects qualitative reasoning Artiﬁcial Intelligence Engineering 3 3 1988 156169 53 P Struss Testing discrimination diagnoses In Working Notes 5th International Workshop Principles Diagnosis DX94 New Paltz NY 1994 54 P Struss Fundamentals modelbased diagnosis dynamic systems M Pollack Ed Proceedings Fifteenth International Joint Conference Artiﬁcial Intelligence IJCAI97 Morgan Kaufmann San Francisco CA 1997 pp 480485 55 R Takors W Wiechert D WeusterBotz Experimental design identiﬁcation macrokinetic models model discrimination Biotechnology Bioengineering 56 5 1997 564576 56 L TravéMassuyès P Dague Eds Modèles et raisonnements qualitatifs Hermès Paris 2003 57 G Treitz G Maria F Giffhorn E Heinzle Kinetic model discrimination stepbystep experimental computational procedure enzymatic oxidation Dglucose J Biotechnology 85 3 2001 271287 58 I Vatcheva Computersupported experiment selection model discrimination PhD thesis University Twente Enschede Nether lands 2001 59 I Vatcheva O Bernard H Jong JL Gouzé N Mars Discrimination semiquantitative models experiment selection Method application population biology B Nebel Ed Proceedings 17th International Joint Conference Artiﬁcial Intelligence IJCAI01 Morgan Kaufmann San Mateo CA 2001 pp 7479 60 I Vatcheva H Jong Semiquantitative comparative analysis T Dean Ed Proceedings 16th International Joint Conference Artiﬁcial Intelligence IJCAI99 Morgan Kaufmann San Francisco CA 1999 pp 10341040 506 I Vatcheva et al Artiﬁcial Intelligence 170 2006 472506 61 I Vatcheva H Jong NJI Mars Selection perturbation experiments model discrimination W Horn Ed Proceedings 14th European Conference Artiﬁcial Intelligence ECAI2000 IOS Press Amsterdam 2000 pp 191195 62 D Weld J Kleer Eds Readings Qualitative Reasoning Physical Systems Morgan Kaufmann San Mateo CA 1990 63 S Xia N Smith Automated modelling A discussion review Knowledge Engineering Review 11 2 1996 137160