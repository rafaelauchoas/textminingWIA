Artiﬁcial Intelligence 174 2010 410441 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Democratic instance selection A linear complexity instance selection algorithm based classiﬁer ensemble concepts César GarcíaOsorio Aida HaroGarcía b Nicolás GarcíaPedrajas b Department Civil Engineering University Burgos Spain b Department Computing Numerical Analysis University Córdoba Spain r t c l e n f o b s t r c t Article history Received 4 November 2008 Received revised form 18 January 2010 Accepted 21 January 2010 Available online 1 February 2010 Keywords Instance selection Instancebased learning Ensembles Huge problems Instance selection increasingly relevant huge data constantly produced ﬁelds research Although current algorithms useful fairly large datasets scaling problems number instances hundreds thousands millions When face huge problems scalability issue algorithms applicable Thus paradoxically instance selection algorithms impracticable problems beneﬁt use This paper presents way avoiding diﬃculty rounds instance selection subsets original dataset These rounds combined voting scheme allow good performance terms testing error storage reduction execution time process signiﬁcantly reduced The method particularly eﬃcient use instance selection algorithms high computational cost The proposed approach shares philosophy underlying construction ensembles classiﬁers In ensemble weak learners combined form strong classiﬁer method weak sense applied subsets data instance selection algorithms combined produce strong fast instance selection method An extensive comparison 30 medium large datasets UCI Machine Learning Repository 3 different classiﬁers shows usefulness method Additionally method applied 5 huge datasets thousand million instances good results fast execution time 2010 Elsevier BV All rights reserved 1 Introduction The overwhelming data available nowadays 1 ﬁeld research poses new problems data mining knowledge discovery methods This huge data makes existing algorithms inapplicable realworld problems Two approaches deal problem scaling data mining algorithms 2 data reduction However scaling certain algorithm feasible On hand data reduction consists removing data missing redundant andor erroneous data tractable data One common method data reduction instance selection This work supported Project TIN200803151 Spanish Ministry Education Science Corresponding author Email addresses cgosorioubues C GarcíaOsorio adeharoucoes A HaroGarcía npedrajasucoes N GarcíaPedrajas URL httpcibrgorg N GarcíaPedrajas 00043702 matter 2010 Elsevier BV All rights reserved doi101016jartint201001001 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 411 Instance selection 3 consists choosing subset total available data achieve original purpose data mining application data Different variants instance selection exist We distinguish main models 4 instance selection method prototype selection algorithms based prototypes knearest neighbors instance selection obtaining training set learning algorithm decision trees neural networks The problem instance selection instance based learning deﬁned isolation smallest set instances enable predict class query instance higher accuracy original set 5 Many widely instance selection algorithms O n2 n number instances 6 Although methods scaling learning algorithms proposed 7 algorithms methods applicable application troublesome For huge problems hundreds thousands millions instances instance selection methods applicable One natural way scaling certain algorithm dividing original problem easier subproblems applying algorithm separately subproblem In way scale instance selection dividing original dataset disjoint subsets performing instance selection process separately subset However method work application algorithm subset suffers partial knowledge dataset Instance selection algorithms evaluate relevance instance decide remove To evaluate relevance instance algorithm needs know dataset relevance depends instances Thus direct application instance selection subsets original dataset yield good performance In paper propose methodology basic idea applying instance selection algorithm subsets original dataset way allows performance close application algorithm dataset retaining advantages smaller subset The underlying idea based following premises 1 As stated promising way scaling instance selection algorithms smaller subsets A simple way partitioning dataset disjoint subsets applying instance selection algorithm subset separately 2 The solution perform subset partial view original dataset In way important instances removed superﬂuous instances kept In sense talk weak learners classiﬁer ensemble construction framework consider instance selection algorithm applied subset dataset weak instance selection algorithm 3 Following philosophy classiﬁer ensembles conduct rounds weak instance selection algorithms combine voting scheme Therefore approach called democratic instance selection sidered form extending classiﬁer ensemble philosophy instance selection Democratic instance selection based repeating rounds fast instance selection process Each round able achieve good performance However combination rounds voting scheme able match performance instance selection algorithm applied dataset large reduction time algorithm In different setup case ensembles classiﬁers consider method form ensembling instance selection In classiﬁcation weak learners combined ensemble able improve performance weak learners 8 In method instance selection algorithm applied partition disjoint subsets original dataset considered weak instance selector partial view dataset The combination weak selectors voting scheme similar combination different learners ensemble The main advantage method instance selection algorithm applied small subsets time reduced signiﬁcantly In fact size subset chosen researcher apply method problem regardless number instances involved As case classiﬁer ensembles base learner parameter algorithm method instance selection method parameter algorithm This paper organized follows Section 2 presents proposed model instance selection based approach Section 3 reviews related work Section 4 describes experimental setup Section 5 shows results exper iments Section 6 states conclusions work directions future research 2 Democratic instance selection method The democratic method instance selection consists performing r rounds instance selection algorithm applied number disjoint subsets dataset constitutes partition available data For round process consists dividing original dataset disjoint subsets approximately size Then instance selection algorithm applied subset separately The instances selected algorithm removed receive vote Then new partition performed round votes carried After predeﬁned number rounds performed instances received number votes certain threshold removed An outline method shown Algorithm 1 Each round considered similar classiﬁer ensemble 412 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 combination process voting similar combination base learners bagging boosting 9 Fig 1 shows example algorithm 10 rounds votes dataset 50 instances Algorithm 1 Democratic instance selection demoIS algorithm Data A training set T x1 y1 xn yn subset size s number rounds r Result The set selected instances S T k 1 r cid2 ti T size s Divide instances ns disjoint subsets ti j 1 ns Apply instance selection algorithm t j Store votes removed instances t j end end Obtain threshold votes v remove instance S T Remove S instances number votes cid2 v return S 1 2 3 4 5 6 7 The important advantage method large reduction execution time The reported experiments large difference standard widely instance selection algorithms Additionally method easy implement parallel environment execution instance selection algorithm subset performed independently Furthermore size subsets parameter algorithm choose complexity execution processors However stated method important issues addressed obtain useful algorithm First partition method trivial strictly random partition perform Second determination number votes problemdependent We carried preliminary experiments ﬁxed threshold different problems poor results Depending problem certain threshold low high If set certain ﬁxed threshold votes remove instance problem datasets threshold means removing instances hand datasets threshold results keeping instances Thus method developed automatic determination number votes needed remove instance training set Automatic determination threshold additional advantage relieving researcher duty setting diﬃcult parameter algorithm These issues discussed following sections We emphasize method applicable instance selection algorithm instance selection algorithm parameter method 21 Partition dataset cid2 An important step method partitioning training set number disjoint subsets ti comprise ti T The size subsets ﬁxed user The actual size relevant inﬂuence training set results provided small avoid large execution time Furthermore time spent algorithm depends size largest subset important partition algorithm produces subsets approximately equal size We need different partition dataset round votes Otherwise votes cast cause instance selection algorithms deterministic The simplest method random partition instance randomly assigned subsets Each round votes receive different random partition This ﬁrst attempt partition method inspired 10 bagging sparse grandmother representation Kernel Principal Component Analysis However method problems kNN local learning algorithm partition partially locality instances performance kNN greatly affected Thus ﬁrst goal partition method keeping possible certain locality partition However additional important factor performance method subtler Each partition represents different optimization problem different error surface instance selection algorithm If partitions different error surfaces different In case votes cast different rounds randomly distributed obtained performance poor Thus obtain good performance partitions different rounds algorithm vary smoothly1 These requirements met theory Grand Tour 11 The idea Grand Tour method introduced Asimov 11 Buja Asimov 12 generate continuous sequence lowdimensional projections high dimensional dataset based premise fully understand subject item examine possible 1 In fact performed experiments random partitions worse results However different random partitions varied smoothly example performing initial random partition exchanging instances subsets round performance clearly improved C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 413 Fig 1 Example democratic instance selection dataset 50 instances subsets 10 instances The instance selection algorithm available 414 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 angles The method rotates plane highdimensional space The data projected plane orientations sequence projections visualized screen animation obtained useful identifying structures data set clusters outliers Grand Tour shares common objective exploratory projection pursuit techniques In cases human ability visual pattern recognition exploited 211 Algorithms When Grand Tour visualization sequence planes hold conditions The sequence dense set planes highdimensional space b The sequence smooth visual impression data points moving continuous way The stateoftheart algorithms Grand Tour guided tours manual tours 13 based interpo lation sequence randomly generated planes In context algorithm use onedimensional Grand Tour project data rotating vector use projection divide dataset subsets pass underlying instance selection algorithm In addition concerned sim plicity algorithm Thus instead interpolation class algorithm chose parametrization class algorithm torus method 11 based obtaining sequence rotation matrices leaves problem obtain matrices We want obtain generalized rotation matrix Q use rotate vector area going project data This implemented choosing Q element special orthogonal group denoted SOd orthogonal d d matrices having determinant 1 matrix properties rotation matrix So need continuous curve SOd In torus method achieved obtaining continuous curve pdimensional torus p d 1d2 d dimension dataset points angles calculate Q The idea varying vector angles αs θ12 θ13 θd1d use generate Q mapping β 0 2π p SOd given βθ12 θ13 θd1d R12θ12 R13θ13 Rd1dθd1d 1 The R jθi j elements SOd rotate eie j plane angle θi j R jθi j 1 0 0 0 0 cosθi j sinθi j 0 0 0 sinθi j cosθi j 0 0 0 1 To summarize coordinates point ptorus angles rotation matrices R j combined obtain rotation matrix Q rotating vector There different ways curve ptorus 14 AsimovBuja winding algorithm random curve algorithm fractal curve algorithm In experiments use random curve algorithm First randomly use points si s j 0 2π p create linear interpolant points going si s j needed point sk join s j 212 Some implementation details Obtaining curve strictly shortest path ptorus adds burden complexity extra advantage algorithm So instead interpolate points hypercube 0 2π p If point near pdimensional point 2π 2π 2π point near pdimensional point 0 0 0 actual ptorus points close shortest path walls hypercube 0 2π p However current implementation interpolate point path strictly inside p2π 2 Furthermore interpolation ﬁrst points 0 2π p hypercube length approximately usually obtain orientations partitions required algorithm cid9 Because density projections context instance selection critical factor need long tour good results ﬁfteen steps Grand Tour usually use simpler ways obtaining sequence projections In case unidimensional projections applied pseudo Grand Tour obtained Andrews curves 15 If want sequence bidimensional projections use orthogonal vectors given Wegman curves 16 One concern Grand Tour dynamic data visualization general mapped curve SOd uniformly distributed curve ptorus equally distributed Here interested uniformly rotating projection vector solve simply dynamically adapting interpolation step obtain curve phypercube angle changes 10 previous angle C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 415 Fig 2 Example method partitioning dataset 1500 instances classes features ﬁve rounds votes Four subsets created round 22 Partition algorithm Following approach obtain ﬁrst partition projecting dataset random vector dividing projection equal sized subsets The vector obtained described procedure new partition The procedure repeated subsequent partitions Algorithm 2 shows method performing partition based methodology Algorithm 2 Algorithm partitioning training set disjoint subsets cid2 Data A training set T x1 y1 xn yn subset size s Result The partition disjoint subsets ti Get vector Grand Tour method Project instances vector Divide projected instances subsets size s linear ordering induced projection Assign ti subset cid2 Return ti ti T ti T 1 2 3 4 5 An example partition performed artiﬁcial training set 1500 instances data divided subsets depicted Fig 2 The ﬁgure shows original dataset contains classes ﬁve parti tions performed ﬁve rounds votes The ﬁgure shows smooth variation subsets rounds votes performed This partition speciﬁcally designed kNN instance selection algorithms If apply methodology classiﬁers random partition dataset shown Section 511 416 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 23 Determining threshold votes An important issue method determining threshold votes remove instance training set Preliminary experiments showed number depends speciﬁc dataset Thus possible set general preestablished value usable dataset On contrary need way selecting value directly dataset run time A ﬁrst natural choice use crossvalidation procedure However method time consuming A costly method estimating best value number votes effect training set The choice number votes account criteria training error cid6t storage memory requirements m Both values minimized We deﬁne criterion f v combination values f v αcid6tv 1 αmv 2 m measured percentage instances retained cid6t training error α value interval 0 1 measures relative relevance values Because minimization error usually important storage reduction value α 075 Different values researcher interested reduction error Estimating training error time consuming large datasets To avoid problem training error estimated small percentage dataset 10 medium large datasets 01 huge datasets The process obtain threshold following Once performed r rounds algorithm stored number votes received instance obtain threshold votes v remove instance This value v 1 r We calculate criterion f v Eq 2 possible threshold values 1 r assign v value minimizes criterion After remove instances number votes equal obtained threshold v 24 Complexity methodology The aim work obtain instance selection methodology able scale large huge problems Thus analysis complexity method essential In section algorithm linear number instances n dataset We divide dataset partitions disjoint subsets size s Thus chosen instance selection algorithm applied subset ﬁxed size s independent actual size dataset The complexity application algorithm depends base instance selection algorithm small size s small Let K number operations needed instance selection algorithm perform task dataset size s For dataset n instances perform instance selection process subset ns times spending time proportional nsK The total time needed algorithm perform r rounds proportional rnsK linear number instances K constant value Fig 3 shows computational cost function number instances quadratic algorithm approach algorithm subset sizes s 100 1000 2500 5000 instances 10 rounds votes If complexity instance selection algorithm greater reduction execution better The method additional advantage allowing easy parallel implementation Because application instance selection algorithm subset independent remaining subsets subsets processed time different rounds votes Also communication nodes parallel execution small As stated additional processes complete method partition dataset determination number votes The determination number votes accomplish different ways If consider training instances cost step O n2 However complexity linear use random subset training set determine number votes limit maximum size subset ﬁxed dataset In way medium large datasets use 10 training set huge problems 01 percentage reduced size dataset grows In fact experimentally veriﬁed consider reasonable bound2 number instances damaging performance algorithm With method complexity step O 1 number instances bounded regardless size dataset Finally consider partition dataset apart algorithm different partition methods devised The partition described Section 21 implemented complexity O n logn quicksort algorithm sorting values subsets complexity O n dividing projection vector equal width intervals Both methods achieve performance obtained partition similar In experiments method complexity procedure linear However partition specially designed kNN classiﬁers When method classiﬁers methods random partition complexity O n In fact experiments reported decision trees support vector machines random partition dataset 2 This reasonable bound thousand instances huge datasets C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 417 Fig 3 Computational cost method base instance selection algorithm O n2 3 Related work The usefulness applying instance selection disjoint subsets shown 17 In work cooperative evo lutionary algorithm Several evolutionary algorithms performed disjoint subsets instances global population account global view This method scalable medium large problems applied huge problems There previous studies dealt instance selection huge problems Cano et al 18 proposed evolutionary stratiﬁed approach large problems Although algorithm shows good performance computationally expensive huge datasets Kim Oommen 19 proposed method based recursive application instance selection smaller datasets In recent paper De HaroGarcía GarcíaPedrajas 20 showed application recursive divideandconquer approach able achieve good performance attaining dramatic reduction execution time instance selection process Domingos Hulten 2122 developed method scaling learning algorithms based Hoeffding bounds 23 The method applied choosing set discrete models estimating continuous parameter The method consists steps ﬁrst derive upper bound relative loss subset available data dataset step learning algorithm Then derive upper bound time complexity learning algorithm function number samples step Finally minimize time bound number samples step subject target limits loss performance subset dataset Although method able achieve interesting results need derive bounds makes application troublesome algorithms On hand advantage method respect approach modiﬁcation original algorithm needed Furthermore experiments reported authors 22 dataset size million instances method worthwhile The experiments reported method able reduce execution time tested algorithms problem size thousands instances In subsequent study 24 Domingos Hulten developed method inductive algorithms based discrete search The complexity method independent process generating candidate solutions process method need access data In way applicable randomized search processes The general framework proposed 7 scaling decision trees Bayesian network learning kmeans clustering EM algorithm mixtures Gaussians To best knowledge approach applied instance selection There second advantage method To apply method Domingos Hulten derive upper bound time complexity learning algorithm function number samples step On hand proposal uses standard algorithms black boxes modiﬁcation In way applicable existing instance selection algorithm 418 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 Table 1 Summary datasets The features dataset C continuous B binary N nominal Data set Cases Features Classes Inputs 1NN error 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 abalone adult car gene german hypothyroid isolet krkopt kr vs kp letter magic04 mfeatfac mfeatfou mfeatkar mfeatmor mfeatpix mfeatzer nursery optdigits pageblocks pendigits phoneme satimage segment shuttle sick texture waveform yeast zip 4177 48 842 1728 3175 1000 3772 7797 28 056 3196 20 000 19 020 2000 2000 2000 2000 2000 2000 12 960 5620 5473 10 992 5404 6435 2310 58 000 3772 5500 5000 1484 9298 4 Experimental setup 7 6 C 6 7 617 6 16 10 216 76 64 6 240 47 64 10 16 5 36 19 9 7 40 40 8 256 B 1 3 20 34 1 20 N 1 7 6 60 11 2 2 7 2 29 2 4 3 2 4 26 18 2 26 2 10 10 10 10 10 10 5 10 5 10 2 6 7 7 2 11 3 10 10 10 105 16 120 61 29 617 6 38 16 10 216 76 64 6 240 47 23 64 10 16 5 36 19 9 33 40 40 8 256 08034 02005 01581 02767 03120 00692 01443 04356 00828 00454 02084 00350 02080 00435 02925 00270 02140 02502 00256 00369 00066 00952 00939 00398 00010 00430 00105 02860 04879 00292 To fair comparison standard algorithms proposal selected 30 problems UCI Machine Learning Repository 25 We selected datasets 1000 instances For estimating storage reduction generalization error kfold crossvalidation cv method In method available data divided k approximately equal subsets Then method learned k times turn k subsets testing set remaining k 1 subsets training set The estimated error average testing error k subsets A fairly standard value k k 10 A summary datasets shown Table 1 In ﬁgures paper use number order dataset reduce size needed graphs The table shows 10fold cv generalization error 1NN classiﬁer instance selection considered baseline measure error dataset These datasets considered representative medium large problems As main statistical test Wilcoxon test comparing pairs algorithms We chose test assumes limited commensurability safer parametric tests assume normal distributions homogeneity variance Furthermore empirical results 26 test stronger tests The evaluation instance selection algorithm trivial task We distinguish basic approaches direct indirect evaluation 27 Direct evaluation evaluates certain algorithm based exclusively data The objective measure extent selected instances reﬂect information present original data Some proposed measures entropy moments histograms Indirect methods evaluate effect instance selection algorithm learning task If interested clas siﬁcation evaluate performance classiﬁer reduced set obtained instance selection learning set Therefore evaluating instance selection algorithms instancebased learning usual method evaluation estimating performance algorithms set benchmark problems In problems criteria considered 28 storage reduction generalization accuracy noise tolerance learning speed Speed considerations diﬃcult measure evaluating algorithm certain implementation However main aim work scaling instance selection algorithms execution time basic issue To allow fair comparison performed experiments machine biprocessor Intel Xeon QuadCore processors 160 GHz To perform sound experiments algorithm training set algorithm method exactly C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 419 The source code C licensed GNU General Public License methods partitions datasets freely available request authors 41 Instance selection algorithms To obtain accurate view usefulness method select widely instance selection algorithms We chose test model successful stateoftheart algorithms Initially algorithms DROP3 28 ICF 5 DROP3 Decremental Reduction Optimization Procedure 3 shown Algo rithm 3 This algorithm example new generation algorithms designed taking account effect order removal performance algorithm ICF designed insensitive order presentation instances It includes noiseﬁltering step method similar Wilsons Edited NearestNeighbor Rule 29 Then instances ordered distance nearest neighbor The instances removed beginning instances furthest nearest neighbor This tends remove instances farthest boundaries ﬁrst Algorithm 3 DROP3 algorithm Data A training set T x1 y1 xn yn selector S Result The set selected instances S T Noise ﬁltering Remove instance T misclassiﬁed k neighbors S T Sort instances S distance nearest enemy foreach Instance P S Find P N1k1 k 1 nearest neighbors P S Add P neighbors list associates end foreach Instance P S Let associates P classiﬁed correctly P neighbor Let associates P classiﬁed correctly P cid2 Remove P S foreach Associate A P Remove P As list nearest neighbors Find new nearest neighbor A Add A new neighbors list associated 1 2 3 4 5 6 7 8 9 10 11 end end end return S 12 ICF Iterative Case Filtering shown Algorithm 4 For ICF algorithm coverage reachability deﬁned follows Coveragec Reachablec cid10 c cid10 c cid6 T c LocalSet cid6 T c cid13 cid6 LocalSetc cid12cid13 cid6 cid11 c 3 4 The local set case c deﬁned set cases contained largest hypersphere centered c cases class c contained hypersphere 5 hypersphere bounded ﬁrst instance different class The coverage set instance includes instances neighbors reachable set formed instances neighbors The algorithm based repeatedly applying deleting rule set retained instances instances fulﬁll deleting rule In addition methods worth mentioning Reduced Nearest Neighbor RNN rule 30 This method extremely simple shows good performance terms storage reduction However RNN drawback computational complexity Among standard methods RNN shows worst scalability taking hundreds hours largest problems Therefore RNN perfect target methodology instance selection method highly eﬃcient scalability problem So tested approach RNN shown Algorithm 5 base instance selection method We recent algorithms instance selection Modiﬁed Selective Subset MSS method 31 The procedure shown Algorithm 6 We chose algorithm example fast algorithm With MSS want test method able improve execution time algorithms timedemanding previous ones As alternative standard methods applied genetic algorithms instance selection considering task search problem The application easy straightforward Each individual binary vector codes certain sample training set The evaluation usually considering data reduction classiﬁcation accuracy Examples applications genetic algorithms instance selection 3233 34 Cano et al 4 performed comprehensive comparison performance different evolutionary algorithms instance selection 420 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 Algorithm 4 ICF algorithm Data A training set T x1 y1 xn yn Result The set selected instances S T Noise ﬁltering Remove instance T misclassiﬁed k neighbors repeat forall x T Compute reachablex Compute coveragex end progress false forall x T reachablex coveragex Flag x removal progress true end end forall x T x ﬂagged removal T T x end progress return T 1 2 3 4 5 6 7 8 Algorithm 5 RNN algorithm Data A training set T x1 y1 xn yn selector S Result The set selected instances S T Obtain Condensed Nearest Neighbor set S x1 foreach Instance P T P misclassiﬁed S Add P S Restart end end Obtain Reduced Nearest Neighbor set foreach Instance P S Remove P S instance T misclassiﬁed S Add P S end end return S 1 2 3 4 5 6 Algorithm 6 MSS algorithm Data A training set T x1 y1 xn yn selector S Result The set selected instances S T S Sort instances xi T distance D nearest enemy 1 n add false j n x j T dxi x j D j T T x j add true end end add S S xi T return S end return S 1 2 3 4 5 6 7 8 They compared generational genetic algorithm 35 steadystate genetic algorithm 36 CHC genetic algorithm 37 population based incremental learning algorithm 38 They evolutionarybased methods able outperform classical algorithms classiﬁcation accuracy data reduction Among evolutionary algorithms CHC able achieve best overall performance Nevertheless critical problem addressed applying genetic algorithms instance selection scaling algorithm As number instances grows time needed genetic algorithm reach good solution C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 421 increases exponentially making totally useless large problems Because concerned problem ﬁfth instance selection method genetic algorithm CHC methodology The execution time CHC clearly longer time spent ICF DROP3 MSS gives good benchmark test methodology algorithm like RNN scalability problem 5 Experimental results The parameters standard version algorithm application methodology None standard methods relevant parameters The value set k number nearest neighbors For DROP3 ICF k 3 neighbors k 1 RNN MSS For CHC performed 100 generations population 100 individuals k 1 Mutation applied 10 probability These fairly standard values 4 Our method parameters subset size s number rounds r For subset size use value large allow meaningful application instance selection algorithm subset small allow fast execution time method grows s As compromise value chose s 1000 minimum subsets dataset 1000 fewer instances For number rounds chose small value allow fast execution r 10 In Section 59 carry study effect parameters performance algorithm The application method certain instance selection algorithm X named demoISx A summary results ﬁve algorithms shown Tables 2 3 standard demoISx methods 51 DROP3 vs demoISdrop3 The results standard DROP3 algorithm method DROP3 base algorithm plotted Fig 4 The ﬁgure shows results testing error storage requirements execution time Throughout paper use graphic representation based kappaerror relative movement diagrams 39 However instead kappa difference value use storage difference The idea diagrams represent arrow results methods applied dataset The arrow starts coordinate origin coordinates tip arrow given difference errors storages method standard instance selection algorithm The numbers indicate dataset according Table 1 These graphs convenient way summarizing results For example arrows pointing downleft represent datasets method outperformed standard algorithm error storage arrows pointing upleft indicate algorithm improved storage worse testing error Numerical results shown Tables 2 3 In terms error method able match results original DROP3 algorithm differences small In fact demoISdrop3 able improve performance DROP3 datasets car mfeatzer nursery In terms storage reduction demoISdrop3 performs better DROP3 Although achieves worse results DROP3 problems demoISdrop3 able obtain large reduc tion results DROP3 abalone gene german isolet krkopt waveform yeast datasets In terms execution time advantage demoISdrop3 signiﬁcant For small problems small overload 10 rounds votes performed problem grows size approach shows large reduction time needed form instance selection process In way timeconsuming problem adult dataset demoISdrop3 needs 5 time spent original DROP3 achieve similar error better storage reduction 52 ICF vs demoISicf Results ICF demoISicf plotted Fig 5 numerical results shown Tables 2 3 In terms testing error demoISicf able improve match results ICF datasets exceptions gene krkopt kr vs kp nursery problems Furthermore problems isolet letter mfeatkar page blocks zip test error clearly better error achieved ICF In terms storage reduction average performance algorithms similar remarkably good performance demoISicf nursery dataset In terms execution time behavior similar case DROP3 For complex problems advantage demoISicf ICF clear 53 MSS vs demoISmss Results MSS demoISmss plotted Fig 6 numerical results shown Tables 2 3 In terms testing error storage reduction performances demoISmss MSS similar The relevance experiment stated test approach able reduce execution time simpler algorithm case complex ones DROP3 ICF The results large datasets adult krkopt letter shuttle improvement execution time signiﬁcant Table 2 Testing error storage requirements execution time seconds standard instance selection algorithms Dataset DROP3 ICF MSS RNN CHC Storage Error Time s Storage Error Time s Storage Error Time s Storage Error Time s Storage Error Time s abalone adult car gene german hypothyroid isolet krkopt kr vs kp letter magic04 mfeatfac mfeatfou mfeatkar mfeatmor mfeatpix mfeatzer nursery optdigits pageblocks pendigits phoneme satimage segment shuttle sick texture waveform yeast zip 03069 01248 02668 03877 03073 00514 02852 04431 02229 01744 01789 01208 02473 01655 02062 01095 02231 02934 00911 00430 00451 01852 01366 01219 00028 00625 00878 02961 03193 01040 07782 01714 02378 02776 02870 00610 01770 04803 01016 01037 01978 00600 02320 00835 02885 00480 02375 03327 00420 00437 00168 01383 01101 00784 00016 00509 00329 02276 04500 00497 18 22 8539 19 356 09 118 2089 15330 101 18498 1998 393 56 65 14 765 40 3374 1610 157 1750 115 577 41 75434 148 970 288 06 6017 02510 01082 03813 02508 01485 00398 01713 05290 02707 01362 01160 00896 01395 01035 02008 00864 01503 08752 00606 00307 00348 01392 00713 01077 00229 00452 00725 01211 02137 00497 08082 02194 02709 03527 03260 01156 02648 04032 01267 02018 02395 00905 03280 01725 03685 01000 02715 02414 01103 02185 00651 01941 01677 01394 00473 00912 00973 02840 05095 02549 17 91708 11 261 04 37 1031 11098 53 7603 138 175 24 25 06 27 17 2872 828 56 706 46 254 16 26400 47 468 15 03 2198 06435 02950 03424 04442 04309 01675 03414 06565 03192 02265 03204 01672 03453 02159 03253 01661 03488 04160 01663 00991 00900 02433 02032 01628 00078 01240 01335 03435 05339 02283 08053 02281 02424 03274 03550 00995 01871 04323 00843 00749 02440 00555 02515 00715 03170 00420 02475 02249 00425 00432 00135 01291 01212 00541 00012 00608 00213 03052 05412 00440 16 29908 03 69 02 07 395 3567 13 2667 234 62 10 08 04 85 08 572 210 08 178 11 82 03 5847 08 139 53 01 717 00079 00333 00984 00402 00296 00313 00447 00425 00558 00581 00293 00387 00444 00544 00239 00413 00351 00579 00309 00143 00188 00472 00254 00428 00014 00207 00329 00130 00266 00348 07935 01951 02471 03997 02950 00655 02665 05678 01423 01420 01805 00925 03135 01265 03135 00810 03010 02802 00881 00559 00276 01778 01345 00866 00018 00594 00518 03198 05230 00884 71117 1 896 5403 124 16332 282 1684 59508 1 057 7155 1289 21 3940 50 8172 477 1462 315 649 394 1027 59597 2814 998 2899 4858 9763 178 13394 658 1318 21322 491 14202 03818 01988 04192 03004 03483 02613 02993 05237 02712 02952 02952 03933 03384 03838 03573 03759 03439 02941 02755 02786 02903 02846 02825 03030 02638 02578 02825 02911 03711 02871 07998 02257 02639 02968 03290 00775 02026 04711 01276 00905 01225 00455 02280 00650 03265 00440 02205 02427 00404 00408 00121 01457 01157 00649 00055 00514 00249 02878 05014 00510 77222 91 0960 54836 72366 4401 71839 10 8854 137 0150 71075 51 0240 29 3270 65184 70269 70108 70542 64419 70763 22 3973 78464 76628 11 6366 77729 84918 70624 77 0890 71798 78761 79268 29811 97482 4 2 2 C G r c í O s o r o e t l A r t ﬁ c l I n t e l l g e n c e 1 7 4 2 0 1 0 4 1 0 4 4 1 Table 3 Testing error storage requirements execution time seconds democratic instance selection algorithms Dataset demoISdrop3 demoISicf demoISmss demoISrnn demoISchc Storage Error Time s Storage Error Time s Storage Error Time s Storage Error Time s Storage Error Time s abalone adult car gene german hypothyroid isolet krkopt kr vs kp letter magic04 mfeatfac mfeatfou mfeatkar mfeatmor mfeatpix mfeatzer nursery optdigits pageblocks pendigits phoneme satimage segment shuttle sick texture waveform yeast zip 00822 00899 03278 01872 02012 00631 01635 02679 02347 02236 01130 01436 02210 01966 01494 01776 01710 02299 01093 00530 00822 01792 01260 01561 00164 00814 01260 01120 01460 01180 07782 01848 02163 02738 02870 00690 01840 04916 01031 01203 02048 00680 02415 00855 02865 00410 02200 02300 00459 00448 00218 01439 01173 00731 00034 00565 00400 02354 04561 00646 51 12045 80 437 68 264 507 704 283 1401 955 888 217 254 60 873 155 870 696 336 831 211 574 121 3371 295 596 314 25 1062 00802 00890 03775 02012 00807 00294 01722 03370 02221 02408 00967 01216 01569 01402 01585 01201 01395 02137 01110 00392 00790 01735 01110 01462 00588 00480 01293 00742 01094 01644 07837 01942 02448 03628 03040 00804 02060 04721 01279 01267 02154 00715 02785 01200 03385 00635 02680 02449 00617 00583 00293 01646 01356 01117 00126 00682 00460 02706 04865 00723 40 6216 49 231 30 83 246 562 133 810 371 326 99 106 28 408 73 590 283 105 317 81 214 48 2256 98 256 145 14 427 05030 03448 03634 03547 04309 01782 02789 05443 03128 02830 03168 01842 03363 02314 03619 01604 03567 04105 01242 00884 00900 02943 01942 01788 00275 01530 01553 02386 05137 01456 07945 02076 02593 03290 03280 00751 01959 04114 00837 00885 02269 00550 02445 00725 03315 00560 02255 02393 00591 00428 00205 01491 01163 00888 00063 00488 00302 02758 05014 00653 40 13090 10 91 12 16 124 1621 39 586 193 127 47 35 13 182 33 226 104 17 103 28 81 16 196 15 81 64 10 220 00167 00238 00844 01161 00296 00258 01335 02889 01471 01775 00612 00804 01184 01157 00392 01093 00931 01440 00861 00215 00490 00827 00697 00796 00138 00204 00970 00381 00567 00773 07873 01746 02797 03309 02860 00705 02109 04634 01201 01152 02469 00955 02860 01025 03775 00600 02640 02417 00550 00596 00197 01681 01236 01139 00058 00610 00371 02690 04804 00639 9634 12 1449 410 14329 2491 1026 11227 51682 1826 18772 16450 1418 4095 1066 1655 1304 2799 7506 1642 533 706 2138 3604 242 196 478 903 9439 1256 4768 00425 00203 02893 01001 00804 00306 01112 02678 01538 02244 00614 01273 01962 01902 01323 01253 01491 02017 00810 00609 00656 01462 00789 01612 00130 00107 01023 00592 01124 00802 08084 02114 02826 03804 03390 00822 02381 04691 01684 00958 02620 00680 02500 00855 03330 00660 02545 02439 00619 00594 00246 01683 01330 00926 00048 00674 00587 03012 05284 00715 12315 81521 2724 5583 1415 4800 16092 76275 4989 45858 29658 2586 3227 2919 2698 2671 3017 24250 8275 6953 15495 7894 9072 2970 72867 4725 7829 8405 2455 16280 C G r c í O s o r o e t l A r t ﬁ c l I n t e l l g e n c e 1 7 4 2 0 1 0 4 1 0 4 4 1 4 2 3 424 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 Fig 4 Storage requirementstesting error execution time seconds logarithmic scale standard DROP3 algorithm approach 54 RNN vs demoISrnn The experiment conducted RNN base instance selection algorithm The results plotted Fig 7 numerical values shown Tables 2 3 As stated previous section perfect example potentialities approach In experiments RNN showed best performance terms storage reduction However algorithm problem scalability As extreme example adult problem RNN took 500 hours experiment This scalability problem prevents application problems useful The ﬁgure shows demoISrnn able solve scalability problem RNN In terms testing error demoISrnn able improve performance RNN better performance 21 30 datasets In terms storage reduction algorithm performs worse RNN However performance demoISrnn good fact better previous algorithms So approach able scale RNN complex problems improving results terms testing error worse results terms storage reduction Execution time results remarkable reduction time spent selection process large The extreme example results timeconsuming datasets adult krkopt speedup times 55 CHC vs demoISchc Fig 8 plots results CHC algorithm numerical values shown Tables 2 3 Due high computa tional cost CHC chose algorithm smaller subset size s 250 A ﬁrst interesting result problem scalability CHC algorithm marked algorithm previous ones In studies 417 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 425 Fig 5 Storage requirementstesting error execution time seconds logarithmic scale standard ICF algorithm approach CHC algorithm compared standard methods small medium problems For problems perfor mance CHC better performance methods However datasets larger scalability problem CHC relevant In set problems CHC clearly performs worse DROP3 ICF MSS RNN terms storage reduction We account CHC need bit chromosome instance dataset This means large problems adult krkopt letter magic shuttle chromosome 10 000 bits making convergence algorithm problematic Thus CHC RNN excellent ex ample applicability approach For method scaling CHC provided demoISchc evident terms running time large reduction 30 datasets terms storage reduction demoISchc able improve reduction CHC 30 datasets average improvement 20 average storage CHC 3183 average storage 1158 The negative effect worse testing error compensated improvement running time storage reduction 56 Control experiments The previous experiments showed method able match performance standard methods signiﬁcant reduction execution time However argued reduction respect standard methods signiﬁcant standard methods useful In way simple random sampling worse standard methods usefulness approach partly compromised In case 426 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 Fig 6 Storage requirementstesting error execution time seconds logarithmic scale standard MSS algorithm approach forget random sampling determine number instances retain subset solves problem 28 cases random sampling achieves good results In section results control experiment designed test simple random approach competitive respect standard instance selection methods For problem performed random sampling sampling rate equal storage obtained algorithm compared testing error standard method random sampling Table 4 shows comparison methods The experiment shows interesting results First widely algorithms Drop3 ICF RNN able improve performance random sampling consistent way All algorithms signiﬁcantly better random sampling The conclusion valid democratic counterparts This control experiment validates usefulness algorithms However experiment shows new algorithms compared random sampling assure viability MSS CHC signiﬁcantly better behavior random sampling Nevertheless rule use algorithms comparison value obtained corresponding instance selection algorithm random sampling rate If consider random sampling able determine percentage instances sample Thus instance selection algorithms able improve results random sampling useful obtain sampling rate 57 Study execution time In previous sections showed methods computational cost linear number instances To illustrate property behavior standard algorithms approach terms execution time C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 427 Fig 7 Storage requirementstesting error execution time seconds logarithmic scale standard RNN algorithm approach function number instances Fig 9 We plot time spent algorithms number instances increases A Bezier line drawn points create clearer plot The ﬁgure shows MSS ICF DROP3 methods execution time approximately quadratic respect number instances RNN CHC worse behavior far longer execution time Our proposal approximately linear allowing use methods hundreds thousands instances This corroborates theoretical arguments Section 24 58 Summary results As summary previous experiments Table 5 shows comparison approach ﬁve tested instance selection algorithms averaged datasets shown previous tables The table shows advantage approach In terms testing error demoIS worse standard algorithms methods exception CHC However CHC small increment testing error coupled large decrement storage reduction In terms storage reduction demoIS worse cases exception RNN However RNN reduction terms execution time remarkable storage reduction achieved demoISrnn worse RNN better algorithms In terms execution time showed Fig 9 behavior excellent ﬁve algorithms In Section 3 discussed previous method based recursive divideandconquer approach 20 able obtain good results terms execution time storage reduction However main drawback method 428 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 Fig 8 Storage requirementstesting error execution time seconds logarithmic scale standard CHC algorithm approach Table 4 Summary performance instance selection methods terms testing error random sample sampling ratio The table shows windrawloss record algorithm random sampling The row labeled ps result twotailed sign test winloss record row labeled p w shows result Wilcoxon test Signiﬁcant differences conﬁdence level 95 Wilcoxon test indicated cid3 Windrawloss ps p w Windrawloss ps p w Drop3 2406 00014 00039cid3 Drop3 2505 00003 00010cid3 ICF 2208 00161 00012cid3 ICF 2109 00428 01020 Standard methods MSS 18012 03616 02289 Democratic methods MSS 18111 02649 03820 CHC 16014 08555 07971 CHC 19011 02005 02134 RNN 2703 00000 00000cid3 RNN 2415 00005 00009cid3 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 429 Fig 9 Execution time seconds standard methods approach function number instances testing error worse obtained apply original method Fig 10 shows comparison demoIS method terms testing error DROP3 ICF base methods The ﬁgure shows demoIS improves testing error previous recursive approach problems A pairwise comparison algorithms DROP3 ICF methods separately shows signiﬁcant differences Wilcoxon test conﬁdence level 99 430 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 Table 5 Summary performance methodology standard methods terms testing error storage requirements execution time Signiﬁcant differences testing error storage reduction conﬁdence level 95 Wilcoxon test indicated cid3 Method Democratic instance selection DROP3 ICF MSS CHC RNN Error Equal Better cid3 Equal Worse cid3 Better cid3 Storage Better Better Equal Better cid3 Worse Time Better Better Better Better Better Fig 10 Testing error recursive democratic instance selection DROP3 ICF base methods 59 Study subset size number rounds effect We stated size subset relevant provided kept small hundreds thousands instances Thus chose subset size 1000 instances good compromise subset small obtain signiﬁcant reduction execution time large allow meaningful instance selection process In section study effect subset size behavior method We performed experiments DROP3 ICF subset sizes 100 250 500 1000 2500 5000 instances 10 rounds votes Figs 11 12 results testing error storage requirements execution time different sizes DROP3 ICF respectively For DROP3 reduction kept similar regardless subset size With larger subset size reduction somewhat smaller differences signiﬁcant In terms testing error method needs subset size large form meaningful subsets In way subsets smaller 1000 instances obtain worse results minimum size 1000 instances achieved longer decrement testing error In fact results subset sizes 1000 2500 5000 instances equal In terms execution time observe large increment example DROP3 base method time grows approximately quadratically subset size grows The behavior ICF similar In case signiﬁcant reduction storage requirements subset size larger This reduction effect worsening testing error subset sizes 2500 5000 instances The behavior execution time DROP3 As subset size grows execution time grows As size larger O n2 algorithm begins relevant processing subset C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 431 Fig 11 Average testing error storage requirements middle execution time function subset size DROP3 algorithm The plots relative values respect results subset 1000 instances important reduction number subsets processed The results corroborate 1000 instances good compromise sizes favor storage reduction testing error execution time A similar test performed determine effect number rounds performance method We ran method 5 10 25 100 rounds The results DROP3 ICF shown Figs 13 14 respectively Again similar behavior observed algorithms As rounds added reduction storage decreases This effect fact threshold removing instance higher rounds agree remove The testing error affected ﬁrst rounds added Inspecting results observed rounds 25 votes cast redundant advantage having rounds In way value measured 10 rounds The effect adding voters testing error marginal new round increases execution time This behavior similar case classiﬁer ensembles little gain obtained ﬁrst classiﬁers added 8 510 Huge problems In previous experiments shown performance methodology problems consid ered medium large In section consider huge problems hundreds thousands million 432 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 Fig 12 Average testing error storage requirements middle execution time function subset size ICF algorithm The plots relative values respect results obtained subset 1000 instances instances shown Table 6 These datasets methodology allows scaling standard algo rithms huge problems As previous experiments testing error storage reduction obtained 10fold crossvalidation The size datasets prevents execution standard algorithms reasonable time validity approach tested 1NN 10fold cv testing error shown table For problems demoISdrop3 demoISicf demoISrnn Results shown Table 7 The ﬁrst remarkable result method able scale huge problems In fact algorithm makes possible instance selection datasets execution time prohibitive In worst case demoISrnn poker dataset approach took 93 hours This value good account standard RNN took 500 hours adult dataset problem 48 842 instances poker dataset 1 025 010 instances Regarding effectiveness scalability results good The achieved testing error close 1NN error problems methods exception covtype problem demoISicf method This testing error comes remarkable reduction storage size demoISrnn 1 original dataset census kddcup99 kddcup991M poker Similarly demoISdrop3 demoISicf achieve large reductions problems C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 433 Fig 13 Average testing error storage requirements middle execution time function number rounds DROP3 algorithm The plots relative values respect results obtained 10 rounds 511 Application methods classiﬁcation We stated approach applied classiﬁers Other learners beneﬁt democ ratization instance selection algorithm provides way scale instance selection algorithm In way classiﬁers complexity related size training set decision trees support vector machines SVM beneﬁt instance selection constructed classiﬁer simpler 640 When instances selected training set instancebased learner SVM decision tree term prototype se lection instance selection We use instance selection kNN oriented methods prototype selection methods developed selecting training instances instancebased learner Our method signiﬁcant modiﬁcation classiﬁers We need prototype selection algorithm suitable classiﬁer apply procedure described Algorithm 1 As described instance selection methods prototype selection algorithms decision trees neural networks SVMs suffer problem scalability Thus method contribute scaling algorithms shown kNNbased instance selection In section present experiments showing applicability democratic algorithm decision trees SVMs classiﬁers We chose classiﬁers complexity depends quality training 434 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 Fig 14 Average testing error storage requirements middle execution time function number rounds ICF algorithm The plots relative values respect results obtained 10 rounds Table 6 Summary datasets The features dataset C continuous B binary N nominal The Inputs column shows number input variables Data set Cases Features Classes Inputs 1NN error census covtype kddcup99 kddcup991M poker 299 285 581 012 494 021 1 000 000 1 025 010 C 7 54 33 33 5 B 4 4 N 30 3 3 5 2 7 23 21 10 409 54 118 119 25 00743 03024 00006 00002 04975 set 40 widely machine learning application As stated partition method described Section 21 specially designed kNN method Thus experiments decision trees SVMs simple random partition training set disjoint subsets approximately size C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 435 Table 7 Testing error storage requirements execution time seconds approach huge problems Dataset census covtype kddcup99 kddcup991M poker census covtype kddcup99 kddcup991M poker census covtype kddcup99 kddcup991M poker Storage demoISdrop3 00289 01627 00123 00114 00247 demoISicf 00296 02250 00266 00097 00483 demoISrnn 00006 02653 00063 00026 00001 Error 00771 03333 00066 00019 05009 00818 04003 00112 00072 05099 00623 02955 00036 00037 04990 Time 20 8943 73520 44 1980 89 5470 66600 65480 38913 49241 15 1200 52653 75 1810 190 9030 112 9470 229 2730 335 1417 As prototype selection algorithm use previously described However algorithms specially designed kNN classiﬁers results classiﬁers poor Thus use method designed type classiﬁer This method 41 ﬁlter approach based set different classiﬁers noise ﬁlters These classiﬁers detect noisy outliers mislabeled instances remove training set The procedure shown Algorithm 7 Brodley Friedl proposed versions method consensus ﬁlter majority vote In consensus ﬁlter set classiﬁers D d1 d2 dk available classiﬁer di trained original training set After instances misclassiﬁed classiﬁers D discarded Then classiﬁer choice trained remaining instances In majority vote procedure instances discarded majority learners misclassify In experiments approach resulted removal instances We use term Majority Vote Filter MVF algorithm refer method Algorithm 7 Majority vote ﬁlter algorithm Data A training set T x1 y1 xn yn set learners D Result The subset selected instances S foreach di D Train di T end S T foreach xi S xi misclassiﬁed majority D Remove xi S end end 1 2 3 As classiﬁers D chose 1NN classiﬁer kNN classiﬁer k obtained crossvalidation C45 decision tree 42 SVM linear kernel SVM Gaussian kernel Decision trees SVMs sensitive parameters performed experiments crossvalidation setting values parameters For classiﬁers obtained best parameters set different values For SVM linear kernel tried C 01 1 10 SVM Gaussian kernel tried C 01 1 10 γ 00001 0001 001 01 1 10 testing 18 possible combinations For C45 tested 1 10 trials softening thresholds trying 4 possible combinations Although method assure optimum set parameters good set parameters obtained reasonable time The SVM learning algorithm programmed functions LIBSVM library 43 The experiments performed experimental setup previously There change democratic algorithm threshold votes Section 23 evaluated classiﬁer going learn prototypes selected algorithm The experiments performed standard classiﬁers C45 SVM dataset Then applied MVF algorithm trained C45 SVM dataset selected MVF Finally performed experiment democratic version MVF demoISMVF Results C45 classiﬁer shown Table 8 SVM shown Table 9 These results plotted Figs 15 16 respectively 436 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 Table 8 Testing error tree size number nodes execution time seconds standard C45 algorithm majority vote ﬁltering MVF demoISMVF Dataset abalone adult car gene german hypothyroid isolet krkopt kr vs kp letter magic04 mfeatfac mfeatfou mfeatkar mfeatmor mfeatpix mfeatzer nursery optdigits pageblocks pendigits phoneme satimage segment shuttle sick texture waveform yeast zip C45 Error 07914 01470 01331 00946 03170 00056 02997 01933 00063 01221 01661 01150 02415 01825 02955 01190 03088 01678 01082 00331 00348 01326 01446 00307 00002 00098 00666 02474 04527 01340 MVF C45 demoISMVF C45 Size 23102 198856 1302 2744 2882 272 13682 75274 702 2553 719 1488 2722 2322 219 1742 2905 367 4398 121 4024 2548 6544 892 586 542 3084 5998 4536 7954 Error 07568 01735 01582 00729 02720 00114 02988 02739 00081 01219 01763 01100 02405 01645 02933 01130 03200 01683 00998 00269 00359 01411 01271 00329 00007 00196 00645 02288 04209 01324 Size 1872 2576 1020 1636 1276 204 12594 36924 568 22086 4576 1388 1668 2212 970 1646 2678 3108 3834 584 3420 1966 4202 770 478 296 2586 4602 992 7298 Time s 623 387 4061 83 1887 38113 2161 11280 37087 406 20896 18 5772 2657 1417 1478 20293 2068 1148 6609 3803 27564 10595 560 7476 475 298 5678 1326 2692 2242 65 9164 Error 07391 01427 01657 00757 02770 00202 02987 02554 00088 01245 01699 01210 02365 01740 02770 01050 03095 01739 00929 00285 00332 01326 01299 00407 00006 00167 00640 02384 04068 01273 Size 2522 2230 880 1836 1374 186 12530 43208 536 21240 4496 1288 2166 2138 774 1572 2448 2928 3746 466 3360 2276 4026 712 436 316 2572 5442 1014 7210 Table 9 Testing error size number support vectors execution time seconds SVM majority vote ﬁltering MVF demoISMVF Dataset abalone adult car gene german hypothyroid isolet krkopt kr vs kp letter magic04 mfeatfac mfeatfou mfeatkar mfeatmor mfeatpix mfeatzer nursery optdigits pageblocks pendigits phoneme satimage segment shuttle sick texture waveform yeast zip SVM Error 07372 01546 01430 00735 02460 00239 00568 01644 00081 00160 03190 00195 01690 00305 02645 00195 01695 01279 00171 00364 00046 01065 00748 00424 00014 00311 00016 01410 04149 00102 Size 37532 15 1753 5396 17200 5495 2613 33628 18 1087 5130 73700 48227 5351 11900 8700 9939 8234 9721 28466 12441 5324 11255 24899 17469 4500 5636 5059 6640 27676 10836 19646 MVF SVM demoISMVF SVM Error 07511 01572 01064 00773 02630 00316 00605 02598 00085 00303 01964 00250 01530 00250 03233 00195 01940 01044 00107 00287 00040 01189 00877 00403 00019 00485 00049 01374 04236 00120 Size 5952 14155 3435 14594 2975 1277 30461 17 6583 5478 10 1127 45175 3283 7346 7009 3347 6789 4020 11775 12815 1577 10621 17146 19279 5938 6271 1496 8176 15080 3410 11465 Time s 623 387 4061 83 1887 38113 2161 11280 37087 406 20896 18 5772 2657 1417 1478 20293 2068 1148 6609 3803 27564 10595 560 7476 475 298 5678 1326 2692 2242 65 9164 Error 07413 01528 01442 00729 02640 00515 00587 02404 00094 00305 01589 00250 01690 00280 02675 00235 01780 01471 00153 00380 00064 01264 00823 00467 00018 00361 00038 01370 04000 00126 Size 6091 29375 5813 17411 335 2144 34778 13 4727 3722 69527 23991 6128 9555 9013 2348 8059 7553 29752 11612 2948 10859 129325 12955 3951 7672 3657 7378 18281 424 20851 Time s 301 5208 64 528 71 158 1710 1696 179 1415 1037 696 579 497 101 610 368 673 475 203 505 221 441 103 1931 161 685 518 82 1405 Time s 316 20950 110 1194 97 284 2926 3175 411 6645 2592 1051 613 525 84 1194 398 9032 1975 285 1270 278 1244 126 3804 245 965 1197 84 5473 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 437 Fig 15 Testing error relative tree size measured ratio number nodes respect C45 applied dataset execution time seconds logarithmic scale standard MVF algorithm approach compared C45 algorithm applied dataset Both tables results usefulness approach MVF able obtain classiﬁers cases simpler obtained instances training set match testing error However previous methods MVF scalability problem large datasets This problem especially noticeable adult shuttle datasets demoISMVF able performance MVF signiﬁcant reduction execution time As case experiments kNN reduction signiﬁcant problem larger supporting claim proposed method able scale prototype selection algorithms instance selection methods eﬃciently These results methodology applied different kinds classiﬁers provided prototype selection method Other methods reported good results PSRCG 44 SiS 45 512 Noise tolerance Instance selection algorithms learning algorithm 46 degraded performance presence noise In ﬁeld ensembles classiﬁers Dietterich 47 tested effect noise learning algorithms introducing artiﬁcial noise class labels different datasets Realworld problems noise relevant study 438 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 Fig 16 Testing error relative tree size measured ratio number support vectors respect SVM applied dataset execution time seconds logarithmic scale standard MVF algorithm approach compared SVM applied dataset behavior learning algorithm presence noise In section study sensitivity method noise compare standard algorithms To add noise class labels follow method Dietterich 47 To add classiﬁcation noise rate ρ chose fraction ρ instances changed class labels incorrect choosing uniformly set incorrect labels We chose datasets rates noise 5 10 20 With levels noise performed experiments DROP3 ICF democratic counterparts demoISdrop3 demoISicf Fig 17 shows results methods noise levels 5 10 20 DROP3 ICF algorithms The ﬁgure demonstrates robustness method The degradation performance smooth class label noise added It important note method able maintain good performance presence noise uses partial views dataset sensitive noise The ﬁgures method able relative behavior respect original algorithms noise added 6 Conclusions future work In paper presented new method scaling instance selection algorithms applicable instance selection method modiﬁcation The method consists performing rounds applying instance C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 439 Fig 17 Comparison DROP3 demoISdrop3 ICF demoISicf presence noise selection disjoint subsets original dataset combining means voting method Using ﬁve known instance selection algorithms DROP3 ICF RNN MSS CHC genetic algorithm shown method able match performance original algorithms considerable reduction execution time In terms reduction storage requirements testing error approach better use original instance 440 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 selection algorithm dataset methods Our method straightforwardly paralellizable modiﬁcations Additionally method tested prototype selection algorithms additional classiﬁers decision trees support vector machines In cases shown ability scale prototype selection algorithms instance selection algorithms We shown approach able scale huge problems hundreds thousands instances Using ﬁve huge datasets method able execute rapidly achieving signiﬁcant reduction storage keeping testing error similar 1NN error datasets We think proposed method breakthrough instance selection algorithms design allows development complex methods instance selection This relaxation constraints complexity base method possibility democratic instance selection As principal research approach working development better methods partitioning original dataset believe relevant inﬂuence performance method Additionally recent paper 48 shown instance selection mechanism constructing ensembles classiﬁers The method presented paper provides promising way extend method larger datasets References 1 M Craven D DiPasquoa D Freitagb A McCalluma T Mitchella K Nigama S Slatterya Learning construct knowledge bases World Wide Web Artiﬁcial Intelligence 118 12 2000 69113 2 FJ Provost V Kolluri A survey methods scaling inductive learning algorithms Data Mining Knowledge Discovery 2 1999 131169 3 H Liu H Motada L Yu A selective sampling approach active feature selection Artiﬁcial Intelligence 159 12 2004 4974 4 JR Cano F Herrera M Lozano Using evolutionary algorithms instance selection data reduction KDD An experimental study IEEE Transac tions Evolutionary Computation 7 6 2003 561575 5 H Brighton C Mellish Advances instance selection instancebased learning algorithms Data Mining Knowledge Discovery 6 2002 153172 6 JR Cano F Herrera M Lozano Evolutionary stratiﬁed training set selection extracting classiﬁcation rules trade precisioninterpretability Data Knowledge Engineering 60 1 2007 90108 7 P Domingos G Hulten A general framework mining massive data streams Journal Computational Graphical Statistics 12 4 2003 945949 8 N GarcíaPedrajas C GarcíaOsorio C Fyfe Nonlinear boosting projections ensemble construction Journal Machine Learning Research 8 2007 133 9 RE Schapire Y Freund PL Bartlett WS Lee Boosting margin A new explanation effectiveness voting methods Annals Statis tics 26 5 1998 16511686 10 C GarcíaOsorio C Fyfe Regaining sparsity kernel principal components Neurocomputing 67 2005 398402 11 D Asimov The grand tour A tool viewing multidimensional data SIAM Journal Scientiﬁc Statistical Computing 6 1 1985 128143 12 A Buja D Asimov Grand Tour methods An outline D Allen Ed Computer Science Statistics Proceedings Seventeenth Symposium Interface Elsevier Science Publisher BV North Holland Amsterdam 1986 pp 6367 13 A Buja D Cook D Asimov C Hurley Computational Methods HighDimensional Rotations Data Visualization NorthHolland Publishing Co 2005 Ch 14 pp 391414 14 EJ Wegman JL Solka On mathematics visualising high dimensional data Indian Journal Statistics Series A Pt 2 64 2002 429452 15 DF Andrews Plots high dimensional data Biometrics 28 1972 125136 16 EJ Wegman J Shen Threedimensional Andrews plots grand tour Computing Science Statistics 25 1993 284288 17 N GarcíaPedrajas JA Romero del Castillo D OrtizBoyer A cooperative coevolutionary algorithm instance selection instancebased learning Machine Learning 78 3 2010 381420 18 JR Cano F Herrera M Lozano Stratiﬁcation scaling evolutionary prototype selection Pattern Recognition Letters 26 7 2005 953963 19 SW Kim BJ Oommen Enhancing prototype reduction schemes recursion A method applicable large data sets IEEE Transactions Systems Man CyberneticsPart B Cybernetics 34 3 2004 13841397 20 A HaroGarcía NG Pedrajas A divideandconquer recursive approach scaling instance selection algorithms Data Mining Knowledge Discovery 18 3 2009 392418 21 P Domingos G Hulten A general method scaling machine learning algorithms application clustering Proceedings Eighteenth International Conference Machine Learning Morgan Kaufmann 2001 pp 106113 22 P Domingos G Hulten Learning inﬁnite data ﬁnite time Proceedings Advances Neural Information Systems vol 14 Vancouver Canada 2001 pp 673680 23 W Howffding Probability inequalities sums bounded random variables Journal American Statistical Association 58 1963 1330 24 G Hulten P Domingos Mining complex models arbitrarily large databases constant time Proceedings International Conference Knowledge Discovery Data Mining Edmonton Canada 2002 pp 525531 25 S Hettich C Blake C Merz UCI Repository machine learning databases httpwwwicsuciedumlearnMLRepositoryhtml 1998 26 J Demšar Statistical comparisons classiﬁers multiple data sets Journal Machine Learning Research 7 2006 130 27 H Liu H Motoda On issues instance selection Data Mining Knowledge Discovery 6 2002 115130 28 DR Wilson TR Martinez Reduction techniques instancebased learning algorithms Machine Learning 38 2000 257286 29 DL Wilson Asymptotic properties nearest neighbor rules edited data IEEE Transactions Systems Man Cybernetics 2 3 1972 408421 30 GW Gates The reduced nearest neighbor rule IEEE Transactions Information Theory 18 3 1972 431433 31 R Barandela FJ Ferri JS Sánchez Decision boundary preserving prototype selection nearest neighbor classiﬁcation International Journal Pattern Recognition Artiﬁcial Intelligence 19 6 2005 787806 32 L Kuncheva Editing knearest neighbors rule genetic algorithm Pattern Recognition Letters 16 1995 809814 33 H Ishibuchi T Nakashima Pattern feature selection genetic algorithms nearest neighbor classiﬁcation Journal Advanced Computational Intelligence Intelligent Informatics 4 2 2000 138145 34 CR Reeves DR Bush Using genetic algorithms training data selection RBF networks H Liu H Motoda Eds Instances Selection Construction Data Mining Kluwer Norwell Massachusetts USA 2001 pp 339356 35 DE Goldberg Genetic Algorithms Search Optimization Machine Learning AddisonWesley Reading MA 1989 C GarcíaOsorio et al Artiﬁcial Intelligence 174 2010 410441 441 36 D Whitley The GENITOR algorithm selective pressure MK Publishers Ed Proc 3rd International Conf Genetic Algorithms Los Altos CA 1989 pp 116121 37 LJ Eshelman The CHC Adaptive Search Algorithm How Have Safe Search Engaging Nontraditional Genetic Recombination Morgan Kauff man San Mateo CA 1990 38 S Baluja Populationbased incremental learning Tech Rep CMUCS94163 Carnegie Mellon University Pittsburgh 1994 39 J MaudesRaedo JJ RodríguezDíez C GarcíaOsorio Disturbing neighbors diversity decision forest G Valentini O Okun Eds Workshop Supervised Unsupervised Ensemble Methods Their Applications SUEMA 2008 Patras Greece 2008 pp 6771 40 M Sebban R Nock JH Chauchat R Rakotomalala Impact learning set quality size decision tree performances International Journal Computers Systems Signals 1 1 2000 85105 41 CE Brodley MA Friedl Identifying mislabeled training data Journal Artiﬁcial Intelligence Research 11 1999 131167 42 JR Quinlan C45 Programs Machine Learning Morgan Kaufmann San Mateo 1993 43 CC Chang CJ Lin LIBSVM A library support vector machines software available httpwwwcsientuedutwcjlinlibsvm 2001 44 M Sebban R Nock Identifying eliminating irrelevant instances information theory H Hamilton Q Yang Eds 13th Biennial Conference Canadian Society Computational Studies Intelligence AI 2000 Montreal Lecture Notes Artiﬁcial Intelligence vol 1822 Springer 2000 pp 90101 45 SS Sane AA Ghatol A novel Supervised Instance Selection algorithm International Journal Business Intelligence Data Mining 2 4 2007 471495 46 E Bauer R Kohavi An empirical comparison voting classiﬁcation algorithms Bagging boosting variants Machine Learning 36 12 1999 105142 47 TG Dietterich An experimental comparison methods constructing ensembles decision trees Bagging boosting randomization Machine Learning 40 2000 139157 48 N GarcíaPedrajas Constructing ensembles classiﬁers means weighted instance selection IEEE Transactions Neural Networks 20 2 2008 258277