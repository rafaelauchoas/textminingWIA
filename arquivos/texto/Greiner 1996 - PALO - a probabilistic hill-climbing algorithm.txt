ELSEVIER Artificial Intelligence 84 1996 177208 Artificial Intelligence PALO probabilistic hillclimbing algorithm Russell Greiner Siemens Corporate Research 755 College Road East Princeton NJ 085406632 USA Received April 1994 revised May 1995 Abstract Many learning systems search space possible performance elements seeking element expected utility distribution problems high As task finding globally optimal element intractable practical learning systems instead hill climb local optimum Unfortunately problematic learner typically know underlying distribution problems needs determine elements expected search utility utility This paper addresses function estimated sampling We present general algorithm PALO returns element generality algorithm presenting element efficiency accuracy completeness nearly optimal These results suggest learning multiple extension approaches solving utility problem explanationbased problem nonmonotonic tradeoff problem knowledge representation provably high probability essentially local optimum We demonstrate reasoning tractabilitycompleteness distinct applications task approximating hillclimbing respectively Keywords Computational learning theory Hillclimbing Speedup learning Utility problem Knowledge compilation Theory revision Prioritized default theories 1 Introduction Many learning mance elements examples inductive seeking element tasks viewed search space possible perfor optimal based utility measure As optimally accurate systems seek classifiers classifications This paper expands short article Probabilistic hillclimbing theory applications awarded Artificial Intelligence Journal Best Paper Award Ninth Canadian Conference Artificial Intelligence CSCSI92 Vancouver May 1992 Email greinerscrsiemenscom 00043702961500 1996 Elsevier Science BV All rights reserved KYDI0004370295000402 178 K GretnerArtificiurl htelligence 84 I 996 177208 learning optimally explanationbased solvers compare expected value particular goals queries problems samples different elements efficient 30591 17601 chunking 1551 systems seek problem function In cases utility defined function averaged distribution classifiers problem solvers scoring seen 3842 There problems implementing samples determine element learning First optimal unfor usually unknown There course standard statistical techniques For example systems incorporated 78 use estimates identify element information needed estimate This use set observed samples information second problem systems approximately need know distribution tunately techniques classes learning PAClearning high probability leads ally optimal element spaces elements climbs BACKPROP 1441 genetic algorithms speedup learning methods guarantee hillclimbing ment superior elements Moreover learning reached point diminishing fewer systems 3042 A common especially given lncuf optimum Many wellknown global optimum unfortunately correct distribution response intractable task identifying glob information hill build inductive including learning systems 681 use approach systems final ele space determine existing 1281 Unfortunately step improvement meaning initial optimum include stopping criterion 6 45 returns The work presented draws ideas themes particular learning produces general algorithm I 6 local optimal describes utility measure 0 PALO efficiently incremental effects sample order Moreover 621 passively gathering element PALOs hillclimbing minor solve problems batched statistics opposed relevant PALO hillclimbs local optimum estimated sampling Given parameters element expected utility EC probability As PALO processes sample time learner uses statistical tests mollify work unobtrusively performance needs simply watching users applications Here incremental problems cost simply solving performance cost elements Section 4 defines use expected utility quality measure Section 2 compares contrasts approach literature comparing general PALO algorithm deals high final statistical better rigorous generality Section 3 motivates performance sequentially series performance I improvement confidence O local optimum result proposed modification tool determine original performance version Mintons utility analysis approach presenting tool viewed mathematically O performance elements 01 Oi PALO space searched 591 Section 5 demonstrates different applications It describes element Theorem I defines OUT sense efticiency local optimality R GreinerArtcial Intelligence 84 1996 177208 179 set transformations performance completeness behavior limitations paper particular respectively nearoptimal elements optimality defined It summarizes situation Section 6 discusses particular set element terms efficiency accuracy study illustrate PALOS variations contains proofs claims empirical extensions approach The Appendix 2 Related results Finding element best average performance techniques use statistical 581 There projects element average performance evaluate N performance Moore set elements meaning explicitly Their Hoeffding Race approach elementsample removing evaluations element optimum performance k training samples Maron small explicit performed total number clear works relatively evaluations reduce element soon statistically In general learning N x k elementsample optimal elements attempts 221 presents different mathematically Fong reducing ment deal sample The resulting YW tE number elementsample evaluations 50 rigorous solution problem specifying single ele framework extends Kaelblings Combinatorial space hillclimbing These approaches work explicit representation possible perfor In cases implicitly defined combinatorial set neighbors mance elements number elements Here makes sense impose structure space form small subset space necting element current element use hillclimbing neighbors There course huge number hillclimbing sys field tems machine element science Each evaluate easily computed This true case quality measure expected value elements known depends unknown distribution currently proposed performance quality neighbors This comparison score instance climb successively elements instances trivial learning classifiers As mentioned optimal example learning systems attempt address challenge learning proce 61 68 neural nets 44 genetic algorithms distribution Most sys heuristically By contrast PALO performs ing element expected behavior dures symbolic Each systems uses set training uses information tems implicitly explicit statistical superior samples determine element test determine prescribed corzjdence element estimate superior 180 R GrelnerArtcicrI lntellience 84 I 996 177208 As similar samples hillclimbing By contrast PALO stop return statistical criteria While PALOs COMPOSER Gratch DeJong Chien element 0 Os neighbors appears significantly 27 291 COMPOSER differs PALO significant ways First COMPOSER use available bet currently best performance returns ter Owhich means PALO stop reaching point diminishing test based The second difference Hoeffdings sam samples ples COMPOSERS standard drawn empirically Section 62 effective COMPOSER Moreover PALOs conserva makes simplifying errors successive hillclimbs tive mathematically add producing empirically assumptions necessary inequality Eq 6 holds bounded stationary distribution assumes assumption correct implicitly COMPOSER normal distribution While test based Nadas rule appropriate guaranteed example assumption Rationality Doyle Patil 19J recently argued decide different possible performance case analyses advocated expected case analysis This raises obtain information embodied PALO addressing exactly distribution information required standard practice worst instead elements obvious questions expected case behavior available We view approach determine questions Moreover PALO exhibits type Type II rationality element expected utility ing feasible time similarly motivated issue computational exhibit given performance 46 Etzioni works Horovitz These systems assume available immediately elements By contrast PALO estimate reached current phase hillclimbing total space elements PALO reach statistically observing manyfewer utilities elements algorithms PALO usually Section 4 supply statistical methods finished collecting allows PALO require smaller samples akin utilities optimal subject 26 seeks resource constraint spend element Many systems best cf resources 701 utilities elements utilities Hoeffding Race yIE framework mentioned effectivenessie limited computational 21 Russell Subramanian estimating Parr significant required systems elements process As small subset conclusions estimate long means Note NPALO5 begin climbing samples Moreover total number samples 2 A major difference COMPOSER like Hoeffding Race yIE systems mentioned qualifies wrapper learner 1 10481 COMPOSER views performance element black box behavior sampled internals ate unavailable By contrast PALO examine internals performance elements use structural information efficiently determine scores neighboring elements Section 5 I I36 I R GreinerArtijicial Intelligence 84 1996 177208 181 Incremental algorithms Many methods attempt effective use training samples cf inforcement learning algorithms 5076 systems address bandit prob lem 3641 Each systems makes sequence decisions attempting maximize total reward Such systems tend run continuously making successive decisions evaluated terms number mistakes entire learning performance lifetimes By contrast PALO evaluated terms quality performance element returns provided returns answer reasonablepolynomialamount time Like PALO incremental learners climbs series differ ent elements PALO probabilistically guaranteed improve time performance element produced jth hillclimbing step high probability strictly better previous produced j 1st iteration As resembles anytime algorithms 4161 differs standard anytime algorithms terminating reaching point diminishing returns Probabilistic hillclimbing Finally phrase probabilistic hillclimbing suggest simulated anneal ing 53 readers worth explicitly distinguishing different ideas The general simulated annealing process assumes quality measure com pare different elements accurate use probabilistic refers stochastic way simulated annealing algorithm probabilistically decides climb downhill attempt avoid local optima By contrast PALO know quality element estimate values Our use proba bilistic refers uncertainty estimates possible sampling error One course write PALOlike algorithm annealing process climb downhill occasionally satisfy useful specifications presented Theorem 1 3 Framework To illustrate relevant concepts consider following example A pure PROLOG 121 We form new program return set answers query posed programs rearranging order clauses While programs return set answers require differing amounts time answer query Our goal determine optimally efficient program ordering clauses requires minimal average time answer distribution queries In general assume given possibly infinite set performance elements Se Oi 0 E Se returns answer given problem query goal qi E Q Q ql q2 set possible problems 3 We 3 We assume Q countable purely pedagogical reasons There obvious ways extending analysis handle au uncountably infinite set problems 182 R GreinerArtial Intelligence 84 1996 177208 function c SC x Q t1 R cOq measures use given utility clement B solving clement 0 corresponds programs sample problem solve y Section 5 later defines classes performance utility functions We insist A Ac Q Se E LR problem 4 In PROLOG context performance set PROLOG time 0 requires samples range possible values ordering clauses Se query c Oq quantifies c bounded elements Vo E So V9 6 Q minO cOq minO A 1 min minEQcOq q E Q Section 51 specifies A value PROLOG case minimal utility value 0 instances This utility function specifies score performance element individual instance 4 Our performance problems Q 4i To specify element distribution problems stationary probability probability performance elements solve entire ensemble best overall consider elements encounter We model 0 I PVqj denotes expected utility problem 4 selected We define performance obvious way function Pr element Q H C0 2 EqQrCOq CPrqj x cOq 2 4EQ Our underlying challenge performance element expected utility problems First problem distribution determine element information optimal task identifying usually unknown Second optimal element maximal As mentioned needed knew distribution intractable 4 The PALO1 algorithm PALOI estimate given initial 01 performance local optimum This section This section presents Icarning lems set sample queries efficiently ity essentially specifies PALOls motivation underlying theorem functionality sidesteps prob distribution hillclimbing high probabil element theorem summarizes PALOts code finally sketches states fundamental As shown Fig 1 PALOI takes arguments Sj collection possible performance error confidence order pair clauses ri 0 moves Os clause transformations element parameters E 6 0 bound initial performance element 01 E 7 ri rj Se H Se maps allowed In context PROLOG example ri rearranges PALOt uses oracle draws samples fixed unknown distribution Pr I Here sample beginning qj random according query 4 PALO abbreviates Probably Approximately Locally Optimal Section 6 I explains I subscript R GreinerArtijicial Intelligence 84 1996 177208 183 posed user performance specified conditions 01s neighbors 02 different 03 7202 returned PALO climb 02 Al given 71 E 7 possibly Note NPALO Under element 01 reaching O initial performance eventually Theorem 1 specifies PALO1 s behavior It uses I 7O ESj7E7700 denote set Os neighbors The proof theorem appears Appendix 1 The PALO1 ir E 6 process Theorem formance elements 02 probability 1 6 incrementally produces series O Ojl rj Oj rj E 7 1 expected utility performance element strictly better prede cessors Vl j m COj COi 2 thenal pelformance element returned PALO1 O elocal optimum 47 E 7 C70 C0 E Moreover PALO1 stay j terminating climbing Ojl number samples terminate probability new l6 A c Se I Oj polynomial lc ISe finite 1 provided The PALO1 code shown mance elements 0O E Se Fig 1 uses additional terms For pair perfor A 0 0 nlEaxC q c 0 q tlilIcO q c0 q 3 bounds range possible values c O q c 0 q samples q E Q A1 gO given 0 neighbors 0 E I 01 Notice largest range A 01 2A 0 To summarize A specified Eq 1 code PALO1 examines sequence sample queries element On seeing query PALO computes value comparable summed queries seen far compares line L2 If neighbor appears significantly values 0 s neighbors element 02 PALO compares L3 better 02s performance 02s neighbors set samples 02s neighbors appears better PALO1 climb apparently appear superior element 03 forth On hand utility given 01 performance js neighbors new performance line 4 184 R GreinerArtifciul Intelligence 84 1996 177208 Algorithm PALOE Forj Ioodo Let 6T 66 I_ ForEach H E 710 I Let djRO 0 For lL Get sample y oracle ForEach C E 7z o Lj mux samples jth iterution LI 8 Get und process ith query Let dlli dtNi I CWy cjqi If L If 39 E II I Then Then Let l C1 Exit For inner loop Else If WI E 7Hjl Ji E A I LJ ll7Tjll 6 1 Then Return 0 Exiting inner outer For loops L2 L3 L4 Then Else Let Hjl 0 Exit For inner loop Else Return 0 Exiting inner outer For loops End For inner loop End For outer loop End PALO Fig I Code PALO algorithm R GreinerAiciul Intelligence 84 1996 177208 185 comparable worse current Oj line IA PALO1 terminate returning Oj If conditions holds PALO general simply process query use query addition previous ones comparing current Oj neighbors However PALO1 dealt current Oj sufficiently large number queries Lj line Ll PALOI use easier satisfy thresholds decide climb I terminate line L5 necessarily perform actions Notice PALOI climbs 0 new 0 T 0 0 likely better 0 highly confident C CO equivalently P Ef C0 C0 0 5 Unfortunately C 0 C0 quantity depends unknown distribution immediately determine Eq 5 holds We obtain approxima tion usually good To define random variable di zf COqi COqi difference utility deal query qi versus 0 As query qi selected randomly according fixed distribution di independent identically distributed random variables common mean Eq 5s P Now let def 1 Yn di n c jl sample mean n samples Notice A 0 O n quantity computed line L2 corresponds n x Y From Law Large Numbers know average tend true population mean p n 4 00 lim Y Hoeffdings inequality 11451 bounds probable rate convergence probability Y p y goes 0 exponentially fast n increases fixed n exponentially y increases Formall Pr Y p y e2nyA2 Pr Y p y e2nylA2 6 n A 0 range possible values cO 4i 0 qi defined Es 3 The PALOI algorithm uses equations values A Oj O determine confident C0 C Oj lines L3 L5 7neighbor Oj TkOj E better j lines L4 L5 proof Appendix See 5 p 121 Nb inequalities require underlying distributions normal instead hold arbitrary bounded distribution 186 K GreinerArtijiciul Intelligence 84 I 996 177208 We close algorithm 6 section general comments PALO1 framework PALO uses produced user Note NPALO The samples performance simply asking questions unobtrusively relevant current applications gathering statistics user solving problems solves performance simply solve successive performance performance elements element PALO 621 This means problems learns hillclimbing marginally cost running performance problems total cost overall PALO uses user provided samples objective approximate utility values elements distribution element actually address This average case analysis differs approaches example assuming problems uniform particular collection benchmark 25 necessarily challenge problems distribution problems correspond 1521 average performance A Olocal optimum Note NPALO local optimum slocal optimum local optimality This means real local optimum elements 0 rO PALO produce bana fide local optimum difference PALOls corresponds exactly standard notion condition 2 Theorem I generalizes output O high probability utility distinct performance larger c Thus sufficiently small values E Note NPALO As I O set distinct nondegenerate smaller disjoint pairs 7 r8 rO l7j r E I r 0 elements map 0 elements Note NP04 Our PALO formance lines pass This behavior numbers samples later better elements later associated desirable means overall dealing larger L3 L4 indirectly line Ll earlier ones tests directly increasingly difficult process samples probably uses different approach PALOtt Note NPALOS The PALO An alternative samples start use simultaneously elementsin performance Section 2 In particular simultaneously sets samples climb set utilities use estimates comparing different elements process If total space contains N different elements PALO11 suggested systems discussed e2 probability instead obtain single estimate N elements I 6 requires hillclimbing manner estimate We end sections comments In case casual reader skip suffer loss continuity R GreinerArtQicial Intelligence 84 I 996 177208 1 Amax Ma 2 E2 187 7 samples nrnax maxj Aj elements Oj largest range values performance In situations PALO1 require fewer samples PALO1 requires Lj samples perform k 1 climbs terminate deal jth element meaning PALOall To note mL 221n271 jl 2 JS A 2 k c jl ln 2jljll 63 2 T 2 lIlTOj lIlz jl 8 Lj samples jth element require far fewer samples deal far Amax 2 PALO1 line L3 far PALOlls thanks usually maI1 overbound 1 A Oj k elements In practice PALO1 usually L4 branches Moreover samples usually use far fewer line Mall To motivate elements different neighborhoods observe pessimal general empirical observation assume neighborhood effectively disjoint b IT Oj 1 total space like INI bK elements K real depth space Now PALOls k K In fact PALO1 begin non optimum expect k K element Ignoring Eq 8s lnj27r236 stop nonglobal terms Eq 7s ln26 notice mall 2 hlj jl 2 klnb Given assumptions Mall mall Kln b xs Mall lny kin 9 infrequent Eq 9 exposes PALO This happen PALOI forced terms compensate neighborhoods overlapped elements PALOall estimate situations PALO require samples bad element ln r k 36 utilities times costs PALO1 extra samples By contrast expected utility element exactly entire space meaning difference k K It happen starts exceptionally large overlap explore essentially forcing PALOI estimate 188 R GremerArticiul Intelligence 84 I 996 177208 Rule Set Fact Set NJ btlK Nh bt2K 5 Attempt hrIr q C Attempt ht 2 K b NS b N7 Fig 7 Inference graph GA J I Hence rnll Mall mall M depending possible stances However experimental mungfcr PALOII samples uses Lj samples dealing jth element PALO requires data shows practice PALO1 basic reasons mentioned circum requires PALO rarely lnh INI iterations termination typically 5 Instantiations PALO1 algorithm generality PALO algorithm presenting This section demonstrates instantiations elements Se Oj process 3 different possible performance hillclimbing expected utility We present parameters summarized begins quick simplistic description application build comprehensive framework For instantiation specify set transformations 2 utility function c specify The instantiations reasons subsection derived values A O 0 Table 2 For pedagogical provides notes 1 set 7 ok 5 I Improving ejicienq Many derivation processes viewed satisficing search graph structure As example notice information answer search successful database heprc query ground inference graph GA formed retrieval A strategy specifies 741 given shown Fig 2 individual K corresponds naturally given set rules seeking order perform 7 Here hep x means x hepatitis y tests positive blood test This graph traversal situation corresponds j sunx means x jaundiced badB x means x bad blood immediately bti Section 3s PROLOG x means situation R GreinerArtifcial Intelligence 84 1996 177208 189 jaunK rulebased reductions NO hepK al arc reduces subgoal based rule RI database retrievals Nl arc N1 N2 corresponds express strategy sequence GAS arcs strategy attempted database retrieval j aun K We goal 22 0 0 1234uSu6u7 lefttoright obvious depthfirst element corresponds performance reductions 00 reaches success nodes N2 NS NT There possible alternative depthfirst success node N2 stops success reaches success nodeeg strategy stop strategies traversal understanding exhausted succeeds Fig 2 doubly boxes GAS u2 retrieval strategies including 0 1 1236745 0 2 u34u5u67ulu2 0 3 3674512 nondepthfirst strategies Each strategy exists As answer acceptable 74 means costs strategies preferring search satisficing strategies equally equally answers accurate We consider expected cost minimal We use fi E IV nonnegative cost strategy 0 answer propositions Fig 2s Fact Set cost traversing ai compute cs 0 q query q For example given atomic cOohepW fl f2 f f2 f3 f4 f5 cohepbl cfhepbl f3 f4 f5 These different strategies different costs given query strategy stops soon answer The expected cost course depends versus distribution NPhard hepb2 query posed hepbl queries Moreover task finding globy optimal strategy 301 This looks like job PALO TRo Tij Tij maps strategy ui arc Uj subgraph For example We define set reordering moving transformations subgraph 7640 al a2 a3 a4 Q5 01 7310 a3ra4ru5a6Q7 a2 02 Of course signs fig 1 flipped hem measuring cost utility element minimal maximal cost Note viewing strategy prefer performance element I90 R CreiwrArttiul Intelbgeru 84 1996 177208 PALO requires C f sum costs arcs inference graph G value A 8 values bounded cG elements proposition corresponding In general class ot performance N2 corresponds shown antecedent rule single Note NEFF defined respect inference graph G N A S f associated given set rules In situation literal N set nodes hepK arcs corresponding N1 based rule RI database corresponds Ns success nodes doubled boxes function perform A c N x N set al arc NO Q arc NI N2 The set S C N subset N2 N5 shown proof successful The cost f A 7Zl maps arc nonnegative value cost required reduction We earlier retrieval disjunction reaching nodes means let J refer value fa node No corresponds attempted database disjunction rulebased jaunc reduction retrieval To deal general rules antecedents c X1 1 use directed hypergraphs conjunctions bX node set children nodes conjunction imply literal aX hyperarc descends nodes common parent We define S set logically subsets N query processor reach member s E S derivation specifying 37 Appendix A 383 succeed This extension leads additional complications strategies It trivial extend definitions accommodate complicated f cost functions allow cost traversing arc depend factors success failure traversal arcs traversed elements corresponds operators working Note NEFF2 This class performance lem solvers graphs ference graph corresponds probabilistic operator ns encodes forth btl standard prob including PROLOG 121 24 We use inference state spaces internal arc leaf arc general blood tests positive experiment Using GA example a3 encodes operator experiment succeeds patient invocation PALO algorithm In 1361 discuss instantiation learning basis Mintons utility analysis fits Note NEFF3 systems particular framework explanationbased 591 We framework provides mathematical computes upper lower present efficient PALO bounds d 0 rO n based information acquired running 0 L2 L3 respectively code Nb uses information ij PALO obtain good estimates A 0 T 0 n constructing T E 7 executing element S qr queries That paper provides battery empirical evidence demonstrate PALO work effectively JuriSica 49 presents extensive body related results analytically lines R GreinerArticial Inielligence 84 1996 177208 191 Table 1 Average number samples PALO 1 climb 00 6 005 ES E 20 I0 05 01 To 02 221 251 267 347 To O3 1986 2186 2761 To terminate 565 383 822 2197 To illustrate PALOIS effectiveness Note NEFF4 Fig 2 assume arc unit costie terms independent distribution queries realworld distribution retrievals suppose 1 We define graph shown consider fi fai probabilities database Pr jaunK Fact Set 1 query hep K posed 001 Prbtl K Fact Set 1 query hep K posed 060 Pr bt2 K Fact Set 1 query hep K posed 095 events disjoint Given fact set shown happen respectively hepb21 hep b6 hep b7 asked 4 respectively 1 Notice hep bl 39 56 time We use values compute 751 COc 5792 COt 5069 CO2 3840 CO3 3140 Of course learner initially know probability values know optimal strategy expected costs strategies 03 We ran PALO 00 starting element 6 005 settings realize appropriate sample queries terminatedwhich required average 221 samples 02 usually step reach globally optimal 03 As expected E Using E 20 PALO1 climbed global optimum Over 100 02 20local optimum 565 climb trials PALO strategy good terminate additional total learning process required average 786 total queries 9 For smaller values E PALO1 went 00 02 second hill number steps required climbing requiring transition reach 02 additional 1986 average 251 267 347 samples decided 21862761 samples 03 fact elocal optimum element deal final set samples problems PALO1 cost slightly expensive 03 performance optimal element Fig 3 graphs element know E 1 O case cases look similar course respectively reach 03 finally 3838222197 overall 03 performance relevant usersupplied values E 100501 Table 1 Notice simply running time required solving wasted samples element learning 9 In 100 trials PALO1 continued climb reached 83 required 16 additional samples terminate 192 R GreinerArtificiul Intelligence 84 I 996 177208 E PEO 55 7 5 E l 45 m 4 35 3L 0 PE2 50 100 150 200 250 Sample Number Fig 3 rALoI S climbs initial element 80 E I O 6 005 20 trials However 400 trials summarized As final note 6 005 setting means mistake als 4 values E PALO mistakeie climbed terminated Ebetter neighbor This coupled similar trials different inference values allow PALO1 1 100 tri thousand elements tests graphs diverse overly conservative I 8 illustrate results initial performance involving element statistical inferior PALOls 52 Improving accuracy incompatible certain queries A default collectively solutions solution This representation problems 54571 This subsection initial default given correct answer theory ambiguous solutions correct course extension produce individually 691 Unfortunately plausible like return knowledge problem explanation bias multiple statistics problem seeking credulous related optimally essence multiple corresponds 426 17 1771 reference class problem addresses theory produces 4 16369 machine correct learning In assume correct answer c3 2 2 X Yes X H 41 Each correct answer binding credulous performance list shown No Using Oq element 0 define utility function query q denoted Uq Yes possibly answer returned represent R GreinerArtijicial Intelligence 84 1996 177208 193 cOq Ef l 0 Oq Oq Oq IDK 1 IDK represents I dont know 10 We focus stratified THEORISTStyle set facts F set element 0 F H r 691 specific priority allowed hypotheses ordering hypotheses As specific example consider A 310 TA lo triple composed consistent H simple type default 9666779 performance elements sX gray eX IQX sX white aX nX azelda ezelda fact set 11 hypothesis set P hi IQ hypothesis ordering color Cl holds A imagine want know To explain OA process query want binding nA zelda C T szelda C factual information Fa This normal elephant normal holds respectively A considers Zeldaie try prove s zelda fail prove Zelda albino nEzelda hypothesisie Flc proposition enables reach conclusion nEzelda gray nA zelda white Notice know encoded 30 Unfortunately assume options resulting theory j U nEzelda element Fc addition query posed Here A consider asserting colored elephant colored consistent albino consistent known options assert instantiation itICOIISiSteIIt normal normal allowed individually Zelda Zelda meaning meaning facts We nA zelda decide ifies priority hypotheses Here r hi h2 means priority hi nAX means nEzeldaie gray szelda Gray encoded YesC I gray A return options As hypothesis ordering TA spec takes associated hi nE x conclusion U nEzelda Now consider different priority ordering TB hz hi As rs considers OB 250 H 0 2 s e ement differs A opposite hypotheses 1 lo Here zelda means ys color q5 The clauses albinos white We leave implicit This uses instantiation view qNo yq azelda statements gray refers Zelda aX means y albino ey means y elephant 4 Eq 11 state normal elephants gray normal function gray j white sczelda CYeaC H gray To simplify notation order return Zelda white answer YesC white query claim imagine Eq stating Which elements better C better If concerned single Zelda read accurate Oi larger value C 0 Oszelda queries To azt e 1 aztoc z albino elephant queries form query cOszelda In general consider trivial distribution illustrate eziau sz s z C query z 0 s z C return YesC white answer Hence plugging Eq 10s c function larger C 1 value YesC H gray defined 0 C z The best Oi depends distribution queries expected accuracy C Oi posed correct answers 1 1 s corresponds Eq 2 C Qszelda select opposed In general B 3X include larger set hypotheses 3t ht h As ordering based permutation queries Let smallest ylp IDK answer r zI ij sequence 7Is elements r I N H 1 I N 0 uses information answering index 3ih p If 0 returns consistent 3Uhr fl 0 returns priority ordering queries unfortunately accurate As known priori optimal ordering hypotheses NPcomplete Our goal identify depends distribution worse approximatable simplistic situation exactly hypothesis task identifying I 1 knew distribution considering derivation 321 Once PALO1 designed deal situation We define transformations ust theith IA r ri moves jth given ordering ternie term ordering r ht h2 h involves set TT h I h __l Ilk I I __I lI IIn We compute value d rk 7 Tk II ri transformation set queries qNz based 3 U hi b qc3q hypothesis hg Observe finally AT 2 0 E S 7 E IA Note NAcc The motivation underlying tri 73 use probabilistic given default rules Our work differs providing way obtaining tics assuming static analysis ground research Shas ordering relevant statis known priori computed purely facts database work similar information I2 Technically binding F U hil performance element considers adding instunfiation I list 4 seeking b qp binding smallest lists q5 pi index F u hrci hq consistent R GreinerArtficial Intelligence 84 1996 I77208 195 situations want In set subhypotheses collectively Note NAcc2 conjunction reach conclusion Here view 31 PH subhypotheses H power set set hypothesis asserted consider far assumes The description In contexts Note NAcc meaningful hypotheses based specificity criteria use PALOI initially meaningful partial ordering 401 Here relative priorities partial ordering determining ordering hypotheses incomparable complete elements Note NACCA As PALO1 process require general determine 3 U hi course need insist process decidable probability polytime propositional Horn theories propositional F U hi b q k computation 1 We guarantee 2CNF 83 undecidable guarantee k qOq polytime PALOls theorem proving general We PALO1 terminate iterations dealing Note NAC Recall c Q q rij TA Above obtained general need compute values C rij rl q information determining FU hi k qOq efficient ways estimating F U hi hypotheses discussed independent Note NACC holds hypothesis hi In situations values Horn approximation Section 53 We simplify corresponds computation set subhypotheses hj This paper considers type transformation rearranging anotherviz eliminating Note NAcc6 theory approaches modifying viewed set transformations theories We element individual antecedents consider convert set hypotheses There 131 65 Each approaches sets hypotheses inappropriate rules navigate space interrelated objective described identify implied space highest expected accuracy identify cf PA0 algorithm discussed Here expected accuracy score element depends unknown distribution meaning need use sampling process In simple cases globally optimal element able 381 In cases high probability identification makes sense close local optimality based classes transformations local optimum high probability define space theories approximable identify element use hillclimbing 33 Here approximation intractable Of course like PALOI task Note NAcc There obvious extensions sumes answer general imagine query range answers completely task First model correct completely false query better 196 R GreinerArtijicrul Intellipvce 84 1996 177208 IDK Fig 4 Flow diagram S W addressing X k IT N important 2000 watch7 expensive knowing For example points correct answer wrong answer We assumed cost watch7 location saltshaker stalking particular existential query set instantiations Here returning 9 better returning 0 I wrong answer As situation able rank responses query costs 1 tiger One way user specify general c 0 q factors differentially weighting 10 distinct returning terms precision precise knowing queries equally asking addressing function incorporate different queries On related cost answer Within framework consider users tradeoffs accuracy 341 See obtaining general c functions efficiency This allow user prefer example performance returns correct answer allow subsection situations wrong different possible answers incorporate spend long instances computational IDK complex completely subsection different time returning permit ignored theme 53 Improving categoricity theory task determining query The intractable It performed 181 I3 Selman Kautz compilation method Given general propositional general propositional 721 use observation efficiently known assuming P NP 14231 Horn clauses define particular knowledge Z compiler computes theory entailed theory theory contains theory theory set conjunction A clausal literals positive negative A theory When convenient write clause disjunction yaVnzVnjisequivalenttoynacr Horn clause clauses clause set disjunction includes positive atomic literal literals set literals R GreinerArtcial Intelligence 84 1996 177208 197 pair bracketing Horn theories S W property S k _Z F W S Strengthening initial theory 2 W Weakening Fig 4 shows resulting compiled 0 S W uses bracketing theories determine query T follows 2 If W k cr 0 terminates yes S p u 0 terminates Notice correct answers W b guarantees 2 u S p u guarantees 2 b u Moreover tests linear sizes u S respectively u W provided 1u Horn 181 l4 Otherwise W F u S k u 0 returns IDK Notice compiled usually tractable I5 deal arbitrary propositional theory However completely categoric return IDK queries Yes No Hence sacrificed completeness tractability We course like use approximation Si Wi categorical possible minimizes probability associated Si Wi return IDK To state precisely Given approximation S W query u let CSWU dzf dWu l dSu theory T dTu Ef 1 ifTu 0 Hence cc S W 1 u covered S W W k u S F u Using Eq 2 define C S W expected value c S W Our goal determine approximation S W largest C value As task intractable 72 depends distribution suggesting use PALOI Observe set queries covered strengthening weakening approximation S W query u W u disjointie S p u This means approximation Si W probability 1 6 e local optimum Si respectively Wj E locally op timal strengthening respectively weakening probability 1 62 We decouple task finding good strengthening finding good weakening handle separately This paper focuses good strengthening Note NCATI discusses compute good weaken ing Hence seeking strengthening Sort DS value minimal D r Ed S expected value d S s Recall want S u fail queries possible It easy S weakest strengthening satisfy OptS 2 S I4 We actually allow query T conjunction Horndual Horndual I5 Note NCATI explains iff negation 1 Horn Notice class Hornduals caveat propositions proposition u strictly includes CNE 198 R GmnerArtijiciul Intelligence 84 1996 177208 OptSXS M S 2 HornS br maximal clause Opt Define Hornstrengthening To compute dq Hornstrengthening Here k Hornstrengthenings j I k For example y E al V a2 V 761 V Tb2 yl E al V d V 7b2 y2 a2 V 161 V Tb2 clause Y subset Y Hornie Ys positive Y form y aj 41 formed simply discarding Hornstrengthenings nonHorn ak literals p clause subset Selman Kautz V ZH U 2 ZH subset Xs clauses nonHorn 72 prove form S 2 U _k Y E 2 Now write ZN Yif strengthening Y E Zv By identifying positive consider Hornstrengthened 2U YY2lY Horn clauses 1v yl yz y1 al V V bj V lb2 y2 cl V cz V CJ V 41 13 strengthening theory set form Scic 1 j__m theory 2 2 U 2 non literal y form shown yfi LZ Tb _ bi Horn optimal theory index For example given Hornstrengthened Hornstrengthening WC navigate space ol Hornstrengthened theories changing index nonHorn associated individual F LJQQ 7ki function changing Sg 15 Of course m number nonHorn number propositional index kth clause variables maps strengthening 7kS39_j _Z II total clauses theory Continuing earlier example clauses That define set transformations I S13 S11 XH u I Cl V lb v Tb2 V ldl 712Sl3 S23 zU a2 v b v Tb2 ci V ldl 1 This instantiation PALO1 process starts given Hornstrengthened theory Sll hillclimbs theories set 7 transformations As dS Sn depends S b c S k LT answered efficiently S S Horn In fact process use support u S efficiency Notice finally 2S S I strengthenings space Hornstrengthened Si S improve Note NCATS Selman Kautz I721 prove unique optimal weakening theory Unfortu ws corresponds theory nately w exponentially complexity w g cost set Horn implicates initial larger original S w answer queries exponential 5 I This means R GreinerArtificial Intelligence 84 1996 177208 linear T This issue strengthenings Iw 0214 size T theory T number clauses Si small strengthening 199 fact ll Xl We avoid potential blowup considering weakenings size K K Zl K usersupplied users tradeoffs efficiency weakening size maximally Once task determining Theorem A2 Appendix best given implement polynomial categoricity Our goal function designed categorical distribution queries intractable distribution best Ksized weakening depends distribution This motivates use PALO1 subtask The space transformations Selman Kautz 72 provide expo clause resolvent removing subsumed clauses Each computing resolve Horn clause nonHorn optimal weakening w In essence 7k E Iw performs step There keeping remove clause current approximation total number clauses bounded course additional force trans room iteratively time algorithm LUB attempts complicated nential algorithm adds successful transformations challenge formations proposed addition We discuss transformations hillclimbs called ADCOMP S Wj approximation spaces nearoptimal weakening This algorithm 39 present PALOish algorithm nearoptimal strengthening senses tractable The Si Wj Horn bounded tractable basically ADCOMP computes 2 j T Instead ADCOMP theories Si Wj approximates neighbors 7 Si T Wj As polynomial number neighbors theory 2 F T efficient Horn bounded size overall computation size ADCOMPS steps guaranteed admits efficient computation approximates computation produces current The userspecified K function bound quantifies Note NCAT2 ing implicitly answer query idea allowing ci S W quantifies approximation specify arbitrary combination efficiency On related See discussion theme current factors Note NAcc7 Si Wj returns user insisting including time user allow stop return specify general utility measure size weaken spend trying ci e 7 accuracy categoricity IDK We generalize S W solving situationeg spend long necessary IDK W F u S k 0 guess compute 2 k depends users objectives incorporated way handling parallel search good weakenings use PALOlike function differ climb elements There options answer alternatively Of course ci S W g utility space performance W F CT S CT situation strengthenings 391 200 R GreinerArticiul lnrelligence 84 1996 177208 7 15204756 Note NCAT This compilation work obviously approximation theory representation work extends maximally efficient autonomous way computing results I quantifying categorical anticipated admits efficient related work vividization try transform given intractable categorical reasoning Our goal producing distribution queries 2 providing efficient approximation 6 Conclusion 61 Other vuriants PALO systems specified PALO properties sample 1 The technical note climbing terminating PALOMAR Note NPALO climb Another alternative As suggested 1 subscript PALOI family algorithms Theorem 311 presents small significant simpler instead examines entire collection L samples PALO uses different batch satisfy PALOi algorithms differ ways While PALO considers online batched PALO0 time Unlike samples climb bounded number times bound precisely Finally distribution barriers deciding likely There PALOON PALOZN algorithms differ PALO0 PAL02 assumptions Notice splits PALO0 versus making normality PALO1 versus PAL02 PALOX versus PALOX orthogonal orthogonal Section 5 In particular PALO systems address applications PALO2 guaranteed specified world viz use lower data drawn normal distribution PALOIN makes stronger assumptions set applications discussed climb terminate Of course normal This allows samples drawn PALOIN mistakes We 3 I empirically tested different PALO systems PALO discussed usually different contexts best terms element function empirical sample complexity particular PALOIN worked effectively utility final performance More recently context 35 62 Limitations designed stationary The examples discussed PALO objective identifying arbitrary required computing information common handle situation distribution versatility Section 5 illustrate performance generality element expected utility optimal Our particular PALO situations 1 distribution samples task known priori 2 problems determine optimal element based quality measure given distribution expected values intractable The situations presented illustrate R GreinerArtijkial Intelligence 84 1996 177208 201 It worth discussing PALOs limitations understand applied PALO expected utility tionary best maximal Notice defining task goal performance implies expected utility problematic distribution inherently minimar seeking imagine 01 requires 05 seconds useful critical worst possible good possible For example return answer 1 second taking 1 second extreme penalty know PALO worst case performance tem benefit 1 second Here require To illustrate 02 requires 0001 seconds pears 0001 time 02 requires 2 seconds 02 clearly better expected efficiency worse means criterion model q infinite prevent PALO ing situation Here extremely 01 cc defining 0 q 0 iff 0 element sta Second element imagine need sys additional taking longer element samples rare query Cd ap Cad Here Of course takes 1 second time performance 01 worst case efficiency prefered value Eq 1s A hc terminat climbing Another limitation PALO reach global optimum hill local optimum probabilistically climbing Worse guaranteed slopeie 0 As mentioned nonglobal This approach sacrifices elocal optimum means Os neighbors best slightly earlier build PALOlike clocal optima stochastically descending guarantees proven stop reaching gentle read e better avoids annealing attempts la simulated The conditions global optimum weak hillclimbing method situations PALO shouZd For example use known efficient puting cf 2781 Here sufficient distribution inappropriate run standard hillclimbing actual expected utility computed directly obvious variants PALO constrained sample efficient specify situations PALO work effectively There need technique com simply estimate let efficient algorithm use estimate PALO initially probably better simply element variants known See PALOIN Gaussian mentioned algorithm quality measure estimated Similarly distribution samples distribution known 63 Contributions This paper poses problems element expected utility arise optimal required determine element finding globally optimal performance learning 4380 systems distri usually element intractable optimal algorithm PALOI approximate sidesteps shortcomings distribution hillclimbing produce information seek performance bution unknown It presents statistical technique 202 K GrernerArticiul Intelligence 84 1996 17720X Table 2 Summary applications Performance Utility function c elements J Transformations T I I R T f9 I Range Efficiency Accuracy Categoricity satisficing strategies hypothesis orderings computation time reorder arcs LG Iq Oq reorder priority Hornstrengthenings WFY sl4 change 1 clause 61 algorithm specifying behavior locally optimal element After detining demonstrate PALOts element different different criteria optimality These suggest approaches explanationbased ing tractabilitycompleteness learning results generality showing settings based different nearoptimal elements spaces performance See Table 2 reason efficiency accuracy categoricity respectively solving multiple extension problem utility problem nonmonotonic tradeoff problem knowledge representation Acknowledgements This work began University Toronto Robotics Intelligent Systems operating grant supported Institute National Science Engineering Research Council Canada edge receiving helpful comments anonymous referees William Cohen Dale Schuurmans acknowl I gratefully Appendix A Proofs Theorem 1 The PALOt formance elements I probability 1 6 01 I F 6 process jil 7kj incrementally produces series Tk E 7 1 expected utility performance cessors element strictly better prede VI j 6 m Ce C0 2 thenal pelformance element returned PALOt elocal optimum 47 E 7 C70 2 Cf9 E Moreover PALO stay 0 il fora numberof samples ispolynomial terminate probability 1 provided terminating climbing l6 IE IS1 finite new c Q Se IrOj 1 R GreinerArtQicial Intelligence 84 1996 177208 203 Proof To prove parts 1 2 consider dealing Oj Notice types mistakes single stage PALO algorithm PALO samples 1 Lj I PALO1 1 Lj 1 PALO1 climb Oj better Oj based line L3 samples After seeing 0 r Oj 0 appears test reality 0 better seeing 0 r Oj appears test 0 better seeing Lj samples PALO1 climb Oj 0 rOj 0 appears better After seeing Lj samples PALO E better Oj 0 better better Oj based line L5 test reality 0 Oj based line L4 0 r Oj appears E better terminate terminate A B C D Using ei Aj ln 2Lj 17jll si 1 barrier decide seeing respective probabilities samples events climb neighboring 0 rOj Pr 30 E 7Oj jdOBi Ed CH Cj 9 1 bi Pr 30 E TOj fdjsi E iO C0 COj E I cjPr 307Oj idOOLj 2 andCO COj J I dj Pr 30 E TOj iASLj z COj COj E J 1 Of course existential Pr elements I Oj Moreover ai considering C 0 C Oj I 0 E I Oj 1 C 0 C Oj finite disjunction ranging subset Os Pr v iAji bEiO 1 7 0 E 7Oj C Cj E A 0 6 E Ei 1 204 R GreinerArrificiul Intelligence 84 1996 177208 Now observe fddi 3 C0 COj jd 1 A1 A21 6 7 j exp 2i A zz II 6 2L 1 l7 I 12i In 2tLj lljlllsj A 0 ii A1 follows C observation 0 implies line Cr0 A B implies Pr A Pr B J events A B Line Hoeffdings empirical Eq 6 based realization lidOj distributed average set independent IidjTOji identically inequality lidOj O 3 CTOjCOji 3 A2 uses rOj random values C 0 C Oj eiO crql range possible values cJIL il O 0 common mean Similarly 0 c Pr LlHOi YE7 E0 I fAOi CH COj pi 1 In similar manner bound 4 72i7j line A3 uses fact l Oj 0 A j likewise A3 R GreinerArtificial Intelligence 84 1996 177208 205 Hence probability making type mistake jth stage bounded U b Cj dj L I 1 c il sj F 7 disjoint subsets 7Oj SO lirl 71 Q IlOjl The probability PALO mistake kind step desired To deal PALOls efficiency Notice stay Oj performance LJ samples quantity 2Ac QSo le l6 clearly polynomial 7Oj element 171 _4j To PALO1 terminate probability 1 IJ finite notice way PALO1 fail terminate cycles strictly better time thinking later thinking better switching Of course inequalities necessarily maxucjij PALO mistake PALO Si2 62 The probability Oj switching false probability bounded type infinitely mistake infinite number times lim flz 62 0 0 Definition A1 The KWEAK rusk Instance A propositional theory _E CNF positive integer K sample S qi integer f E OK Question Is Hornweakening f Ss queries Ie 2 W q E S 1 W k q 2 f conjunction 2 size K covers K Horn clauses W Theorem A2 The KWJZAK task NPcomplete clearly coverage To KWEAK Proof KWAK confirm task 23 Given boolean let K 2 f 1 set samples S qlq SAT SAT let 2 set clauses single unsatisfiable NP need guess potential weakening NPcomplete NPhard reduce formula 206 R GrevxrArtiJlciul Intelligence 84 I 996 177208 If 2 consistent proposition coverage 0 W qlq size 2 weakening form r v categoricity solve arbitrary Otherwise consistent 1 Hence algorithm 0 instances KWEAK solve arbitrary SAT instances weakening W necessarily 2 inconsistent References II S Arora C Lund R Motwani M Sudan M Szegedy Proof verification hardness approximation Science 1992 1423 problems Proceedings 33rd Annuul IEEE Symposium Foundations Computer 12 1 P Auer R Holte W Maass Theory applications agnoistic PACtearning small decision Conference Muchine Learning Lake Tahoe CA 1995 Chapman Hall 13 1 DA Berry B Fristedt Bandit Problems Sequential Allocation trees Proceedings Twelfrh cfExperimens International London 1985 14 1 M Boddy T Dean Solving time dependent planning problems Tech Repr Brown University Providence RI 1988 5 B Bollobls Random Gruphs 16 J L Booker D Goldberg J Holland Classifier systems genetic algorithms Artif Academic Press New York 1985 Intell 40 1989 235282 17 I A Borgida D Etherington Hierarchical knowledge bases efficient disjunctive reasoning Proceedings KR89 Toronto Ont 1989 3341 18 I E Boros Y Crama t Hammer Polynomialtime inference valid implications Horn formulae Ann Moth ArttJ related G Brewka Preferred subtheories IJCAI89 Detroit MI 1989 10431048 R Caruana D Freitag Greedy attribute selection Intell 1 1990 2132 extended 191 1101 logical framework default reasoning Proceedings Proceedings Eleventh International Conjkrence Machine Learning New Brunswick NJ 1994 2836 H Chemoff A measure asymptotic efficiency rests hypothesis IIll based stuns observations Ann Math Stat 23 1952 493507 WF Clocksin CS Mellish Programming WW Cohen Learning textbook knowledge 1121 1131 irt Prolog Springer New York I98 I case study Proceeding AAAI90 Boston MA I141 I lfil 1161 I171 1181 I191 120 121 122 I23 procedures theoremproving Proceedings 3rd ACM Symposium 1990 SA Cook The complexity Theory Computing New York I97 I IS I 158 M Dalal D Etherington Tractable approximate deduction limited vocabulary Proceedings Nmth Biennial Conjtirencc ofthr Canadian Societyfir Computational Studies ojlntelligence Vancouver BC 1992 T Dean M Boddy An analysis timedependent MN 1988 4954 G DeJong ed Proceedings AAAl Wirkshop ExplanationBased WF Dowling JH Gallier Linear time algorithms formula J Doyle RS Patil Two classification DW Etherington A Borgida RJ Brachman H Kautz Vivid knowledge tractable preliminary IJCAI89 Detroit MI 1989 1146l 152 j Logic Program 3 1984 267284 Proceedings AAAI88 St Paul satisfiability propositional Horn utility representation Intell 48 1991 261297 theses knowledge Proceedings services Artif representation restrictions testing taxonomic reasoning planning language Learning 1988 report 0 Etzioni Tractable decisionanalytic P Fong A quantitative Machine Learning Lake Tahoe CA 1995 MR Garey DS Johnson Computers und lntructability Freeman New York 1979 study hypothesis selection control Proceedings KR89 Toronto Ont 1989 Proceedings Twelffh International Conference A Guide Theory NPCompleteness R GreinerArrijicial Intelligence 84 1996 177208 207 24 MR Genesereth NJ Nilsson Logical Foundations Artificial Intelligence Morgan Kaufmann Los Altos CA 1987 25 A Goldberg An average case complexity analysis satisfiability problem Proceedings 4th Workshop Automated DeducGon Austin TX 1979 16 26 IJ Good Twentyseven principles rationality VP Godambe DA Sprott eds Foundations Staristical Inference Holt Rinehart Winston Toronto Ont 197 1 271 J Gratch S Chien G DeJong Improving learning performance rational resource allocation Proceedings AAAI94 Seattle WA 1994 57658 1 281 J Gratch G DeJong A hybrid approach guaranteed effective control strategies Proceedings Intemationnl Workshop Machine Learning Evanston IL 199 1 5095 13 ZQ J Gratch G Dejong COMPOSER probabilistic solution utility problem speedup learning Proceedings AAAI92 San Jose CA 1992 30 J R Greiner Finding optimal derivation strategy redundant knowledge base Artif Intell 50 1991 95116 3 1 R Greiner PALO algorithms Tech Rept Siemens Corporate Research Princeton NJ 1993 321 R Greiner The challenge revising impure theories Proceedings Tweh International Conference Machine Learning Lake Tahoe CA 1995 331 R Greiner The complexity theory revision Proceedings IJCAI95 Montreal Que 1995 See ftp scrsiemenscompublearningPapersgreinerlcomptrps 341 R Greiner C Elkan Measuring improving effectiveness representations Proceedings IJCAI91 Sydney Australia 1991 518524 35 R Greiner R Isukapalli Learning select useful landmarks M Dorigo ed Special Issue Learning Approaches Autonomous Robots Control IEEE Trans Syst Man CybernParr B 26 3 1996 437449 36 R Greiner I JuriSica A statistical approach solving EBL utility problem Proceedings AAAI92 San Jose CA 1992 1371 R Greiner P Orponen Probably approximately optimal derivation strategies J Allen R Fikes E Sandewall eds Proceedings KR91 Cambridge MA Morgan Kaufmann San Mateo CA 1991 381 R Greiner P Orponen Probably approximately optimal satisficing strategies Arr Inrell 82 1996 2144 39 R Greiner D Schuurmans Learning useful Horn approximations B Nebel C Rich W Swartout eds Proceedings KR92 Cambridge MA Morgan Kaufmann San Mateo CA 1992 1401 B Grosof Generalizing prioritization Proceedings KR91 Cambridge MA 1991 289300 1411 S Hanks D McDermott Default reasoning nonmonotonic logics frame problem Proceedings AAAI86 Philadelphia PA 1986 328333 1421 D Haussler Quantifying inductive bias AI learning algorithms Valiants learning framework Arrif Inrell 36 1988 177221 43 D Haussler Decision theoretic generalizations PAC model neural net learning applications Inf Cornput 100 1992 78150 44 G Hinton Connectionist learning procedures A 45 W Hoding Probability inequalities sums bounded random variables J Am Star Assoc 58 Intell 40 1989 185234 301 1963 1330 46 EJ Horovitz Reasoning beliefs actions computational resource constraints Uncertainty ArSzl Inrelligence 3 NorthHolland Amsterdam 1987 47 T Imielinski Domain abstraction limited reasoning Proceedings IJCAI87 Milan 1987 997 1003 48 J GH John R Kohavi K Pfleger Irrelevant features subset selection problem Proceedings Eleventh Internarional Conference Machine Learning New Brunswick NJ 1994 121129 1491 I JuriSica Query optimization knowledge base management systems machine learning approach Masters Thesis Department Computer Science University Toronto Toronto Ont 1992 1501 LP Kaelbling Learning Embedded Systems MIT Press Cambridge MA 1993 151 I H Kautz B Selman Speeding inference acquiring new concepts Proceedings AAAI92 San Jose CA 1992 208 R GreinerArciul Inrelligence R4 1996 I77208 52 1 RM Keller Defining operationality explanationbased learning Proceedings AAAI87 Seattle WA 1987 482487 157 I S Kirkpatrick CD Gelatt MP Vecchi Optimization simulated annealing Science 220 1983 671680 1541 H Kyburg The reference class Philos Ser 50 1982 155 I JE Laird A Newell PS Rosenbloom SOAR architecture general intelligence Arti Intell 33 1987 l64 I56 1 H Levesque Making believers computers Artif I57 1 K Loui Computing reference classes Intell 30 1986 81108 Proceedings AAAI Workshop Uncertuing St Paul MN 1988 I58 I 0 Maron A Moore Hoding Advances function approximation Los Altos CA 1994 races accelerating model selection Neural Information Processing Systems 6 Morgan Kaufmann search classification S9 1 S Minton Leurning Seurch Control Knouledge An ExphnutionBased Approach Kluwer Academic Publishers Hingham MA 1988 I60 1 S Minton J Carbonell C Knoblock D Kuokka 0 Etzioni Y Gil Explanationbased learning problem solving perspective Arrif Intell 40 1989 63 1 19 61 1 TM Mitchell The need bias learning generalizations Tech Rept CBMTR117 Laboratory Computer Science Research 1980 62 I TM Mitchell S Mahadevan LI Steinberg LEAP learning apprentice VLSI design Proceedings IJCAI85 Los Angeles CA 1985 S73580 163 1 I Morris Curing anomalous extensions 1641 KS Narendra MAL Thathachar Learning Automata An Introduction Proceedings AAAI87 Seattle WA 1987 437442 PrenticeHall Englewood Cliffs NJ 1989 1651 D Ourston RJ Mooney Theory refinement combining analytical empirical methods Artif Inrell 66 1994 2733 10 I66 D Poole R Goebel R Aleliunas Theorist logical reasoning default diagnosis semantics stratified deductive databases Deductive Databuses und Logic Programming N Cercone ii McCalla eds The Knowledge Frontier Essays Representation Springer New York 1987 33 I352 I67 I TC Przymusiriski On declarative J Minker ed Foundions Los Altos CA 1987 193216 JR Quinlan Cd5 Programsfor R Reiter Nonmonotonic S Russell D Subramanian Chambery France 1993 SJ Russell BN Grosof A declarative AAAI87 Seattle WA 1987 505510 B Selman H Kautz Knowledge compilation Horn approximations Anaheim CA I99 1 904909 reasoning Ann Rev Cornput Sci 2 1987 147187 R Parr Provably bounded optimal agents Muchine burning 168 169 I70 concept approach learning bias 72 171 Proceedings IJCAI93 Proceedings Proceedings AAAI91 Knowledge logic programs Morgan Kaufmann Morgan Kaufman San Mateo CA 1993 1711 L Shastri Default reasoning semantic networks formalization recognition inheritance Arti InteN 39 1989 283355 74 HA Simon JB Kadane Optimal problemsolving search allornone solutions Arlif Inrell 6 1975 235247 175 I DE Smith Controlling backward 761 RS Sutton ed Special 1771 PE Utgoff Shift bias inductive concept inference A Issue Reinforcement Learning Much Learn 8 1992 fntell 39 1989 145208 learning PhD Thesis Laboratory Computer Science Research Rutgers University New Brunswick NJ 1984 1781 LC Valiant A theory learnable Commun ACM 27 1984 1134I 142 I79 I F van Arragon Nested default reasoning priority levels Proceedings Ninth Biennial Conference Canadian Society Computational qf Dependences Based Empirical Data Studies Intelligence Ottawa Ont 1990 7783 Springer New York 1982 I 80 1 V Vapnik Estimation