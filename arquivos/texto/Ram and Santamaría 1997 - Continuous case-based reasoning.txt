Artificial Intelligence 90 1997 2577 Artificial Intelligence Continuous casebased reasoning A Ram JC Santamaria College Computing Georgia Institute Technology Atlanta GA 30332 USA Received December 1994 revised September 1996 Abstract Casebased reasoning systems traditionally perform highlevel reasoning problem domains adequately described discrete symbolic representations However realworld problem domains autonomous robotic navigation better representations Such problem domains require continuous characterized continuous performance online sensorimotor interaction environment continuous adap tation learning performance task This article introduces new method contin uous casebased reasoning discusses application dynamic selection modification acquisition robot behaviors autonomous navigation SINS selfimproving navigation The program underlying method systematically eval uated statistical analysis results empirical studies The article concludes general discussion casebased reasoning issues addressed research Keywords Casebased control Motor schemabased navigation reasoning Machine learning Reinforcement learning Robot navigation Reactive 1 Introduction reasoning Casebased systems traditionally perform highlevel rea soning problem domains adequately described discrete symbolic representations For example CHEF uses casebased planning create recipes 211 AQUA uses casebased explanation understand newspaper stories 451 HYPO uses casebased interpretation legal argumentation 51 MEDIATOR uses casebased prob lem solving dispute resolution 26 PRODIGY uses casebased reasoning form derivational analogy highlevel robot planning 60 Corresponding Email ashwinccgatechedu URL httpwwwccgatechedufacultyashwin author Email carlosccgatechedu URL httpwwwccgatecheduaistudentsjcs 00043702971700 PIISOOO4370296000379 1997 Published Elsevier Science BV All rights reserved 26 A Ram JC SantamariaArtcial Intelligence 90 1997 2577 In research investigating realtime problem domains problem performance autonomous learn robotic navigation representations require different underlying solving process place ad 131 In article present reasoning guide action learn systems design casebased class problems addressing In addition reasoning problem domains ing continuous Continuous ditional constraints new method continuous research presented implications general problem domains problem casebased domains 2 Learning called continuous Our method mental assumptions bolic problem guided previous adapting ing lies retrieveadaptapplylearn 212749 New cases called discrete experience New problems reasoning integrated performance casebused reasoning shares funda sym casebased cases test solving mechanism systems reasoning solved retrieving solutions proposed cycle common evaluating casebased Performance learned real simulated world The basic problem However continuous requirements problem domains significantly different reasoning methods problem driving car highway Car driving experiences ways permit ready application traditional casebased For example consider vary experience continuously highway operate continuously process 54 mph Within given episode exit ramp The problem solving learning process infinitely ways The speed car 55 mph speed car moment significantly think logical point vary infinitesimally moment stop time Such problem domains continuous senses First require continuous representations problem domains Second continuous limits digitization task requires continuous For example robotic navigation information The input representations ceptual motor control data ultrasonic sensors input parameter vary infinitesimally sampling parameters mance For example driving car requires continuous solving performance incremental reasoning best execute evaluate actually encounters learning As problems encountered varied difficult necessary incremental manner rely continuous experiences stream perceptual data analog sense value require continuous perfor online action Often problem necessity limited knowledge available require continuous adaptation act adapt actions learn andor unpredictability best shortterm progress A robot example know obstacles problem domains detailed knowledge use finegrained environment actions available environment Third feedback lie 2 We eschew symbolic representations representations symbolic numeric proposed issue continuous time varying nature A Ram JC SantamariaArtcial Intelligence 90 1997 2577 21 enhancements requires significant discrete symbolic Casebased reasoning problem domains reasoning methods addressed When experiences basic casebased Several issues need warrant consideration independent entire car trip ones house example guide improve ones driving performance continuous How guide performance How learned modified experience And performance online In systems scope single case For grocery store single case future situations How matched retrieved continuous realtime process article provide cases represented How learning integrated reasoning different cases What answer questions task The proposed methods fully performance continuous adaptation experience The robot navigation puter uses reactive control reasoning learning implemented tion task domain proposed method eral empirical studies analyzed proach putational model mic choices eters mental methods conditions studies appropriate predict circumstances understand determine analyze analyze performance element relevant selfimproving SINS based research implemented com element casebased continuous navigation robot We begin descrip technical details sev evaluate approach The results efficacy ap terms design com algorith systems design param environ proposed behavior changing sources power We present implements representational demonstrate settings statistical methods behavior Denning MRVIII discuss impact different recommended systemsand casebased learning We conclude contributions systems reasoning case response casea representations adaptation We discuss solution reasoning sign casebased approach common cuss merits finegrained support online adaptationadaptation tion standard casebased modification notion virtual actually hadand experiences subsequent uous dynamic memory reasoning SINS beneficial evaluation methods fruitfully evaluate proposed analogous 53 We argue time history similar experiences Our situation representative casebased standard casebased reasoning reasoning systems systems analyze research implication general We discuss assumptions underlying representations reasoning systems Next dis differences solution fit new situa case case modificationretroactive experience We introduce virtual cases represent past alterations introduced kind contin implements casebased dynamic memory traditional innovations instantaneous general We believe representations introduced empirical AI applications theoretical model underlying 28 A Ram JC SantamaraArtijicial Intelligence 90 1997 2577 2 The robot navigation task Autonomous robotic navigation defined task finding path robot safely source point destination point obstacle ridden terrain executing actions carry movement real simulated world Several methods proposed task ranging highlevel plan ning methods reactive methods Highlevel planning methods use extensive world knowledge available actions consequences formulate detailed plan actions actually executed world 15183351 Consid erable highlevel knowledge needed learn planning experiences 2 1374 1551 Situated reactive control methods contrast perform planning traditional sense instead simple sensory representation environment 392343 Actions rep select action performed resented simple behaviors selected executed rapidly real time These methods cope unknown dynamic environmental configura tions lie scope predetermined behaviors Furthermore methods modify improve behaviors experience predictive capability account future consequences actions higherlevel formalism represent reason knowledge necessary analysis We developed selfimproving navigation uses reactive control fast performance augmented continuous casebased reasoning method allow adapt novel environments learn experiences The autonomously progressively constructs representational structures aid navigation task supplying predictive capability standard reactive systems lack The representations constructed hybrid casebased reinforcement learning method extensive highlevel reasoning The robust perform successfully learn novel environments compares favorably traditional reactive methods terms speed performance A advantage method designers need foresee represent possibilities occur develops understanding world actions Through experience able adapt perform wide range environments user intervention supervisory input This primary characteristic autonomous agents interact realworld environments Before presenting technical details approach let discuss reactive control robot navigation approaches proposed perform autonomous navigation task 21 Background related work Several different architectures reactive autonomous robotic navigation proposed 393 1431 Typically methods rely combination task achieving modules behaviors schemas perform simple substasks avoiding obstacles wandering exploration Each module stimulus response type A Ram JC SantamarfaArtificial Intelligence 90 1997 2577 29 relationship world The response robot result interaction responses different response modules supress schemes subsume final response subsumption response modules The interaction final response depends modules propose weighted average individual 93 weighted summation 3 voting computed according responses 3 1 precompile solve problem One main difficulties reactive control approach autonomous navigation active situations The simplest priorities behaviors manually decide modules approach priorities constant completion task way problem activating modules priorities performs simple entire scenario fixed constant The problem approach 39 In activation solve handle architecture designed sense predesigned avoided altogether specific scenarios sufficient strategy remain responsible activates A complex approach precompile specific conditions module activation relevant modules switching circuitry robot wander looking condition modules avoid obstacle wander wandering behavior activate approach design let robot learn modules static predetermined powerful approach Although approaching architecture For example trash collecting 4750 floor During active Once robot detects deactivate module perform complex navigation time A interesting active situations approach pursued situations situations modules control activation robot commonly casebased faces navigates associate set parameters levels priorities trigger activationdeactivation article We use continuous This learn reasoning tasks updates estimate incrementally perceptual modules positively Maes Brooks module activations correlated positive feedback condition relevant reliable estimation correlations 34 propose algorithm robot navigates The algorithm uses robots experiences correlations feedback The algorithm activates vates modules correlated negative limitation approach currently mation perceived modules area past information density obstacles currently perceived situations learn coordinate modules conditions positive negative task acti feedback negatively facing One activate based infor determine cluttered The right choice depend robot uses tried squeezing robot robot face backs In approach different world situations information sensed situation This problem sensory activate prioritize For example robot robot decide modules try squeeze situation recent history leading current situation provide robot currently rich finds time sequence disambiguate similarly 30 A Ram JC SantamaraArtijicial Intelligence 90 1997 2577 localize characterization position current position behavior selection robots sensors A direct approach based landmarks detects new landmarks world Then sensors For navigation robot navigates The map proposed Mataric construct landmarks goal As robot navigates map Additionally landmark map However 351 Her method qualitative map uses functional robot environment task robot uses learned map detect uses map surrounding plan best route verifies rely handcoded knowledge approaches qualitative map learning achieve activated behavior combination robot decide modules particular priority scheme This knowledge activate landmark qualitative map A robust approach allow robot learn disposition effects behaviors advantage navigates Another difficulty dependent terrain map learning specific 291 behaviors enables objective relative positions landmarks robot trained encodes terrain knowledge acquired knowledge selects behaviors intermediary accomplish landmarks approach terrain 22 Motivation casebased reasoning approach behavior coordination situations navigation robot prioritize A robot performing task autonomous complex environments space tendency require different coordination free space obstacles complex environments goal proceed directly operation priorities motor robot focus worry avoiding obstacles This avoiding obstacles slow robot pay attention reactive control method able coordinate modules behaviors The reason different schemas For example moving allow cluttered important moving responsible plished set gains control parameters determine robot eter modulates robots parameter goal invite collisions motor schemas accom final response param robot relatively direct path output obstacle avoidance motor schema affects In clear environment obstacles goal avoiding obstacles implemented goal delay However behavior Coordination reactive control simple behaviors avoid In schemabased motor schemas weighted 31 For example reduced avoid obstacles permit summation goal tendency schema coordinate motor schemabased As mentioned previously approach priorities precompile designers know types situations dination situation successfully robot encounter appropriate coor use situations Thus robot simple detect scheme use precompiled use encoding navigating task One method currently perform 41 In approach gains design situations coordination time behaviors scheme A Ram JC SantamariaArtijicial Intelligence 90 1997 2577 31 situations past 471 However considered library cases encode navigation experienced encounters encoded cases otherwiseis learned modified robot time Additionally appropriate priority require optimal control parameters A robust approach provide result execution specific coordinations use expert foreseen design scheme strategies approaches fail robot different situations time knowledge hand coded designer finding process automated designers determine time consuming situation robot knowledge learn robot perceives topology situations situations let robot approach scheme closer desired situation Although context motor schemabased reactive control approach explored researchers usually refered current situation selects desired situation intermediate qualitative map learning terrain navigates specific coordination achieve situation 2935 motor schemas In use genetic algorithms 461 applicable priori knowledge reliable specific problems use form situations In situations schemes While useful priori knowledge approaches knowledge require different coordination coordination schemes unavailable experiences This suggests experiencebased method coordination robot new situation situation This suggests casebased casebased use previous experience schemes control parameters exactly unreliable reasoning 2 1271 robot perform similar require approaches control parameter pairs Thus available robot learn situations motor schemas appropriate situations Since priori knowledge problem casebased approach appropiate situations use situations Furthermore learn relevant based learning unlikely able adapt best candidate right piece knowledge memory specifics new fundamental approach adaptation Pandya Hutchinson 421 discuss casebased approach robot motion planning robot navigation strategies solution strategies methods set path planning It tries solve collisionfree research issues similar focusses motion planning ones exploring Although addresses disposition planning problems applying similar problems Some methods computationally solve simple problems The planner use experience apply specific method planner descriptions adaptation The proposed method In case failure repairer suggest repaired version method diagnosis In approach planner use solve path path planning problem retrieving planner successfully solved previous learn problems similar applied proposes solution method applies given problem proper effectiveness nature failure retested The cycle plan deemed successful failure given problem For new problem tested world model evaluate diagnose explain retrieves cases strategies repair continues expensive solved 32 A Ram JC SantamadaArticial Intelligence 90 1997 2577 encountered case library future reference clear fix In case experience stored new case Another path planning uses casebased methods 191 The perform highlevel planning topological map The modelbased method plans space ROUTER searching hierarchical model navigation occupied regions space represented previously planned integrates modelbased casebased methods routes connect points paths heuristically spatial relationships The casebased method plans new paths adapting combining paths The selects specific method divides subproblem path segments navigation robot use navigate original problem combining destination noncasebased accomplished solve particular problem simpler subproblems solving solutions The resulting path symbolic description recursively traditional approaches work focusses casebased realtime level requires online execution highlevel motion path planning level plan actually executed Additionally test evaluate proposed highlevel planning solutions task requires interaction real world These differences In ROUTER reactive control reasoning robotic control carried relies impose typically While related robot navigation line world model robot navigation different constraints demands approaches solve problem central task online learning learning performance One constraint reasoning cases consist time sequences best robots ability learning continuous casebased In approach article situations control parameters The robot periodically current situation recent history situations suggested case successful task occur robot navigates taking place learning method retrieves leading current tries new case future use The architecture SINS integrated navigation This suggests type proposed associations case similar If control parameters past situation reasonable random following methods robot uses control parameters robot control parameters remembers section describes coordination behaviors outcome situation selecting adapting set control parameters suitably modified current situation If case memory picking responsible similar 3 The SINS SINS consists navigation module reactive control methods online adaptation learn casebased reasoning supported reinforcement robotic navigation The selfimproving uses schemabased ing module uses continuous learning methods The navigation module environment location obstacles The adaptation starting way The adaptation learning module responsibilities submodule performs online adaptation reactive control parameters responsible desired goal location avoiding moving robot A Ram JC SantamaraArtijcial intelligence 90 1997 2577 33 Robot Agent Learning Adaptation Module Sensors Navigation Module Actuators SfZll80 InpUtS Motor Outputs Environment Fig 1 SINS functional architecture best performance navigation module The adaptation cases capture model recommendations environment With model actions act accordingly The learning incrementally modifies shows module observes adapts navigation module turn drives robot able predict submodule monitors Note learning based interaction progress experience Fig 1 case representations future consequences adaptation functional architecture 31 Schemabased reactive control reacts representing represent sensory based AURA architecture The reactive control navigation module consists set motor schemas Each schema vector velocity produces given current environmental STATICOBSTACLE directs associated repulsive potential vectors produced schemas combined directs avoidance 3 individual motor behaviors available information robot schema AVOID away detected obstacles schema parameter ObstacleGain determines field generated obstacles perceived The velocity field wandering obstacle direction conditions For example actual movement robot Simple behaviors produce complex emergent behaviors produce potential speed goal following environment magnitude combine 34 A Ram JC SantamariaArtifcial Intelligence 90 1997 2577 particular simple behaviors environment Different emergent behaviors obtained modifying directs schema directs reactive control methods A detailed description schemabased 31 In research motor schemas AVOIDSTATICOBSTACLE MOVETO away GOAL NOISE AVOIDSTATICOBSTACLE detected obstacles MOVETOGOAL particular point terrain The NOISE schema makes random escape local minima conjunction schemas direction control produce wandering behaviors Each motor schema set parameters field generated motor schema In research following potential parameters ObstacleGain associated AVOIDSTATICOBSTACLE field generated obstacles perceived magnitude GoalGain associated MOVETOGOAL determines magnitude goal NoiseGain associated NOISE attractive potential noise NoisePersistence associated determines NOISE determines noise value allowed repulsive potential field generated magnitude duration determines persist 32 Behavior selection modication reasoning grain size Our attempt building casebased reactive navigation guide reactive control A central issue casebased nature guidance behaviors kind advice casebased reactive control module To investigate robotic casebased casebased learning focussed issue represent reasoning module provide solely guide reactive control deal issue issues built ACBARR reactive control module forerunner cases necessary SINS reasoning focussed reactive appropriate represent cooperating complex environments In order achieve robust behavior switching dynamically given environment dynamically called behavior assemblages haviors appropriate existing behaviors behavior adaptations considered One option current behaviors based immediate past experience This local response problem A global solution blages behaviors based current environment able learn adapt environment ways Different robotic control ACBARR sets behaviors collections select behaviors behavior adaptation adapt fine tune types modify new assem finds A robust schema parameters produce different behaviors select completely novel environments 47 There combinations dynamically hibited different environmental parameters ditionally However online current environment evaluating ACBARR qualitatively selection Fig 2 This allows configurations fixed determined modification enhance navigational quantitatively interact ex successfully strategies Tra ahead time designer based performance We tested idea stud extensive parameters simulation appropriate requiring different navigational A Ram JC SantamanhArtijicial Intelligence 90 1997 2577 35 Fig 2 Typical navigational behaviors different tunings reactive control module The figure left shows nonlearning high obstacle avoidance low goal attraction On right learning lowered obstacle avoidance increased goal attraction allowing squeeze obstacles relatively direct path goal center level adaptation behavior ACBARR traditional ACBARR box canyons able navigate reactive control incorporated framework At local adapt current behavior working continues behavior accomplished different performance metrics robust performing hard reactive systems perform ies variety different environments 471 details The experiments novel environments Additionally environments poorly In switching allowing harder conversely little different This technique allows fine tune current behavior patterns robot exact environment finds For example picks speed open area period time encountered cluttered worry obstacles reactive area lowers systems pro translates appropriate modifications ACBARR vided method rules behavior modification These uses casebased rules encountered environmental retrieve set gain parameter values appropriate things proceeding attempts speed treats obstacles seriously For schemabased obstacles If hand environment based current schema gains parameters continuously If little bit order build momentum reasoning method tries determining values incrementally altering conditions alter The method longer suited environment global level If currently acting control assemblage behaviors selects new assemblage based robot current environment like Continuing example suppose ACBARR past successes behavior modification 36 A Ram JC SantamariaArtifcial Intelligence 90 1997 2577 cluttered environment employing conservative assemblage motor behaviors It breaks obstacles enters large open field analogous moving forested area meadow If local changes allowed robot eventually adjust new environment However allowing global change place needs realize radically new environment select new assemblage motor behaviors better suited new surroundings Interestingly casebased reasoning realize type modification Assemblages behaviors represented cases standard scenarios known guide performance novel situations As traditional casebased reasoning 212749 case propose plan solution behavior assemblage problem current environmental configuration However method differs traditional use casebased reasoning important respect A case propose set behavior adaptarions merely behaviors This allows use different strategies different situations For example use cautious strategy crowded environment gradually slowing allowing closer surrounding obstacles In order permit strategies suggest boundaries behavioral parameters precise values parameters Cases suggest behavior assemblages perform dynamic online adaptation parameters behavior assemblages suggested boundaries The knowledge required kinds suggestions stored case contrast traditional casebased reasoning systems cases suggest solutions separate library adaptation rules adapt solution fit current problem Further details 47 Two important requirements ACBARR SINS ability manipulate continuous representations ability perform continuously real time Manip ulation continuous representations required easy extract information sensors real time maintain symbolic representations envi ronment clear priori right vocabulary symbolic features concepts ought Continuous performance required needs modify behaviors online manner navigates Thus ACBARR sen sor values preprocessed produce realvalued variables represent current environmental situation The current environmental information retrieve appropriate case guide behavior adaptation To guarantee continuous performance adaptation information stored cases coded mathematical formulae produce new set parameter values timely manner 33 Case representation While ACBARR demonstrated feasibility online casebased reasoning sys tems requiring continuous realtime response relied fixed library cases hand coded The adapt novel environmentsan important source flexibilitybut improve adaptation behavior experience Since knowledge required behavior adaptation stored A Ram JC SantamariaArtificial Intelligence 90 1997 2577 37 cases turned attention built SINS selfimproving learn modify cases SINS different designed systems similar navigation cases similar problem learning cases experience We ACBARR ideas experience The representation learning underlying support performance approximation A primary motivation SINS avoid relying handcoded highlevel domain knowledge There disadvantages relying knowledge First based priori model interaction robot environment Such aspects model successful especially designer Second model quality model depends highly environment robot unclear skills designer Third knowledge real time extract input standard motivations provide theoretical standpoint place scientific explanation reality cover relevant novel circumstances anticipated based designers understanding necessary highlevel knowledge developing highlevel knowledge comes representation learned reactive systems Fourth userdesigned lowlevel sensory representations underconstrained task As Thus initially navigation module gradually modifies provide environment reliable hand SINS model generic contain little useful interaction environment information learning useful particular environment interacts content representations information adapting navigation The learning navigation modules function integrated manner The learning trying module environment tune The navigation module provides model interaction The behavior point established environment need reestablished generic point The navigation module learning module complex dynamic SINS adapted environment better model interaction function better learning module build better navigation module feedback perform result equilibrium trying refine model nature This equilibrium shift changes drastically model able deal wide range environments exhibit different behaviors performance learning tune navigation module config learn discriminate environmental SINS improves In way use appropriate behavior uration encountered The learning module different environments performed motor schemas This requires representational environment However sive highlevel perceptual external environment ensure easily available reactive knowledge represented information motor reasoning scheme adaptations model exten model based interaction bogged associate appropriate SINS uses model consisting associations schema parameters values ObstacleDensity AVOIDSTATICOBSTACLE schema Each set associations inputs associated represented level sensory ObstacleGain 38 A Ram JC SantamariaArtifcial Intelligence 90 1997 2577 Sensory Inputs xi Association i__ 1 1 1 I 1 p21iq Control Parameters p3 1k 1 I 1 I I I I I I 1 I I I r p4 lk ir 4 0 1 2 3 time Fig 3 Sample representations showing time history analog values representing perceived inputs schema parameters Associations sensory inputs control outputs arranged vertically sequence associations time arranged horizontally Each case represented manner current ongoing navigational experience inputs provide type information obtained adapt systems reactive module case Sensory cable Each analog value corresponds rameter able A case models association grouping tion respective vectors specific information configuration sensors Schema parameter environments information environment specifies appli vector analog values Each input schema pa trend recent history vari inputs schema parameters sensory case represented quantitative variable time A vector represents sensory Fig 3 shows example representa A Ram JC SantamariaArtificiaI Intelligence 90 1997 2577 39 This representation essential properties First representation sensory wide range possible associations permits continuous Second captures representation capturing parameters Finally time This allows having decision based instantaneous ability thought kind time history clustering refinement trends patterns input output values inputs This time windows values perceptual detect patterns larger discussed progressive later capable inputs schema associations In research input vectors characterize configurations ObstacleDensity areas impede navigation AbsoluteMotion measures change environmental provides motion activity actually updated input parameters information represents isometric insensitive representation world input parameters sensors An important different environment goal These specifies progress input vectors constantly characteristic discriminate measure occupied activity RelativeMotion MotionTowardsGoal wards ceived form propioceptive tion Additionally mation directly perceived 3 For example ObstacleDensity environment surrounding vidual obstacles respect movement representation environmental quire different control parameter values Thus systems given world goal location approaching situations robot allows situations translations encode discriminate learned navigational area slow information cluttered robot encode robot Similarly MotionTowardsGoal measures goal encode apply similar control parameter values different situations summarizes level infor cluttered positions indi location This coarse similar wide range specific learning strategies general deployed representa rotations world configuration 2 That higher We output vectors represent schema parameter values navigation module schema parameters ObstacleGain NoisePersistence discussed recommendations case best matches earlier The values set current interval The new values remain constant control adapt GoalGain NoiseGain periodically environment setting period according The choice input output vectors based complexity navigation task The input vectors chosen configurations relevance environment required culation represent processing obstacle position output vectors chosen uses tune navigation module produce generic manner taking vectors obstacle density obtained easily robots ultrasonic represent directly actions cal sensors The learning module account generic schema parameter values 3 Section 5 analyzes impact design decisions SINS including library systematic choice input empirical representation studies choice adaptation method size case 40 A Ram JC SantamariaArtcial Intelligence 90 1997 2577 34 Case learning control reasoning online The casebased case representations construct jective learning method interaction environment appropriate behavioral continuously schema parameters detect discriminate appropriate online manner This means perceiving schema parameters dating situations schema parameter values different environments environment cases observed reflect detecting learning module creates maintains adaptation reactive module The main ob applies model continuous mapping parameters This model allows sensory schema adaptation module behavior navigation module selecting adapting To learn mapping configurations different environment context identify sensorimotor inputs reactive module navigating environment configuration dynamic learning module modifying reactive module accordingly simultaneously results systems actions ideas reasoning The method based combination casebased deal learn learning deals issue 571 However reinforcement content systems knowledge based feedback systems learning deals issue past experiences novel situations updating adaptation planning classical planning 39 behavior fall slow nonreactive avoid Earlier attempts requires detailed model domain This systems trying systems reactive control systems Unlike relied deep reasoning lo explanationbased casebased planning typically environment 211 learning exactly reactive reactive control systems slow fast reflexive approaches method reactive control traditional combine techniques required learning effects different actions prescribes improving regularity particular environmental values schema far knows based previous tasks The learning module performs following Each case represents observed figuration parameters experience cyclic manner appropriate environment 1 perceive represent 2 retrieve case sensory current environment current environment input vector represents environment similar 3 adapt schema parameter values 4 values recommended installing learn new associations reflect new information enhance situation andor adapt existing associations use reactive control module schema parameter vectors case case use case new represented gained reliability predictions reasoning terms case retrieval adaptation learning carried executing behaviors casebased In traditional uation assessment evaluation fying actual effects sensory control parameters carrying suggested movements information 27 steps correspond respectively sit suggested case modi observing critiquing A Ram JC SantamdaArtifcial lnrelligence 90 1997 2577 41 distance representing sensory The perceive Euclidean case handed convolution vectors cases The reward signal corresponds values reactive behaviors currently reverse sweep time axis similar step builds set vectors corresponding step The case similarity metric matches best The best matching schema parameter values case modifies input systems memory based mean squared differ vector values case matched retrieve ence trending window vector values environment The best match window calculated process relative position step selects adapt corresponding metric scalar reward traditional discussed goodness match chosen parameters reward signal current environment use parameters kind basic animal common particular respectively AI learning cases case similarity notion outcome reinforce good performance actual adaptations performed depend usefulness suggested case This thought based executing action beneficial prejudicial idea increasing decreasing state 591 unlike learning satisfactory better match learning law effect SINS mediated intermediate long indicated reward signal casebased retrieved case result terms later Thus case environment higher probability performance action probability representations experience reinforcement use Intuitively traditional reasoning indicates response systems situation stimulus learning shows like learn measure Finally formula information information configuration step uses statistical prior applications reward reinforcement current environment current application case case new case created The vectors relative signal The relative case determine modify cases adapted reinforcement encoded scalar similarity similarity measure quantifies similar environment situation involves modifying away good case modified regularity bad fit case makes sense create new case represent probably new class situations case beginning case direction current situation Alternatively environment current situation worthwhile previous utilizations better regularities likely capture encoded case relative case Intuitively current situation converging Finally case matches similar previous match configuration situations In summary navigates encounters new situations schema param eters tuned adjust behavior accordingly The learns faced past control parameters remembering situations situations The uses measures produced good outcomes relative similarity success metric ensures control control parameters produce similar parameter values This associations situations cases capture consistent algorithm First learning likelihood provide feedback increases 42 A Ram JC SantamariaArtifciaI Intelligence 90 1997 2577 future situations Second external reward signal ensures associated situation produce positive outcomes appropri In way measured reward results ate control parameters learn control parameters signal A detailed description step presented Note represent associations performed overall reinforcement learning effect ification measure verge stable associations eters Stable fied navigate teraction set causal patterns associations formed The method allows use modify ate experience future environment regularities configurations world provide formula based relative cause process cases case mod similarity schema param identi predictive power necessary finite inputs actions causal patterns appropri method learn sensory situations The assumption environment characterized actions updating schema parameters 4 Technical details The continuous casebased reasoning algorithm implemented SINS fol lows Algorithm 1 SINS algorithm currentenvironment end control perceive interval outcome good C reinforce_schemas previouscase prediction good end sequence currentenvironment extend_caseprevious_case 1 explore_schemasprevious_case bestcase bestcase good match retrieve_best_case currentenvironment bestcase create_case currentenvironment aduptschemas bestcase previouscase bestcase execute goal reached maximum number steps exceeded A Ram JC SantamariaArtificiaI Intelligence 90 1997 2577 43 constructs perceive The perceive maintains representations function situation reading time sequence values parameters given representation robots sensors updating ronmental vectors accordingly Recall rent instant interval Thus sensory k described module performs reactive control module learns useful sequences associations parameters current envi input output cur time set J 4 input vectors Einrui j K 4 output vectors Eoutput output vector adaptation use schema interval T learning adapts schema parameters currently new environment situations earlier Then control performs better environment main functions descriptions function results input Schema parameters adapted retrievebestcase case similar adaptschemas func current environment function environments selected matching tions In retrievebestcase situation E output perceive step Gtpt cases C systems memory Cnh position best match pbesi handed modifies dations Ci schema parameter values currently corresponding pbest 1 output vectors case input output vectors Eirt input output vectors Cut Fig 4 The best matching adaptschemas case function use based recommen Finally reinforces information learning case suggestions different ways improving adaptation module decides utilize reliable creating new case case library The current experience best case order improve content case learns best case retrieved order good extending length case order build longer sequences associations The contents case improved reinforce_schemas function favorable outcome control uses random exploration set values prove useful Random exploration parameter values set parameter values values likely implemented function4 control movement instead led suggestions function interval exploreschemas try schema parameter values suggested main objective positive outcome poor selecting random exploration behavior robot lack suitable performance metric produced positive outcomes nonuniform obtained positive produced negative outcomes This probability evaluated monitoring In application selection parameter values The outcome interval increase order cycle However likehood obtaining nonuniformly applications undesirable selected probability distribution reduce collisions rewards In traditional casebased reasoning systems case adaptation rulebased cf 321 SINS utilizes handcoded set adaptation contrast uses kind reinforcement carried 241 provide rules learning method 4 Section 57 presents alternatives implemented SINS evaluated systematic empirical studies 44 A Ram JC SantamartaArtijicial Intelligence 90 1997 2577 recent cast Environment length IE I current time Case length I I bst Current Environment Configuration Representation Case Environment Configuration Representation output Vectors I t Fig 4 Schematic representation match process Each graph case matched corresponding graph current environment determine best match remaining case guide navigation shown dashed lines necessary case adaptation functionality The issues underlying integration multiple learning strategies single multistrategy learning discussed 481 One difference methods traditional reinforcement learning SINS trying maximize consistency useful behaviors deter mined reward signal traditional reinforcement learning tries maximize expected utility going receive future determined reward signal cf 58621 In schemabased reactive control navigation inher ently good idea modify schema parameters online fashion modifications equally good cause robot collide obstacles SINS uses reward signal decide reinforce behavior explore alternative behaviors reinforcement chosen A Ram JC SantammfaArtcial Intelligence 90 1997 2577 45 reinforce behaviors nal outcome learning method 5 consistent consistency internal experiences Thus reward signal addition reinforcement exter states corresponds learns associate actions learning reinforcement assumes predefined states order maximize set known task likely appropriate sequence situations Thus SINS learning model sensorimotor actions known learning situations turn associate sequences environmental adaptations adaptations navigation module states traditional Furthermore states actions reward In SINS performed discover result adaptations interaction environment learning improve reactive control schemas relevant given different navigational performance represented set cases time online adaptation criterion judge situation current prior applications If best matching based statistical situation This determination cases SINS extend perform appropriateness modifying decide kind learning similarity cases learn new given situation SINS best matching information quality case probably learn new case represent In addition cases In order uses relative case quality match match current current environment inappropriate createnew_cuse probably add case function library To determine current match mean match plus standard deviation matches past utilizations case This ensures new sequences associations available current environment created case library fit case compared case create new case based current experience situation previous situations create new case SINS compares If occurs SINS uses new class situations sequences associations situation similar captured better increase carried extend_case_size situation associations best case makes accurate prediction sequence case accurately predicts environment kind learning length case The extends environment allows confident suggested values matched actual environmental better predicts likely beginning current function sequence This length sequence associations changes predicted match case case case incorporate good case parameters Intuitively previous regularities case extended predicted involves mean match current situation better confidence result situations current situation situation Alternatively To estimate schema parameters worthwhile match capture extending 5 SINS run outcome SINS learns cases improve improve performance perceptionaction model external reward signal With reward navigational performance signal based external learns cases regularities learned This issue discussed correct represent mote Section 59 46 A Ram JC SantamariaArtijicial Intelligence 90 1997 2577 modified converging away regularities Since reinforcement formulae based relative similarity criterion given en initial design useful change schema parameters line navigation schema parameters cause cases converge stable associations representing schema parameters reward utility identified useful predictive perceptionaction models different schema parameters regularities regularities approach capture consistent faces environments configurations interaction algorithms modify 46 However effect learning process environment systemenvironment learn These basis modifying situations Genetic vironment navigation significantly training phase genetic algorithm selforganizing neural network ditional systems fundamental task improved Their incorporate new input data conditional SINS improves navigation module input patterns regularities methods similar ment evolving world model Unlike world world responses Although location destination adaptive control difference Sutton improves location strategy learning stimuli initial learn associate conditional Verschure Krose Pfeifer stimulus selfimproving different environments cf 201 Another approach 61 uncon navigation navigation learning working navigation performance navigation performance navigation performance learning adapt Our rely new sensory perceived environments Our learning detected reinforce 561 uses trialanderror develop world mode1 plan optima1 routes SINS need trained particular times results learning specific We present detailed description mathematical formulae perception matching adaptation learning tasks 41 Perception situation generate accurate description The objective perceive function current environment It performs current input output vector position time 6 calculating j 1 J output vector Eoutput 0 k values 1 time The current values input vectors based robots sensors current values output vectors respective values schema parameters interval The vectors updated end control input vector Eirrj 0 K 0 current position previous control task shifting previous values interval time T suggested 6 This implemented circular buffer require copying values cell A Ram JC SantamariaArticial Intelligence 90 1997 2577 41 To update input vectors monitors corresponding input vector Eips The sensors monitored Sensorj time step yield environment interval past control new value corresponding values robots sensors averaged input vectors readings sensor input vectors Thus following representation updated formula 7 puti 1 0 CT_SenSOrjf T 0 sensory Sensorjn sensed obstacles position t ranges robot step control RelativeMotion normal ObstacleDensity distance corresponds traveled relative position input interval input vector Einput AbsoluteMotion relativ MotionTowardsGoal 42 Retrieval matching current environment situation The case similarity metric The function retrievebestcase responsible selecting case case library best matches based mean squared difference vector values case trending window vector values environment The best match window process calculated reverse sweep time axis p similar matched best matching case Pb relative position nest match Fig 4 After mean variance cases statistical match history retrieving updated criterion learning matches best Each case C case exhaustive search returns later calculate current environment relative similarity relative position convolution best case library The case similarity metric SM case C position p relative environ sequence associations indicates similarity case sequence associations current environment position p The lower sequences associations value case similarity metric formula The case similarity metric sum squared difference corresponding environment For SM valid p sit cal vectors lie 0 starting ment E value encoded uation similar culates weighted case 1 SMCECPI wj jl c iO Pl minpx Eiptj Cinput J p mipSk Eoutputki Gutputkp kl io Pl Note counts time 0 current time z 0 recent past 48 A Ram JC SantammfaArtificial Intelligence 90 1997 2577 For article wj wk 10 input output vectors contribute equally similarity metric The best case obtained matching case C case library positions p selecting pair esrsr yields lowest SM Formally expressed Each case C maintains statistical record similarity metrics produced past updated time case retrieved best case The mean CSM_ variance C SM case similarity metric number times case Cd updated standard formulae descriptive statistics new CSM d4 SM Cused 1 new CSM C C CSM new CSM CSM SM new CSM C 9 new cuxd id 1 43 Adaptation The best matching case C adapt schema parameter values currently use reactive control module The values output vectors association C determine new set schema parameter OW position fist values Paramrk control interval Since learning tends reinforce associations new set schema parameters expected cause robot safely environment configuration results movement expected predicted association Since output vectors directly represent schema parameters adaptation straightforward operation consistently observed experiences ParaiWterk CE4 fiest 1 Vk 1 K 44 Learning In addition perceiving environment retrieving best matching case adapting schema parameters reactive control module SINS learn updating case library based current experience Three types learning possible modification associations contained case creation new case based current experience extension size case yield associations larger time windows Modification case contents turn A Ram JC SantamdaArtijicial Intelligence 90 1997 2577 49 successful unsuccessful experience types reinforcement associations contained experience exploration alternative associations case based based SINS decides kind learning If current match perform relative similarity criterion quality best match The match value best case based compared match values case previous mean match better match create invoked values current situation past In case createcase function sequence associations best match case worse standard deviation determines case similarity metric situations value considered situations new case containing sequence associations different formed copying representation current environmental cg4 0 Jqgt 0 9 Vjll If case provides good recommendations If hand situation best case matches representative current situation class situations converge current beginning recommendations reinforced In SINS collisions obstacles lack movement navigation lead undesirable improve schema parameter values robot task A set schema parameters result functions accuracy prediction systems cases turn discover environmental outcome The objective learning beneficial situations likely case action modified definition undesirable considered beneficial recommendations If best case recommends expZore_schemas function set schema parameters robot different output vectors C best match position best modified useful space possible following schema parameters formulae set schema parameters modify similar circumstances beneficial case suggests future Specifically following random manner current values controlled manner These changes defined explore situation The small random changes allow best 1 associated environment p min 1 u collisions max_velocity velocity max_velocity csgt Pbest 1 1 p qtk pbest 1 p random min CUt max C4 bklK p reject value dations p 0 specifies taken determines extent current recommen account determining value output vector left unchanged modified values A value 50 A Ram JC SantamarfaArtificial Intelligence 90 1997 2577 value p 1 specifies new random value p depends Y 6 represent moving changed depending tion functions implemented bestreward value output vector replaced completely value allowable respectively For article LX 05 3 10 values selec evaluated Boltzmann distribution Section 57 details desired application Two different random importance avoiding collisions range In given learning cycle function If hand schema parameters reinforcexhemas like current environmental similar situations function suggested best matching case pro invoked This function updates produce future This reinforcement situation results duce desirable case making recommendations following formulae Ci puPbest 9 Ci Vj lJ Vi 0 phst A determines learning extendcase function extends rate For article h 09 sequence associations Finally case The decision rion If cases predictions CFAt fist extend case based statistical 1 similar resulting environment contained relative similarity crite sit uation standard deviation associations parameters mean predictive similarity case provide set schema sequence case extended duplicating association case CkSt liPbest2CtlPbest1 VjlJ CbrSl output best 2 ctk fiest I bk 1 _ k The net result learning procedures cause cases systems case converge regularities systems learns useful sequences schema parameters interactions environment different environment situ guide navigation turn updated based navigational improve reliability predictions similar situations library The ations outcomes future 5 Evaluation SINS fully implemented C Arkins 3 AURA architecture schemabased In real mode reactive control The works controls Denning MRVIII modes robot real simulation radio link A Ram JC SantamariaArtificiaI Intelligence 90 1997 2577 51 robot consists Denning perceptual laboratory grade Polaroid Ultrasonic Rangefinders plane parallel Rangefinders floor In simulation mode dynamics actual robot sonar ring twentyfour equally spaced 360 degrees values simulates performance qualitative environmental types environments simulation mode running design parameters The methods presented evaluated extensive experiments variety different criteria configu rations The results presented based largely experiments performed allows run exper systematically iments navigation varied We measured effects performance design decisions performance The results efficacy methods wide range qualitative metrics flexibility ability measure performance optimality experiments evaluated validity approach configurations number navigational paths problems systems performance quantitative metrics problems In addition solved successfully simulation verify configurations improvement evaluated SINS systematically deal difficult environmental quantitative real mode insight learning 1 12251 combinations priori performance theoryin implementation evaluate known like casebased underlies theoretical models multistrategy introduced multistrategy formal complex One result Evaluation methods verify important words ideas proven successful theory past applications range problems design The proposed handle based case theoretical guarantee success behavior relate empirical evaluations program theory provide theory based reasoning application However methods approach theoretical basis predicting understanding This makes underlying SINS operates sources behavior significance observed behavior specific situation Straightforward performance good specific works design decisions given analyze 11251 analyze performance information based extreme operating improves time improves affect behavior studies provide performance In studies modules removed deactivated changes Although variability cause performance measure defined variability domain behavior SINS evaluate performance behavior Ablation systems modules curves provide useful behavior different circumstances merit different modules predict variability impact different studies performance performance turn makes test problems This complex information impractical difficult especially conditions assess reasoning systems curves 52 A Ram JC SantamariaArtijicial Intelligence 90 1997 2577 modules set active inactive Moreover design decisions deal allocating resource allocation disabling nature ablation possibility allocate module deciding optimal resources studies deal allornothing different modules Due resources certain experiments proposed 521 We systematic characteristics designed statistical evaluation methodology In methodology statistical terms changes mathematical model behavior In analysis filter undesirable change domain systematic SINS performance problem eval tools design sources tools terms design pa assess merit uate performance analyze decisions evaluated variability The results experiments construct rameters domain characteristics design decisions performance Such evaluation theory design computational model select best configuration given domain case characteristics domain change An important faces problem domains different characteristics terms predict behave use previous cases analyzed statistical behavior enables understand continuous analyze casebased characteristic This model casebased algorithm reasoning systems improves variability solve new similar problems Thus important solving new similar problems decreases number problems increases Any significant deserves 17381 Systematic verify significance behavior verify performance performance past behaviors sources utility problem empirical behaviors identify analysis based statistical sources variability tools reveal possible study indication solved 51 Systematic evaluation SINS The performance adaptation SINS varies different worlds configurations amounts experience Moreover nature task architecture world case library The SINS perform differently reason tune navigation module randomly appropriate case exists allows explore discover new regularities This means treated random variable assess performance metric evaluate techniques learning module mean value statistical estimation given The subsections SINS The set experiments parameters number cases maximum cases maximum case size belong world clutter belongs studies perfomed evaluation study 1 focuses effect design factor performance SINS maximum case size world clutter The maximum number design decision group factors The group factors characteristic domain characteristic systematic domain problem A Ram JC SantamriaArtificial Intelligence 90 1997 2577 53 We consider experience improves The second set experiments design decisions input SINS The tation adaptation method represent highlevel systems learning ing environment module adapts situation The experimental brevity systematic study summary results situation control parameters level influences performance SINS verify experience performance study 2 focuses choice input represen SINS Both factors reasoning casebased level increases influence performance important representation including adaptation module SINS uses represent categorize information refers surround The adaptation method refers method suggested best matching case current sake studies described similar procedure evaluation methodology presented second study study 3 verifies The experiment provided robot indoor room static obstacles trials We plot learning method actual performing performance improves different metrics number trials increases number trials verify navigation performance improvement performance robot We measure performance curves 52 Study I experimental design data collection conditions The objective sets simulation studies applicable relationship factors performance describes characteristics model selecting systems performance operating conditions In way possible optimized To collect data evaluation optimize appropriate configuration parameters analyze empirical model design parameters domain performance robustness differ conditions simulations environment analysis performed provided batch mode facility simulation run range environments A run consisted placing letting reached time limit The condition guarantees The data estimators obtained run This ensure experiences worlds size runs facility allowed gather statistics systems performance robot start location location reached maximum worlds unsolvable terminated effect learning significant consistently measuring single experience destination run termination median We evaluated performance SINS solve world The reason mean sensitive control trapped local minima points resulting change SINS number cases case size level experience world clutterness reporting behavior An experiment solve world independent median value time takes robust estimator reactive significant time consisted measuring runs runs response variable outliers Outliers common conditions median schemabased takes 54 A Ram JC SantamariaArtijiciaI Intelligence 90 1997 2577 15 available Two experiments designed objectives study In space occupied obstacles data satisfy experiment ran different versions SINS 15 cluttered world randomly generated world Each different configuration relates required parameters time In second experiment ran best configuration model created world In way verify domain characteristic experience dealing specific 15 cluttered world determined randomly generated 20 cluttered performance holds In way collected experiment performance build model configuration parameters changes During experiments collected data independent holding environmental effects configuration effects parameters design decisions world environment domain characteristics environments conditions constant experience noise The experiment parameters affect performance The second experiment runs In way balance level block allows determine systems different allows study different different 521 discussed affect systems performance Further details methodology 53 Model construction determined As explained earlier solve world Thus performance model level experience We following SINS evaluated estimating needs time T response variable parameters variables maximum time iment median configuration independent level experience terms C2 S E2 quadratic considering plain variability response variable better individual reveal terms significant final model Eq 1 shows complete hypothetical model factors allow possibility median exper mode1 relates T case size S regressors quadratic terms ex terms Statistical analysis considered interactions CE SE CS The reason E We considered number cases C maximum interaction regressors additional TPo PcC PsS PEE CS BmCE SE t 12 PccCPSSS PEEE E 1 V standardized value variable V V V VI x Use standardized multicollinearity values instead original values helps reduce roundoff errors problems independent variables A Ram JC SantamariaArtijicial Intelligence 90 1997 2577 55 Table 1 Best subsets regression results Number variables I 2 3 4 5 6 7 8 9 R 539 661 737 759 775 790 793 796 798 RZdj B C S 538 665 136 757 773 788 790 792 794 II031 9394 8346 8002 7732 7482 7434 7402 7372 x X x X X x X X X x X X E X X X X X X x X X CS CE SE C S E X X X X x x X X X X X x x X x x X X X X x X x X relationship second order polynomial mathematical smooth variables proposed model response variable Assuming expression rela independent good approximation Also early tionship experiences showed behavior related maximum num ber allowable cases maximum case size level experience The quadratic terms possibility maximum allow possibility utility problems direct relationship response variable terms 9 number cases maximum terms included interaction case size allowed significant regression An allsubsets terms influence analysis performed In analysis possible subsets regressors considered determine terms response model subset Table 1 shows results analysis We measure adjusted coefficient multiple model Rzdj explain changes This coefficient measures 0 explained model variable constructed optimality determination response variable changes variation means gressors 100 means variation model response variation RS response explicative ability model explained variation regressors Thus regressors larger Its range Table 1 shows best model obtained subset constant size number coefficient variables R2 shows shows adjusted coefficient multiple determination deviation model The X variables included size multiple determination model Rzdj lo B estimated standard best model y Among interaction terms CS physical meaning The interaction This example particularly influence conditions term CS direct difficult resource measure total memory available evaluation limitations t The Rf R adjusted account different design decisions problem having different number parameters compared number parameters model This allows models 56 A Ram JC SantamariaArtifcial Intelligence 90 1997 2577 Table 2 Model coefficients Coefficients PO PE PC Ps PEE PCC Pss E PSE PCS Table 3 ANOVA table Source Regression Residual Total Value 7223 1192 519 197 233 299 095 432 091 074 Std error Pvalue 95 Cl 078 034 034 034 038 042 042 034 034 034 0000 0000 0000 0000 0000 0000 0024 0000 0008 0028 70707377 12581126 645 513 131263 159307 216382 178012 499 366 157024 008141 df 9 470 479 SS 1006757 255437 1262194 MS 111862 543 F Pvalue 205824 71E157 The best model obtained allsubsets analysis corresponds independent results variables individual parameter having F 205824 Pvalue 0000 model regressors Table 2 shows 95 confidence Table 3 shows statistical analysis tool variance determine identifies significance respectively The fifth column statistical column degrees freedom source determine A high significance explained variation independent model calculus Considering standard model respect values C S given techniques relevant parameters value means optimal interval estimation real value source variation second ANOVA sources variability table The ANOVA table model The fourth columns df sum squares SS mean squared shows value F statistic regression The sixth column shows variation response variable MS Pvalue variables regressors setting configuration parameters partial derivatives zero Eqs 2 3 optimal level experience E t The F statistic determine significance regression The Pvalue probability determined F lower value better result significance regression 1 Pvalue 100 Pvalue 0 A Ram JC SantantmWArtifcial Intelligence 90 1997 2577 51 Fig 5 Residual plots 2E SkhE g S WCCPSS 080 07X c 2hSPS PS h 4PccPss 2hdE SkEE P 4PccPss 005 04lE 2 3 According equations optimal parameter values change level experience This interaction terms exists variables These equations determine optimum configuration given situation Section 55 54 Model validation There assumptions verified accepting proposed model valid model residuals zero mean constant variance residuals normal distribution The squared error technique relies assumptions model coefficients calculated technique verify assumptions hold Otherwise conclusions derived model wrong understanding factors influence performance misleading In particular violation assumption residuals having zero mean constant variance introduce inaccuracy estimation model coefficients violations assumption residuals normally distributed produce underestimation confidence intervals bigger confidence inter vals A scatter plot residuals fitted response diagnose changes variance normal probability plot residuals verify normality distribution residuals The results validation techniques shown Fig 5 The left chart Fig 5 shows constant band residuals horizontal axis Thus chart indicates variability residuals constant fitted values response variable median time 58 A Ram JC SantamariaArtcial Intelligence 90 1997 2577 Table 4 Model coefficients Coefficients WJ LYE aEE Value 8020 286 253 Std error Pvalue 071 048 055 0000 0000 0000 95 CI 78578147 384187 141365 axis The right chart Fig 5 shows normal probability constant variability residuals horizontal When residuals value drawn plot straight conclude line normal distribution residuals normal crosses band tends narrow widen plot expected case If residuals normal actually origin Since In chart values residuals plotted Since assumptions uals having normal distribution residuals zero mean constant variance resid hold model considered valid 55 Robustness analysis A second experiment designed evaluate generality SINS approach SINS best configu difference In experiment evaluated particular configuration ration determined previous analysis performing different environmental conditions The data experiment collected experiment 20 cluttered world selected mance experience conditions size 11 S 026 manner robot solved fixed randomly generated perfor level E equal 20 E 052 Subject cases C 119 configured 43 maximum run The configuration experiment model constructed optimize parameters model needs determined As experiment time T response variable However variable level experience way model related experience learns changing environmental compared respective coefficients derived nificant difference 15 20 affects learning performance Eq 4 shows complete hypothetical model second experiment median case model relates response In model shows level conditions The coefficient derived model previous model If sig world clutterness response variable conclude factors constant detected conclude significant changing T a0 aEE aEEE1 E 4 simplification This model E included parameter As inferred model shows bigger regressor Table 4 shows statistical model 95 confidence level results individual interval estimation value model Eq 1 experience intercept value obtained means A Ram JC SantamaraArtcial intelligence 90 1997 2577 59 Cases needs time solve 20 cluttered world Also increased world clutter big influence 286 This means reduce learning 95 confident mean rate LYEE influenced change world clutter fast 15 cluttered world The acceleration 1730 performance experienced Q reduced level improve rate learning interval PEE time 56 Learning projiles increases results demonstrate validity SINS approach look learning profile provide intuitive internal behaviors external performance While interesting feel changes gains experience The learning profile determined assessing number size cases case library experience level learning curves based systems looking traditional number length cases performance Fig 6 shows graph displays level experience It seen section early stages experience cases small time dimension As experience sequences consistent level increases cases containing extended progressively sequences 2 3 samples focus constructing SINS configured previous proven sequences Fig 6 provides intuitive understanding algorithm observable based reasoning The externally beled Median experience handcoded point graph nature case learning behavior taken actual time highlevel knowledge trial median internals continuous discrimination case process la starting prior randomly generated world Fitted T runs The graphs shown Fig 7 The graphs labeled 60 A Ram JC SantamadaArtificial Intelligence 90 1997 2577 Fig 7 Performance profiles showing median time actual runs predicted time Fitted T empirical models On left general model entire range configuration parameters right specific model fitted configuration parameters runs shows predicted performance empirical model derived previous section error bars model The graph left describes performance model entire range configurations design param eters model specific configuration methodology observed performance configuration fall general model The model right describes performance model specific configuration runs obtained redoing statis tical analysis data obtained configuration As shown Fig 7 results demonstrate improve performance ex perience improvement predicted empirical models derived performance approaches statistical analysis Furthermore optimal level E 20 expected design decisions discussed Section 55 57 Study 2 choice input representation adaptation method Using methodology performed second systematic evaluation study empirical model describes relationship choice input representation adaptation method performance conditions model applicable In study evaluated choices input representations choices adaptation methods The input representation refers information learning adaptation module SINS uses represent categorize surrounding environment situation The adaptation method refers methods module adapts control parameters suggested best matching case current situation The reason studying choices input representation analyze influence level information provided input performance One option use sensory inputs lowlevel information In navigation domain involve ultrasonic sensors measure distance closest obstacle direction goal Another option use sensory inputs encode highlevel information example array ultrasonic sensors A Ram JC SantamadaArtcial Intelligence 90 1997 2577 61 input cases surrounding measure density obstacles specific allow SINS discover compute type sensory parameters similar identical generic allow SINS discover good control parameters However cases cases robot The best control robot use specific situations However expect learned specific work perform nearoptimally type sensory turn coarse learned In contrast situations input information earlier The lowlevel impede navigation ObstacleDistanceBehind We studied types lowlevel highlevel inputs ObstacleDistanceAhead ObstacleDistanceLeft choices input representations introduced infor type consists follow Obstacle Each variables provides measure right mation ing sensory DistanceRight nearest obstacle left direction perceived goal respectively The highlevel sensory type consists following occupied areas robot impede navigation sures activity RelativeMotion appropriate actually constantly case 24 ultrasonic encoders information provides measure AbsoluteMotion mea change motion activity inputs computed robots physical sensors robot 15 degrees shaft goal Both types sensory received interval MotionTowardsGoal specifies progress sensors arranged inputs ObstacleDensity contrary direction information updated represents increase configuration control parameters case similar new control parameters Another design decision likehood obtaining current environmental parameter navigation module To accomplish SINS choice adaptation algorithm Every learning module adaptation steps determined recommend situation recent retrieves time window adapts use navigation module based values suggested case The best values control parameters positive outcome cycle goal number measured performance metrics progress control parameters SINS collisions obstacles In order learn appropriate explore try values learn values produce positive negative environmental adaptation method One option results This presents design options select past In method values outcome achieved likely produced positive outcomes selected select value past similar situations The adaptation method enforces exploration discover better solutions reason produced negative outcomes Another option best reward On hand control parameter new values control parameters space possible parameter method converge We studied obtained positive produced stochastically similar according situations rewards situation values faster I2 Note sensory input provide information distances direction obstacles simply measures density occupied area robot 62 A Ram JC SantamariaArciaI Intelligence 90 1997 2577 choices adaptation method adaptation stochastic algorithm lead positive ing values distribution PU exp R Ci exp Ri Boltzmann value pected led positive expected stochastic method selectbest method The favor ex value value largest selects control parameter reward Specifically values selected according adaptation method simply selects Ri represent past The selectbest randomly reward reward values As previous study performed experiments relates performance design decisions combinations model independent method experience parameters significant residual plots variables estimate collect data possible linear time T parameters median choice input representation level We allsubsets choice adaptation determine regression analysis performed model validation analyzing adaptation representations stochastic achieves best performance algorithm For purposes brevity details study omitted The results highlevel configuration T 5173 seconds E 15 representation experiences Highlevel choice adaptation method However stochastic adaptation method adaptation provides method choice better performance input representations rate performance While 3 1279 secondsexperience interaction adaptation procedures Furthermore converged affects learning time converge takes longer bestvalue following effective independent limitations contribute learning results encouraging plots linearity completely worlds In addition residuals zero mean assumption indicates normal probability slight departure normal distribution results knowledge function choice input representation factors constant variance valid Thus care taken generalize determine research effect world performance world adaptation method size case library necessary investigate learned knowledge transfers acquired noted The 58 Study 3 experiments real robot While simulation allow evaluate systems performance important experiments range design decisions domain characteristics worksand learnswith actual Denning MRVIII type input representation configured highlevel trials measured adaptation method We ran number virtual collisions A trial consisted placing point let run reached came real robot We performed experiment robot verify validity approach We selectbest time robot starting goal 300 seconds elapsed whichever free The experiment performed verify room rectangular accumulated indoor additional learning A Ram JC SantamuriaArtifciaI Intelligence 90 1997 2577 63 Fig 8 A picture left schematic right robot environment In schematic robot shown figure hollow circle near represents goal black circles represent static obstacles black bars represent occupied areas robot navigate 25 x 14 feet circular static obstacles space approximately walls Two obstactles 55gallon obstacle Denning robot laboratory navigable shape irregular drums diameter 2 feet feet Fig 8 shows room experiment Note boundaries walls desks chairs area flat example robot diameter 2 performance robot plotted trials The left number virtual collisions trials robot able reach destination point trials minutes During performance The robot final value 2 minutes task successfully taken 5 minutes following improve learning terminated right Fig 9 shows total time graphs time taken trial During trials manually robot able complete reduced 10 trials reduced 15 trials produced taken robot different summarizes showed significant The subsection number virtual collisions improve metric Also 60 steady state 10 path The SINS metrics Fig 10 shows path jerky movements improvement trials 1 5 10 20 results studies 59 Discussion results The performance SINS complex depends simple interactions The evaluation solve 15 cluttered world decreases mainly experience maximum number cases improves shows median term deteriorate performance performance quadratic level Increasing positive coefficient big values On time terms takes 64 A Ram JC SantamariaArtificiai InteNigence 90 1997 2577 Fig 9 Performance real robot Left total time trial Right number virtuaI collisions trial Fig 10 Actual path followed robot different left 20 right trials trials 1 left 5 right 10 A Ram JC SantamariaArtcial Intelligence 90 1997 2577 65 indicates interaction coefficients maximum linear coefficient case size positive large cases improve performance indicate hand coefficient small cases Negative number cases case size requires experiences performance store regularities construct The performance factor subject realized SINS influenced world clutter influence Finally simulated real mode experience expected improvement greatest significant Intuitively required bigger values maximum start improving space available regularities reliable learning rate performance negative quadratic compared The results shown help verify understand aspects SINS In particular l The evaluation l The performance interactions experience simulation shows SINS improve significantly performance Table 2 Fig 7 actual robot Fig 9 depends alternative design decisions Eq 1 Table 2 l The choice input representation performance Section 57 The model allows determine choice adaptation method SINS interactions indepen best choices influence dently decisions design decisions l Highlevel lowlevel converge better solutions bestvalue Section 57 input representations provide better starting point learning input representations Also stochastic adaptation method adaptation method converged takes longer arrives l The model allows determine world prespecified level experience l The results change performance affects l The analysis shows SINS Eq 4 proposed best way configure SINS 15 cluttered 2 3 characteristics Eqs environment clutter performance empirical model account actions variability explained introducing factors changing terms Eq 1 rest variation performance factors C S E inter RO798 Part remaining 212 forms functional 798 randomness l The empirical model second study account performance This result 653 important variability captures explained forms terms limitations derived model Part remaining introducing empirical model factors changing percentage functional l When configured highlevel input representations selectbest adaptation suggested simulation studies indoor navigation real robot improve task static obstacles method navigation different performance metrics unexpected performance One interesting reinforcement lier hypothesized learning method Fig 9 result deserves mention arose ear reward signal based consistency SINS uses case adaptation As discussed internal 66 A Ram JC SantamartaArtijicial Intelligence 90 1997 2577 models provide accurate predictions reward signal However navigation SINS reduced schema gains zero learning This hypothesis enhance performance guide sufficient learns perceptionaction actions external necessarily experiments turned motor control went While tination point useful tarily external tem situations schemas useful avoid moving obstacle As currently reward signal depending learned task For example turned correct SINS results models initial des physical world stop momen SINS run sys implemented users goals observe task moving needed correctly result consistently particular correct model action example The evaluations focussed SINS continuous systematic particular However believe successfully usefully applied machine systems Furthermore implications casebased continuous reasoning reasoning method methodology ing casebased reasoning method provides general reasoning discussed casebased evaluation learn casebased theories 6 Discussion implications Continuous casebased reasoning variation traditional tasks The underlying case retrieval adaptation casebased steps reasoning method execution continuous assessment SINS systems perform CHEF 21 However kind casebased planning interesting perform situation respect similar similar learning The ACBARR differences continuous performance Lemmons intended processing performs approach combines realtime earlier attempts systems systems tightly knit cycle similar Ramsey combine 10391 perceptionaction 201 reasoning designed learning robotics tasks Our approach 281 use casebased similar realtime control Their nature domain online nature Kopeikina Brandau issues time constrained need represent cases evolve time They suggest In contrast task batch mode peak hours reasoning online different reasoning think reactive control types higherlevel stop casebased In respect research learning learning special capabilities handle typically require aspects reactive control task adaptationlearning anytime learning approach Grefenstette In task integrated Our approach basic casebased methods conjecture casebased issues reasoning continuous reasoning casebased introduces reasoning paradigm Due similarity innovations assumptions innovations useful systems Let discuss underlying casebased traditional reasoning A Ram JC SantamariaArtcial Intelligence 90 1997 2577 67 6 I Assumptions underlying casebased reasoning Our approach combines continuous representations continuous performance learning integrated conditions result tinuous underlie environment environmental outcomes variations By consistent mean vironmental use past experience future hope obtain underlying future experiences similar mon assumption manner The assumption traditional 45 approach underlying interaction framework There basic assumptions reasoning single approach First causal consistent By causal mean actions executed conditions result outcomes similar slower execution cycle en executed actions outcomes This guarantees small changes small changes guide performance similar situations results actions The second assumption systems experiences usually encounter problem experience These assumptions example typical situations com typicality stated explicitly exact casebased likely reasoning systems approach discussed 62 Finegrained representations adaptations While casebased requires formal welldefined required semantic concepts operations The assumption unique given situations requires similarity metric necessary current work assumed titatively This particular method similarity magnitude domains existing finitesimally adequate example cess theory similarity metric representations similarity representations symbolic 131 approach research needed compare systems fine grained cases place situations variations continuous reasoning casebased continuous l3 In problem domain represented quan In similarity metric method judge direction noncontinuous determine reasoning determine vary continuously partial matching metrics degree similarity relaxed based qualitative pro issue Furthermore require situations similarity metrics developed continuous instantaneous scale This assumption descriptions planning situations periods time The finegrained For example rule recommends SWALE nature representations 2454 pattern adapted man substituted horse Similarly CHEF important explanation case adaptation domains traditionally I3 However note medical domains require ROENTGEN continuous attributes Other domains weather prediction require hybrid symbolic continuous representations For example Bergers therapy plans patients uses representations design radiation reasoning continuous example representations representations treated symbolic 22 81 68 A Ram JC SantamanhArticial Intelligence 90 1997 2577 representations concepts SWALE partway 2 1 substitute chicken symbolic invent manhorse horse The continuous modifications able power This assumption constructive example scope traditional 40 currently discrete casebased beef recipe But interpolate example man finegrained consider adequate algorithms modification developed implementation relaxed ability SINS systems representations limits SINS permit arbitrarily concept creation representations interpolation outside providing reasoning 63 Time history representations Our methods represent novel approach casebased reasoning new kind Furthermore continue evaluation reactive control unlike online performance The continuously task requires continuous evaluate performance current environment features available perceptual features abstract world models casebased continuous time course features suitably retrieved basis similarity metric current learned basis systems experiences Additionally reasoning casebased continuously simultaneously adapt solution seek new based simple thematic requires represent time windows Relevant cases recent history case library cases adapted new cases SINS learned modified task domains features retrieve cases adaptation chosen compares reasoning representation case representations guide action terms available situation cases systems Casebased desirable complex cases strategies reasoning improvement 601 represent learn time history AI To knowledge SINS reasoning discrete casebased sequences significant systems Whereas previous casebased systems use recent history current situation representations reasoning inductive 211 CHEF integrated conceptual Similarly clustering input examples based feature clustering lists descriptions In effect SINS thought learning ability learning PRODIGY cases cases Because perceiveact retrieval temporal 161 classify COBWEB associative classificatory situation recent history situation retrieveadaptapply progression loop events states index merely description rules antecedent cycle events features vary systems systems time 64 Abstract cases In traditional symbolic abstraction For example cases CHEF program In continuous histories real parametric actual experience 21 represent actual recipes created domain actual experience consists time control parameters For example values perceptual task domain case represents A Ram JC SantamdaArticial Intelligence 90 I 997 2577 69 starting propioceptive experience location twodimensional involve location 671m 1098m navigational grid destination grid The experience consist values perceptual parameters current position goal respect real numbers integer minimum robot parameters vary continuously time graphs parameters Clearly time history parameters useful coordinates xy coordinate pair vicinity robot sensed nearest obstacle control parameters meters speed radians These represented store entire robot solves current heading robot time complete experience number obstacles meters robot immediate safe distance approach meters second problem feasible distance obstacle I4 Thus SINS learns stores abstraction CHEF actually actual cooking looking frying pan judging control output actual experience One experience moving experiences abstracted actual form One open representations spatula issues pot represented In CHEF symbolic input browned argue involve perceptual ingredients stir ingredients programmer research continuous automatic experiences extraction symbolic 30441 65 Virtual cases likely task domains infinitely ways differences A related different problem continuous power casebased representative experience range signif infinitesimal Only tiny fraction possible experiences actually reasoning comes library cases idea remember experience create abstraction process described earlier abstract generalized differ icant undergone However cases desirable cover range experiences virtual case represents representative actually Rather details abstraction details SINS combines past cases present experiences virtual experience This similar difference actual experience virtual experience derived actual experiences A virtual case thought average proto space typical experiencea experiences grain size defined programmer virtual case represent represents points encounter We introduce close combination centroid region trying description experience centroid One problem virtual cases usually isnt priori information centroids region centroids boundaries located big regions learned experience Since experiences I4 However range allowable variations perceptual control parameters bounded nature task memorybased approach fact feasible 161 70 A Ram JC SantamarLaArtcial Intelligence 90 1997 2577 sequentially undergone manner This means alterations standard casebased generalization content case cf 45 cases learned adapted progressively ongoing content case depends past experience similar experiences This approach deviates reasoning case contains previous experience previous future similar experiences introduced subsequent modify The notion virtual case useful To simple example AQUA based new experiences true single experience hypotheses reasoning sophisticated algorithms systems cases future If viewed virtual cases SINSs virtual cases use refinement continuously different discussed symbolic casebased learns updates existing hypotheses useful plausible 451 This process reasoning refined results 66 Dynamic memory cases converge useful requires ongoing problem solving guide problem solving learning SINS designed result time organized algorithms time Since learning process systems memory The regularities experiences usefulness Cases experiences useful contain virtual experiences refinement mechanisms associations These cases usually reliable guide cases solving contain cases having degrees reliability actual navigational future problems Cases exposed useful sequences future problems consistent solving conceptual Thus representations methods SINS allow incorporate single representation relative sensorimotor new useful successive gradual incremental manner This implications change create higherlevel 441 Second SINS implements similar experiences differentiate representations consists First SINS carries process constructive strategic set lowlevel original kind concepts Schanks MOPS dynamic memory formed consistent Schanks example visits dentist doctor The virtual cases SINS thought experiences Part learning process dynamic organize memory task hand use concepts aggregates use act successfully memory basis casebased 531 aggregate memory structures constructed tenet dynamic concepts interpret relevant useful terms internally organize experiences fundamental environment prototypical reconstructions reasoning concepts systems 67 Two types behavior modification As discussed earlier systems use casebased reasoning behavior cations selection adaptation The knowledge suggest local modifications kinds suggestions required suggest global modifi behavior stored case A Ram JC SantamariaArticial Intelligence 90 1997 2577 11 In problem domains noncontinuous casebased separate contrast traditional suggest solutions fit current problem types problem solving 361 In situations casebased tion continuously refine cases trajectory reactive control module proposed trajectories reasoning library adaptation systems cases rules adapt solution ones planning performed separately plan execution solu propose plan reasoning execution Another difference directly plan result modifications ACBARR SINS propose modifications 68 Two types adaptation systems reasoning Traditional casebased retrieve cases adapt solutions pro posed cases order provide new solutions new problems hand How order build virtual cases systems need adapt cases case modification similar response case deal new situation process use experience new experiences This addition incremental AQUA 45 learn existing cases represent experience These provide environmental cases future situations Cases behavior adaptation viewed process In problem domain terms reasoning casebased navigate identified necessary standard recommendations In addition viewed process discovery world The explores traverse space good niches viewed process solution modification regularities predictive power currently pursued experience develops model search space case representations representing adaptation regularities The process case provided case adapt solutions adapted cases 561 uses trialanderror The particular method case modification Sutton develop world model plan optimal routes differences discussed earlier In general hypothesize modification useful different methods need AQUAs incremental SWALEs solution adaptation reasoning types casebased developed modifications perform example viewed extension evolving world model case systems reinforcement case modification similar 24541 strategy learning Different criteria need developed fit new experience learn new case represent use case solution adaptation modifying relative approach discussed earlier We believe casebased represented deciding modify case new experience Our uses similar approach different information systems determine new experience modify best available case case intuition identify potential similarity measure regularities reasoning merit 72 A Ram JC SantamarIaArtcial Intelligence 90 1997 2577 69 Online realtime response Unlike traditional casebased reasoning systems 211 unlike machine analysis trol systems fall nonreactive compared continuous inherently continue perform casebased continuous require continuous pure reactive control Even realtime required reasoning problem domains response representations learning augmentations reasoning rely deep reasoning reactive lo method allows overhead reactively little performance 610 Adaptive reactive control robot navigation demands reactive control single multiple Our research contributes autonomous use assemblages robots follow tailored behaviors behaviors dynamically nav ing ways One propose method particular environmental haviors Two systems select adapt relying user manually program igation problem Three automatically exhibits considerable forms reconfiguration environment casebased 4748 required experience multiple behavior selection modification learning methods Finally uncluttered worlds highly cluttered worlds worlds box canyons results learning kind In article focussed furthermore environments aspects work robot control flexibility multiple domains For example correct behavioral parameters transfer reasoning issues discussed knowledge independent acquired Our research contributes extends related work behavior coordination Matarics 35 approach order use learns robot learns topological map land future planning The robot performs better terrain current module activations spatial arrangements activate appropriate modules mappings conditions landmarks knowledge goal However design method time In contrast change control parameters conditions However approach allow robot learn informa perceived conditions module activation robots learns control parameters surroundings immediate robot information indexed descriptive terrain For example marks experience uses position precompiled conditions suitable map landmark tion robot More research needed combine map learning approaches navigational Although maps help path planning approaches terrain In contrast navigational egy learning specific terrain changes guidance strategies robot slow navigate carefully specific path planning terrain robot learn robust obstacle density starts increasing terrains For example robot avoid collision This learned On hand information terrain trained relearned strategies provide higherlevel strat A Ram JC SantamaraArtcial Intelligence 90 1997 2577 13 landmarkbased available information obstacle cluster altogether One approach maps map learning local navigational navigation techniques strategies global route planned combining provide associated learning approach able avoid techniques use guidance actual largerscale navigational techniques perform Other approaches focused learning mapping situations update information feedback situations behaviors negatively modules 341 use experiences reinforcement correlated negative current situation This approach rewards Using positively external proven correlated feedback past situations ordination behaviors For example Maes Brooks correlations robot selects positive match approaches learn useful behavior Maes Brooks sensation disambiguate different control parameters create cases time window This allows select best control parameters based current history recent past In approach experiences capture feedback One difference approach reward approach produce input recent history inputs provides information robot able perceptual common shares learning similar learn select appropriate control parameters conditions regularities techniques situations 7 Conclusions We presented control reinforcement implemented analysis novel method casebased augmenting reasoning online case learning combines learning evaluated extensive performance reactive online parameter adaptation fully adaptation The method statistical simulations rigorous actual implementation The power method derives robot ability capture common environmental environment regularities interaction reactive control configurations online adaptive process The method adds considerably flexibility underlying select utilize different behaviors appropriate perform functions SINS characterized constructs higherlevel actions acquired automatically performing situation hand furthermore kind constructive particular lowlevel different representations representations sensorimotor sets schema parameter values required knowledge experience change inter representational cases systemenvironment performance allows 441 adaptationlearning task anytime action required learning approach Grefenstette explore In SINS perceptionaction 20 Perception tightly knit cycle similar Ramsey environment derlying performance generalize regularities detect regularities course form task navigation Adaptation provide predictive suggestions learning task integrated basis based prior expe required 74 A Ram JC SantamariaArtcial Intelligence 90 1997 2577 rience Both allowing manner tasks occur simultaneously progressively improving performance carry performance task continuous online work problems analysis presented focus component needed studies continuous simulation extent cases dynamically research While able size domains tested SINS generality aspect algorithm number cases issues There unresolved appropriate time windows 27 SINS adjust issue method appears SINS represent extended experiences determine extent cases needed open systematic research Furthermore retrieval process handle deteriorating leading place upper bound number cases allowed solution develop method conventional memory organization 271 assume structured nominal varying analog schemes casebased information kind utility problem 17381 Our current expensive organization determine information performance problem solution A better cases memory time systems 141 continuous reasoning limits overall navigational kind cases nature regularities Another open issue methods possible desirable Interpretation learning methods tems cases While SINS cases enhance interpret understanding ing schema parameter values modifying explanationbased vide better suggestions best schema parameter This requires symbolic cases values understanding integration higherlevel captured easy performance purpose obtaining sys deeper reason initial trial error pro speeding search process finding situation systems instead guessing knowledge environment represented For example incrementally module working case adaptation module values associated particular SINS Despite limitations complete autonomous navi gation interact environment user input reactive control domain knowledge implicit preprogrammed task builds library experiences schemas As performs learning Since performance changes fine tune situations cope major environmental static specific environment navigation module help enhance selfimproving Acknowledgements This research supported Army Research Laboratory Georgia Institute Technology We thank Ron Arkin Kenny Mootman Russ Clark entire help ACBARR useful suggestions course research Anthony Francis Mark Devaney anonymous reviewers helpful comments earlier drafts paper A Ram JC SantamariaArtijicial Intelligence 90 1997 2577 75 References I DW Aha Generalizing case studies case study Proceedings Ninth International Conference Machine Learning Aberdeen 1992 l10 2 P Agre D Chapman Pengi implementation theory activity Proceedings AAAI87 Seattle WA 1987 268272 31 RC Arkin Motor schemabased mobile robot navigation 4 RC Arkin DC MacKenzie Temporal coordination IEEE Trans Rob Autom 10 1994 276286 navigation Int J Rob Res 8 4 perceptual algorithms 1989 92l 12 mobile robot 5 K Ashley E Rissland Compare contrast test expertise Proceedings AAAI87 Seattle WA 1987273284 6 CG Atkeson Memorybased learning intelligent control systems Proceedings 1990 American Control Conference San Diego CA 1990 988 71 T Balch G Boone T Collins H Forbes D MacKenzie JC Santamarfa 10 Ganymede Callisto multiagent S J Berger ROENTGEN robot janitorial radiation team AI Magazine 16 2 1995 3951 therapy casebased reasoning Proceedings Tenth Conference ArtijZal Intelligence Applications San Antonio TX 1994 171177 191 R Brooks A robust layered control 1 10 1 SA Chien MT Gervasio GF DeJong On decreasingly mobile robot IEEE J Rob Autom 2 1986 1423 deliberate reactive learning minimally 288292 Proceedings Eighth International Workshop Machine Learning Chicago IL 199 I 1 I PR Cohen AE Howe How evaluation guides Al research AI Magazine 9 4 121 PR Cohen AE Howe Towards AI research methodology case studies 1988 3543 evaluation fEEE Trans Syst Man Cybern 19 1989 634646 13 GF DeJong Learning 141 EA Domeshek Do right thing component thesis Department Computer Science Yale University New Haven CT 1992 plan continuous domains Artif Intell 65 1994 71141 theory indexing stories social advice PhD I5 I RE Fikes PE Hart NJ Nilsson Learning executing generalized robot plans Artif Intell 3 1972 251288 161 D Fisher Knowledge acquisition incremental conceptual clustering Mach Learn 2 1987 139172 171 A Francis A Ram Computational models utility problem application utility Proceedings ML93 Workshop Knowledge Compilation analysis casebased Speedup Learning Amherst MA 1993 reasoning 181 M Georgeff Planning Ann Rev Comput Sci 2 1987 359400 191 A Goel A Khaled M Donnellan A Gomez De Silva T Callantine Multistrategy adaptive navigational 201 JJ Grefenstette path planning IEEE Expert 9 6 1994 5765 Conference Machine Learning Aberdeen anytime 1992 189195 CL Ramsey An approach learning Proceedings Ninth International 21 KJ Hammond CaseBased Planning Viewing Planning Memory Task Perspectives Artificial Intelligence Academic Press Boston MA 1989 1221 EK Jones A Roydhouse Intelligent retrieval archived meteorological data IEEE Expert 10 1995 6 23 I L Kaelbling Learning Embedded Systems MIT Press Cambridge MA 1993 24 A Kass Tweaker old explanations CK Riesbeck 295 RC Schank A Kass new situations eds inside CuseBased Explanafion Lawrence Erlbaum Hillsdale NJ 1994 263 adapting 25 j D Kibler P Langley Machine Working Session Learning Glasgow learning experimental 1988 8192 science Proceedings Third European 26 JL Kolodner RL Simpson K Sycara A process model casebased reasoning problem solving Proceedings IJCAI85 Los Angeles CA 1985 284290 I 271 JL Kolodner CaseBased Reasoning Morgan Kaufmann San Mateo CA 1993 28 1 L Kopeikina E Brandau A Lemmon Casebased reasoning continuous control Workshop CaseBased Reasoning Clearwater Beach FL 1988 250259 Proceedings 76 A Ram JC SantamariaArtificial Intelligence 90 1997 2577 1291 BJ Kuipem A qualitative approach robot exploration map learning Proceedings AAAI Workshop Spatial Reasoning MultiSensor Fusion St Charles IL 1987 390404 30 BJ Kuipers YT Byun A robust qualitative method robot spatial learning Proceedings AAAI88 St Paul MN 1988 774779 3 I D Langer JK Rosenblatt M Hebert A behaviorbased offroad navigation IEEE Trans Rob Autom 10 1994 776783 32 DB Leake Learning adaptation strategies introspective reasoning memory search Proceedings AAAI93 Workshop CaseBased Reasoning AAAI Press Menlo Park CA 1993 5763 33 F Maes Situated agents goals Rob Autonom Syst 6 1990 4970 34 F Maes RA Brooks Learning coordinate behaviors Proceedings AAAI90 Boston MA 1990 796802 351 MJ Matzuic Environment learning distributed representation Proceedings IEEE Conference Robotics Automation 1990 402406 36 D McDermott Planning acting Cognit Sci 2 2 1978 71109 371 S Minton Learning effective search control knowledge explanationbased approach PhD thesis Tech Rept CMUCS88133 Computer Science Department CarnegieMellon University Pittsburgh PA 1988 38 S Minton Quantitative results concerning utility explanationbased learning Art Intell 42 1990 36339 1 391 TM Mitchell Becoming increasingly reactive Proceedings AAAI90 Boston MA 1990 105 I 1058 40 K Moorman A Ram A model creative understanding Proceedings AAAI94 Seattle WA 1994 7479 1411 J Mostow N Bhatnagar FAILSAFEa floor planner uses EBG learn failures Proceedings IJCAI87 Milan 1987 249255 42 S Pandya S Hutchinson A casebased approach robot motion planning Proceedings 1992 IEEE International Conference Systems Man Cybernetics Chicago IL 1992 492497 43 D Payton An architecture reflexive autonomous vehicle control Proceedings IEEE Conference Robotics Automation San Francisco CA 1986 18381845 44 A Ram Creative conceptual change Proceedings Fifteenth Annual Conference Cognitive Science Society Boulder CO 1993 1726 45 A Ram Indexing elaboration refinement incremental learning explanatory cases Mach Learn 10 1993 201248 46 A Ram RC Arkin G Boone M Pearce Using genetic algorithms learn reactive control parameters autonomous robotic navigation Adapt Behav 2 1994 277305 47 A Ram RC Arkin K Moorman RJ Clark Casebased reactive navigation casebased method online selection adaptation reactive control parameters autonomous robotic systems Tech Rept GITCC9257 College Computing Georgia Institute Technology Atlanta GA 1992 48 A Ram JC Santamaria Multistrategy learning reactive control systems autonomous robotic navigation Informatica 17 1993 347369 49 CK Riesbeck RC Schank Inside CaseBased Reasoning Lawrence Erlbaum Hillsdale NJ 1989 501 SJ Rosenschein L Kaelbling The synthesis digital machines provable epistemic properties J Halpem ed Proceedings Conference Theoretical Aspects Reasoning Knowledge Monterey CA 1993 5 1 ED Sacerdoti A Structure Plans Behavior Elsevier New York 1977 52 JC Santamaria A Ram Systematic evaluation design decisions casebased reasoning systems Proceedings AAAI94 Workshop CaseBased Reasoning Seattle WA 1993 2329 531 RC Schank Dynamic Memory A Theory Learning Computers People Cambridge University Press New York 1982 54 RC Schank Explanation Patterns Llnderstanding Mechanically Creatively Lawrence Erlbaum Hillsdale NJ 1986 A Ram JC SanramaridArtifcial Intelligence 90 1997 2577 II 551 AM Segre Machine Learning Robof Assembly Plans Kluwer Academic Publishers Norwell MA 1988 56 RS Sutton Integrated architectures dynamic Proceedings Seventh International Conference Machine Learning Austin TX learning planning reacting based approximating programming 1990 216224 571 RS Sutton ed Special Issue Reinforcement Learning Mach Darn 8 34 SS RS Sutton AG Barto RJ Williams Reinforcement 1992 direct adaptive optimal control learning Proceedings American Control Conference Boston MA 1991 21432146 591 EL Thorndike Animal Intelligence Hafner Darien CT 19 I 1 1601 M Veloso JG Carbonell Derivational analogy PRODIGY automating case generation storage retrieval Mach Learn 10 1993 249278 6 I PPMJ Verschure BJA Kriise R Pfeifer Distributed structured behavior Rob Autonom Sysf 9 1992 18 l 196 adaptive control selforganization 1621 CJCH Watkins Learning delayed rewards PhD thesis University Cambridge Cambridge 1989