Artiﬁcial Intelligence 214 2014 125 Contents lists available ScienceDirect Artiﬁcial Intelligence wwwelseviercomlocateartint Potentialbased boundedcost search Anytime NonParametric A Roni Stern Ken Goldberg c Ariel Felner Jur van den Berg b Rami Puzis Rajat Shah c Information Systems Engineering Ben Gurion University Beer Sheva Israel b School Computing University Utah Salt Lake City UT USA c University California Berkeley CA USA r t c l e n f o b s t r c t Article history Received 1 May 2012 Received revised form 1 May 2014 Accepted 3 May 2014 Available online 10 May 2014 Keywords Heuristic search Anytime algorithms Robotics 1 Introduction APTSANA This paper presents new search algorithms Potential Search PTS Anytime Potential SearchAnytime NonParametric A Both algorithms based new evaluation function easy implement require usertuned parameters PTS designed solve boundedcost search problems problems task ﬁnd fast possible solution given cost bound APTSANA nonparametric anytime search algorithm discovered independently research groups different derivations In paper coauthored researchers groups present derivations sequence calls PTS non parametric greedy variant Anytime Repairing A We experiments evaluate new algorithms 15puzzle KPPCOM robot motion planning gridworld navigation multiple sequence alignment search domains Our results suggest compared previous anytime algorithms 1 require userset parameters 2 ﬁnds initial solution faster APTSANA 3 spends time solution improvements 4 decreases suboptimality bound currentbest solution gradually 5 converges faster optimal solution reachable 2014 Elsevier BV All rights reserved Heuristic search algorithms widely compute minimumcost paths graphs Applications heuristic search range map navigation software robot path planning automated planning puzzle solving Different search algorithms return solutions varying quality commonly measured cost high quality solutions low cost Ideally like ﬁnd optimal solutions minimum cost Given admissible 2 return optimal solutions However problems heuristic search algorithms A hard solve optimally 3 algorithms 1 IDA In paper propose algorithms Potential Search PTS Anytime Potential SearchAnytime Non These algorithms especially suited cases optimal solution hard ﬁnd Parametric A PTS designed solve problems solution cost C input problem acceptable solutions cost C useless We problems boundedcost search problems Boundedcost search problems APTSANA Corresponding author httpdxdoiorg101016jartint201405002 00043702 2014 Elsevier BV All rights reserved 2 R Stern et al Artiﬁcial Intelligence 214 2014 125 arise example expense budget business trip limited trip ﬂights hotels planned quickly possible budget limit If online travel agency Expedia Priceline planning trip computational resources diverted clients plan budget limits Pricelines Name Your Own Price option The second algorithm present APTSANA anytime search algorithm algorithm quality results improves gradually computation time increases 4 APTSANA viewed translation anytime search algorithm sequence boundedcost search problems solved PTS intelligent approach avoid parameter setting problem Weighted A based anytime search algorithms Setting parameters boundedsuboptimal search algorithms known problem heuristic search literature 5 A key beneﬁt APTSANA require users set parameters w 0 cid2w parameters ARA 6 Furthermore experiments suggest APTSANA improves previous anytime search algorithms cases 1 ﬁnding initial solution faster 2 spending time solution improvements 3 decreasing suboptimality bound currentbest solution gradually 4 converging faster optimal solution reachable based new evaluation function Cgn hn discovered independently research groups different derivations In paper coauthored researchers groups present derivations The ﬁrst derivation u based novel concept called potential node The potential node n deﬁned respect given value C probability node n solution cost lower C We prove node highest u node highest potential certain probabilistic relation heuristic function cost estimates Both PTS APTSANA The second derivation u based desire nonparametric version Anytime Repairing A algo rithm 6 We expanding node highest u effect setting parameters ARA dynamically improve best solution far fast possible In addition u bounds subop timality current solution We compare PTS APTSANA previous anytime algorithms ﬁve representative search domains 15puzzle robot motion planning gridworld navigation Key player problem communication KPPCOM multiple sequence alignment As mentioned experimental results suggest APTSANA improves previous anytime search algorithms terms key metrics determine quality anytime algorithm As boundedcost algorithm results suggest PTS speciﬁcally designed boundedcost problems outperforms competing algorithms cost bounds exhibits overall robust behavior This paper extends preliminary work 79 1 providing substantially rigorous theoretical analysis presented algorithms 2 extending experimental results 3 adding comprehensive discussion relation boundedcost search anytime search 4 discussing limitations PTS APTSANA The structure paper follows First provide background related work In Section 3 introduce boundedcost search problem present Potential Search PTS In Section 4 present Anytime Potential Search APTS 78 Anytime NonParametric A 9 showing equivalent discussing theoretical properties Section 5 presents experimental results comparing PTS APTSANA previous algorithms Finally discuss generalization PTS Section 6 conclude suggestions future work Section 7 ANA 2 Background related work Search algorithms ﬁnd solution starting initial state traversing problem space graph goal state Various search algorithms differ order decide traverse problem space graph Traversing problem space graph involves generating expanding nodes The term generating node refers creating data structure represents expanding node means generating children One widely search frameworks bestﬁrst search BFS 10 BFS keeps lists nodes open list denoted OPEN contains generated nodes expanded closed list denoted CLOSED contains nodes previously expanded Every generated node OPEN assigned value evaluation function The value assigned node called cost node In iteration BFS node OPEN lowest cost chosen expanded This lowestcost node moved OPEN CLOSED children node inserted OPEN The purpose CLOSED avoid inserting nodes expanded OPEN CLOSED help reconstruct solution goal Once goal node chosen expansion lowestcost node OPEN BFS halts goal returned1 Alternatively BFS deﬁned node assigned value iteration node highest value expanded BFS general framework wellknown algorithms special cases For example Dijkstras singlesource shortestpath algorithm 12 A algorithm 1 special cases BFS differing evaluation function2 Dijkstras algorithm BFS evaluation function gn shortest path far 1 This textbook version BFS 10 However variants BFS search halted earlier BFS lookaheads 11 2 In paper consider Dijkstras algorithm bestﬁrst search variant known Uniform Cost Search It shown 13 variant Dijkstra eﬃcient implementation Dijsktra detailed common algorithm textbook 14 R Stern et al Artiﬁcial Intelligence 214 2014 125 3 BFS evaluation function f n gn hn hn heuristic start search node n A n denote lowestcost path function estimating cost state n goal node We use notation h node n goal hn said admissible overestimates cost lowestcost path n goal hn h guaranteed lowestcost path goal goal node chosen expansion In general use term optimal search algorithms denote search algorithms guarantee returning optimal solution Other known optimal search algorithms include IDA n node n Using admissible hn A 2 RBFS 15 Finding optimal solution search problems infeasible Additionally case nonoptimal solutions good Hence search algorithms provide weaker guarantee solution return respect optimal search algorithms We list types search algorithms provide weaker guarantees 21 Boundedsuboptimal search algorithms Boundedsuboptimal algorithms guarantee solution returned w times cost optimal solution w 1 predeﬁned parameter These algorithms called wadmissible value w referred desired suboptimality We use term suboptimality solution cost C denote ratio cost optimal solution C Thus suboptimality solution returned wadmissible algorithm bounded desired suboptimality w The wellknown boundedsuboptimal search algorithm probably Weighted A expands node n OPEN minimal trading running time solution quality It similar A WA sooner solution typically If h admissible heuristic WA suboptimality solutions WA algorithm include A cid3 18 Optimistic Search 19 Explicit Estimation Search 20 WA inﬂates heuristic value w 1 Thus f w n gn w hn The higher w greedier search boundedsuboptimal search algorithm bounded w Other examples boundedsuboptimal search 163 WA extends A 22 Any solution algorithms In cases solution quality importance This case problems hard obtaining meaningful bound quality solution possible We algorithms settings solution algorithms Such algorithms usually ﬁnd solution faster algorithms ﬁrst classes possibly lower quality Examples solution algorithms include pure heuristic search BFS h evaluation function4 beam search variants 21 variants local search algorithms Hill climbing Simulated annealing 10 23 Anytime search algorithms Another class search algorithms lies range solution algorithms optimal algorithms anytime algorithms An anytime search algorithm starts conceptually solution algorithm5 After ﬁrst solution continues run ﬁnding solutions better quality guarantee suboptimality Anytime algorithms commonly domains provide natural continuum solution algorithms 6 introduced optimal solution algorithms Some anytime algorithms AWA guaranteed converge ﬁnding optimal solution time given 22 ARA Many existing anytime search algorithms loosely based WA Since paper addresses anytime search algorithms based anytime search algorithms A commonly anytime al depth provide brief survey existing WA gorithm related WA Depthﬁrst branch bound DFBnB 23 DFBnB runs depthﬁrst search pruning nodes cost higher incumbent solution best solution far DFBnB require pa rameters However DFBnB highly ineffective domains cycles large search depth6 24 WA based anytime search algorithms Anytime Weighted A AWA 22 anytime version WA given value w ﬁnds ﬁrst solution Then continues search w Throughout AWA expands node OPEN minimal f w n gn w hn w parameter algorithm Each time goal node extracted OPEN improved solution Let G denote cost incumbent solution If h admissible suboptimality incumbent solution bounded G minnOPENgn hn G upper bound cost optimal solution minnOPENgn hn lower bound cost optimal solution Given It runs WA 3 The proof wadmissibility WA given Appendix later paper 17 That paper proposed variation WA dynamic weighting proof holds plain WA 4 Pure heuristic search called Greedy bestﬁrst search literature 5 One use virtually search algorithm ﬁnd initial solution anytime algorithm 6 Large solution depth partially remedied applying iterative deepening framework DFBnB 4 R Stern et al Artiﬁcial Intelligence 214 2014 125 runtime AWA optimal solution eventually expand nodes gn hn larger incumbent solution return Anytime Repairing A ARA Restarting Weighted A 6 based WA First ﬁnds solution given initial value w It continues search progressively smaller values w improve solution reduce suboptimality bound The value w decreased ﬁxed time improved solution currentbest solution proven wsuboptimal Every time new value determined w f w nvalue node n OPEN updated account new value w OPEN resorted accordingly The initial value w decreased iteration denoted cid2w parameters algorithm 24 similar ARA time w decreased restarts search root node That new search started initial node OPEN It takes advantage effort previous searches putting nodes explored previous iterations SEEN list Each time search generates seen node puts node OPEN best gvalue known Restarting proven effective comparison continuing search restarting situations quality heuristic varies substantially search space As ARA initial values w cid2w parameters algorithm Anytime Window A breadth regular A For comprehensive survey empirical comparison anytime search algorithms 27 limit search Iteratively increasing breadth provides anytime characteristic algorithms 25 BeamStack Search BSS 26 BULB21 based WA RWA AWinA based anytime search algorithms require users set parameters example w factor Most existing WA 6 instance parameters initial value w w inﬂate heuristic ARA decreased iteration Setting parameters requires trialanderror domain expertise 25 One contri butions paper nonparametric anytime search algorithm based solving sequence boundedcost search problems Section 4 3 Boundedcost search potential search In section deﬁne boundedcost search problem task ﬁnd quickly possible solution cost lower given cost bound We explain existing search algorithms optimal search algorithms boundedsuboptimal search algorithms suited solve boundedcost search problems Finally introduce new algorithm called Potential Search PTS speciﬁcally designed solving boundedcost search problems We deﬁne boundedcost search problem follows Deﬁnition 1 Boundedcost search problem Given initial state s goal test function constant C boundedcost search problem problem ﬁnding path s goal state cost C 31 Applications boundedcost search In Section 4 solving boundedcost search problems eﬃcient nonparametric anytime search While constructing eﬃcient anytime algorithms noteworthy achievement solving boundedcost search problems important right practical applications Generally search algorithm larger reasonable deﬁne search algorithm acceptable solution terms cost Once solution resources diverted tasks instead optimizing searchrelated criteria For example consider application server online travel agency Expedia customer requests ﬂight speciﬁc destination given budget In fact Priceline allows precisely option booking hotel Name Your Own Price option This naturally modeled boundedcost problem cost price ﬂighthotel Furthermore recent work proposed solve conformant probabilistic planning CPP problems compiling boundedcost problem 28 In CPP identity start state uncertain A set possible start states given goal ﬁnd plan goal reached probability higher 1 cid3 cid3 parameter search We refer reader Taig Brafmans paper 28 details compiled CPP problem boundedcost search problem A elaborate application boundedcost search exists task recognizing textual entailment RTE RTE problem checking text referred text logically entails referred hypothesis For example text Apple acquired Anobit entails hypothesis Anobit bought Recent work modeled RTE search problem sequence text transformation operators referred proof transform text hypothesis 2930 Each proof associated cost representing conﬁdence proof preserves semantic meaning text Stern et al 29 Machine Learning learn cost threshold RTE proofs proofs cost lower threshold valid Thus solving RTE problem determining given text entails given hypothesis boundedcost problem ﬁnding proof learned cost threshold A boundedcost search problem viewed constraint satisfaction problem CSP desired cost bound simply constraint solution cost However modeling search problem CSP nontrivial know R Stern et al Artiﬁcial Intelligence 214 2014 125 5 depth goal search tree7 Furthermore search problems powerful domainspeciﬁc heuristics clear general CSP solvers use heuristics The boundedcost search algorithm presented Section 33 use given heuristic Finally stateoftheart CSP solvers use variants depthﬁrst search Such algorithms known highly inef ﬁcient problems like pathﬁnding usually cycles state space Nonetheless potentialbased approach described Section 33 somewhat reminiscent CSP solvers based solution counting solution density assignments estimated allow maximal number solutions preferred 31 Another topic related boundedcost setting resourceconstrained planning 3233 resources limited consumed actions The task ﬁnd lowest cost feasible plan feasible plan resources available actions One view boundedcost search resourceconstrained problem single resource plan cost However boundedcost search want minimize cost plan Any plan cost bound acceptable Once plan wasteful invest CPU time improving cost computation resources diverted 32 Naïve approaches boundedcost search It possible solve boundedcost search problem running optimal search algorithm If optimal solution cost C return return failure solution cost C exists One use C pruning purposes prune node n f n C However technique solving boundedcost search problem ineﬃcient ﬁnding solution cost C easier ﬁnding optimal solution One tempted run boundedsuboptimal search algorithms However clear tune variants cost optimal solution suboptimal algorithms example weight use WA known ratio cost desired solution C optimal cost unknown A possible direction solving boundedcost search problem run suboptimal bestﬁrst search algorithm pure heuristic search prune node g h C Once solution guaranteed cost lower C In fact approach pure heuristic search shown effective domain independent planning problems nonunit edge costs 34 The main problem adhoc boundedcost algorithms desired goal cost bound guide search C considered choosing node expand Having deﬁned notion boundedcost search relation existing search settings algorithms introduce PTS algorithm speciﬁcally designed solve problems 33 The Potential Search algorithm PTS The Potential Search algorithm PTS speciﬁcally designed focus solutions cost C ﬁrst solution ﬁnds meets requirement PTS basically bestﬁrst search algorithm expands node OPEN largest u u deﬁned follows8 C gn hn Choosing node highest u intuitively understood selecting node likely lead solution cost C ratio budget left ﬁnd solution C C gn estimate cost n goal hn In Sections 34 43 discuss analytical derivations u evaluation function cid6 The complete pseudocode PTS provided Algorithm 1 The input PTS general boundedcost search algorithm initial state s search begins cost bound C In iteration node highest u denoted n expanded OPEN line 3 For generated node n duplicate detection cid6 exists OPEN CLOSED smaller equal g value line 7 Otherwise value gn performed ignoring n cid6 C updated line 9 If heuristic function h admissible PTS prunes node n line 12 This nodes contribute solution cost smaller C If h admissible cid6 C Any boundedcost search perform pruning experiments n implemented competing algorithms If n pruned goal search halts Otherwise n inserted OPEN search continues pruned gn gn cid6 hn cid6 cid6 cid6 cid6 cid6 34 The potential PTS based novel u evaluation function Next provide ﬁrst analytical derivation relating probability n leads goal cost smaller C We probability potential node 7 Note cost bound C search tree deeper edges cost smaller zero cost edges 8 For cases hn 0 deﬁne causing nodes expanded ﬁrst 6 R Stern et al Artiﬁcial Intelligence 214 2014 125 Algorithm 1 Potential search Input C cost bound Input s initial state n argmaxnOPEN pop node highest foreach successor n n cid6 cid6 Duplicate detection updating gn n cid6 cid6 OPEN CLOSED gn Continue successor n line 4 cid6 gn cn n cid6 gn cn n end cid6 gn Prune nodes bound gn cid6 C h inadmissible check instead gn Continue successor n line 4 cid6 C end If solution bound return n goal node return best path goal cid6 hn 1 OPEN s 2 OPEN 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 end Add n n Insert n end cid6 cid6 cid6 OPEN cid6 OPEN update location OPEN Update key n cid6 OPEN new gn cid6 24 end 25 end 26 return None solution exists cost bound C Fig 1 An example expansion dilemma To motivate concept potential node consider graph presented Fig 1 Assume searching path s g After expanding s search algorithm needs decide node expand node node b If task ﬁnd optimal path s g clearly b expanded ﬁrst path s g passes b cost lower cost path passes f b gb hb 100 f ga ha 103 If task ﬁnd path cost 120 C 120 expanding b necessarily best option For example better expand probably close goal cost 120 ha 3 Informally potential lead solution cost lower C b Next deﬁne notion potential relation u The potential node n deﬁned probability node h value equal hn path goal cost smaller C gn For clarity omit mathematical prerequisites deﬁning probabilities context provide later Deﬁnition 4 Deﬁnition 2 Potential Given heuristic function h cost bound C deﬁne thepotential node n denoted P T hC n cid2 PThC n Pr gn h n C cid3 cid4 cid3 hn In domains relation h h Clearly potential node depends relation heuristic function h value estimates h known property h precision parameter sensor In domains possible evaluate close h h attributes domain In general n hn small For example consider shortest path problem map expect hn closer h air distance heuristic If air distance nodes large likely obstacles exist More obstacles imply greater difference air distance real shortest path R Stern et al Artiﬁcial Intelligence 214 2014 125 7 Fig 2 MD heuristic vs true distance 15puzzle domain Consider case node n linear stochastic relation hn h n hn Xn Xn X random variable drawn probability distribution X We assume distribution X unknown Xn node n independent identically distributed iid according X We denote linearrelative assumption9 Assuming linearrelative assumptions relation h h assumption potential node n given n h cid2 Pr gn h cid2 Pr n C cid3 cid4 cid3 hn cid2 Pr cid4 Xn hn C gn Pr gn hn Xn C cid6 cid5 Xn C gn hn cid4 cid2 Pr cid4 Xn If know distribution X Xn drawn potential node explicitly calculated However given nodes n1 n2 determine node higher potential comparing u values This true Xn1 Xn2 iid Xn1 Xn2 X un1 un2 Pr cid2 cid4 Xn1 un1 cid2 Pr cid4 Xn2 un2 This idea summarized Lemma 1 Lemma 1 Under linearrelative assumption pair nodes n1 n2 un1 un2 iff n1s potential greater equal n2s potential Consequently problem linearrelative assumption holds BFS expands node highest u OPEN PTS expand nodes exactly according potential This result summarized Theorem 1 Theorem 1 Under linearrelative assumption PTS expands node highest potential It hard ﬁnd domain linearrelative assumption holds exactly However assumption holds ap proximately domains For example consider 15puzzle wellknown search benchmark We solved optimally 1000 standard random instances 36 For instances considered states optimal path total 52 523 states Each states assigned 2dimensional point x value denotes Manhattan Distance MD heuristic state y value denotes optimal cost goal The plot points presented Fig 2 The dashed line indicates best linear ﬁt plot line y 131 x 219 It easy observe linear ﬁt close suggesting linearrelative assumption approximately holds domain Appendix A shows domains occurs In Section 6 generalize PTS handle cases linearrelative assumption hold 9 This model reminiscent constant relative error 35 h n T hn constant T 8 R Stern et al Artiﬁcial Intelligence 214 2014 125 35 Limitations PTS Later paper Section 5 provide experimental results ﬁve domains showing PTS effective robust practice However like point limitations PTS 351 Memory requirements PTS bestﬁrst search storing nodes visited search OPEN CLOSED Thus memory required PTS solve problem worst case exponential depth search This prevents running PTS solve problems large domains 24puzzle close optimal cost bounds One consider running iterative 2 potential utility function u This problematic u noninteger deepening scheme like IDA number setting thresholds iterative deepening procedure nontrivial methods cope 3738 352 Distance vs cost heuristics In domains cost reaching goal distance number steps reach goal corre lated 39 Effective search algorithms domains employ types heuristics estimates cost reaching goal denoted h estimates number steps required reach goal denoted d 20 The PTS evaluation function u considers h Thus PTS effective domains d h different Work combining h d boundedcost search showed promising results 40 Resolving problems scope paper remains challenge future work Next APTSANA nonparametric anytime search algorithm PTS evaluation function u 4 Anytime NonParametric A Anytime Potential Search In section present framework constructing nonparametric anytime search algorithm solving sequence boundedcost search problems As instance framework present Anytime Potential Search APTS uses PTS solve boundedcost search problems Then Section 43 present different analytical derivation APTS nonparametric modiﬁcation ARA anytime search algorithm The result derivation known Anytime NonParametric A reﬂect dual origin ANA APTS algorithm APTSANA 9 ANA 41 Rationale nonparametric anytime search algorithm In general need nonparametric algorithms prevalent ﬁelds science AI 4143 inter alia The main reason algorithms parameters require method selecting values parameter method parameter tuning Parameter tuning Time consuming Parameter tuning commonly running parametric algorithm times range instances parameter values Crucial successful implementation Different parameter values great impact performance parametric algorithms This known occur parametric search algorithms 5 observe experimental results given later paper As result nonparametric algorithms accessible practitioners Thus need nonparametric anytime search algorithm great 42 A greedy nonparametric anytime search Algorithm 2 presents highlevel view anytime search algorithm It consists iteratively calling Improve Solution procedure line 4 searches solution better incumbent solution named Incumbent Algorithm 2 cost denoted costIncumbent maintained variable G Initially incumbent solution G set line 1 When solution better G G proven optimal solution cost search halt line 910 Alternatively search halted earlier case Incumbent returned line 12 Different anytime algorithms vary implementation ImproveSolution procedure line 4 For example apply depth ﬁrst search ImproveSolution If ImproveSolution resumes depthﬁrst search identical DFBnB Many eﬃcient anytime search algorithms AWA 24 22 ARA implement ImproveSolution different variants WA based anytime search algorithms require parameters set w WA s f w evaluation function Tuning parameters nontrivial 6 RWA These WA 10 Some anytime search algorithms guarantee better solution We discuss algorithms paper R Stern et al Artiﬁcial Intelligence 214 2014 125 9 Algorithm 2 General anytime search algorithm 1 G 2 Incumbent 3 search halted 4 5 6 7 NewSolutionImproveSolution Seek solution cost G NewSolution G costNewSolution Incumbent NewSolution 8 9 10 end Return Incumbent optimal 11 end 12 return Incumbent It possible intelligently customize parameters anytime search algorithm For example know exactly search halted possible employ DeadlineAware Search 44 estimates search paths goal achievable search halted Another example exists known utility tradeoff computation time solution quality In case possible use BestFirst UtilityGuided Search 45 tries optimize tradeoff In paper assume prior knowledge termination time search assume given utility function trades computation solution quality In absence propose following greedy approach anytime search In ImproveSolution try ﬁnd solution cost lower G fast possible It easy ImproveSolution exactly boundedcost search problem costbound C set cost incumbent solution G Thus use PTS ImproveSolution line 4 cost bound G The resulting anytime search algorithm require parameter tuning w shown empirically superior anytime search algorithms wide range domains Section 5 This anytime search algorithm uses PTS Improve Solution called Anytime Potential Search APTS As stated refer APTSANA emphasize second derivation described later Section 43 Because initially incumbent solution purpose ﬁrst iteration APTSANA fast possible bound cost Thus C result PTS evaluation function Cgn hn equal nodes OPEN making indistinguishable However C approaches inﬁnity node OPEN highest Cgn hn actually node lowest hn Thus C approaches inﬁnity PTS converges pure heuristic search Therefore deﬁne ﬁrst ImproveSolution APTSANA run pure heuristic search ﬁrst solution found11 ﬁnd solution 421 Reusing information PTS calls There known approaches knowledge previous calls ImproveSolution In cases best ignore completely 24 restart search initial state In cases sophisticated mechanism algorithm For comprehensive survey called repairing preferred 6 gave Anytime Repairing A empirical evaluation different ways consider knowledge previous calls ImproveSolution 27 No approach dominated domains For simplicity chose implement anytime algorithms paper OPEN passed calls ImproveSolution However modifying APTSANA use approaches trivial Consequently PTS called new cost bound cost solution previous PTS start initial node Instead PTS expand nodes OPEN previous PTS However incurs overhead nodes OPEN need reordered according u cost incumbent solution changed nonparametric improvement ARA anytime search algo Next different derivation APTSANA rithm 43 APTSANA improved Anytime Repairing A ARA 6 wellknown anytime search algorithm shown effective domains 27 For completeness special case highlevel anytime simpliﬁed version ARA ImproveSolution algorithm described Algorithm 2 It repeatedly calls version ImproveSolution called ARA aims ﬁnd solution wsuboptimal Initially w w 0 decreased ﬁxed cid2w ARA algorithm listed Algorithms 3 4 ARA ImproveSolution line 11 Algorithm 3 11 An alternative approach use function u increasing C inﬁnity results elegant convergence pure heuristic search cid6n 1 hn Cgn instead It easy achieves node ordering 10 R Stern et al Artiﬁcial Intelligence 214 2014 125 Algorithm 3 Simpliﬁed anytime repairing A ARA Input s initial state Input w 0 initial w Input cid2w w decreased iteration 1 G w w 0 OPEN Incumbent 2 Insert s OPEN 3 OPEN 4 5 6 7 NewSolution ARA NewSolution None G costNewSolution Incumbent NewSolution ImproveSolutionOPEN w G 8 9 10 11 12 return Incumbent end w w cid2w Update keys OPEN prune nodes g h G 13 end 14 return Incumbent Algorithm 4 ARA ImproveSolution Input OPEN open list Input w weight h Input G cost incumbent solution n argminnOPEN f w n pop node lowest g wh G f w n return None G proven wadmissible end foreach successor n 1 OPEN 2 3 4 5 6 7 8 9 10 11 cid6 cid6 OPEN gn cn n cid6 cid6 gn cn n gn gn n Insert n cid6 hn n n cid6 cid6 cid6 G cid6 gn cid6 goal return best path goal cid6 OPEN OPEN update position n 12 13 14 end end end 15 end 16 return None solution better G exists ARA ImproveSolution expanding node n OPEN minimal variant WA f w n gn w hn It terminates improved solution line 10 Algorithm 4 G minnOPEN f w n line 4 Algorithm 4 case incumbent solution proven wsuboptimal 6 An open challenge address set value ARA s parameters w 0 cid2w intelligently listed Algorithm 4 A property good anytime algorithm ﬁnds initial solution soon possible solution returned little time available In general higher w greedier search sooner solution Therefore ideally w 0 set However setting w 0 possible ARA w later decreased ﬁnite steps line 11 Algorithm 3 For reason ARA w initialized ﬁnite value w 0 A second desirable property anytime algorithm reduce time spent improvements solu tion incumbent solution requested time spent vain The cid2w w decreased small possible argued 6 However w ImproveSolution expand single node This creased little subsequent iteration ARA ImproveSolution returns minnOPEN f w n G line 4 Algorithm 4 If w hardly decreased ARA iteration case minnOPEN f w n G So maximal value w node expanded That w max nOPEN cid7 cid8 G gn hn cid9 cid10 max nOPEN 1 follows fact f w n G gn w hn G w G gn hn The node expanded node n OPEN maximal value This precisely node APTSANA expands R Stern et al Artiﬁcial Intelligence 214 2014 125 11 One imagine adapted version ARA uses Eq 1 set w iteration ARA maximally greedy ﬁnd improved solution explained Assume ARA ImproveSolution This allow initializing w ﬁrst iteration APTSANA However variation ImproveSolution ARA called w maxnOPENun let ˆw denote speciﬁc value w In ARA value w ﬁxed ImproveSolution node n generated ARA f ˆw n G If f ˆw n G node n expanded w increased A higher w corresponds greedier search instead maximize w node n OPEN f w n G This equivalent APTSANA continually expanding node n OPEN maximal value Thus APTSANA derived nonparametric tuning w search greedy possible nodes expanded f w smaller G ImproveSolution However ARA Additionally time w changed ARA nodes OPEN reordered account new w value line 12 Algorithm 3 w updated new solution incumbent solution proven wsuboptimal line 4 Algorithm 4 Reordering nodes OPEN takes O OPEN time large12 Thus additional beneﬁt APTSANA OPEN needs reordered new ARA solution 44 Suboptimality bounds APTSANA Consider case h admissible heuristic In case strong relation uvalue suboptimality bound incumbent solution time node n selected bounds suboptimality incumbent solution We prove theorem We use n denotes node expanded APTSANA expansion APTSANA denote cost optimal solution G G cost optimal path start state n G true suboptimality incumbent solution g Theorem 2 If hn admissible maxnOPENun G upper bound suboptimality current solution G In words node n selected APTSANA expansion Proof APTSANA prunes node n gn hn G Thus node n OPEN holds gn hn G 1 G gn hn Hence nodes OPEN 1 Thus Theorem 2 holds trivially current solution optimal If optimal cid6 OPEN optimal path goal g value solution node n optimal gn optimal path goal As heuristic admissible hn cid6 Lemma 1 1 The minimal cost n cid6 cid6 Therefore goal G cid6 n cid6 G cid6 g g g n n n cid6 cid4 cid2 n cid6 u cid6 G gn hncid6 n G g hncid6 cid6 inequality follows G G cid9 cid10 cid4 cid2 n cid6 u G G cid2 max nOPEN n G g cid6 G gncid6 n g G G cid6 0 As result Theorem 2 provides interesting view APTSANA behaves The suboptimality bound given maximum value u APTSANA viewed informed effort gradually decrease suboptimality bound incumbent solution Of course children expanded node n larger u value n case maxnOPENun increase resulting worse bound node expansion This overcome maintaining best lowest suboptimality bound seen far expands node Thus APTSANA Note suboptimality bound available running APTSANA additional overhead Previous approaches provide suboptimality bound anytime search algorithm f min minnOPEN gn hn Given fmin suboptimality incumbent solution While bound shown tighter bound provided u calculating required maintaining fmin requires additional priority queue ordered gn hn APTSANA uses single priority queue13 G fmin 12 In fact reordering OPEN requires O OPENlogOPEN general However possible use bucket sort achieve O OPEN runtime 13 Note maintaining f min requires simply storing lowest f value seen search f min increases search node f value f min expanded This requires going OPEN ﬁnd node minimal f value maintaining additional priority queue mentioned 12 R Stern et al Artiﬁcial Intelligence 214 2014 125 1 5 9 4 8 12 13 2 6 10 14 3 7 11 15 1 4 8 12 5 9 13 2 6 10 14 3 7 11 15 Fig 3 The 15puzzle goal state left state moves goal right improves ARA ﬁve ways 1 APTSANA maximally greedy ﬁnd initial solution 3 APTSANA require parameters set maximally greedy improve needs update keys nodes OPEN improved solution makes informed effort gradually decrease suboptimality bound In summary APTSANA 2 APTSANA cumbent solution 4 APTSANA 5 APTSANA 45 Limitations APTSANA While APTSANA attractive properties listed limitations Since APTSANA In addition APTSANA runs sequence PTS calls limitations described PTS Section 35 apply APTSANA limitations 451 Finding initial solution If heuristic inaccurate goals ﬁnding single unbounded solution hard As deﬁned ﬁrst solution APTSANA ineﬃcient domains pure heuristic search ineﬃcient For example domains distancetogo heuristic dn effective way ﬁnd solution fast search according dn hn 4639 runs pure heuristic search Thus APTSANA 452 Finding solutions Every time better solution APTSANA required resort nodes OPEN Algorithm 2 account new incumbent solution u values change Thus solutions slightly better previous APTSANA suffer overhead resorting OPEN time new better solution There ad hoc solutions limitations Instead APTSANA ﬁnd ﬁrst solution possible use algorithm Speedy search 46 ﬁnd ﬁrst solution provide APTSANA initial incumbent solution Additionally bound PTS set lower incumbent solution cid2 avoid ﬁnding solutions Such cid2 parameter algorithm setting raises parameter tuning problem aim avoid 5 Experimental results In section empirically evaluate performance PTS boundedcost search algorithm APTSANA anytime search algorithm This range domains 15puzzle KPPCOM robot arm grid world planning multiple sequence alignment MSA Next domains experiments 51 Domains For domain provide domain details state heuristic function problem instances generated 511 The 15puzzle The 15puzzle wellknown puzzle consists 15 numbered tiles moved 4 4 grid There blank location grid The blank swapped adjacent tile The left Fig 3 shows goal state 15puzzle right shows state created goal state applying operators swapping blank tile 1 swapping tile 5 The number states reachable given state 422 47 The task ﬁnd short path given starting state goal state The 15puzzle common search benchmark 215364849 There advanced heuristics 15puzzle In experiments chose simple Manhattan Dis tance heuristic MD goal compare search algorithms different heuristics The experiments performed Korfs standard 100 random 15puzzle instances 2 512 Key Player Problem Communication KPPCOM The Key Player Problem Communication KPPCOM problem ﬁnding set k nodes graph highest Group Betweenness Centrality GBC GBC metric centrality group nodes 50 It generalization betweenness metric measures centrality node respect number shortest paths pass 51 Formally betweenness node n Cbn σst number shortest cid11 stV stcid15n σst n σst R Stern et al Artiﬁcial Intelligence 214 2014 125 13 Fig 4 Example motion 6 DoF left 20 DoF right robot arm 6 paths s t σstn number shortest paths s t pass n The betweenness group nodes A termed group betweenness deﬁned Cb A σst A number shortest paths s t pass nodes A σst A σst stV A cid11 KPPCOM known NPHard 52 It important network security applications optimizing deploy ment intrusion detection devices 53 KPPCOM solved search problem Let G V E input graph searching group k vertices highest GBC A state search space consists set vertices N V N k N considered candidate group vertices highest GBC The initial state search set child state corresponds adding single vertex set vertices parent state Every state value GBC set vertices contains While goal previous domain 15puzzle ﬁnd solution minimal cost goal KPPCOM ﬁnd solution maximum value We problems type MAX problems problems type MIN problems An admissible heuristic MAX problems required upper bound optimal value Similarly suboptimal solution smaller value optimal solution A number eﬃcient admissible overestimating heuristics problem exist 52 experiments best calculated follows Consider state consisting set m vertices V m First contribution individual vertex v V V m calculated This CbV m v CbV m Then contribution topmost k m vertices summed admissible heuristic k total number vertices needs selected 52 detailed discussion heuristic Since main motivation KPPCOM problem communication network domains experiments performed graphs generated BarabásiAlbert model 54 This random graph model wellused model Internet topology web graph accepts parameters number vertices graph density factor We experimented variety graph sizes density factor values present average results 25 graphs 600 vertices density factor 2 Additionally limited size searched group vertices 20 k 20 513 Robot arm The robot arm domain taken Maxim Likhachevs publicly available SBPL library httpwwwsbplnet This prob lem illustrates performance proposed algorithms domain high branching factor duplicate states We consider 6 degrees freedom DoF arm 20 DoF arm ﬁxed base 2D environment obstacles shown Fig 4 The objective endeffector initial location goal location avoiding obstacles An action deﬁned change global angle particular joint angle respect ﬁxed initial point having joint arm rotate opposite direction maintain global angle remaining joints All actions cost The environment discretized 50 50 2D grid The heuristic calculated shortest distance current location endeffector goal location avoids obstacles To avoid having heuristic overestimate true costs joint angles discretized endeffector cell 50 50 grid single action Note size state space domain 109 states 6 DoF robot arm 1026 states 20 DoF robot arm 514 Gridworld planning The domain considered planar gridworld pathplanning problems different sizes numbers obstacles taken Likhachevs SBPL library This problem illustrates performance algorithms domain 14 R Stern et al Artiﬁcial Intelligence 214 2014 125 Fig 5 An example aligning 8 DNA sequences Table 1 Competing algorithms domain Algorithms AWA ARA DFBnB KPPCOM 15Puzzle Robot arm Gridworld MSA transpositions relatively small branching factor We set start state cell left corner goal state right cell The ﬁrst gridworld problem 100 1200 8connected grid obstacles unit cost adjacent obstaclefree cells The second gridworld problem 5000 5000 4connected grid transition adjacent cells assigned random cost 1 1000 For 5000 5000 4connected grid problem nonunit edge cost considered cases obstacles 515 Multiple sequence alignment MSA Our ﬁnal domain MSA problem The uniqueness domain comparison domains high branching factor nonuniform edge costs costs different edges vary MSA central problem computational molecular biology attempting measure similarity set sequences 55 The input MSA set sequences items gene protein sequences Every sequence mapped array possibly leaving spaces This mapping referred alignment Fig 5 shows example alignment 8 sequences Alignments cost according biologically motivated interpretation alignment We sumofpairs cost function previous works 565755 inter alia According cost function alignment cost k sequences sum alignment costs pairs sequences The alignment cost pair sequences x y considers number matches gaps substitutions alignment A match occurs identical items protein mapped array index A gap occurs single sequence index A substitution occurs different items mapped index The alignment cost assigned match gap substitution cost zero respectively k 2 cid4 cid2 MSA formalized shortestpath problem ndimensional lattice n number sequences aligned 58 A state possibly partial alignment represented items aligned far sequence A goal reached characters sequences aligned A search space assigns speciﬁc index item sequences The cost computed cost partial alignment The MSA problem instances experimented consist ﬁve dissimilar protein sequences obtained 59 60 The heuristic based summing optimal pairwise alignments precomputed dynamic programming 60 52 Boundedcost experiments In section empirically evaluate performance PTS In experiment cost bound C set PTS competing algorithms run solution cost lower C This repeated range cost bounds range C values In domains instances solved optimally reasonable time chose range C values cover bounds close average optimal solution substantially higher bounds In domains solving instances optimally feasible chose cost bounds solvable compared algorithms reasonable time The performance algorithms measured runtime We compared PTS range existing anytime search algorithms AWA 6 DFBnB 23 To comparison PTS fair modiﬁed anytime algorithms prune node n gn hn larger cost bound PTS line 12 Algorithm 1 Thus DFBnB viewed depthﬁrst search node pruning nodes gn hn larger cost bound pruned 22 ARA Different anytime search algorithms performed differently rest section results best performing anytime search algorithms domain Table 1 lists best performing algorithms DFBnB The effectiveness DFBnB KPPCOM surprising DFBnB main For KPPCOM AWA R Stern et al Artiﬁcial Intelligence 214 2014 125 15 Table 2 15puzzle boundedcost results The values average nodes expanded A The values brackets runtimes milliseconds C 55 60 65 70 75 80 85 90 PTS 36 11 7 5 5 4 4 4 AWA 15 AWA 20 AWA 25 AWA 30 955 389 370 353 351 346 342 345 21 12 12 12 12 12 12 12 482 389 389 388 387 389 387 392 48 11 7 6 6 6 6 6 751 418 362 354 357 355 357 360 86 33 13 6 5 5 5 5 1068 643 430 360 347 348 347 347 124 66 67 17 8 4 4 4 1651 1144 735 464 385 350 343 340 Table 3 KPPCOM boundedcost results Values average runtime seconds C PTS DFBnB AWA AWA AWA A 07 08 09 320 000 310 000 300 000 290 000 280 000 1194 1117 1138 1391 2713 7229 727 735 751 972 1850 4389 556 562 569 758 1528 4118 408 422 424 580 1155 2729 329 347 336 438 796 1750 known effective depth solution known advance KPPCOM k size searched group 6162 This conﬁrmed KPPCOM experiments previous work 52 DFBnB effective domains depth search tree varies cycles The relative performance AWA 15puzzle previous work ARA showed 8puzzle domain 22 ARA parametric algorithms We experimented range parameters results best performing parameter settings performed better domains14 Both ARA varies domains Our experiments showed AWA outperformed ARA AWA Table 2 displays results 15puzzle domain Results domain traditionally shown terms nodes expanded avoid comparing implementation details Therefore addition comparing runtime algorithm measured number nodes expanded The number nodes expanded given Table 2 percentage optimal solution Runtime shown nodes expanded respect number nodes expanded A table brackets measured milliseconds The best performing algorithm cost bound marked bold Results clearly drastic reduction size searched state space yielding substantial speedup trying ﬁnd optimal solution For example PTS ﬁnd solution cost bound 70 expanding average 5 nodes expanded A ﬁnd optimal solution In addition PTS performs best vast majority cost bounds PTS performs relatively cost bounds best performing algorithm We large impact w parameter w 3 performed 9 times worse performance AWA AWA w 2 This emphasizes robustness PTS require parameter For example cost bound 65 AWA Due implementation details perfect correlation number nodes expanded al gorithm runtime runtime allocate memory required data structures algorithm initialization processes Nonetheless similar trends noted seen runtime values brackets Table 2 Deeper inspection results shows lowest cost bound 55 PTS outperformed AWA w 15 The average cost optimal solution 15puzzle instances experimented 52 This suggests PTS like effective cost bounds close optimal solution cost In cases conservative A tuned ﬁnd optimal solution We w close beneﬁcial A behavior exhibited AWA observed similar trend domains experimented Next consider results KPPCOM shown Table 3 Values runtime seconds solution cost bound C Similar trends observed domain PTS performs best cost bounds w parameter greatly inﬂuences performance AWA The differences performance PTS AWA 07 DFBnB relatively small domain This DFBnB 07 known eﬃcient domain 52 Hence PTS substantially improve DFBnB As AWA behaves like uniform cost search bestﬁrst search consider case w reaches zero In case AWA g evaluate nodes In MAX problems nonnegative edge costs case KPPCOM uniform cost search 14 For results algorithms httpgoldbergberkeleyeduanaANAtechReportv7pdf 16 R Stern et al Artiﬁcial Intelligence 214 2014 125 Table 4 Robot arm boundedcost results Values average runtime seconds 6 DoF Robot Arm Cost bounds b 20 DoF Robot Arm Cost bounds C PTS ARA 61 2764 647 63 36 95 65 31 61 67 18 61 69 14 31 C PTS ARA 80 101 40 82 84 21 85 16 21 88 8 21 Table 5 Gridworld planning results Values average runtime seconds 100 1200 unit edge costs C PTS ARA 1050 48 4780 1055 45 4780 b 5000 5000 obstacles C PTS ARA 4400 150 3620 4410 140 2010 4430 139 182 4450 068 138 c 5000 5000 obstacles C PTS ARA 2550 15630 129500 2600 4878 8955 2700 0496 5476 2800 0265 4649 2900 0093 3384 1060 37 81 4470 059 138 3000 0072 3167 Table 6 Multiple sequence alignment results Values average runtime seconds C PTS ARA 1585 1087 7894 1590 690 7361 1595 264 6353 1600 74 4274 1605 07 1869 1610 01 00 behaves like DFBnB Thus decreasing w zero results AWA converging DFBnB w 0 This explains similar performance AWA 07 DFBnB behaving like DFBnB eventually Results robot arm gridworld planning multiple sequence alignment domains shown Tables 4 5 6 respectively PTSs favorable behavior viewed domains For example 100 1200 gridworld planning domain PTS orders magnitude faster ARA cost bound 1050 Following boundedcost results shown conclude PTS outperforms best performing anytime search algorithm cost bounds entire range domains Furthermore PTS exhibits robust performance parameter tuning required 521 The effect w MAX problems The KPPCOM results highlight interesting question w parameter affect performance AWA KPPCOM experiments w 07 lowest w MAX problems The best performing instance AWA experimented Thus think decreasing w equivalent effect increasing w MIN problems Indeed decreasing w w 1 MAX problems similar increasing w w 1 MIN problems making admissible heuristic informed search eﬃcient In limit decreasing w MAX problems increasing w MIN problems completely different effects As mentioned MAX problems setting w 0 results AWA behaving like pure heuristic search Pure heuristic search expected ﬁnd solutions fast low quality15 uniform cost search ignores heuristic completely expected slower search uses heuristic Exploring effect w MAX problems left future work behaving like uniform cost search For MIN problems w results AWA 53 Anytime experiments Next present experimental results evaluate performance APTSANA range domains scribed Section 51 In experiment ran APTSANA bestperforming anytime search algorithms different domain recorded suboptimality incumbent solution function runtime In following ﬁgures ARA w 0 X w 0 initial value w ARA X denote ARA Section 23 15 This general guideline 6 deeper study effect w MIN problems needed 39 R Stern et al Artiﬁcial Intelligence 214 2014 125 17 Fig 6 Anytime experiments robot arm domain Time xaxis seconds Fig 7 instances algorithm best lowest cost solution domain clear APTSANA First consider results 6 DoF robot arm experiments shown Fig 6a The yaxis shows reported suboptimality 1 corresponds solution optimal The xaxis shows runtime seconds The beneﬁts dominates algorithms search Although APTSANA visible ﬁgure report APTSANA Next consider performance APTSANA APTSANA better quality However rapid convergence APTSANA suboptimality clear domain demonstrating anytime behavior APTSANA domain APTSANA 20 DoF robot arm experiments shown Fig 6b In domain able ﬁnd solutions optimal solution consistent decrease As 6 DoF experiments best performing algorithm For weights time ranges ARA initial solution faster ARA initial solution faster algorithms The robot arm results single representative instance We experimented set randomly generated 6 DoF 20 DoF robot arm instances 20 instances showing general similar trends As aggre respect algorithms analyzed gated view showing relative anytime performance APTSANA effective algorithm search This measured counting algorithm A millisecond t number problem instance incumbent solution A running t milliseconds smaller equal incumbent solution algorithms running t milliseconds This measures number instances algorithm A best algorithm halted t milliseconds Fig 7 shows results analysis xaxis runtime milliseconds yaxis number instances best performing algorithm best For 20 DoF left 6 DoF right results clearly APTSANA algorithm search majority problem instances The results MSA domain shown Fig 8 APTSANA 6 DoF robot arm dominates largest number steps algorithms search For robot arm MSA experiments APTSANA decrease lower suboptimality Correspondingly time solution improvements smaller For example MSA experiments APTSANA spent average 18 s solution improvements best run ARA 18 R Stern et al Artiﬁcial Intelligence 214 2014 125 Fig 8 MSA 5 sequences Time xaxis seconds Fig 9 100 1200 unit edge cost obstacles Time xaxis seconds took 200 s average ﬁnd better solution As discussed Section 4 intuitively desirable property anytime algorithm Next consider results gridworld domain given Figs 9 10 For 100 1200 grid unit edge cost experiments Fig 9 5000 5000 grid random edge cost experiments Fig 10a APTSANA dominates algorithms search However results 5000 5000 domain obstacles Fig 10b w 0 500 returned solutions lower cost solutions different behavior 30 seconds runtime ARA returned APTS While shown ﬁgure report APTSANA required additional 193 s ﬁnd solution cost ARA Note performance ARA varied greatly value w 0 domains experimented For 5000 5000 gridworld obstacles w 0 30 best w 0 value tested 5000 5000 gridworld obstacles w 0 500 best w 0 value The challenge tuning w 0 ARA especially evident 100 1200 gridworld experiment seen Fig 9 The disparity ARA results different values w 0 illustrates nonlinear relationship w 0 ARA s performance This emphasizes setting value nontrivial higher lower w 0 value necessarily guarantee better worse performance Thus problem instances ARA beneﬁt depending parameter parameter settings outperforms APTSANA APTSANA Next consider results KPPCOM domain seen Fig 11a The yaxis denotes suboptimality incumbent solution function computation time shown xaxis Since KPPCOM MAX problem suboptimality starts close zero converges optimal solution instance R Stern et al Artiﬁcial Intelligence 214 2014 125 19 Fig 10 Anytime experiments 5000 5000 gridworld Time xaxis seconds Fig 11 Anytime experiments KPPCOM 15puzzle domains The results Fig 11a clearly domain APTSANA performs consistently worse better algorithms As discussed Section 52 DFBnB known highly effective domain 52 Indeed results APTSANA runtime 5 seconds DFBnB identical slight advantage APTSANA Negative results APTSANA obtained 15puzzle domain shown Fig 11b Running APTSANA tuned w value w 2 This explained Section 4 APTSANA yielded runs pure worse results AWA heuristic search ﬁnds initial solution In domains including described results ﬁnding initial solution fast With proper tiebreaking case 15puzzle domain The quality wastes signiﬁcant time improving solutions initial solution poor Thus APTSANA high suboptimality converges optimal solution By contrast initial solution AWA w 2 AWA 20 Fig 11b suboptimality 2 relatively easily domain As partial remedy problem tried ﬁrst running WA different weights giving APTSANA variant performed initial solution continues run usual Results APTSANA best performing anytime search algorithm domain To summarize domains 15puzzle APTSANA competitive cases signiﬁcantly bet improves ter existing anytime search algorithms 1 APTSANA incumbent solution faster 3 APTSANA converges faster solutions higher quality Moreover domains experimented performance existing parametric anytime search algo ﬁnds initial solution faster 2 APTSANA 20 R Stern et al Artiﬁcial Intelligence 214 2014 125 rithms greatly affected parameter values By contrast APTSANA manages outperform existing anytime algorithms require parameters set 6 Generalized Potential Search GPTS In Section 3 presented PTS algorithm showed linearrelative assumption PTS expands node highest potential Theorem 1 In section generalize PTS cases assumption hold We resulting algorithm General Potential Search GPTS search algorithm expands node highest potential GPTS implemented BFS evaluation function orders nodes according potential denoted earlier paper P ThC We evaluation function Potential Ordering Function POF Deﬁnition 3 Potential Ordering Function POF A function F called Potential Ordering Function POF pair nodes n1 n2 F n1 F n2 iff P T hC n1 P T hC n2 Of course P ThC trivial POF Calculating PThC nontrivial Next propose practical POFs wide range domains require calculating PThC node This suggests applicability GPTS As preliminary provide rigorous deﬁnition potential given Deﬁnition 2 Let S searched state space let D probability distribution nodes S S denotes random variable corresponding S X hS Y probability X state S randomly drawn according distribution D We denote Prh cost lowest cost path goal random state S heuristic value Y The potential node n deﬁned probability random state S h value node n path goal cost lower C gn We deﬁne formally Deﬁnition 4 Potential Given heuristic function h cost bound C deﬁne potential node n denoted PThC n cid2 PThC n Pr gn h S C cid3 cid4 cid3 hS hn The potential node deﬁned depends relation h h We formalize htoh relation introducing notion heuristic model hmodel short An hmodel heuristic function function captures probabilistic relation heuristic lowest cost path goal estimates Deﬁnition 5 hModel A function e said hmodel heuristic function h hvalue v heuristic function h cid3 cid3 hS v value K state state space cid4 cid2 Pr ev K cid2 h Pr S K cid4 Domains linearrelative assumption described Section 3 simply domains hmodel ev X v X random independent identically distributed iid variable Correspondingly type hmodel linearrelative hmodel Using notation Lemma 1 given Section 3 states PTS evaluation function Cgn hn POF linearrelative hmodel Next POFs hmodels 61 Additive hmodel Consider following hmodel ev v X X iid random variable This imply distri bution X uniform additive error node taken distribution independently We hmodel additive hmodel16 If distribution X known nontrivial POF required potential easily calculated gn h cid2 PThC n Pr S C cid2 S C gn Pr h cid2 cid4 hn X C gn Pr cid2 cid4 X C gn hn Pr cid3 cid4 cid3 hS hn cid3 cid4 cid3 hS hn 16 This reminiscent bounded constant absolute error model described Pearl 35 difference h h h n hn K Here K largest value X bounded constant R Stern et al Artiﬁcial Intelligence 214 2014 125 21 For example special case X constant K potential node simple binary function cid7 PThC n 1 gn hn K C 0 If distribution X known directly computing PThC impossible Next distribution X unknown possible POF Corollary 1 presents theoretical POF applies given hmodel Corollary 1 F C n Prehn C gn POF Proof For pair nodes n1 n2 PThC n1 P ThC n2 S C S C gn1 cid2 gn1 h Pr cid2 h Pr cid2 cid2 cid4 hn1 Pr e F C n1 F C n2 cid4 C gn1 cid3 cid4 cid3 hS hn1 cid3 cid4 cid3 hS hn1 cid2 Pr e cid2 Pr cid2 Pr h cid2 cid4 hn2 gn2 h S C S C gn2 cid4 C gn2 Deﬁnition 5 cid3 cid4 cid3 hS hn2 cid3 cid4 cid3 hS hn2 Proving reverse direction straightforward F C POF cid2 Using POF given Corollary 1 requires calculating F C n Prehn C gn For additive hmodel F C n depends X ehn hn X Theorem 3 provides applicable POF depend X Theorem 3 If hmodel additive f n gn hn POF cid2 cid4 hn1 Proof For pair nodes n1 n2 P ThC n1 P ThC n2 cid2 cid2 cid2 cid4 cid4 Corollary 1 Pr C gn1 hn2 e e Pr cid2 cid2 cid4 cid4 hn2 X C gn2 Pr hn1 X C gn1 Pr cid2 cid2 cid4 cid4 X C gn2 hn2 Pr X C gn1 hn1 Pr C gn1 hn1 C gn2 hn2 f n1 gn1 hn1 gn2 hn2 f n2 cid4 C gn2 X iid additive hmodel The reverse direction straightforward cid2 A direct result Theorem 3 additive hmodel GPTS A expand nodes order 62 General hmodel Consider general case hmodel ev algebraic combination v random iid variable X We overload function e algebraic combination write ev ev X Note model generalizes previously discussed hmodels Let er inverse function e erev v X We denote hmodel invertible inverse function er exists Theorem 4 shows hmodel invertible er monotonic P genn erC gn hn POF Theorem 4 For iid random variable X invertible hmodel ev ev X er monotonic P gen POF cid2 Pr e cid2 Pr e cid2 Pr cid2 cid4 C gn1 cid4 cid2 cid4 hn1 cid2 hn1 X cid2 Proof For pair nodes n1 n2 P ThC n1 P ThC n2 according Corollary 1 cid2 cid2 cid4 Pr hn2 e cid2 cid2 cid4 cid4 Pr C gn1 C gn2 hn2 X e cid2 Pr C gn1 hn1 C gn2 hn2 X er X er cid2 cid4 cid4 C gn2 hn1 C gn1 hn1 er P genn1 P genn2 cid2 cid12 cid4 hn e hmodel invertible cid4 C gn2 cid4 X iid er monotone cid2 hn X er e cid4cid4 cid4cid4 cid4cid13 cid2 cid13 cid12 The reverse direction straightforward cid2 22 R Stern et al Artiﬁcial Intelligence 214 2014 125 Table 7 h models corresponding functions hmodel ev v X additive v X linear relative v X er ev v ev v ev v logv ev P genn er C gn hn C gn hn Cgn hn loghnC gn Notice Lemma 1 Theorem 3 special cases Theorem 4 Table 7 presents examples Theorem 4 obtain corresponding POFs hmodels The exact hmodel domain heuristic dependent Analyzing heuristic given domain identifying hmodel analytically domains explicit knowledge domain Another option identify ing hmodel add preprocessing stage set problem instances solved optimally hmodel discovered curve ﬁtting methods In experiments linearrelative hmodel suﬃciently accurate saw justiﬁcation complex hmodels This option given cases theoretically exist 7 Conclusions future work This paper discussed search problems boundedcost search anytime search In boundedcost search solution cost lower given cost search halt In anytime search search continues returning better better solutions search halted user optimal solution Both types problems important applications paper presents PTS APTSANA solve We showed eﬃcient boundedcost search algorithm easily converted eﬃcient anytime search algo rithm This running boundedcost search algorithm iteratively giving boundedcost search algorithm lower cost bound iteration An attractive property resulting algorithm need parameter tuning contrast common anytime search algorithms The relation boundedcost anytime search problems emphasizes need eﬃcient boundedcost search algorithm In paper propose algorithm called PTS PTS bestﬁrst search expands nodes order potential probability node lead solution cost bound The relation given heuristic optimal cost develop cost function order nodes OPEN approximately according potential actually calculating Both PTS corresponding anytime algorithm APTSANA outperform competitive algorithms wide range domains 71 BEES BEEPS AEES incorporating distance estimates The heuristic h estimates minimum cost reaching goal Recent work shown domains nonunit edge cost h correlated number actions needed reach goal 39 In cases prior work shown beneﬁcial incorporate search algorithm additional heuristic estimates minimum actions needed reaching goal 46 Such distance heuristic commonly denoted d online learned inadmissible heuristic ˆh new suboptimal search algorithm called EES 20 new anytime search algorithm called AEES 63 new boundedcost search algorithm called BEES 40 BEES shown outperform PTS domains nonunit edge costs including Zenotravel Elevators domains International Planning Competition IPC solved domain independent planner Follow work showed IPC benchmarks nonunit edge cost PTS outperformed pure heuristic search 34 Similar results appear comparing AEES APTSANA 63 However PTS competitive BEES domains unit edge costs See results Tiles domain 15puzzle 40 Tinybot domain 34 unit edgecost domains experimented with17 When PTS good BEES probably prefer PTS implementing simpler BEES requires maintaining open lists online learning improved heuristic PTS simple bestﬁrst search algorithm easy compute evaluation function Similar reasoning applies comparing APTSANA AEES This emphasizes need PTS consider d domains nonunit edge cost A ﬁrst attempt BEEPS algorithm 63 equivalent BEES PTS evaluation function nodes OPEN estimated bound Empirically combination BEES PTS performed exactly like BEES Thus incorporating d PTS effective manner open challenge A possible direction n For example apply machine considering explicitly probabilistic relation hn dn h learning techniques learn relation past experience 17 Further experimental results domainindependent planning domains unit edgecost needed provide conclusive statement performance PTS domainindependent planning R Stern et al Artiﬁcial Intelligence 214 2014 125 23 Fig 12 Optimal solution vs heuristic KPPCOM blocksworld domains 72 Expected search effort instead potential PTS aims expanding node highest probability lead solution bound The task boundedcost search ﬁnd solution fast possible Thus consider expected effort ﬁnding solution probability solution exists Estimating search effort search effort prediction formulas algorithms 6466 Future work investigate incorporate estimates addition potential node For example node close goal preferred node slightly higher potential farther goal This paper combines results research groups independently discovered APTSANA One group derived anytime search algorithm APTS studying boundedcost search problems 78 The research group derived ANA motivated desire avoid parameter tuning 9 Both groups papers review simultaneously subsequently published 2011 We thank Wheeler Ruml pointing relationship Acknowledgements This research supported Israel Science Foundation ISF grant number 41713 Ariel Felner This work supported Goldberg van den Berg US National Science Foundation Award IIS1227536 We thank Maxim Likhachev making implementation ARA Our implementation ANA freely available Searchbased Planning Library SBPL httpwwwsbplnet available publishing code ANA Appendix A Domains hmodels In appendix hmodels domains heuristics These models obtained optimally solving set problem instances Then backtracked goal start node path plotted h value versus heuristic value according selected heuristic A1 Key Player Problem Communication KPPCOM Fig 12a shows htoh relation 100 KPPCOM problem instances See Section 512 details domain heuristic Each problem instance graph randomly generated according BarabásiAlbert model 54 choice type graphs motivated Section 51 having 700 nodes density factor 3 The dashed black line Fig 12a linear ﬁt data As seen slight curve logarithmic model ﬁt nicely However linear ﬁt simpler accurate A2 Blocks world Next analyzed htoh relation blocks world domain wellknown planning domains We Fast Downward planner 67 admissible LMcut heuristic 68 Fig 12b shows htoh relation blocks world problem instances International Planning Competition 06 publicly available Fast Downward software suite Again dashed black line linear ﬁt data As seen heuristic domain exhibits clear linear relative hmodel 24 References R Stern et al Artiﬁcial Intelligence 214 2014 125 1 PE Hart NJ Nilsson B Raphael A formal basis heuristic determination minimum cost paths IEEE Trans Syst Sci Cybern SSC4 2 1968 100107 2 RE Korf Depthﬁrst iterativedeepening optimal admissible tree search Artif Intell 27 1 1985 97109 3 M Helmert G Röger How good perfect AAAI 2008 pp 944949 4 S Zilberstein Using anytime algorithms intelligent systems AI Mag 17 3 1996 7383 5 RA Valenzano NR Sturtevant J Schaeffer K Buro A Kishimoto Simultaneously searching multiple settings alternative parameter tuning suboptimal singleagent search algorithms ICAPS 2010 pp 177184 6 M Likhachev GJ Gordon S Thrun ARA 7 R Stern R Puzis A Felner Potential search new greedy anytime heuristic search SoCS 2010 pp 119120 8 R Stern R Puzis A Felner Potential search boundedcost search algorithm ICAPS 2011 pp 234241 9 J van den Berg R Shah A Huang KY Goldberg Anytime nonparametric A provable bounds suboptimality NIPS 2003 AAAI 2011 pp 105111 anytime A 10 S Russell P Norvig Artiﬁcial Intelligence A Modern Approach 3rd edition PrenticeHall Englewood Cliffs NJ 2010 11 R Stern T Kulberis A Felner R Holte Using lookaheads optimal bestﬁrst search AAAI 2010 pp 185190 12 EW Dijkstra A note problems connexion graphs Numer Math 1 1959 269271 13 A Felner Position paper Dijkstras algorithm versus uniform cost search case Dijkstras algorithm SOCS 2011 pp 4751 14 TH Cormen CE Leiserson RL Rivest C Stein Introduction Algorithms 2nd edition The MIT Press 2001 15 RE Korf Linearspace bestﬁrst search Artif Intell 62 1 1993 4178 16 I Pohl Heuristic search viewed path ﬁnding graph Artif Intell 1 34 1970 193204 17 I Pohl The avoidance relative catastrophe heuristic competence genuine dynamic weighting computational issues heuristic problem solving IJCAI 1973 pp 1217 18 J Pearl J Kim Studies semiadmissible heuristics IEEE Trans Pattern Anal Mach Intell 4 4 1982 392400 19 JT Thayer W Ruml Faster weighted A 20 JT Thayer W Ruml Bounded suboptimal search direct approach inadmissible estimates IJCAI 2011 pp 674679 21 D Furcy S Koenig Limited discrepancy beam search IJCAI 2005 pp 125131 22 EA Hansen R Zhou Anytime heuristic search J Artif Intell Res 28 2007 267297 23 E Balas P Toth Branch bound methods EL Lawler JK Lenstra AHG Rinnooy Kan DB Shwoys Eds Traveling Salesman Problem A Guided optimistic approach bounded suboptimal search ICAPS 2008 pp 355362 Tour Combinatorial Optimization Wiley Chichester 1985 window constrained anytime heuristic search algorithm IJCAI 2007 pp 22502255 24 S Richter JT Thayer W Ruml The joy forgetting faster anytime search restarting ICAPS 2010 pp 137144 25 S Aine PP Chakrabarti R Kumar AWA 26 R Zhou EA Hansen Beamstack search integrating backtracking beam search ICAPS 2005 pp 9098 27 JT Thayer W Ruml Anytime heuristic search frameworks algorithms SOCS 2010 pp 121128 28 R Taig RI Brafman Compiling conformant probabilistic planning problems classical planning ICAPS 2013 pp 197205 29 A Stern I Dagan A conﬁdence model syntacticallymotivated entailment proofs RANLP 2011 pp 455462 30 A Stern R Stern I Dagan A Felner Eﬃcient search transformationbased inference ACL 2012 pp 283291 31 A Zanarini G Pesant Solution counting algorithms constraintcentered search heuristics Constraints 14 2009 392413 32 P Haslum H Geffner Heuristic planning time resources European Conference Planning ECP vol 1 2001 pp 121132 33 H Nakhost J Hoffmann M Müller Improving local search resourceconstrained planning SOCS 2010 pp 8182 34 P Haslum Heuristics boundedcost search ICAPS 2013 pp 312316 35 J Pearl Heuristics Intelligent Search Strategies Computer Problem Solving AddisonWesley Pub Co Inc Reading MA 1984 36 A Felner RE Korf S Hanan Additive pattern database heuristics J Artif Intell Res 22 2004 279318 37 U Sarkar P Chakrabarti S Ghose S De Sarkar Reducing reexpansions iterativedeepening search controlling cutoff bounds Artif Intell 50 2 1991 207221 38 E Burns W Ruml Iterativedeepening search online tree size prediction LION 2012 pp 115 39 CM Wilt W Ruml When weighted A 40 JT Thayer R Stern W Ruml A Felner Faster boundedcost search inadmissible estimates ICAPS 2012 pp 270278 41 M Boullé A parameterfree classiﬁcation method large scale learning J Mach Learn Res 10 2009 13671385 42 GR Harik FG Lobo A parameterless genetic algorithm GECCO vol 99 1999 pp 258267 43 A Foss OR Zaïane A parameterless method eﬃciently discovering clusters arbitrary shape large datasets International Conference fail SOCS 2012 pp 137144 Data Mining ICDM IEEE 2002 pp 179186 44 AJ Dionne JT Thayer W Ruml Deadlineaware search online measures behavior SOCS 2011 pp 3946 45 W Ruml MB Do Bestﬁrst utilityguided search IJCAI 2007 pp 23782384 46 JT Thayer W Ruml Using distance estimates heuristic search ICAPS 2009 pp 382385 47 WE Story Notes 15 puzzle Am J Math 2 4 1879 397404 48 RC Holte A Felner J Newton R Meshulam D Furcy Maximizing multiple pattern databases speeds heuristic search Artif Intell 170 1617 2006 11231136 49 U Zahavi A Felner RC Holte J Schaeffer Duality permutation state spaces dual search algorithm Artif Intell 172 45 2008 514540 50 MG Everett SP Borgatti The centrality groups classes J Math Sociol 23 3 1999 181201 51 LC Freeman A set measures centrality based betweenness Sociometry 40 1 1977 3541 52 R Puzis Y Elovici S Dolev Finding prominent group complex networks AI Commun 20 4 2007 287296 53 S Dolev Y Elovici R Puzis P Zilberman Incremental deployment network monitors based group betweenness centrality Inf Process Lett 109 20 2009 11721176 54 AL Barabási R Albert Emergence scaling random networks Science 286 5439 1999 509512 55 DJ Lipman SF Altschul JD Kececioglu A tool multiple sequence alignment Proc Natl Acad Sci USA 86 12 1989 44124415 56 T Ikeda H Imai Enhanced A algorithms multiple alignments optimal alignments sequences kopt approximate alignments large cases Theor Comput Sci 210 2 1999 341374 57 AS Konagurthu PJ Stuckey Optimal sumofpairs multiple sequence alignment incremental Carrillo Lipman bounds J Comput Biol 13 3 2006 668685 58 T Yoshizumi T Miura T Ishida A 59 T Ikeda H Imai Fast A 60 H Kobayashi H Imai Improvement A 61 W Zhang RE Korf Performance linearspace search algorithms Artif Intell 79 2 1995 241292 62 W Zhang Depthﬁrst branchandbound versus local search case study AAAIIAAI 2000 pp 930935 algorithms multiple sequence alignment Workshop Genome Informatics 1994 pp 9099 partial expansion large branching factor problems AAAI 2000 pp 923929 algorithm multiple sequence alignment Genome Informatics Series 1998 pp 120130 R Stern et al Artiﬁcial Intelligence 214 2014 125 25 63 JT Thayer J Benton M Helmert Better parameterfree anytime search minimizing time solutions SOCS 2012 pp 120128 64 LHS Lelis S Zilles RC Holte Predicting size IDA 65 L Lelis R Stern A Felner S Zilles RC Holte Predicting optimal solution cost bidirectional stratiﬁed sampling ICAPS 2012 pp 155163 66 RE Korf M Reid S Edelkamp Time complexity iterativedeepeningA 67 M Helmert The fast downward planning J Artif Intell Res 26 2006 191246 68 M Helmert C Domshlak Landmarks critical paths abstractions whats difference ICAPS 2009 pp 162169 s search tree Artif Intell 196 2013 5376 Artif Intell 129 12 2001 199218