ELSEVIER Artificial Intelligence 92 1997 169227 Artificial Intelligence Map learning uninterpreted sensors effecters David Pierce Benjamin J Kuipers Department Computer Sciences University Texas Austin Taylor Hall Austin TX 78712 USA Received March 1996 revised October 1996 Abstract This paper presents set methods learning agent learn sequence increasingly abstract powerful interfaces control robot sensorimotor apparatus environment initially unknown The result learning rich hierarchical model robots world sensorimotor apparatus environment The learning methods rely generic properties robots world almosteverywhere smooth effects motor control signals sensory features At lowest level hierarchy learning agent analyzes effects motor control signals order define new set control signals robots degrees freedom It uses generateandtest approach define sensory features capture important aspects environment It uses linear regression learn models characterize contextdependent effects control signals learned features It uses models define highlevel control laws finding following paths defined constraints learned features The agent abstracts control laws interact continuous environment finite set actions implement discrete state transitions At point agent abstracted robots continuous world finitestate world use existing methods learn structure The learning agents methods evaluated simulated robots different sensorimotor systems environments 1997 Elsevier Science BV Keywords Spatial semantic hierarchy Map learning Cognitive maps Feature leaming Abstract interfaces Action models Changes representation Corresponding This work taken place Qualitative Reasoning Group Artificial author Email kuiperscsutexasedu University Texas Austin Research Qualitative Reasoning Group IRI9216584 Research Program grant 003658242 IRI9504138 Intelligence Laboratory The NSF grants NASA grants NCC 2760 NAG 2994 Texas Advanced supported 2 Email dmpiercecsutexasedu 00043702971700 PIISOOO4370296000513 1997 El sevier Science BV All rights reserved 170 D Pierce BJ KuipersArtijkial Intelligence 92 1997 169227 1 Introduction Suppose unknown environment creature emerges sufficient clarify environment knowledge support learning process sensors sensing effecters effecting How creature learn nature environment learn sensors effecters capabilities What primitive idealized This problem embodies knowledge designed programmed effecters appropriate goals robot A real biological evolution sensorimotor environment We idealize problem learning agent little domainspecific number scientific value allowing newlydesigned We report variations general problem goals results research A real robot engineers select sensors demands faced individual apply In addition practical value instance problem learning methods learning agent considerable robot learn properties sensorimotor knowledge ability range possible solutions solves specific embodies knowledge begin explore domainindependent sophisticated laws appropriate organism implement idealized matches capabilities organism acquired learning control agent Henceforth distinction learning learning agent agent robot The learn apparatus machine uninterpreted meaning simulated apparatus physical robot comprised set sensors effecters use The robots sensorimotor The sensorimotor agent learning use robot priori knowledge meaning sensors structure sensory effects motors control signals From learning raw sense vector s apparatus agents perspective raw motor control vector u The current values sensors The vector real numbers called control signals produced learning agent sent robots motor apparatus The agents situation learning represented vector real numbers giving sensorimotor illustrated Fig 1 This paper solves learning problem presenting set methods learning agent use learn 1 model robots set sensors 2 model robots motor apparatus 3 set behaviors allow learning agent abstract world discrete world places paths robots continuous simulated mobile robot ring These methods demonstrated distance These sensors learning methods comprise agent priori They incorporate control based particular structure dimensionality body knowledge given knowledge basic mathematics multivariate theory The learning methods domain independent set sensors effecters assumptions robots environment learning analysis In rest paper number learning methods robots world agent develops understanding learning D Pierce BJ KuipersArtijicial Inrelligence 92 1997 169227 171 Sensory input Control I 2 0 I Fig I The learning problem addressed illustrated interface learning agent teleoperated learn model robot environment initial knowledge meanings sensors effects control signals robot unknown environment The learning agents problem changes control signals zero paper defining learning agents problem solution given sequence increasingly powerful abstract interfaces robot The Problem Given A robot uninterpreted almosteverywhere approximately linear sensori motor apparatus Learn Descriptions continuous static environment structure robots sensorimotor apparatus environ ment abstract interface robot suitable prediction navigation Solution Representation A hierarchical model At hierarchy models robots sensorimotor abstraction robots environment apparatus At hierarchy egocentric discrete defined set discrete views actions objects learning Method A sequence statistical generateandtest methods hierarchical model An almosteverywhere approximately linear sensorimotor apparatus satisfies fol functions realvalued motor control vector A continuous world time sensor values approximated includes state represented vector state variables A discrete world hand rep robot longitude lowing The derivatives respect linear robot environment x continuous resented finite set states The primary example continuous world latitude facing A static world state change result nonzero motor control vector A static world exhibits inertia When motor controls zero stop In static world active agents robot comes pedestrians position orientation paper 3 mobile state variables robot immediate direction Experiments robots described connection particular learning methods 172 D Pierce BJ KuipersArtcinl Intelligence 92 1997 169227 world The learning efficiently refers ability agents goal understand These definitions apply perfectly learn model prediction navigation Prediction refers ability predict effects learning agents world discovered invented learning agent level global structure world People understand visual learning based suitable motor control signals Navigation place places exist priorithey The raw sense vector raw motor control vectors wrong abstraction world scenes agent use abstractions raw sense vector needs world The hierarchy 1618201 features behaviors Understanding accompanying descriptions spatial semantic hierarchy requires hierarchy features behaviors called use abstractions continuous world predictions understand Instead trying terms sequences visual places objects learn highlevel describing agent uses imagesthey In order learning 11 The spatial semantic hierarchy The spatial semantic hierarchy SSH hierarchical structure substantial body larger knowledge largescale spatial structure environment showing cognitive map built sensorimotor commonsense interaction world The cognitive map body knowledge Largescale significantly constructed environment problem sensory obtained successful changes sensory horizon agent meaning time agent solution agent means map travels cognitive mapping sensors focus learning solution The result subtle important integrating Since SSHbased features control strategies necessary robot ring distance cognitive mapping4 SSH approach simulated time revealed observations support required topological sensorimotor levels level abstract metrical At sensorimotor The spatial semantic hierarchy comprised causal robot defined raw sense vector set primitive actions freedom robot Section 3 set learned action models learned control vectors features Local state variables learned behaviors pathfollowing set local state variables homing behaviors cuusul abstracted view set currently level sense vectors abstracted finite set actions control interface degree level effects motor homing robot defined behaviors At interface gives current finite set views behaviors Section 7 The abstract Section 5 The abstract features At control contextdependent pathfollowing defined predict applicable order interface actions The contribution paper This papers work complementary levels descriptive ontology engineered learning agent learning structure environment set methods learning work Kuipers Byun levels 18191 hand focus The agent 4 The important change use local state variables Section 4 D Pierce BJ KuipersArtiial Intelligence 92 1997 169227 173 control topological laws fixed set form control levels At topological selected appropriate abstracted ambiguities representation level topological map supplemented distances directions information level level perceptual states map view resolved global worlds structure finitestate graph learned At metrical metrical multiple metrical By showing learn paper lays groundwork semantic hierarchy domainindependent levels spatial semantic hierarchy building learning agent learn entire spatial knowledge 12 Overview apparatus set behaviors Sections 2 7 sequence methods learning model robots sensorimotor abstract robots continuous world discrete world places paths Fig 30 summarizes entire set representations described learning methods resulting behaviors allow learning agent rest paper method learning Section 2 describes representing set robust model structure robots sensory apparatus Section 3 describes method learning model structure robots motor apparatus Section 4 describes method learning set variables suitable robots state learning space Section 6 describes number experiments previous sections methods Finally Section 7 shows define abstract interface apparatus continuous local state robot Section 5 describes method navigation repeatable behaviors generality limitations learning described demonstrate abstracts sensorimotor addition discrete sensorimotor apparatus learning problem described instance general solution outlined These learning methods provide particular solution Section 1 This particular solution Apply generateandtest ii Try learn control algorithm produce set scalar features generated scalar features Those controlled identified local state variables iii Define homing behaviorsbehaviors local state variable target value iv Define pathfollowing behaviorsbehaviors local state variable target value presented The set learning methods final word problem learning Instead sequence steps Future work involve improving identifying path goal Clearly alternate paths solution use uninterpreted sensorimotor ways instantiate paper represent apparatus current set methods robot keeping The learning methods experimental section describes learning method method source information method applied simulated robot results interleaved representations paper objects produced method demonstrations 174 D Pierce BJ KuipersArtQicinl Intelligence 92 1997 169227 13 Contributions The results research following ii iii learning agent solve nontrivial demonstration learning problem identification robot support learning agent identification enable useful cognitive maps complex environments set learning methods intermediate domainspecific unique plausible learning agent instance set primitive capabilities representations knowledge learning methods interesting These source information available motor apparatus second provides method learning way interacting robots environment agent new way understanding experimentation uninterpreted exploiting robots sensory information sensori input new right First identifies result work The beginning result support conditions learning end idealized existence proof demonstrating important learning problem We hope path work establish minimal sets primitives necessary success limits heterogeneous bootstrapping method inference As intended methods learning method laws specific generality capabilities required set features control experiments The type robot environments learned type environment robot We results First needed low inference methods nature robot degree dependence add primitive choice robot environment level symbolic neuralnet mechanisms 5 Second attempted explicit environment temporal spatial continuity sensory key steps learning method empirically sensorimotor paper Naturally limited systems different environments generality able inputs 6 Third tested generality robot remains These results shown establish means feature generators require almosteverywhere independent plausible different assumptions For example implement minimize applying In spite limitations existence proof believe important demonstrated ing methods trol 391 constructed laws Only shows heterogeneous deep hierarchy sensory learning methods construct previous similarly deep concept hierarchies Second AM First approach set learn features knowledge 22 5 We follow restriction implementation sophisticated method called principal component principal component analysis implemented h Real sonar sensors satisfy neural network requirement specular analysis 151 feature For example use fairly identification method However 291 reflection property sonar sensors makes difficult use systems engineered hand D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 175 hierarchy shows foundational grounded continuous sensorimotor domain symbolic commonsense interaction continuous tained knowledge world 2 Learning model sensory apparatus The learning agents step learn model robots step set groups related sensors The source information apparatus layout ratus The output learning method sensory physical sequence choosing motor control vectors ing method robots demonstrates values produced robots sensors randomly The rest section describes method different sensory appa learned model sensors description step agent wanders learn simulated 21 A simulated robot define The robot For concreteness nearest object room dimensions The 21st element 24 directions These maximum learning methods illustrated particular robot en 6 meters vironment The robots world simulated rectangular 4 meters The room number walls obstacles modeled point The robot 29 sensors Each sensors value lies 00 1 O Collectively raw sense vector s input robot learning agent The 24 elements raw sense vector distances nearest objects numbered clockwise value 02 The 25th element slowly compass The element value 1 corresponds robot motor apparatus left treads Moving backward motion moving Moving learning agent knows control vector elements Its motor control signals a0 tell fast right treads speed produces pure forward speed produces pure rotation treads different circular arc The robot agent know sensors effecters The learning robots raw sense vector 29 elements raw motor batterys voltage decreases initial value 10 The 26th 29th elements comprise digital E N W S sensor noise The robot tankstyle value 10 meter away The sonars defective returns opposition speeds causes sensor giving direction nearly facing There 22 A language features learning agent develops The learning current value ues robots raw sense vector The type feature robots sensory apparatus paper time function history current past val determined type new features A feature completely understanding defined determined 176 D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 value feature vector image element focused constructs The group feature paper following value point vector The types features functions time vector group matrix scalar field image jield vector field element Scalar vector matrix dard mathematical Section 23 The image imageelement focusedimage element vector The ator rule features scalar image vector features based stan defined Section 24 The vectorfield Section 32 Examples features raw sense features agent produces new features feature generators A feature gener creates new feature set features based existing elements raw sense vector Section 411 The vectorfield defined feature type vector feature features vector features defined defined learning feature scalar 23 Discovering related sensory subgroups A sensory apparatus contain structured array similar sensors Examples video camera agent uses groupfeature generator arrays similar sensors A group feature vector feature X array arrays ring distance sensors array photoreceptors array touch sensors The learning recognize elements xi related similar sensors way correspond sensors generator array sensors The groupfeature based following engineered typically varies continuously sensor position robot nearby objects array behave similarly Two sensors said behave similarly observation Given measure property following holds Sensors physically close ring distance distance sensors time tend similar 1 sensors values instant 2 sensors frequency distributions similar Given scalar feature X frequency distribution gives n subintervals variable assumes value subinterval variables domain dist x nelement vector percentage time Corresponding criteria distance metrics examples matrix features groupfeature l The metric dl based principle generator sensors generally similar values The metric matrix feature continuous world adjacent vector feature x defined dlit Here dlij t distance variable r time index ranging 0 t sensors xi Xj measured time t The l The second metric d2 based observation sensors homogeneous array similar sensors distinguished frequency distributions For example array binary array photoreceptors touch fact D Pierce BJ KuipersArti_iicial Intelligence 92 1997 169227 177 dl 4 Fig 2 Two measures dissimilarity feature robot wandered dlij dzij minutes The coordinates ith jth elements raw sensory j indices types sensors radically different different touch sensors assume value 0 1 photoreceptors value continuous intervals absolute differences range dzij proportional frequency elements j frequency distributions Binary assume sum distribution subintervals frequency distributions frequency distributions use 50 subintervals im uniformly distributed In 1 ranges plementation range ll computes distance metrics period minutes strategy choose random repeat 7 The values 5 minutes robot second robot explored 10 time steps following agent moves This generator learning motor control vector execute distance metrics dl d2 example 3000 observations The groupfeature 1 formation subgroups sensors given Fig 2 generator exploits similar according distance distance metrics steps 2 metrics taking related sensors transitive closure similarity relation form closed subgroups Formation subgroups similar sensors step The groupfeature subgroups similar according similar distance metric dk generators sensors Elements use distance metrics dk form M j j similar written 7 Our experiments shown strategy effective efficiently exploring large subset robots state space choosing motor control vectors randomly time step 178 D Pierce BJ KuipersArtzial Intelligence 92 1997 169227 z j iff Vk zk j j requires use threshold One way define threshold robust use constant The definition q proven Eki 2 ydkrj Each element neighbors Elements dkri kj constraints threshold based minimum distance j considered similar dkij ki vice versa Combining j close perspective gives k j dkj Idki lkj Formation closed subgroups generators The groupfeature second step relatedto relation N Consider transitive closure ring tend sensors relation produce sensors Adjacent similar according similarity distance metric sensors opposite detect information In spite fact entire array distance This similarity relation M Two elements x j exists element k N k k N j sides ring dissimilar distinct uncorrelated relatedto relation N transitive accomplished defining sensors grouped j related written according regions environment distance dl closure N j j iff N j V 3k N k A k N j The relatedto equivalence straightforward described relation N clearly relation Computing group feature s reflexive symmetric relation N j given transitive relation x 4 An equivalence class relation N singleton For example robot raw sensory feature 29 elements defective batteryvoltage In order sensor digital compass The distance metric 3000 steps For elements raw sensory computed robot wanders set feature sensors 24 distance fourelement randomly similar elements j M j computed shown 0 1 2 3 23 0 1 2 22 23 0 1 2 3 4 1 2 3 4 5 2 3 4 5 6 3 4 5 6 7 4 5 6 7 5 6 7 8 9 7 8 9 10 7 8 9 10 11 8 9 10 11 12 9 10 11 12 13 13 14 15 16 17 10 11 12 13 14 14 15 16 17 18 20 19 21 22 23 11 12 13 14 15 15 16 17 18 19 12 13 14 15 16 16 17 18 19 17 18 19 21 0 1 21 22 23 0 21 22 23 26 27 28 24 25 Notice distance sensors grouped sensors For example element 0 The relatedto similarity group 0 1 2 22 23 contains relation N obtained taking relation described following equivalence classes groups neighboring elements transitive closure D Pierce BJ KuipersArtcinl Intelligence 92 1997 169227 179 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 21 22 23 20 defective 24 battery voltage 25 east 26 north 27 west 28 south The distance sensors sensors grouped group containing 24 A structural model sensory apparatus generator represents subgroups array This accomplished step tells structure group sensors An image The grouping sensors imagefeature relative positions sensors rule takes group feature associates generator The imagefeature order produce image position vector element group feature feature function time completely determined current past values raw time sense vector value given list scalar associated position vector image elements An image element vector n real numbers continuous space An example use image feature photoreceptors intensities The imagefeature elements captures metric dt This means image equal di Expressed mathematically structure array sensors reflected distance distance positions distance metric positions elements elements according image feature y satisfy hitting task assignment image An image pattern light represents represent ordered ndimensional camera position generator feature I PO8 Yi Pas Yj I diij pos yi position vector associated ith element 11 pos yi pos yj 11 Euclidean distance elements Finding set positions satisfying equation image positions ith jth constraintsatisfaction If group feature x n elements problem constraints Specifying parameters placed x axis 2 xy plane Thus metric dl provides n n 12 requires n n 1 2 placed origin 1 second placed n 1 positions n points n 1 dimensions n position vectors dimension 0 point constraints satisfy The metric represented symmetric matrix zeros diagonal Such matrix nn 1 2 free parameters 180 D Pierce BJ KuipersArtificial Intelligence 92 1997 169227 required Solving technique called metric scaling remains The problem 151 9 position vectors given distance constraints n points dimension large n In general sensory arrays I 2 3dimensional smallest number dimensions use objects method given constraints excessive error error given n 1 inconvenient finding meaningless What needed equation needed satisfy E lpOSy POSYjII dij lJ dimensions according contribution Metric scaling helps ordering minimizing Ignoring error term dimension yields rough description sensory array large error element position onedimensional vectors array zero error contains called scree diagram accounted dimensions The imagefeature m m maximizes variance The set twodimensional shown sensors data accounted Fig 3b Fig 3a shows dimension object Using n 1 dimensions lot useless information subjectively variance choose number dimensions a2 m m 1 um Statisticians yields description use graph data right number equal For example m 2 group distance mth dimension positions metric scaling generator chooses expression The set n 1dimensional positions position vectors optimally describes structure projected subspace lower dimensionaiity group resulting description n 1 dimensions To compensate smalldimension relaxation algorithm adjusted slightly The process continues iteration lo The relaxation vector positions dimensions relaxation global minimum group distance relaxation algorithm longer optimal Elements generally close twodimensional right distance apart projection best set positions n 1 dimensions The given distances space approximate iterative process On iteration position vector direction reduces value error term E defined error small ceases decrease appreciably algorithm metric scaling simply randomly Metric scaling provides initializing It shows image feature provides starting point finds local algorithm benefits chance error function The application relaxation algorithm needed algorithm decreasing sensors illustrated Fig 3c 9 It plausible metnc scaling implemented component implement principal input matrix In See 32 p 651 description algorithm set eigenvectors analysis 29 cases main computation decomposition neural net analogous D Pierce BJ KuipersArtijcial Intelligence 92 1997 169227 181 Metric scaling eigenvalues I 1 7 35 2 0 vertical account Fig 3 Learning variance dimensions group distance produce positions relaxation defective distance structural model ring distance axis accounted dimension sensors assign positions position vectors projected dimensions The scree diagram gives elements axis shows horizontal b Metric scaling variance sensors The 22dimensional representation group distance sensors obvious shown algorithm c A relaxation algorithm set twodimensional jpi pj 11 dij The usefulness best satisfies example section Notice gap corresponding constraints sensor The element index 0 corresponds robots forward sensor To summarize imagefeature generator takes group feature x produces image feature y position vectors pi metric scaling relaxation algorithm approximately constraints satisfy IIPi PII kClxit xit1 t dimensionality keeping experiment later analyze structural description robots ring distance sensors robots motor apparatus position vectors pi small The result Fig 3 c 25 Learning sensory model roving eye The learning methods demonstrated fanciful robot called roving eye Its primary sensory array retina photoreceptors directions rotation This robot simulation small camera mounted movable platform XY plotter pointing square picture 10 centimeters The camera sees square centimeter picture time The robot 3 degrees freedom state space described state translation position variables Fig 4a The actual picture sensors replaced 5 5 retinal looking picture The motor control vector robot array forward elements backward The robots structure Fig 4b The sensory left right slide motion ring distance orientation rotate slip motion shown shown The results parallel identified seven equivalence previous classes singletons experiment The groupfeature candidate generator application 182 D Pierce BJ KuipersArlificial InteNigence 92 1997 169227 Picture I IX image Fig 4 The robot 10 centimeters wide b The picture rovingeye coast roving eye 1 centimeter wide image experiment b picture closeup view Oregon Metric scaling eigenValUeS 18 16 14 12 1 08 06 04 02 4 3 2 9 8 7 14 6 1 12 I 19 24 8 17 6 23 22 21 2 0 5 10 IS 0 LI 12345678910 b C array group photoreceptors Fig 5 The metricscaling organized twodimensional scaling photoreceptors algorithm previous c The final set positions set positions initial values scree diagram group photoreceptors indicates sensors b The 2D projection set positions produced metric grid structure array provides initial approximation relaxation produced constraintsatisfaction generator Metric scaling produces sensory array imagefeature indicating scaling assigns positions positions produced metric scaling distances resulting dimensions resulting set positions shown best modeled twodimensional element group feature Projecting mapping produces shown improved relaxation scree diagram Fig Sa object Metric positions Fig 5b The set algorithm distance metric dl The image closely match Fig 5c D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 183 3 Learning model motor apparatus Using interface learning identifies types motion learned model robots sensory robot capable producing step learn model robots motor apparatus The result learning new abstract motor apparatus motion The source information motion feature type field feature defined choosing motor control vectors wall wall I The image agents second robots tells produce type step sequence values learned Section 32 agent wanders touching facing away input terms locations sensors define spatial temporal derivatives features defined knowledge physical structure environment The learning agent uses new motion capable turning change define spatial attributes sensory image With spatial attributes motor apparatus In simulations position feature makes following possible robot possible analyze motion randomly feature steps ii iii iv v feature discretized effects vectors z decompose infinite space motor It average value finite set representative effect control vector control vector times different The agent repeatedly executes locations measures Sample space motor control vectors The robots control vectors Compute average motion vector fields amvfs representative average value resulting motion characterizes Apply principal component analysis PCA The set computed amvf s representation PCA set representative combination Identify primitive actions Each principal amvf s produced representative produces identified primitive action produce motion robots degrees freedom Dene new abstract interace For degree freedom allows agent specify signal degree freedom matched eigenvector control vector control vectors effect opposite Such motor control vector exists motor apparatus set basis set principal eigenvectors amvfs amvf s produced linear new control capable producing motion defined interface new abstract The result learning robot comprised new set control signals degree freedom robot The new interface hides robots motor apparatus details motor apparatus For example mobile uses tankstyle interface presents learned agent control signals rotating advancing These control treads synchrodrive mechanism robots motor apparatus characterize signals learned The use physical prevent robot damaging robot require provision innate obstacleavoidance behavior 184 D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 static dynamic action models rest section Sections 4 5 Steps 1 5 explained 31 Sample space motor control vectors The choice set representative motor control vectors satisfy adequately space possible eflects motor control vectors dense amvf corresponds produces effect criteria cover space possible motor control vectors represented Second motor control vector given desired effect distribution adequately robots degrees freedom amvfs suffices 1 magnitude motor apparatus respectively easy effects uniformly distributed 32 100 vectors approximately set unit motor Since assumption characterize A unit vector magnitude linear control vectors equal square root sum squares elements For threedimensional spaces motor control vectors adequate For 2D case distributed unit circle The ith n vectors value cos 2rin For 3D case set vectors uniformly unit sphere points collection electrons charged sphereeach possible These vectors representative motor control vectors sampling continuous dimension lie l target distance pair vectors space average motion vector fields This method generalizes algorithm Section 24 The vectors constrained vector far neighbors set vectors 2 The resulting unit sphere magnitude uniformly relaxation configuration analogous distributed sin 2kn larger 32 Compute average motion vector fields feature field ordered motion vectorfield A vector field feature list vector field elements A vector field element function time completely determined current past values raw sense vector value given time vectorpeld A vector vector associated position vector Given specifically vectorfield motion detected corresponding measuring image feature x motion x denotes feature elements measure local object minimum time steps motion robot A vector position subsequent image element motion object example local motion vector A list local motion vectors image element property image feature image element position second robots environment motion vector field To understand corresponding points suppose discontinuity image changes feature represents location The detection motion vectors require sophisticated object recognition It simply image feature The spatial information spatial temporal requires information provided provided positions elements D Pierce BJ KuipersArtificial Intelligence 92 1997 169227 185 information temporal time A temporal provided derivatives elements values image vectors values represented respect sequence images associated positions viewed intensity t maps image function Ep function time Such function positions iP called spatial derivative gP temporal derivative E The spatial derivative gradient increases rapidly image detected robots sensory array corresponds intensity A large gradient gives direction E vector values called imageposition coordinates intensities detectable property environment relative This motion gradient informal motivation flow point optical optical flow constraint magnitude image edge object If object moves image image large Ill defines edges detected equation EtlllppII direction EPp results intensity A point presence motion large temporal derivative This change robots sensory array vice versa Here IliPpll magnitude vector zP equal square root sum squares elements gP A problem formulation magnitude zero error undefined _lP small goal measure average motion time measurement optical Since flow precise edges general gradient Ep large calculation prone value useful weight expression term llPp112 measure v E vision applications In images represented spatial derivative point picture elements With representation spaced regularly straightforward image The images use different flow measured distance given vector positions associated feature n val X denotes arrays pixels define approximation defined regular structure approach defining sensoryflowjGld element element defined elements pas x denotes vector values associated feature x taken weighted sum local motion vectors Vii direction element j j ranges elements close element Section 23 The weight j The precise definition motion operator inversely proportional The sensory pos motion x Gf pos x vaZmoti0nx zffVijllpijl 186 D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 Fig 6 Examples average motion vector fields anzvfs associated motor control vectors lowerleft average local motion vector position position direction magnitude average shown image collections line segments represented comer picture An amvf associates represents Fig 3 Each line segment local motion vectors vij EfiIp ij 9 Ei valxi jj _ vuzxj Valxi PJ1 llPijIl 1lPij II IJpijj distance Here Ei temporal derivative intensity component Using gradient Ep element motion operator sentative motor control vector ui amvfipmotionx ud image positions element direction function element element j j Epij definition amvf associated ith repre x image feature control vector control average value argument steps ui taken Examples learning randomly time steps agent wandered learned motor apparatus u operator Section 24 II motor computes In case average value taken time Fig 6 These obtained shown choosing representative motor control vector executing 20 minutes exploration strategy second 33 Apply principal component analysis The goal step basis set space effects motor set representative motion vector fields motion apparatus D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 187 110 066 074 Ill 074 068 Fig 7 The eigenvectors space average motion vector corresponds forward robots control vectors shown sensor The robots motor apparatus translation motion standard deviations associated fields The corresponds In diagrams principal pure rotation motion second topleft element motor effects directly associated produce components vector fields produced linear combination This type decomposition performed principal introduction Oja 29 discusses neural network function Principal Component Analyzer Ritter et al 371 selforganizing maps seen generalization component variable y produces See Mardia et al 25 PCA analysis set values 131 component analysis PCA unit vectors v called eigenvectors ith principal yi In practice y approximated remaining component throwing analysis performed technique variable y The Principal orthogonal sis set y eigenvector eigenvectors component composition tion principal tell ple values Fig 7 35 important identifies set viewed ba y dot product linear combination ones away Principal called singular value standard devia standard deviations sam shown experiment eigenvector y The eigenvectors obtained purposes approximating eigenvectors computes component The relative magnitudes 34 Identify primitive actions In previous step principal component matching analysis determine basis set set eigenvectors The goal step effects This effects motor apparatus discover motor control vectors produce accomplished j angle motor control vectors The matching 0ii defined equation cos B vi amvfj vector fields vi amvfi treated simple vectors vector flattening ignoring positions local motion vectors An angle near zero indicates eigenvectors amvfs representative local motion vectors single nmdimensional jth amvf This angle n mdimensional involves computing ith eigenvector The principal eigenvector components ordered according standard deviations This means accounts variance set observed values y forth 188 D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 017 099 005 003 003 100 099 013 004 Fig 8 The principal eigenvectors correspond motor apparatus pure translation motions corresponds produce associated singular values rovingeye robot The pure rotation motion The robots effects directly motor control vectors shown eigenvector An angle near 180 degrees ith eigenvector ui opposite eigenvector action defined amvf similar similar 45 degrees collinear vector amvf assume uic M Ui df _ u Subsequently action The values z shown shown experiment Fig 8 antilinear robots motor apparatus approximated indicates amvf If amvf s match ith eigenvector motor control vector amvf motor control laws Section 5 control In case ui plus minus ui respectively defined I3 The definitions implying linear definition ith primitive rovingeye Fig 7 The analogous results 35 Dejine new abstract interface defined The goal step define new interface abstracts away details motor apparatus For robots degrees freedom new control degree freedom Negative signal robot opposite direction For robot values control left right example advancing defined following forward backward The effect control signals equation control signals turning producing motion robot signal U uP UUl 0 UI u1 primitive actions corresponding range 1 1 new control signals u principal eigenvectors 36 Discussion The learning methods described robot synchrodrive section applied simulated motor control signals directly specify fast I3 This matching anzvfs criterion restrictive appears In highdimensional space space highly unlikely random vectors define angle 45 degrees D Pierce BJ KuipersArtifcial Intelligence 92 1997 169227 189 respectively The details experiment tankstyle turn advance synchrodrive identical effects details motor apparatus providing robots degrees freedom The motor control capabilities learned signals robots demonstrate abstract 3 11 The given different motor apparatuses sensory grounded new set control signals abstracts away interface The learning methods described previous learned signals Section 5 define behaviors section The result section build sensory new abstract navigation image structure interface control 4 Local state variables The result agents learning far abstract interface includes model apparatus The model sensory apparatus represented primarily positions elements description robots sensorimotor physical structure learned actions motion image feature The model motor apparatus tells agent degrees freedom set learned primitive produce behaviors gives distance The agents ultimate goal abstract continuous world robot cognitive places viewed discrete set recognizable The cognitive map gives learning agent ability world map defined paths connecting predict places Learning robot moving behaviors repeatable state moves examples pathfollowing cognitive map requires effects highlevel behaviors navigate set recognizable behaviors state space In order useful prediction sense executing behavior given initial final state The following paragraph gives agent learn pathfollowing robot If learning agent feature feature constant feature constant correspond feature based retina robot wall robot keeping knows robot follow wall For robot retina Section 25 feature behavior simple sum inputs define pathfollowing following Moving keeping path line detector intensity A complex constant basis linefollowing compass giving value omnidirectional robot robots sensor decrease distance behavior based error signal level detected sensor nominal value sensors behavior For robot continuous behavior based compasss constant direction Finally consider robot light mounted robot suppose responding dark room white walls The light detected light middle robots heading pathfollowing nearest wall A wallfollowing difference robot photosensor range values value In section following threestep method learning pathfollowing behaviors 190 D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 1 2 3 set features variables use define error signals minimizing learn behaviors robot keeping learn behaviors learning error signals errors near zero agent control called local state This section shows learn local state variables Section 5 shows use define pathfollowing behaviors What required local state variable controllable agent know control signals affect A feature following definition controllable learning meets Definition Let ii vector control signals ui A scalar feature vi local state variable effect control signals yi approximated locally 1 mi nonzero Determining feature dependent value mi job static action model information step set learned wanders learned primitive actions local state variable context Section 42 The source features produced learning agent learning constraint analogous 0 reduces following state variables Local state variables state variable state space If y local state variable dimensionality reduces constraint access knowledge called robots state space sense If x robots j 0 reduces robots motor control vector space I4 In words learning agent local state variables access They defined robots degrees freedom Since robots state space dimensionality constraint motor control vector space local state variables required defines An important moved definition variables components feature satisfies feature local state variables target value yi simple control homing behaviors controllable feature vi law This fact exploited Section 52 The discovery local state Section 41 testing generating new features definition local state variable Section 42 41 Generating new features If sensory directly provide useful useful A generateandtest features approach tankstyle mobile robot local state variables better candidates features experiment generate following scalar features raw sense vector possible demonstrated agent learns new elements I4 If 0 Fq I ii lie subspace perpendicular vector rni D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 191 411 A set feature generators In paper identify small set feature generators local state variables Our feature generators robot rich sensorimotor transformations new features candidates tially special case functional appropriate demonstrate tuses We claim robots described ments sufficient particular set environments particular set feature generators paper sufficient robots environ produce essen 391 These feature generators appara sensorimotor necessary apparatus The generated features based set generic mathematical fields vector human list salient properties robots environment The feature generators constructs fields scalar scalars vectors matrices generated experiments l splitter l vmin vmax described paper described takes vector feature length n produces n scalar features vector features length greater apply 1 They provide different ways reduce vector feature scalar feature l group image described sensory apparatus Group image features scalar features able serve local state variables serve basis higherlevel features turn useful Section 2 identify useful structure lmax localmax features A focusedimage image features They produce field scalar field mask scalar field It viewed 0 1 The focus attention particular properties image local minima element associated weight apply feature field Boolean boolean feature l Zmin localmin focusedimage pair image weights maxima l tracker applies focusedimage pairs From features produces focused generator produces imageelement features imageelement image produced lmin gen local ab order feature form focus attention image The tracker away small changes implements value position image element tracks interesting property robots environment tracker single valueposition erator minimum stracting produce feature minimum distance 0 val extracts scalar value feature imageelement nearby object feature roving eye robot augment operators An interesting appropriate This set feature generators proven successful sensors To handle features based variety convolution masks twodimensional processing generators functional 22 We conjecture broad class mobile developing require new feature generators set generally converge reasonably robots set feature generators discovered small subset class initially new robot set feature generators robot ring distance set generators image define general set feature small general set AM sized set feature generators apply learning mobile robots analogous performance Shen transformations open problem replicate applicable eventually solutions 39 192 D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 412 Generating testing features The generateandtest following feature This feature steps continuous marked new process learning loop Initially potentially feature useful features executes raw sensory Each generator ii The features applied new feature applicable new marked old features generated marked new approaches important learning controlling concern Without constraints In generateandtest possibilities generated iteration generateandtest ways constrain search In current set limit number generations limit way population search large space number features loop grow exponentially There depth possible created A second genetic algorithms certain number This method requires fitness search algorithm One way limit generateandtest new features breadth search This method size constrained implementation algorithm vector Fig 9 The complete hierarchy features generators learning agents featurelearning process produce candidate local state variables The feature generators shown bold face feature types shown italics D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 193 tester feature search space limit tell members population defined measure measure way constrain learning problem old feature step generateandtest feature reasonably small strongly group features limited small number generators learning problem typed generators branching worthy survival Such fitness A factor For feature factor kept kept generator applies generated process The branching ways total number generators given feature apply average number new features imagefeature 413 An experiment In experiments agents described paper combinatorial devised experiment process At figure choosing unit motor control vectors executing explosion features form deep narrow hierarchies tractable issue The generators agent explores set features To study second randomly 10 time steps Fig 9 shows complete hierarchy features generators raw sense featurelearning learning sequence feature vector s We refer feature derived tr tracker generators feature Thus raw sense vector s The features produced applying shown figure left right s sg svmin svmax s1 1 s28 sgh sgvmin sgvm gimlmaxtr robots position Each generated tested Section 42 sgimlmintrval leaves tree generated multiple scalar features im image umin generator serve local state variable s features sgimlmaxtrval Notice feature results sgimlmaxtrval g group sgimlmintrval feature generator produce depending applying sgimbintr example sgimbin sgidma group sgvmin features 42 The static action model feature proceeds behavior feature The purpose static action model action predict tries predict Eq 1 Section 4 static action model learning agent primitive feature function action agent tries predict If feature local state variable simple matter variable moves l5 With information define homing behaviors target value action dependent contextdependent predictable form given set equations behavior scalar feature The learning steps In step account behavior action effect action feature serve static action model robot local state taken If fails primitive contained moving contexts taking If fails tries predict I5 One use constrained predictable results constraining given context definition definition local state variable local state variable robust control context We chosen laws feature action dependent 194 D Pierce BJ KuipersArtifciul Intelligence 92 1997 169227 Aso vs At As24 vs At Emin vs At Fig IO Plots A vertical axis versus At horizontal axis learning agent try predict behavior feature J independently Av Ar reset 0 center plot From m r yi computed From unpredictable motor control vector Whenever new motor control vector sets At Av points statistics ri Ay At shown correlations features su lmin short barge r small 4 constant learning agent concludes sgimbintrvu text The numbers statistics y 0001 r When trying predict effects actions features approximately assumption control linear relationships laws define pathfollowing relationships approximately action magnitudes behaviors linear learning agent looks feature derivatives Section 5 based 421 An actionindependent model The step modeling predict behavior explores repeatedly time steps correlator This produces function time primitive independently choosing behavior feature yi possible motor control vector The agent second set statistics based plot features value axis At t horizontal motor control vector changed The vertical axis gives behavior feature device action executing Fig 10 The coordinate time It analyzes Ayi yit yito The statistics mi ri yi The value rni slope line best fits set At Ayi points The value ri correlation variables Ayi At The value yi ratio standard deviations Ayi At It measure fast feature changes yi 0001 It increasing defined properties holds ri 06 decreasing Otherwise behavior unpredictable feature actiondependent model terms statistics The feature constant function time A number properties learning agent tries predict It predictable ri 06 use local state variables The rest candidates features svmin svmax 20 broken distance sensor constant sgvmux diagnosed step For running example battery voltage 24 suitable learning static action model 422 An actiondependent model If previous yi learning step failed produce model agent uses correlator predicts primitive behavior feature analyze action D fierce BJ KuipersArtificial InfelliRence 92 1997 169227 195 As0 vs uoAt As0 vs uAt Almin vs uoAt Almin vs ulAt Fig possible unpredictable constant Il Plots A versus UjAr features primitive actions These sg behavior feature function motor control vector Feature predict action r small y large predictable action 1 r large Feature bin action UQ y 0001 unpredictable action UI r small y large relationship selecting primitive actions executing In case correlator characterizes statistics mij slope line effect feature UiAt Ayi At Ayi defined The agent continues randomly computes points Yii correlation deviations uiAt Ayi A feature yi yi4 The properties Ui defined For predictable form explore second time It best fits set UjAt Ayi UjAt Ayi yj ratio standard signal u constant control signal predictable signal pair rule labeled increasing decreasing featurecontrol control Jji iTIijl_lj added actions For static action model If feature predictable primitive feature predictable example running primitive action ug rotating Fig 1 l distance features SO 1 2 3 23 increase sensors The effect 141 advancing features sg 14 Its effect features SJsg s15s19 21 22 The discrete compass sensors 1 The features sgvmin 1 Feature primitive actions One defined ug In fact lmax rapidly small unpredictable decrease unpredictable 25 s2s unpredictable sgimlmintrvu1 sgimlmaxtrval guess robot constant lmax constant fluctuates lmin constant lmax uo unpredictable uo constant diagnosed corner unpredictable aka aka turns 423 A contextdependent model If u effect yi unpredictable partition sensory space discrete set contexts relationship approximated local state variable yi control signal Ui integervalued context l6 In general context feature linear equation feature takes Zj learning agent tries I6 This approach analogous Dreschers marginal attribution 17 I 196 D Pierce BJ KuipersArtlial Intelligence 92 1997 169227 finite set values This set defines partition robots state space finite set contexts defined predicates Zi k One way define context feature finite set intervals choose feature x divide defined Zk zii k iff x E Ik Using value x good predictor effect control signal nj feature yi TO test hypothesis 2ij k effect uj yi correlator Ujs effect y1 context defined predicate range values context The context feature x define set contexts x good predictor interval defines appropriate determine feature large set features improve predictability signals effect features expensive Heuristics use defining contexts For example guide makes sense search sense closely related feature analyzed tree features produced generateandtest Testing control relevant look features close process implemented Currently heuristic use position element feature based value element image feature context Since discrete set contexts For trivial example 23 possible positions break sensory space partition 23 contexts defined predicate 2ij k zi integer feature value 0 22 identifies discrete set possible positions space possible positions case fmin lmax features position associated local minimum maximum image imageelement define break For context zij k correlator try predict effect ui yi given computing robot context The agent continues yjk The properties statistics mijk rk explore consfanf randomly increasing decreasing form predictable defined For predictable context rule j z mijk Uj t zij k added constant primitive predictable action static action model If milk 0 predicate context useful actions effect feature defining pathfollowing predictable context behaviors zj k defines If feature For running example features associated context features lmin tmax constant lmin predictable The effect u lmin predictable lmin contexts O5 1922 increase 6 18 Fig 12 The effect lmax unpredictable The effect ut decrease contexts 816 The effect unpredictable robots heading control signal 0 context Its effect decrease contexts 717 For contexts lmin constant wall parallel context lmax contexts O5 2022 increase contexts 6 7 17 18 D Pierce BJ KuipersArtificial Intelligence 92 1997 169227 197 0985 Y A kO I 0996 k12 Fig 12 Example plots Aji versus UJ At sgimlmintrval possible current context For action III feature 12 respectively feature different contexts These behavior feature function motor control vector lmin decreasing constant increasing contexts 0 6 predict feature actiondependent predictable At point local state variable k current value context local minimum generator This generator minimum robots neighborhood range Zmin Its behavior modeled equation pi rniikut location ln produced trucker lmin features local feature The number local state variables depends corner single wall input location There local state variables image feature The feature actually produces multiple feature zii represents neighborhood Tintersection image 5 Learning control laws The goal step learn suitable set homing pathfollowing behaviors set local state variables step learned static action results preceding set primitive actions Recall local state variables lmin features learning model robot running experiment identified controllable Section 42 dynamic action model agent The sources information features Section 532 specifically sections A behavior term paper object components function signals The upp component currently called output upp init The output component vector motor control indicates 0 indicating applicable The signal behavior behavior finished The init signal input signal tells behavior state information case internal returns scalar function value applicable The value feature behavior 100 behavior behavior 1 indicating certainty needs reset applicable number tells applicable Boolean initialize indicating function Pathfollowing 1 continuous 2 behaviors 3 behaviors learned steps behaviors error signals defined minimizing moving keeping learned learned error signals error signals near zero 198 D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 51 DeJining error signals control laws The learning navigation uses path error signal near involves agents approach exploration mapping robot moves maintaining right corridor behavior based error signal following behaviors zero An example pathfollowing person walking corridor The error signal e y y y distance y constant person corridor depends person mood number people If error The error signal positive negative moves straight path end control path ends corridor place time person follows person moves wall walking law efficient repeatable right The control follows efficient left away law moving law person corridor control Britain left In example y local state variable The agents approach defining path define error signals form e y y local following behaviors state variable y I7 52 Learning homing behaviors The purpose homing behavior error signal behaviors based error signal applicable While pathfollowing possible ior given error signal The homing behavior independent model control law use reinforcementlearning methods 2433 relevant defined Fig 13 drawing zero learn homing behav learning instance generic domain static action knowledge rule form ii miikuj For local state variable yi control signal ui homing behavior includes error close error e y yi It applicable reducing static action model definition characterize The components possible context k Fig 13 A homing behavior Fig 14 robot illustrated effects ui yi This partition homing behavior zero Its output mijk nonzero given simple control defined context zii k It law The described set contexts k mobile agent learns app output defined based partition sensory space static action model 53 Learning pathfollowing behaviors The previous section presented method learning homing behaviors given error signal In section method presented minimize moving minimizing Choosing learning agent chooses value equal half features maximum value target value JJ feature y optimal scope paper The implemented D Pierce BJ KuipersArtijicial intelligence 92 1997 169227 199 For exh context zii Ic Lijk WJJ e W2 s e dt feature zij The applicability defined goal vi The applicability local state variable primitive action Fig 13 A homing behavior output defined functions current context defined achieve context rijk Uj j magnitude 1 O minimum value zero correlation magnitude 05 law parameters 5 I O w 005 12 1 The output minimizes close zero The init function resets value integral error zero difference vi y The behavior maximum value 10 correlation given proportionalintegral difference PI control j Fig 14 An example homing behavior apparatus The agents static action mode1 predicts value local state variable applicable e1 y FZ y context 1 c This information mobile robot distance sensors tankstyle motor second primitive action U decreases context definition homing behavior error b uses primitive action u robot minimize error signal The result steps involves behavior 1 learning necessary 2 learning defined minimum pathfollowing behavior Learning pathfollowing general direction feedback error correction keeps error near zero avoid straying path error signal The learning agent uses static action model determine primitive action use provide motion path It learns dynamic action model tell use remaining provide error correction primitive actions 200 D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 531 Learning openloop pathfollowing behaviors The static action model agent information behaviors error correction agent define closed define openloop pathfollowing lacks error correction loop pathfollowing formation behavior static action model action uj effect local state variable yi local state variable yi primitive turn useful defining pathfollowing useful For behaviors t8 An openloop pathfollowing learning action model behaviors error correction Re identifies constant contexts ZQ k primitive dynamic context defined direction motion The constant action uj zi1 k openloop behaviors outputs given behaviors uup c UC 6 learning uj 1 ug 1 The ug components dynamic action model The purpose openloop pathfollowing allow agent learn effects orthogonal control signals feature motor control use control signals vector t9 With knowledge error correction The definition openloop pathfollowing summarized Fig 15 A behavior behavior applicable current behavior start new robot strays far path new agent choice continue possible behaviors indicating behavior turning example For mobile robot running behavior based u It applicable yi y according effect yi There advancing facing parallel value 6 18 Fig 20b learning robots environment openloop pathfollowing local state variable yi Fig 16a turning behavior based u robot feature zij shows trace behavior robot results feature y Fig 16b It applicable object detected yi agent uses learned openloop pathfollowing openloop pathfollowing static action model context explore behaviors 532 The dynamic action model The static action model predicts contextdependent effects control signal local state variables The dynamic action model predicts contextdependent effects control signals local state variables openloop pathfollowing behavior executed The dynamic action model tells openloop pathfollowing orthogonal base action local state variable action primitive action pathfollowing effect behaviors definition pathfollowing behavior control I In closedloop minimizes I9 The primitive actions orthogonal Section 33 error law error signal feedback determine motor control vector sense amvfs orthogonal D Pierce BJ KuipersArtciul Inrellience 92 1997 169227 201 app Iv Yil YT output uusu Ji 01 A zzj k Iv Yil 04 Y V new behavior applicable behavior ufi maintains vi constant according defined local state variable vi primitive opposite constant context zj k The predicate zij k defines constant context applicable Fig 15 An openloop pathfollowing action implies small orthogonal 3 seconds Only uss nonzero time The behavior large new behavior applicable error signal I vi small The output components learning dynamic action model orthogonal component changes static action model The behavior base motor control vector error signal component During b J J applicable vi jf changes Fig 16 Two examples openloop pathfollowing constraint based primitive action u1 advancing parallel robots heading r y I near zero behaviors A behavior based u turning value yi b A behavior constraint Y applicable jr I error context ut keeps wall left zj 18 dynamic action model exploration behavior chooses applicable homing openloop pathfollowing longer applicable regression actions features yi context running behavior based feature yi motor control vector UP fuj regressors linear learn new pathfollowing relationships behaviors behavior openloop path context test hypotheses mjjkluj error signal To learn runs applicable Linear behaviors randomly A behavior orthogonal following Zij k While Yi mijkszUs computing lrjkat 06 rule running correlations rijk 8 yi If rijks rijkS2 1 ji mijkstua 2ij k A u d U 1 202 D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 OOOll 00012 0 13 Ol 01602 relationships measured linear regressors dynamic plots values j k 6 n n number learning illustrating Fig 17 Plots action model The labels derivative y openloop pathfollowing instances produced tracker generator The second itr yi respectively openloop 741 6 This context robot heading parallel pathfollowing tested The plots effect U advancing 0 ij respectively behavior based u executed Here 0 local state variables plots effect u turning context behavior based U executed wall right added dynamic action model Otherwise Irs2 06 rule Yi mijk82 zij k A II zj U action model Otherwise relationship ug yi dynamic added zero unpredictable mobile Suppose 2o robot running experiment wall left tc signals changes parallel distance pathfollowing wall Fig mijk 0 Therefore wall vi constant effects control I6 b In context primitive action heading advancing maintains behavior based u1 yi applicable While executing openloop In behavior ji rnit2uc This example uc affects wall direction turning wall advances determines Examples linear regressors learn dynamic action model robot action running effect y openloop behaviors based model u predictable behaviors based uO effect U executing For openloop pathfollowing U vi unpredictable second derivative feature relative robots direction motion ug diagnosed fast robot moves Fig 1721 According example illustrated away dynamic 533 Learning closedloop pathfollowing behaviors The final step openloop learning pathfollowing pathfollowing behaviors behaviors add error correction order define closedloop pathfollowing 2o For dynamic action model Informally Together necessary consider second derivatives features ttij thjsus rule fact Uj constant product ji thjnj v tijuj rnjsusuj mijs2us affect derivative Wrj equation pathfollowing The linear regressors operate filtered versions 1 nj remove noise hide relationship signals The signals filtered moving average taken seconds behavior D Pierce BJ KuipersArticial Intelligence 92 1997 169227 203 Fig 18 Defining closedloop add error correction behavior pathfollowing openloop pathfollowing In example small turning motion behaviors The learning agent uses dynamic action model behavior order obtain closedloop pathfollowing robot path advances primitive action U leaves feature y distance receives uses modify case environment feedback motor control signals agent knows static action facing parallel robot learning behaviors A closedloop behavior form error signal minimize error Consider wall left In context model constant Moreover signal ua turning sufficient wall Fig 18 Because error correction pathfollowing small perturbations wall If yi goes agent knows increase robust behavior define closedloop pathfollowing taken Together wall approximately agent knows dynamic action model control affects yi u robot robot gets close turn right shown control signal 0 apparatus action models value ua implemented shape wall inaccuracies face noise target value robustly moves sensorimotor information behavior template behavior defined generic A closedloop pathfollowing Fig 19 constraint y y primitive action opposite uj constant context z k The predicate z k z vector context features zii zj E z k vector context values ki defines constant context ki E k Zi ki defines constant context static action model The variable vector context k The behavior near target values y z y z k indicating model predicts behavior agent choiceto choose new For example lijkarl correlation u6 yj motor control applicable elements y static action motor control vector UP keeps error vector y y near zero The new pathfollowing continue behavior current pathfollowing set pathfollowing y WI according contains behaviors behavior applicable behaviors indicating robot place following walls For behavior based u1 advancing turning predictable effect orthogonal primitive action u local state variables error correction For behaviors based u turning error correction effect U unpredictable 22 learning agent The implemented learn contextdependent effect U predictable control law dynamic action model openloop pathfollowing static action model An extension In way behavior learns contextdependent action error correction contextdependent 204 D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 app z vyj E y IYiYil Yi 01 A vzj E z Zij ki output c 7j u6 Jj 3yi E y IYi Yil 04 Yt V new behavior applicable vhere c 2 YEY 2cw ei mijk61 cd2 mijk62 W2 mijkdl s ei dt ei 2cw mijk62 ei 0 Yt Yi IL U Ui ei bijml hj1 06 hjk621 hjkdll 06 vector target values u fi fuj behavior Here y vector local state variables v y Fig 19 Definition closedloop pathfollowing z corresponding vector vector context context values k The equation static action model The values nijksa rijksjr taken dynamic action model Simple PI PD proportionalderivative primary effect j y respectively Again 5 I O w 005 2 I depending primitive actions opposites local state variable y k corresponding maintains y constant according features Zi z k defines context controllers 1 t b simple world randomly Fig 20 Exploring applicable learning model sensorimotor dynamic homing openloop pathfollowing action model c The robot explores randomly choosing applicable homing closedloop pathfollowing behaviors based dynamic action model apparatus behaviors based static action model learning b The robot explores randomly The robot wanders levels competence choosing D Pierce BJ KuipersArrijicial Intelligence 92 1997 169227 205 Fig 20 shows behavior robot different stages agent behaviors Section 6 demonstrates learning pathfollowing behaviors rectangular environment learns set containing Tshaped environment section basis exploration In Section 7 pathfollowing mapping agent develop discrete abstraction robots continuous set pathfollowing homing number behaviors strategy world obstacles learned allows 6 Additional experiments sensorimotor sections demonstrated The previous learn agent use hierarchy The purpose section addition els described methods limitations previous control sections set learning methods levels spatial number experiments demonstrate learning semantic generality lev control learning sensorimotor The learning methods demonstrated mobile robot cluttered learned model sensorimotor environment model learned controllevel control level demonstrates room apparatus applies learning agent learning set learned path level ap agent demonstrate environment learning control learning learned room demonstrates learned pathfollowing demonstrate particular environment new Tshaped relearns behaviors Finally particular Then yond transferred erased Here following plies transferred behaviors Sections 64 65 failed explain generator methods imagefeature structure ring distance learning ways ways experiments failed Section 64 describes fails produce ringshaped learning learning methods fail Finally Section 67 identifies number learning methods improved agent fails discover local state variables Section 66 summarizes sensors Section 65 describes experiment experiment representation 61 A cluttered room The environment experiment rectangular room dimensions meters meters containing lated mobile robot tion 21 rectangular obstacles section described Fig 23 The simu Sec 61 I Modeling sensory apparatus The step modeling robots sensory apparatus apply groupfeature generator The learning agent computes distance metrics dl d2 wandering 20 minutes Their values qualitatively Fig 2 The group shown similar 206 D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 _i 069 0731 073 069 Fig 21 Example amvf s associated motor control vectors clutteredroom experiment feature generator modeling learning wandering qualitatively identifies robots sensory apparatus groups Section 23 The second step generator The apply imagefeature agent computes distance metric dt group 23 related sensors 40 minutes 23 The outputs metric scaling relaxation algorithm similar shown Fig 3 612 Modeling motor apparatus The step modeling robots motor apparatus characterize ef learning time steps The eigenvectors fects large set representative motor control vectors In experiment chosen Eight exam 100 representative motor control vectors unit magnitude Fig 21 These ple amvfs associated motor control vectors shown choos repeatedly 60 minutes obtained agent wandered second ing representative motor control vector random executing analy component produced principal pure rotation motion sis shown motor control vec second tors None eigenvectors match amvfs Notice actions analysis primitive dom closely match robots motor apparatus actions Fig 7 The result degree free translation motion The shown principal Fig 22 The corresponds eigenvectors primitive degrees freedom pure actions identified produce motion shown primitive corresponds identified long wandering periods robot adequately explores room shorter periods group imagefeature 23 We use fairly tered rectangular converged See Section 67 discussion converged improved feature generators state space For unclut generators quickly detect automatically D Pierce BJ KuipersArtifcial Intelligence 92 1997 169227 207 140 110 027 022 1 u 0706 0707 ul 0728 0683 Fig 22 The eigenvectors primitive actions clutteredroom experiment behaviors When behavior robot learning applicable agent randomly randomly middle The learning agent begins homing behavior taken Fig 23 The path pathfollowing robot initially obstacle pathfollowing results homing behaviors behavior The diagonal robot wall path learned homing selects selects primitive actions The long comers trajectories 613 Learning behaviors As described Section 4 learning agent local state variables identifies generated set localminimum features sgimlmintrval features identified action dependent predictable The learned static dynamic action models qualitatively turning Sections 4 5 In use openloop It uses information trace random behaviors pathfollowing experiment primitive action behavior based second learning agent discovers error correction executing advancing define closedloop pathfollowing exploration behavior demonstrating learning similar learned primitive action behaviors Fig 23 shows learned agents 62 Relearning behaviors Tshaped room For experiment robot moved Tshaped environment static action model dynamic action model learned behaviors erased Its task begin apparatus learn appropriate set homing intact model robots sensorimotor cluttered learning agents controllevel learning room 208 D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 Fig 24 Releaming behaviors Tshaped room Pathfollowing behaviors based advancing primitive action produce straightline trajectories parallel walls Pathfollowing behaviors based turning primitive action leave robot place changing robots heading The homing behaviors based advancing action produce rest trajectories shown picture A trajectories produced random wandering behavior behaviors applicable The learning agent selects behaviors stochastically occasionally selects random wandering behavior behaviors applicable behaviors The environment pathfollowing corridors long 15 meters wide The shorter corridor wide form T The corridor connected experiment forming consists T 6 meters long 15 meters 45 meters The learning agent successfully learns openloop behaviors Fig 24 shows trace random exploration learned behaviors This experiment model sensorimotor applicable demonstrates second environment apparatus closedloop pathfollowing behavior demonstrating set features learned environment 63 Using behaviors room room For experiment robot moved Tshaped environment rectangular robots sensorimotor Fig 25 shows random exploration behavior demonstrating apply 6 meters 4 meters The learning agents model apparatus set learned behaviors left intact learned behaviors learned environment dimensions 64 A long narrow room This experiment demonstrates produce ringshaped The environment meters representation experiment instance imagefeature generator structure ring distance sensors room The room long narrow rectangular confuse long half meter wide This environment designed D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 209 Fig 25 Using learned homing pathfollowing behaviors room imagefeature opposite sides ring similar long walls room sensor opposite opposite On hand sensor returns large value good chance sensor opposite generator Since room narrow values distance sensors wall 05 detects distance room Both sensors produce small value return large value If sensor detects distance If opposite sensors return similar values average imagefeature place image feature capture close image feature It unlikely ring structure array distance sensors generator case The outputs metric scaling relaxation The distance sensors algorithm scree diagram left structure 641 Modeling sensory apparatus The result groupfeature generator best captured fourdimensional points metricscaling grouped shown Fig 26 According array sensors arrangement points approximates distance metric dl The middle set points generated metricscaling shows results relaxation ring sensors close algorithm 24 Notice image 2s fewer dimensions distance corresponding figure shows projection dimensions algorithm The figure right adjacent sensors representationthere distance sensors measured 642 Modeling motor apparatus eigenvectors The principal shown Fig 27 The method actually identifies space average motion vector fields turning motor control vector 24 The metricscaling algorithm relaxation algorithm definition image motion features handle images arbitrary dimension However current implementation constrained image feature twodimensional A goal future research remove artificial constraint test methods sensory arrays ate genuinely threedimensional 25 Though results shown run relaxation algorithm distance metric dimensions In case resulting pattern sensors resembles pattern stitching baseball 210 D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 ytric scaling eigenvalues 18 16 14 12 1 08 06 04 02 0 12345678910 2 122 0 I6 8 II I2 ld6 IX I8 Iis 147 s4 9 8 7 21 22 23 0 I 4 3 2 6 5 O II I2 I3 I4 IS I6 17 8 I9 Fig 26 The outputs metricscaling relaxation algorithms narrowroom experiment u 0723 0680 u0532 0837 u2 0877 0481 Fig 27 The eigenvectors primitive actions narrowroom experiment correctly The second primitive action turning component The second primitive vector produces pure advancing motion The method erroneously primarily advancing identifies actions poor approximations action signifi primitive actions motor control 65 A circular room instance demonstrates This experiment cover local state variables The robots environment diameter The results learning sensorimotor set principal eigenvectors ing agent fails happened local state variables The following actions corresponding primitive discover identifies learning circular agent fails dis room meters apparatus summarized Fig 28 The learn turning advancing explains analysis primitive actions shown For feature local state variable For feature predictable possible contexts predictable feature known environments nearby objects walls identified learned learning agent represented robot rectangular localminimum environment features actiondependent effects primitive In rectangular actions Tshaped robot distances local state variables Here summary static action model D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 211 PlFlFl_C u 07460659 u 07650632 Fig 28 The eigenvectors primitive actions circularroom experiment l The primitive action effects primitive turning affect localminimum features The action predictable contexts l The effect second primitive action advancing context dependent When robot facing wall primitive action reliably decreases value localminimum feature When robot facing away wall primitive action reliably increases value localminimum feature primitive wall direction learning agents learned static described following exception When wall effect second primitive action facing parallel feature difference When straight wall robot steps changing linear regression wall significantly This possible unpredictable Here explanation facing parallel When action value feature constant circular environment robot leaves For experiment action model identical robot localminimum facing parallel distance tester analyzes good approximation robot advance steps changing conclusion learning effect advancing agent unpredictable effect primitive zero context action effect wall The regression tester able draw linear context In circular world hand distance conclude 66 Failure modes Sections 64 65 gave examples cases learn set homing exhaustive The section discusses learning methods improved learning methods described list ways pathfollowing learning agent failed behaviors This section provides paper fail Modeling sensory apparatus If structured array sensors small singleton groups imagefeature array sensors sensors adequately environment structure sensors For example values adjacent group image features fail produce representation sensors similar distance sensors groupfeature groupfeature generator produce generator apply If sample continuous property 212 D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 group generator adequately feature generators reflect structure sensory apparatus measured environment explore intersensor If environment applying large learning agent group image distance metrics accurately Representing motion The motionfeature generator case given priori successive meaningful motionfeature imagefeature results requires robots designer image generator apply If robots motion values unrelated feature feature fast motion feature fail produce learned image If Modeling motor apparatus process identifies primitive motor control vectors The matching identify primitive amvfs match action long values amvfs fluctuating time This possible explanation learning agent wandered amvjs converged primitive actions principal eigenvectors fail correctly Section 642 failure identify actions Generating candidate local state variables definition local state variable general In case generated The discovery local state variables fail language features feature scalar features described gen explosion In paper identified small set feature generators demon sensorimotor language features generators agent quickly bogged combinatorial features generators satisfy Section 65 On hand eral learning useless appropriate strated apparatuses robot rich sensorimotor particular apparatus set environments sufficient experiment Learning action models The learning agent fail correctly long explore linearregression case learning agent learn relationships feature large number contexts experiment motor control vector contexts method requires learn static dynamic action models calculations In motor control vector learning agent converge Learning pathfollowing behaviors The learning pathfollowing If primitive behaviors depend set learned primitive local state actions maintain actions variables constant pathfollowing behaviors learned In experiments described preceding methods means failure preceding method This observation methods interesting methods short First paper learning method builds results source failure method left unqualified right sells learning example D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 213 modeling motor apparatus applied given robots designer nature learning partially example success imagefeature generate test generator instead discovery artifact particular learned Second sensory structure sequential learning problem For result independent process general depend local state variables 67 Future work Section 66 identified number ways learning methods fail This section provides suggestions improvements learning methods Improved feature testers One way learning methods fail jumping groupfeature output generator incorrect conclusion generator uses distance metric If model actions identified amvfs converged prematurely For example distance metric converged primitive motor apparatus incorrect In examples distance metrics characterize testersfeatures lem drawing premature conclusions meaningful output value For example testers output fluctuating It providing confidence slowly changing stable amvfs examples features A solution feature prob feature tester tell output measure confidence level tester close 1 close 0 testers output addition It uses separate tester confidence level function set example static action model uses linear tester feature primitive level level interval26 confidence tester based context zero The confidence terms 90 confidence linear regression tester defined triple If robot given context input variables The smaller confidence level Associating steps listed previous interval confidence levels features chance section reducing inaccurate incomplete models For linear regression received Consider testers inputs regression action context linear regression linear regression correlation greater improve learning producing testers confidence An improved static action model learning agent uses behaviorsbehaviors The following variable constant based primitive actions according pathfollowing In current 26 See example 15 p4151 static action model implementation define set openloop path local state behaviors robot maintaining openloop pathfollowing static action model base action If primitive action maintains local state variable constant behavior Using primitive actions base actions limitation 214 D Pierce BJ KuipersArtijicid Intelligence 92 1997 169227 current improved vectors pathfollowing pathfollowing component implementation The method learning pathfollowing static action model predict primitive behaviors actions With comprehensive defined For example behaviors effects arbitrary motor control static action model room circular behavior based motor control vector large advancing small turning component improving One approach static action model discretize space set representative motor control vectors motor control vectors actions Another approach learn models instead use neural network effects arbitrary actions The network serve static action model base actions 121 learn predict contextdependent pathfollowing primitive behaviors Reinforcement learning It possible use reinforcement behaviors pathfollowing models An advantage approach model sensorimotor difficult action models train behavior time 44 large number features simultaneously apparatus learned A disadvantage learning 323364245 learn homing need primitive actions explicit action particular presume possible learn Learning composite primitive actions Consider robot capable rotating advancing oriented identifying sensors distance Section 2 succeed steps Section 3 succeed direction Section 3 currently actions translating identifying robot capable directly ring direction The learning methods structure ring sensors The direction The fourth step corresponding directions basic motions translating perpendicular translating primitive implemented fail identify extend action sequences learning primitive This suggests topic future research actions allow composite actions In example robot fixed sensor ring primitive action composed turn particular direction learn followed advance An alternate homing pathfollowing learning primitive learn model sensorimotor effect sensors behaviors directly reinforcement illustrates section learning action immediate important difficult preceding actions This example apparatus solution 7 From continuous world finitestate world The learning agent transition local state variables highlevel behaviors spatial semantic hierarchy The goal step abstract continuous sensorimotor sensorimotor raw senses motor control vectors level apparatus defining comprise finite sets discrete control apparatus D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 215 vi2 0 v8 I I b apparatus view Fig 29 A demonstration sensorimotor provides pathfollowing 1 0 The solid arrows During discrete abstract select appropriate behaviors interface discrete room At step interface homing behaviors The dotted arrows represent behaviors based left turn motor control vectors represent behaviors based forward advance motor control vectors U 1 0 figure right state finite set applicable interface We abstract 12 unique views shown drive exploration VI current robot identifies identifies actions The source information step set learned behaviors views including knowledge applicable For given state robot finite set homing pathfollowing corresponding sense vectors running terminate apparatus Exe behavior terminates behaviors These behaviors actions discrete sensorimotor cuting actions involves The set states actions mapping implemented Euclidean new new view matches previously vector mapping similar sense vector created associated If current sense vector seen associated view previous sense symbols called views In experiments sense vectors judged If current finite These states named matching predicate small constant distance homing behavior pathfollowing This interface abstracts u2 leads action executing identifies ldegreeoffreedom behavior interface Fig 29 demonstrates available minates v3 ing plicable Choosing Using 6 The robots experience schemas This knowledge chy userguided room interface current view lists interface ul Initially terminates continuous wandering behavior behavior time discrete undefined When current wandering behavior When applicable Selecting behaviors based uo turning time While pathfollowing behavior set applicable behaviors wall sensor range ter view leads applicable Select point ap behavior robot rest exploration corner southeast view returned collection x Aj Vk triples called basis causal level spatial semantic hierar 06 The figure shows eventually 12 The robot learning agent recognizes behaviors based ul view 5 At represented pathfollowing advancing returns leads leads leads exploration shown matching predicate view 4 Selecting 216 D Pierce BJ KuipersArtifcial Intelligence 92 1997 169227 8 Learning topology environment In Section 11 described control causal levels sensorimotor learning agent learned Sections 2 3 The control learned learn remaining topological spatial semantic hierarchy comprised level learned Sections 4 5 The causal level learning levels The sensorimotor metrical We demonstrated level learned levels spatial semantic hierarchy Section 7 We result agents The robots pathfollowing behaviors constrain motion onedimensional sub basis abstraction graph set nodes set edges connecting The edges correspond space robots complete state space This 1D skeleton robots environment nodes produced pathfollowing minate agent stops choose currently construct states new pathfollowing pathstrajectories graph behaviors The nodes correspond robots state space states paths ter applicable paths The agents goal behavior applicable In case views uniquely identify states problem track state seen actions applicable straightforward The state edge randomly view K Vk adds intelligently time agent keeps Each F Al V graph It continues stateaction takes action Aj explore pairs explored takes exploration idea If information In case views uniquely identify states sophisticated required Such strategies generally based following identify current state agent supplements sense vector sense vectors nearby states With area current state uniquely information traverse path With added topological information navigation record including identified representation strategy current view uniquely current surrounding Finally metrical ing time shortestpath planning taken To summarize learning possible sensorimotor continuous abstracting finite set sense values actions Understanding difficult Our learning agent demonstrates continuous world extensively problem understanding studied Section 91 apparatus agent critical change representation discrete apparatus continuous world sensorimotor way reduce problem understanding discrete world problem 9 Related work The work mentioned section deals predicting model environment A complete model environment inputoutput sufficient sensory actions partial model learned input received In cases environment complete model learning behavior environment impractical response predicting sequence case general problem learning description D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 211 Methods learning model environment types deal finitestate worlds deal continuous worlds Examples type given type given agent abstract Section 92 Our contribution learning methods robots continuous world applied Section 91 Examples second learning finitestate world finitestate divided 91 Inferring structure jinitestate worlds The task inferring structure finitestate environment task finding captures behavior automaton actions accurately NPcomplete inputoutput shown finding 19 With active finitestate behavior environ ment In case learning agent passively given examples environments smallest automaton consistent inputoutput learning behavior tively chooses tractable Kuipers TOUR model method understanding cognitive maps Dudek et al 81 generalize Kuipers Byuns discriminating topological maplearning algorithm active experimentation cal states Angluin 381 improve Angluins passively algorithm start state experiment agent ac discrete spatial worlds based theory identi received counterexamples Rivest Schapire 21 gives polynomialtime provide algorithms problem require version reset operation 18191 strategy 171 describes perceptually returning Dean et al 5 extended Rivest Schapires The key method probabilistic actions deterministic FSAs They assume states senses uncertainty washes Dean Basye Kaelbling techniques variety stochastic employs sensory partial knowledge learning method called marginal state transitions statistical effects actions automata Dreschers theory going handle stochastic output function mapping 6 good review learning 7 schema mechanism attribution Schemas emphasize representing ideal circles WeiMin Shens LIVE stochastic worlds 40 experimentation experience learning nition When experiments refine environment boundary learns structure finitestate environment discrimination concept defi positive negative examples concept His complementary hypothesized partially observable LIVE uses locally distinguishing test hypothesized properties unobserved algorithm exploits observed counterexamples A primary focus work Shen constructive learning new features At level description 1028 approach terms actual methods domains 39411 Shens similar However applicability approaches different fact complementary We focus featurelearning methods applicable 2dimensional robots continuousvalued 3dimensional approximation sensors control signals situated world We provide language features generators especially suitable structured continuous laws Shen hand focuses learning arrays sensors Our emphasis learning sensory robots features rules consisting control state variables inductionists 218 D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 conditions predictions descriptions rorure0 actions predictions expressed terms percepts highlevel expressed symbolically The conditions symbolic parameters ONdisk peg The actions continuous action continuous atomic learn The approaches combined uses methods world terms discrete states actions viewing learn relationships nonspatial knowledge doors following way learning agent apparatus It uses Shens methods expressed acquire terms states actions effects pushing objects flipping switches opening navigate continuous sensorimotor A specific example potential combination approaches discrimination learning learning contextdependent Section 423 We currently signal u predictable testing large set features use bruteforce method determining effect given feature x The method define partition state space set contexts relationship u x We expect context Shens methods generate partitions learning Shens complementary models control involves robots linear simple complementary efficiently discrimination intelligently use action 92 Inferring structure continuous worlds similar solutions physical robots Applying automaton abstraction finitestate simulation requires representation Kuipers Byun continuoustodiscrete correspond sitions These constructs manually different sensorimotor 141 engineered Lin Hanson 241 use physical discrete apparatus Mataric abstraction states local control strategies correspond learning methods 18191 demonstrate problem continuous environment engineered real world continuous discrete NX robot NXs distinctive places state tran order apply robot 26271 Kortenkamp Weymouth redesigned solution learning train robot called Ratbot 16 sonar sensors 16 learning topological map locally distinctive places demonstrate engineering corridorfollowing local control corridor infrared sensors Their work inspired work Kuipers Byun use reinforcement strategies learning27 The target behaviors following example moves specified human behavior obstacles hand teacher For robot rewarded running complementary 3032341 desirable behaviors defining appropriate learn specifies learning set local state variables error signals Homing pathfollowing Lin Hanson They specify robot reward signals letting agent hand teacher It define set target behaviors behaviors specified behaviors need human corridor rewards Our Our approach eliminating gain learning 27 The reinforcementlearning algorithm neuralnetwork version Q learning 123431 D Pierce BJ KuipersArtifkial Intelligence 92 1997 169227 219 minimize accomplished given knowledge error signals robot maintaining domainindependent mannerthe corridors corridorfollowing behaviors near zero All robot need Once learning error signals defined number ways directly define learning behaviors learned Reinforcement homing pathfollowing agent given knowledge control hom ap ing pathfollowing proach 28 The approach paper learn static dynamic action models effects actions local state variables use characterize behaviors This approach models theory require quired knowledge consists domainindependent combine approach Lin Hansons Ratbot produce learn knowledge knowledge control ing method agent neuralnet theory The error signals defined learning version Q learning learn local control strategies based error signals The control inputs derivatives motor control signals way includes integrals PI PD control laws implemented include mappings error signals uses domaindependent laws implemented laws defined It interesting set control learning agent If sensory sensory templates inputs An important agent learns given difference approach Lin Hanson feature current context level behavior effects primitive learning agent learns given current context order produce particular behavior There advantages level First learned feature action behavior feature constant signals multiple learning agent approach handles context dependence level Our learning action feature Lin Hansons action learning define multiple behaviors increase decrease action primitive Second agent learn learning features simultaneously learn behavior time homing behavior value feature maintaining primitive pathfollowing effects motor control Lin Hansons possible feature 10 Discussion 101 What value existence proof As discussed beginning strating path single path demonstrated way alternate routes Section 13 results presented existence proof demon learning problem Once end complex narrow future research broaden We progress assessing applying second applying methods learning methods significantly width solidity path robot Section 25 different variety different environments systematically 28 In earlier work explored use reinforcement learning learn homing behaviors 331 220 D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 demonstrate designed step determining learn meaningful predictable success failure methods type sensory cognitive map continuous environment Section 6 This input robot observable environment robot able comprehend The existence proof demonstrates hard interesting heterogeneous rithms While environment eliminated assumptions significant future solution combining strengths focused solution rely number assumptions Section 66 believe sensorimotor assumptions research Section 67 An irreducible minimum set scientific result learning problem learning algo 102 Why learn programmed directly sensorimotor trouble This paper shown apparatus There reasons worthwhile things learning agent learn model learn directly programmed robots designer inevitable For example random variation set distance sensor failure fails learning intervention These position direction sensors failure additional human Sensor variation failure Direct programming consideration methods accommodate methods accommodate sensors Such variation distance Generality Ideally learning algorithm sorimotor solution A deeper understanding problem domain The design learning required learning exploit comprise deeper understanding robots mass produced different process designing agent information agent exploited algorithms learning algorithms types sen particular These sources information problem domain 29 sources information replace sensorimotor generalpurpose identification development apparatuses apparatus learning applies 103 What innate goals We characterized robot innate goals concern methods developed random walk goaldirected behavior survival terms set sensors effecters learning sensory effects actions paper curiosity pain avoidance function observing environment described The Reactive behavior With goal pain avoidance learn reflexive behavior learning pursuit innate goals support learning methods described example learning agent quickly obstacle avoidance Such behavior help agent danger applies learning methods On higherlevel 29 Of course designing learning agent guaruntee deeper understanding problem domain An opaque method neural net genetic algorithm learning conceivably learn model sensorimotor apparatus teaching perception behavior map building D Pierce BJ KuipersArtijkial Intelligence 92 1997 169227 221 hand operating receive biased set experiences observations background goaldirected behavior learning agent Conversely learned methods serve foundation agent learned higherlevel sensorimotor action space larger granularity describing Fig 20 making easier achieve environment goaldirected learning primitives search higher innate goals survival environment When behaviors level curiosity 104 How general learning methods This paper identified demonstrated sensorimotor number generic methods modeling lists examples subsumes specific object method apparatus This section uninterpreted generic object method general makes fewer assumptions scalar fields require constructs example identification characterizing fields vector The learned features sensors sensing objects The method based set generic mathematical learned learning agent example defined list salient properties robots environment The method human identifying assump method assume ef based spatial temporal derivatives motion tracking objects The local terms scalars vectors matrices generated structure sensory apparatus uses generic distance metrics tions sensors measure distances fects motor control vectors objects state variables purely generic concept local minimum meaningful error signals derived example needed concept wall defining pathfollowing laws analyzing control local state variables understanding local state variables The views learning agents discrete abstract terminal robots designer laws based agent behaviors The laws The parameters relationships control signals meanings control signals interface robots designer The learned control concept distancetowall local state variablesthe states pathfollowing behaviors opposed generic control places meaningful pathfollowing implemented learned behaviors learning Related concept generality concept extensibility The current im plementation extended adding new types features feature generators For example new distance metrics groupfeature capture new ways distinguishing recognizing generators method generating types sensors local state variables general adding new feature generator different 105 Changes representation Each abstract interface agent learns provides new representation reason 222 D Pierce BJ KuipersArricial Intelligence 92 1997 169227 l At sensorimotor sensor correlations structure The learned motor capabilities level group imagefeature inter generators feature substantially analyze raw sense vector produce image set primitive actions provide new representation robots grounded sensory effects features learned primitive actions grounded l At control level behaviors egocentric Whereas time external environment homing pathfollowing behaviors grounded reflected local state variables longer purely sensory effects averaged structure level l At causal state space trajectories represented topological map continuous reduced finite set states nodes edges graph 11 Summary tenuous This paper presented sequence learning methods sufficient nitive map robots continuous world absence domaindependent robots sensorimotor object sequence apply While interesting lem investigated experimentation vides method understanding environment learning cog knowledge apparatus structure world The reader subsequent methods learning methods learning prob available pro agent new way input new way interacting robots uninterpreted information exploiting robots sensory sensorimotor learning identifies source information Each learning method true maintain right method failed particular applicable apparatus generators fact wellengineered property environment The learning methods summarized motor apparatus set primitive Fig 30 Section 2 showed learn structural model sensory array sensors sampling layout sensors similarities Section 3 showed use continuous based intersensor define motion detectors use characterize actions local state use group imagefeature apparatus They exploit almosteverywhere reconstructed structural knowledge capabilities robots degrees freedom Section 4 showed recognize variablesscalar linear functions motor control signals The effects primitive actions local state variables captured static action model Section 5 showed use static action model behaviors effects primitive actions local learn dynamic action model execute use state variables openloop pathfollowing behaviors Finally dynamic Section 7 showed discrete abstract interface finitestate world By define continuous world target abstraction features derivatives approximated define homing openloop pathfollowing learning agent abstract contextdependent use homing robust closedloop pathfoliowing finitestate action model pathfollowing allows automaton predict behaviors behaviors define D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 223 Sensorimotor Level Raw senses actions Sensory slructure Motion detection Primlive actions Control Level Homing behaviors I Openloop pathfollowing behaviors YY d L w Causal Level Fig 30 A graphical levels spatial semantic hierarchy summary learning methods paper showing objects learned learning world agent inherits powerful set methods inferring structure In biological world newly hatched organism agent However hope learning knowledge reported shed light structure learnability agents evolution development relationship learning spatial knowledge methods embodies exploration fundamental great deal like knowledge insights biological organisms The potential application direct New robots new sensors effecters designed built humans directly time Robots day sent environments mechanical robots world If provide 224 D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 experienced created robot autonomous methods presented step direction able orient deep ocean floor surface planet For newly sensorimotor experimentation substantial value We believe environment Appendix A Computational complexity summarizes This appendix complexities learning methods described potentially size raw sense vector depth tree generated reduced paper The overall complexity sequence learning methods exponential features appropriate set feature generators explained level complexity In experience drastically Section A3 AI Modeling sensory apparatus distance metric dl groupfeature generator generator Computing complexity OnT n number elements imagefeature raw sense vector T number time steps taken groupfeature generator groupfeature generator time step update groupfeature Identifying element raw sense vector 0 n computation applied Computing requires O 1 computation total complexity 0 nT n distance metric d2 On computation Using frequency distributions applied subgroups generator transitive similar closed identify iterative The relaxation dependence actual complexities complexity subgroups On3 algorithm computation iteration The metricscaling On3 involves algorithm iterative iteration On Since number iterations n unknown In experiments T greater sensorymodeling step approximated 0 nT 3o lower limits n overall closure performed computation A2 Modeling motor apparatus The calculation motion feature requires 0 n computation time step The calculation analysis algorithm overall complexity amvfs complexity 0 nT The principal complexity On3 Again T greater OnT approximated component IZ A3 Identifying local state variables The step identifying If subset current set defined features produce new set features features O2 generate new features local state variables complexity generating testing X An open problem predict value T learning method requires exploration phase D Pierce BJ KuipersArtijicial Intelligence 92 1997 169227 225 potential set feature generators collapse explosion avoided appropriate n number elements raw sense vector In experience combinatorial generators apply certain create arbitrary group features The second subsets raw sense vectorit types features For example local state variables step identifying compute input features small set output features group generator creates n nonoverlapping computation features model The complexity s number singleton time steps actionindependent The complexity c average number contexts associated feature static action OsT learned T number actions OsTuc OsTu number primitive learned The complexity computation contextdependent model actiondependent model computation model model A4 Learning control laws The number openloop pathfollowing local state variables behaviors number primitive Ouac u number c learned average number contexts associated local state variable The complexity O uacT 1 The number action model computation In practice O 22 behaviors generated behaviors upper bound number pathfollowing For example terms 2 2 replaced u3 c3 defining path following behaviors error vectors based local state variables kept reasonable dynamic pathfollowing number pathfollowing In experiments worstcase closedloop behaviors actions facts following I 2 number learned number contexts constant small relative local state variables primitive action maintains total number contexts small local state variable In example u 3 c 20 Acknowledgements The authors like thank Rick Froom Wan Yik Lee Risto Miikkulainen Ray Mooney Lyn Pierce Mark Ring Boaz Super anonymous technical editorial moral support reviewers References 1 I 1 D Angluin On complexity minimum inference regular sets Inform Control 39 1978 337350 12 1 D Angluin Learning regular sets queries counterexamples Inform Cornput 75 1987 87106 3 1 D Chapman LP Kaelbling Learning delayed reinforcement complex domain Tech Rept TR9011 Teleos Research Palo Alto CA 1990 226 D Pierce BJ KuipersArtifcial Intelligence 92 1997 169227 141 TH Cormen CE Leiserson Cambridge MA 1990 RL Rivest Introduction Algorithms MIT PressMcGrawHill ISI TL Dean D Angluin K Basye S Engelson LP Kaelbling E Kokkevis 0 Maron functions application learning map Inferring Proceedings output finite automata stochastic AAAI92 San Jose CA 1992 208214 16 I TL Dean K Basye LP Kaelbling Uncertainty graphbased map learning JH Connell S Mahadevan eds Robot Learning Kluwer Academic Publishers Boston MA 1993 171192 1 I GL Drescher MadeUp Minds A Constructivist Approach Artcial Intelligence MIT Press Cambridge MA 199 1 S G Dudek M Jenkin E Milios D Wilkes Robotic exploration graph construction IEEE Trans Robotics Automation 7 6 1991 859865 9 EM Gold Complexity automaton identification given data Inform Control 37 1978 302320 lo K Hiraki Abstraction sensorymotor features Proceedings 16th Annual Conference Cognitive Science Society Lawrence Erlbaum Associates Hillsdale NJ 1994 1 111 BKl Horn Robot Vision MIT Press Cambridge MA 1986 I 12 I MI Jordan DE Rumelhart Forward models supervised learning distal teacher Cognitive Sci 16 1992 307354 113 1 T Kohonen SelfOrganization Associative Memory Springer Berlin 2nd ed 1988 I4 J D Kortenkamp T Weymouth Topological mapping mobile robots combination sonar vision sensing Proceedings AAAI94 Seattle WA 1994 15 I WJ Krzanowski Principles Multivariate Analysis A Users Perspective Oxford Statistical Science Series 1 16J BJ Kuipers An ontological Clarendon Press Oxford 1988 hierarchy spatial knowledge Proceedings 10th International Workshop Qualitative Reasoning Physical Systems Fallen Leaf Lake CA 1996 1 171 BJ Kuipers Modeling 181 BJ Kuipers YT Byun A robust qualitative method spatial knowledge Cognitive Sci 2 1978 129153 robot spatial learning Proceedings AAAI88 St Paul MN 1988 774779 191 BJ Kuipers YT Byun A robot exploration mapping strategy based semantic hierarchy spatial representations 120 BJ Kuipers TS Levitt Navigation J Robotics Autonomous Sysrems 8 199 1 4763 mapping largescale space AI Magazine 9 2 1988 2543 121 1 BC Kuo Automutic Control Systems PrenticeHall 1221 DB Lenat On automated scientific Hayes D Michie LI Mikulich 251286 Englewood Cliffs NJ 4th ed 1982 formation A case study theory JE eds Machine Intelligence 9 Halsted Press New York 1977 AM program 123 1 LJ Lin Reinforcement learning University Pittsburgh PA 1993 24 1 LJ Lin SJ Hanson Online robots neural networks PhD Thesis Carnegie Mellon learning indoor navigation Preliminary results RatBot Proceedings NIPS93 Robot Learning Workshop 1993 125 J KV Mardia JT Kent JM Bibby Multivariate Analysis Academic Press New York 1979 26J MJ Mataric Navigating rat brain A neurobiologicallyinspired model robot spatial JA Meyer SW Wilson eds Prom Animals Animats Proceedings representation International Conference Simulation Adaptive Behavior MIT PressBradford MA 1991 169175 Books Cambridge fst 271 MJ Mataric Integration representation goaldriven behaviorbased robots IEEE Trans Robotics Automation 8 3 1992 3043 12 I28 1 CJ Matheus The need constructive LA Bimbaum GC Collins eds Proceedings Eighth International Conference Machine Learning Ithaca NY Morgan Kaufmann San Mateo CA 1991 173177 induction 29 E Oja A simplified neuron model principal component analyzer J Math Biology 15 1982 267273 30 D Pierce Learning LA GC Collins eds Proceedings Eighth International Conference Machine Learning set primitive actions uninterpreted sensorimotor apparatus Bimbaum Ithaca NY Morgan Kaufmann San Mateo CA 1991 338342 D Pierce BJ KuipersArtcial Intelligence 92 1997 169227 227 1311 D Pierce Learning IEEE International Proceedings turn travel actions uninterpreted Conference Robotics Automation Los Alamitos CA IEEE Computer Society sensorimotor apparatus 1321 I331 I341 1351 1361 1371 1381 139 140 I41 I 142 Press Silver Spring MD 1991 246251 D Pierce Map learning uninterpreted Austin 1995 hapftpcsutexasedupubqsimpapersPiercePhD95psZ D Pierce BJ Kuipers Learning hillclimbing mobile International Conference Simulation Adaptive Behavior robot JA Meyer SW Wilson eds From Animals Animatst Proceedings 1st functions strategy generating behaviors MIT PressBradford Books Cambridge sensors effecters PhD Thesis University Texas Tech Rept TR AI9 I137 AI Laboratory University Texas Austin explore build maps Proceedings AAAI94 Seattle WA Press Cambridge MA 1994 MA 1991 327336 D Pierce BJ Kuipers Learning AAAIMIT WH Press SA Teukolsky WT Vetterling BP Flannery Numerical Recipes University Press Cambridge M Ring Continual learning 1994 HJ Ritter T Martinez KJ Schulten Neural Computation reinforcement 1988 environments PhD Thesis University Texas Austin SelfOrganitinq Maps An C Cambridge Reading MA 1992 Inference finite automata homing sequences irrn Comput AddisonWesley fntroduction RL Rivest RE Schapire 103 2 1993 299347 WM Shen Functional transformations AI discovery systems Art1 Intelligence 41 1990 Learning 257272 WM Shen Autonomous WM Shen HA Simon Rule creation rule learning IJCAI89 Detroit MI 1989 675680 Proceedings RS Sutton Integrated architectures programming BW Porter RJ Mooney eds Proceedings 7th International klachine Learning Austin TX Morgan Kaufmann San Mateo CA 1990 216224 environmental Environment Freeman New York 1994 learning planning reacting based approximating exploration dynamic Conference 143 I CJCH Watkins Learning 44 1 S Whitehead delayed rewards PhD Thesis Kings College Cambridge 1989 J Karlsson J Tenenberg Learning multiple goal behavior task decomposition KIuwer Academic dynamic policy merging Publishers Boston MA 1993 4578 JH Connell S Mahadevan eds Robot Leurning 145 1 RJ Williams Reinforcementlearning connectionist systems Tech Rept NUCCS873 College Computer Science Northeastern University Boston MA 1987